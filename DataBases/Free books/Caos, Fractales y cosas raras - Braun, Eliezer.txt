Caos, Fractales y cosas raras

Autor: ELIEZER BRAUN

CAOS, FRACTALES Y COSAS RARAS

COMITÉ DE SELECCIÓN

EDICIONES

I. INTRODUCCIÓN

II. LA GEOMETRÍA EUCLIDIANA. LO QUE NOS…ENSEÑARON EN LA ESCUELA

III. EJEMPLOS DE ALGUNAS COSAS RARAS

IV. A VECES SE ESTÁ MIRANDO ALGO PERO NO SE VE…ALGUNOS CASOS HISTÓRICOS

V. LOS FRACTALES. NUEVAS DIMENSIONALIDADES

VI. MÁS SOBRE FRACTALES.

VII. CONDICIONES INICIALES Y SU IMPORTANCIA

VIII. CAOS. FENÓMENOS NO LINEALES

IX. MÁS SOBRE EL CAOS

X. ¿DETERMINISMO O INDETERMINISMO?…PREDICTIBILIDAD

XI. SIMILITUD Y CAOS

XII. ARITMÉTICA. LA SECUENCIA DE FIBONACCI

XIII. CUASICRISTALES

XIV. LEYES DE POTENCIAS. OTRA FUENTE DE SIMILITUD

XV. LA SIMILITUD EN LA MÚSICA. CÓMO USÓ BACH LAS…LEYES DE POTENCIAS DE LAS QUE JAMÁS OYÓ HABLAR

XVI. LA TURBULENCIA DE LOS FLUIDOS

XVII. ACERCA DE LOS CICLOS BIOLÓGICOS. EL CASO DEL…CORAZÓN. EL CAOS SALUDABLE

XVIII. ESTRUCTURAS BIOLÓGICAS Y RARAS. LA SABIA…EVOLUCIÓN Y LOS FRACTALES

XIX. EL DISEÑO DE ESTRUCTURA EN LA INGENIERÍA

XX. SEGURIDAD Y CATÁSTROFE

XXI. EL CAOS ORDENA LA LINGÜÍSTICA. LA LEY DE ZIPF

XXII. ECONOMÍA ¿ES POSIBLE GANAR EN LA BOLSA…DE VALORES?

XXIII. LA COMPOSICIÓN DE MAPAS. RELIEVES Y…LÍNEAS COSTERAS

XXIV. ¿DURARÁ EL SISTEMA SOLAR?

XXV. LOS ASTEROIDES

XXVI. LOS TROPIEZOS DE HIPERION

XXVII. ¿Y QUÉ OCURRE CON LOS PLANETAS?

XXVIII. COMENTARIOS FINALES

COLOFÓN

CONTRAPORTADA

COMITÉ DE SELECCIÓN

Dr. Antonio AlonsoDr. Juan Ramón de la Fuente

Dr. Jorge Flores

Dr. Leopoldo García-Colín

Dr. Tomás Garza

Dr. Gonzalo Halffter

Dr. Guilermo Haro †

Dr. Jaime Martuscelli

Dr. Héctor Nava Jaimes

Dr. Manuel Peimbert

Dr. Juan José Rivaud

Dr. Emilio Rosenblueth †

Dr. José Sarukhán

Dr. Guillermo Soberón

Coordinadora Fundadora:

Física Alejandra Jaidar †

Coordinadora:

María del Carmen Farías

D.R. © FONDO DE CULTURA ECONÓMICA Carretera Picacho-Ajusco 227; 14200 México, D.F.

HACE alrededor de 20 años se ha estado produciendo una revolución en el mundo de las ideas científicas que no ha sido conocida por el público en general. Han surgido ideas nuevas muy útiles para describir y entender la multitud de fenómenos que se da en diversas ramas del conocimiento. Nos referimos a los fractales y al caos. Como verá el lector, las aplicaciones se han dado en los campos de la física, las matemáticas, la biología, la medicina, la economía, la lingüística, por mencionar sólo algunos. Se podrá apreciar la gran amplitud de temas que es posible tratar con estos novedosos conceptos.En todos los campos del conocimiento que hemos mencionado se han dado situaciones que al ser tratadas con los procedimientos en uso no han podido ser explicadas satisfactoriamente. Sólo con el advenimiento de las ideas nuevas es que ha sido posible progresar en el conocimiento de fenómenos antes no comprendidos.

En vista de lo antes dicho, consideraremos una gran variedad de fenómenos y situaciones. El propósito del presente libro es dar una explicación somera, accesible al público no especialista, de los antecedentes de nuestro sujeto de estudio. Será necesario utilizar algunas operaciones matemáticas que no van más allá de la aritmética; sin embargo, el lector no debe espantarse ya que se le llevará de la mano en forma gradual.

El tratamiento formal de los fractales y del caos se ha convertido en una rama muy compleja de las matemáticas. Por supuesto que no entraremos en estos espinosos temas. Así, en el caso del caos no trataremos de hablar en términos del espacio fase. En este libro los conceptos detrás de estos formalismos matemáticos los trataremos de manera accesible.

En el capítulo II se repasan algunos conceptos elementales de la geometría que no son conocidos.

En los capítulos III y IV. presentamos algunos hechos raros que, a pesar de que mucha gente los había conocido, no fueron tratados adecuadamente. La posición que asumieron muchos científicos fue no hacer caso a los hechos que no se ajustaban con la forma de pensar preponderante en su época. Una vez que en 1975 Benoit Mandelbrot los consideró a fondo, se inició la era de los fractales. Estos casos ilustran una situación que ha ocurrido en la historia de la ciencia muchas veces: se tiene la evidencia de algún fenómeno, pero ésta no se ve y se soslaya su tratamiento.

En los capítulos V y VI se presenta el concepto de fractal y de similitud. La idea de fractal nos puede parecer muy extraña, máxime si empezamos a ver algunas de sus características: hay líneas con longitud y cosas semejantes. Sin embargo, esta extrañeza se debe a que nos hemos limitado mentalmente a considerar situaciones que son realmente ideales, como las figuras geométricas. En la naturaleza estas figuras son la excepción, mientras que la mayoría de las figuras que hay a nuestro alrededor son fractales. Aunque parezca increíble, ¡este hecho tan contundente no había sido considerado en serio durante muchos siglos por la humanidad!

En el capítulo VII se presenta el concepto de las condiciones iniciales, crucial en la descripción de fenómenos físicos. Este concepto lo descubrió Isaac Newton al resolver las ecuaciones que describen las leyes que llevan su nombre. Él ya se había percatado de algunos puntos finos que mencionaremos en este capítulo.

En los capítulos VIII y IX presentamos en forma muy elemental, y utilizando principalmente operaciones aritméticas tales como sumas, restas y multiplicaciones, el concepto de caos. Aquí descubriremos hechos cruciales, como las bifurcaciones que, con el tiempo, llevan al caos. Nos daremos cuenta de que el comportamiento de un fenómeno dado puede ser estable o caótico, dependiendo de los valores de los parámetros que lo describen.

Una creencia muy importante en la ciencia es que una teoría que describe los fenómenos de la naturaleza debe poder hacer predicciones acerca del desarrollo futuro del sistema que se esté tratando. En el capítulo X se profundiza lo que significa la predictibilidad. A esto quedan asociados los conceptos de determinismo e indeterminismo. Estos conceptos se puntualizan en ese capítulo y la relación entre el caos y los fractales se ilustra en el capítulo XI.

Los antecedentes que se han presentado hasta este momento nos servirán para aplicarlos en el resto del libro a una serie de situaciones de gran diversidad y así, en el capítulo XII presentamos un ejemplo de aritmética, la secuencia de Fibonacci, que se podría creer que es sólo un tema divertido. Sin embargo, como se ilustra en el capítulo XIII, su aplicación a la ciencia de los materiales, para entender un descubrimiento hecho en 1984, es crucial; nos referimos a un nuevo tipo de arreglo de la materia que se llama cuasicristal.

En el capítulo XIV se introduce el concepto matemático de la ley de potencias, y hacemos ver que tiene propiedades fractales. Las aplicaciones de las leyes de potencias se producen en varios campos, aun en la música, hecho que se explica en el capítulo XV al estudiar la estructura de famosas obras de grandes compositores.

Las características de los fenómenos caóticos que se trataron en el capítulo VIII se aplican a varias situaciones. La primera de ellas es la turbulencia, tratada en el capítulo XV. Desde mediados del siglo pasado se había intentado sin éxito comprender este fenómeno. Sólo a partir de la década de 1990, con ayuda de los novedosos conceptos del caos, se ha podido empezar a vislumbrar la manera en que se puede entender este fenómeno, cuya comprensión es determinante en muchas aplicaciones prácticas como, por ejemplo, la aviación.

Otro empleo de las ideas del caos se hace en la biología y en particular en la medicina, como se puede apreciar en el capítulo XVII. Fenómenos cardiológicos se han empezado a ver desde otras perspectivas que han podido dar un entendimiento más profundo del comportamiento dinámico del corazón y que posiblemente puedan tener aplicaciones prácticas en el tratamiento de varias enfermedades.

En la naturaleza biológica se han encontrado muchas estructuras fractales. A pesar de que estas estructuras, como por ejemplo la de los bronquios, las ha conocido el hombre desde tiempos inmemoriales, su comprensión como fractal es muy reciente. Este tema lo tratamos en el capítulo XVIII.

La aplicación de los fractales y el caos al campo de la ingeniería se presenta en los capítulos XIX y XX. Un problema importante en la ingeniería civil es la determinación de estructuras que por un lado sean ligeras y que por el otro puedan soportar cargas pesadas. Por medio de estructuras fractales es posible alcanzar tales requerimientos que, en apariencia, son contradictorios. Por otro lado, el análisis del comportamiento de sistemas complejos, como los de una red eléctrica, por ejemplo, ha empezado a llevarse a cabo en los últimos años, desde la perspectiva amplia tratada en el capítulo VIII. De este modo se ha podido entender que una pequeña variación en los valores de los parámetros que rigen al sistema puede cambiar drámaticamente su comportamiento. Éste puede pasar de un comportamiento estable a uno caótico.

En el capítulo XXI se presenta una aplicación de los temas tratados al campo dela lingúística, mientras que en el XXII se reseñan algunos elementos de la economía. Aquí hablaremos del interesante caso de la compañía que se ha formado en los Estados Unidos, The Prediction Company, que se dedica a predecir el comportamiento de la Bolsa de Valores. El éxito financiero de esta empresa, formada por científicos que han desarrollado el tema del caos, es algo sorprendente.

En el capítulo XXIII presentamos una manera novedosa de dibujar mapas geográficos, basada en las operaciones para construir fractales.

El resto del libro se dedica a estudiar la estabilidad del Sistema Solar (capítulo XXIV.) y de algunos de sus elementos, como los asteroides (capítulo XXV); de Hiperión, que es un satélite de Saturno (capítulo XXVI) y finalmente de los planetas (capítulo XXVII). Se ha descubierto en años recientes que, desde un punto de vista que comprende intervalos de millones de años, dentro del Sistema Solar sí hay comportamientos caóticos. ¿Qué le ocurrirá? Ésta es una cuestión todavía no resuelta.

Como podrá apreciar el lector, la gama de temas es en realidad muy vasta. Uno de los puntos interesantes es que todos estos temas, y muchos otros que por falta de espacio no hemos tratado, se rigen por el mismo tipo de leyes. Éste es un gran descubrimiento, hecho en época muy reciente, que en el momento actual sigue siendo un capítulo abierto a trabajos de investigación muy activa, realizados por muchísimos científicos en todo el mundo, incluyendo mexicanos. La última palabra sobre estos temas no ha sido dicha todavía; de hecho aún falta mucho terreno por recorrer.

Iniciemos, pues, nuestro viaje por el camino de los fractales y del caos.

II. LA GEOMETRÍA EUCLIDIANA. LO QUE NOS ENSEÑARON EN LA ESCUELA

EL MATEMÁTICO griego Euclides, que vivió alrededor del año 300 a. C., escribió los Elementos, una de las obras más conocidas de la literatura mundial. En ella se presenta de manera formal el estudio de las propiedades de líneas y planos, círculos y esferas, triángulos y conos, etc.; es decir, de las formas regulares. Los teoremas que nos enseña Euclides son los que generalmente aprendemos en la escuela. Por citar algunos de los más conocidos:

a) La suma de los ángulos de cualquier triángulo es 180°

b) En un triángulo rectángulo el cuadrado de la hipotenusa es igual a la suma de los cuadrados de los catetos, que es el famoso teorema de Pitágoras.

La geometría de Euclides, además de ser un poderoso instrumento de razonamiento deductivo ha sido extremadamente útil en muchos campos del conocimiento, por ejemplo en la física, la astronomía, la química y diversas ingenierías. Desde luego es muy útil en las matemáticas.

Inspirados por la armonía de la presentación de Euclides, en el siglo II se formuló la teoría ptolemaica del Universo, según la cual la Tierra es el centro del Universo, y los planetas, la Luna y el Sol dan vueltas a su alrededor en líneas perfectas, o sea círculos y combinaciones de círculos.

Sin embargo, las ideas de Euclides constituyen una considerable abstracción de la realidad. Por ejemplo, supone que un punto no tiene tamaño; que una línea es un conjunto de puntos que no tienen ni ancho ni grueso, solamente longitud; que una superficie no tiene ancho, etcétera.

En vista de que el punto, de acuerdo con Euclides, no tiene tamaño, se le asigna una dimensión nula o de cero. Una línea tiene solamente longitud, por lo que adquiere una dimensión igual a uno. Una superficie no tiene ancho, por lo que tiene dimensión dos. Finalmente, un cuerpo sólido, como un cubo, tiene dimensión tres. De hecho, en la geometría euclidiana las únicas dimensiones posibles son las que corresponden a los números enteros: 0, 1, 2 y 3.

En el transcurso del desarrollo de este libro nos estaremos refiriendo a diversas características de las figuras acerca de las que trata la geometría de Euclides.

UNA situación que nos parece común es medir alguna longitud; como la de una costa, entre dos puntos A y B (figura 1).

Figura 1. ¿Cuál es la longitud de la costa entre los puntos A y B? Una manera de hacerlo sería medir la longitud de una línea recta que une A con B (figura 2). Sin embargo, la costa es, en general, irregular, por lo que es claro que su longitud será mayor que la de la línea recta entre sus dos puntos extremos. Podríamos ahora tomar como unidad una barra arbitraria de longitud H, por ejemplo. Para medir la longitud de la costa llevaríamos esta barra a lo largo de la costa (figura 3) y contaríamos las veces que la barra cabe a lo largo de la costa desde A hasta B. A este número, denotado por L1, le llamamos la longitud de la costa.

Nos damos cuenta inmediatamente de que tal número en realidad no es el valor de la longitud de la costa, ya que por ejemplo, entre los puntos A y C donde cayó la barra la primera vez, la longitud de ese tramo de costa no es la de la barra.

Para mejorar nuestra medición tomamos otra barra, de menor longitud, digamos de la décima parte de la anterior, H/10, y repetimos el procedimiento obteniendo para la longitud de la costa el número L2. Nuevamente podemos afirmar, por el mismo argumento que dimos arriba, que no es exactamente la longitud de la costa.

Podemos continuar indefinidamente de esta manera, tomando unidades cada vez más y más pequeñas. Intuitivamente esperaríamos que la sucesión de valores que se obtengan para las longitudes de la costa, medidas de esta manera, tendería a alcanzar un valor bien definido que sería la "verdadera" longitud de la costa. Sin embargo, esto no ocurre. De hecho, lo que sucede es que esta sucesión de longitudes aumenta cada vez más y más. Es decir, al seguir el procedimiento indefinidamente, la longitud de la costa que se mide se va haciendo cada vez más y más grande, esto es, ¡la longitud de la costa entre A y B tiende a un valor infinito!

Este resultado sorpresivo se puede explicar como sigue: si primero observamos la costa en un mapa de escala 1/100 000 nos daremos cuenta de que tiene algunas bahías y penínsulas. Si en seguida volvemos a examinar la misma costa, pero ahora en un mapa que tenga la escala de 1/10 000, es decir, en una escala más amplia, aparecerán características que no se veían en el mapa anterior. Así, ahora se ven nuevas bahías y nuevas penínsulas. Si se sigue examinando la costa, pero en un mapa que esté a una escala todavía más grande, digamos de 1/1 000, aparecerán nuevas bahías y penínsulas que no se veían en ninguno de los mapas anteriores. Así podemos continuar indefinidamente.

Figura 2. La distancia recta entre A y B no es la longitud de la costa.

Figura 3. Con la barra de longitud H se mide cuántas veces ésta cabe entre A y B. En consecuencia, al ir cambiando de escala, como van apareciendo más y más bahías y penínsulas pequeñas, éstas contribuyen a la longitud que se está midiendo. Por muy chica que sea la nueva bahía o península, al ir aumentando la escala, en algún momento aparecerá en el mapa y contribuirá a la longitud de la costa.

Si uno cambiara el método de medición de la longitud, también se llegaría a la misma conclusión.

Otro ejemplo de este tipo de situación ocurre al tratar de medir la frontera entre dos países. Se puede dar un argumento análogo al que presentamos arriba para la bahía y se llega a la misma conclusión: ¡la frontera entre dos países tiene, en rigor, longitud infinita!

En 1961 el inglés L. F. Richardson presentó una serie de las mediciones experimentales que hizo de varias costas, fronteras y cuerpos geométricos regulares. En cada caso fue cambiando el valor de la unidad de medida H; de esta forma obtuvo el correspondiente valor de la longitud L que denotamos como L(H), pues depende de la unidad H. En la figura 4 se muestran algunos de sus resultados. Se puede apreciar que al ir disminuyendo el valor de H la longitud L va aumentando. Sin embargo, se puede ver que la variación de L en ciertos intervalos de H no es muy pronunciada.

Podemos ahora preguntarnos lo siguiente: ¿si aplicamos estas ideas a la medición del perímetro de una figura como un cuadrado o un círculo, no pasará lo mismo? La línea (d) de la figura 4(d) muestra el valor de L para un círculo; se ve que es siempre el mismo (e igual al valor del perímetro del círculo, tal como se enseña en los cursos de geometría) en todo el intervalo de valores de 14 en que se hicieron las mediciones. Lo que ocurre es que en las figuras geométricas, al ir aumentando la escala de la observación NO aparecen estructuras del tipo de bahías o de penínsulas, que eran invisibles en la escala anterior, ya que por definición, la línea que delimita a la figura carece de estas estructuras. Por ejemplo, el círculo se define como el conjunto de puntos que dista una longitud constante del centro. Por lo tanto, en el círculo no puede haber algo análogo a una península, como en el caso de la costa.

Figura 4. La longitud de varias curvas depende de la longitud de medida H. a) Frontera entre Portugal y España. b) Costa occidental de Gran Bretaña. c) Frontera terrestre alemana (1900). d) Perímetro de un círculo.Aquí vemos con claridad lo que significa la abstracción de la realidad que hizo Euclides, quien no consideró figuras tales como las de una costa, sino que supuso que sus líneas no tenían estructuras que eran invisibles en una escala y visibles en otra. Sin embargo, en la realidad, muchas líneas que se presentan en la naturaleza sí tienen esta última característica.

En este punto esperamos que el lector se sienta incómodo. ¿Cómo es posible que, por ejemplo, la frontera entre dos países no esté perfectamente determinada? Pues, efectivamente, en lo que respecta a su longitud no lo está. Richardson menciona que cada país da un valor diferente a la longitud de su frontera común. Por ejemplo, España dice que su frontera con Portugal mide 987 km, mientras que Portugal afirma que son 1214 km; según Holanda su frontera con Bélgica mide 380 km, mientras que Bélgica reclama que son 449 km. Lo que sucede es que, al hacer las mediciones, cada país utilizó, de hecho, otro valor de la unidad 14, y por tanto obtuvo otro valor de la longitud.

La discusión anterior nos lleva a la conclusión inesperada de que la longitud de cierto tipo de objetos, que más adelante llamaremos fractales, no tiene un valor bien determinado. Su longitud depende de la unidad H que se escoja. Si dos observadores eligen dos unidades distintas obtendrán dos resultados distintos. ¡Y ambos observadores tendrán razón! Es decir, este tipo de mediciones no es completamente "objetivo". Es claro que, en las relaciones entre países, se debe reconocer el carácter especial de las cantidades que se van a medir y llegar a un convenio mutuo sobre cuál deberá ser la unidad de longitud que se debe seleccionar. De esta forma se evitarán ambigüedades.

SI SE suelta un grano de polen en un vaso de agua se observa que realiza un movimiento desordenado e irregular. Se mueve siguiendo una trayectoria en forma de zigzag (figura 5). En un cine, en el haz de luz que envía el proyector hacia la pantalla, se puede ver que las partículas de polvo que flotan en el aire realizan también un movimiento en zigzag.

Ambos movimientos reciben en física el nombre de movimiento browniano, que fue descrito por primera vez por el botánico inglés Robert Brown en 1828.* No entraremos en la historia de este fenómeno. Sólo presentaremos algunas características de él que nos serán útiles.Las líneas de la trayectoria de una partícula browniana (figura 5) no tienen en rigor ninguna realidad física. La forma en que se trazaron las líneas del dibujo es imaginando que cada 30 segundos se observa la posición de la partícula de polen y se marca con un punto; luego estos puntos se unen sucesivamente con líneas rectas. Por tanto, lo único que tiene realidad son los puntos, que indican las posiciones de la partícula browniana al final de cada intervalo. Si ahora, en lugar de marcar las posiciones en cada intervalo de 30 segundos se marcan en cada intervalo de 3 segundos y se unieran los puntos con líneas rectas, cada línea recta de la figura 5 quedaría reemplazada por una sucesión de líneas quebradas de menor tamaño, pero de igual complejidad. Así, por ejemplo, si nos fijamos en dos puntos sucesivos, A y B, de la figura 5, se obtendrán entre ellos los puntos mostrados en la figura 6. Si ahora unimos estos puntos con líneas rectas obtendremos las líneas quebradas de la misma figura 6. Concluimos que la segunda figura que se forma tiene el mismo tipo de estructura que la primera.

Se podrían tomar ahora intervalos más pequeños, por ejemplo, de 0.3 segundo y seguir el mismo procedimiento; ocurriría lo mismo que antes. Nos damos cuenta de que la trayectoria que sigue una partícula browniana es tal que mantiene una estructura similar al cambiar la escala de tiempos de la observación. Este tipo de línea fue denominada fractal por el científico Benoit Mandelbrot en 1975.

Figura 5. Trayectoria irregular y azarosa que sigue una partícula browniana.

Figura 6. a) Los puntos A y B son las posiciones de la partícula Browniana al inicio y al final de un intervalo de tiempo. b) Posiciones de la misma partícula browniana al registrarla en intervalos equivalentes a la décima parte del intervalo anterior.Es interesante mencionar que ya en 1906 el físico francés Jean Perrin se había dado cuenta de este tipo de comportamiento. En particular, había hecho notar que si uno toma un punto de la trayectoria que sigue una partícula browniana entonces, en rigor, no se puede trazar una línea tangente a ella, y apuntó entonces:

Usando lenguaje geométrico, las curvas que no tienen tangente constituyen la regla, y curvas regulares, tales como el círculo, son interesantes pero especiales.

A primera vista, la consideración del caso general puede parecer un mero ejercicio intelectual, ingenioso pero artificial. Los que oyen hablar de curvas sin tangente tienden a pensar que la naturaleza no presenta tales complicaciones, ni siquiera las sugiere.

Sin embargo, lo contrario es la verdad. Esta afirmación se puede ilustrar considerando ciertos valores experimentales sin preconcepción.

Considérese, por ejemplo, uno de los copos blancos que se obtienen al añadir sal a una solución jabonosa. A cierta distancia su contorno puede dar la sensación de estar nítidamente definido, pero a medida que nos acercarnos esta nitidez desaparece. El ojo ya no puede dibujar una tangente en cualquier punto. Una línea que, a primera vista, pareciera ser satisfactoria, bajo un escrutinio detallado resulta ser perpendicular u oblicua. El uso de una lupa o de un microscopio aún nos deja más en la duda, ya que aparecen nuevas irregularidades cada vez que aumentamos la magnificación, y nunca logramos conseguir una impresión nítida, lisa como la dada, por ejemplo, por una bola de acero…

…la característica esencial de nuestro copo es que cualquier escala incluye detalles que prohíben absolutamente la fijación de una tangente.

Quedaremos dentro de los dominios de la realidad experimental en el momento en que observemos bajo el microscopio el movimiento browniano con el que se agita una partícula (browniana) suspendida en un fluido. Se descubre entonces que la dirección de la línea recta que une las posiciones ocupadas por una partícula en dos instantes muy cercanos en el tiempo varía irregularmente en forma absoluta a medida que el intervalo entre ambos instantes se hace menor. Un observador sin prejuicios concluiría, en consecuencia, que está tratando con una curva a la que no se le puede dibujar una tangente.

Nadie hizo caso a los comentarios de Perrin, y este asunto quedó dormido hasta finales de la década 1960-1970, cuando Mandelbrot lo retomó. Hablaremos al respecto en el capítulo siguiente. Si se hubiera seguido investigando la observación hecha por Perrin a principios de siglo, lo que hoy llamamos fractales posiblemente habrían sido desarrollados 60 años antes.

Otro caso que nos será de interés en este libro es el del científico francés Henri Poincaré. Para entender su proposición, olvidada durante cerca de 70 años, recordaremos algunos hechos.

Las leyes del movimiento de Isaac Newton, expuestas a fines del siglo XVII, implicaban que si se conoce la fuerza que se aplica sobre una partícula se puede conocer la trayectoria que seguirá. Sin embargo, esta posibilidad contiene una condición: que se debe poder especificar qué posición y que velocidad tenía la partícula en el instante inicial. Es decir, si se pueden precisar las condiciones iniciales de la partícula, las leyes de Newton permiten conocer completamente su futuro, lo cual resultará válido para cualquier sistema que tenga cualquier número de partículas.

Basado en estos hechos, el matemático francés Pierre Simon de Laplace (1749-1827) llegó a jactarse de que si se le dieran las posiciones y velocidades iniciales de cada una de las partículas que componen el Universo, podría predecir el futuro por el resto del tiempo. Este hecho conlleva un riguroso determinismo en las leyes de la naturaleza. Las inferencias de estas conclusiones acerca de las leyes de Newton las trataremos en un capítulo posterior.

En el año de 1903 Poincaré escribió lo siguiente:

…nosotros solamente podemos conocer la situación inicial de manera aproximada. Si esto nos permitiera predecir la situación que sigue en el tiempo con la misma aproximación, es todo lo que necesitaríamos, y podríarnos decir que el fenómeno ha sido predicho, que está regido por leyes. Pero esto no es siempre así; puede ocurrir que pequeñas diferencias en las condiciones iniciales produzcan condiciones muy diferentes en los fenómenos finales. Si un pequeño error en las condiciones iniciales produce un enorme error en las condiciones finales, la predicción se vuelve imposible y tenemos un fenómeno fortuito.

En el capítulo VII se analizará con mayor detalle este comentario.

Al igual que en el caso de Perrin, las observaciones de Poincaré permanecieron olvidadas durante muchos años; ningún científico les puso atención. Si se hubiera continuado trabajando en este campo desde esa época, es posible que el caos como teoría científica se hubiera desarrollado muchas décadas antes.

Éstos son dos ejemplos de situaciones que no son muy raras en la historia de la ciencia. Algún científico se da cuenta de cierto fenómeno, pero por diversos motivos nadie se ocupa de él y cae en el olvido, lo que ilustra el hecho de que el desarrollo de la ciencia no es tan objetivo como se quisiera pensar.

[Nota *]* véase Braun, E., Un moviminto en zigzag. La Ciencia desde México, núm. 13, Fondo de Cultura Económica, México, 1991.

EN LAS últimas dos décadas se ha desarrollado una línea de investigación, iniciada por Benoit Mandelbrot, cuyo tema son los objetos llamados fractales.Se puede construir un tipo de figuras fractales siguiendo el siguiente ejemplo. Tomemos un triángulo equilátero cualquiera (figura 7(a)) al que se denominará iniciador. Divídase cada lado en tres partes iguales. En las partes intermedias de cada lado añádanse dos lados de un triángulo equilátero cuyo lado sea igual a la tercera parte del lado original. Se obtiene así la figura 7(b). Enseguida, divídase otra vez cada uno de los lados de la figura así formada en tres partes iguales, y en cada parte intermedia añádanse dos lados de un triángulo equilátero cuyo lado sea igual a la longitud resultante. Se encuentra así la forma mostrada en la figura 7(c). Si se continúa indefinidamente este procedimiento se encontrará una forma parecida a la mostrada en la figura 7(d). Esta figura es un fractal y, como veremos acontinuación, su perímetro tiene longitud infinita.

Analicemos con un poco de detalle el perímetro de estas figuras. Supongamos que el lado del triángulo iniciador de la figura 7(a) sea igual a 1 (en cualquier unidad). El perímetro del triángulo original, que es igual a la suma de las longitudes de sus lados, es entonces igual a 8.

Por construcción, cada línea recta de la figura 7(b) tiene longitud (1/3). Por tanto, dado que hay 12 líneas rectas de este tamaño, el perímetro de la figura 7(b) es 12 x (1/3) = 4. El lector se dará cuenta de que este nuevo perímetro (4) es mayor que el original (3).

Veamos ahora la figura 7(c). Cada línea recta de esta figura tiene (1/9) de longitud. En vista de que hay 48 de estas líneas, su perímetro es 48 x (1/9) = 5.333, mayor que los perímetros de las figuras 7(a) y 7(b).

Vemos entonces que la sucesión de valores de los perímetros es: 3, 4, 5.333,… Esta sucesión va creciendo. La causa de que crezca es clara, ya que de un paso al otro el número de líneas rectas aumenta más rápidamente de lo que disminuye la longitud de cada línea recta. De hecho, en cada paso de la construcción el número de líneas se multiplica por el factor 4, mientras que la longitud de cada línea disminuye 3 veces. Por lo tanto, el perímetro se multiplica, de un paso al otro, por el factor 4 x (1/3) = 1.333, que es un número mayor que 1. Si el número de pasos es infinito, el perímetro de la figura así formada también resulta ser infinito.

Figura 7. Pasos que siguen para construir el fractal llamado curva de Koch.

Figura 7. Pasos que siguen para construir el fractal llamado curva de Koch (continuación).La curva de la figura 7(d) se llama curva de Koch.

Nos debemos dar cuenta de que si se comparan las figuras que se forman en dos construcciones sucesivas, se verá que ambas tienen la misma estructura. Se recordará del capítulo III que lo mismo ocurre con la bahía cuando se cambia la escala.

Un objeto que presenta la misma estructura al cambiársele indefinidamente la escala de observación recibe el nombre de fractal. Por lo tanto, la curva de Koch y la bahía son fractales.

Mandelbrot asegura que en la naturaleza existen muchos fenómenos de carácter fractal, de hecho, muchos más de los que podemos imaginar. Mencionaremos en forma breve algunos.

La trayectoria que sigue una partícula que realiza movimiento browniano, descrita en el capítulo IV es un fractal. En efecto, al pasar de una escala a otra, como por ejemplo, cuando se pasa de la figura 5 a la 6, las estructuras son similares.

También los paisajes naturales presentan características de los fractales. Así, la forma de las cadenas montañosas (figura 8) da lugar a que si uno intentara medir su superficie encontraría valores infinitos. Una manera de crear un paisaje fractal es la siguiente. Tomemos el triángulo de la figura 9(a). El punto medio de cada lado lo desplazamos cierta cantidad (figura 9(b)). Así el punto A se traslada al punto B; el punto G al D, y el E al F. Uniendo los puntos B, D y F con los vértices del triángulo se forman cuatro triángulos más pequeños que el original, como se ve en la figura 9(c). Si se sigue este procedimiento muchas veces con cada uno de los triángulos formados, se logra obtener una figura que tiene todo el parecido a una montaña (figura 8). Un programa de computadora llena los triángulos resultantes con sombreados apropiados que le dan un toque en extremo realista a la figura.

Figura 8. La forma de una cadena montañosa es un fractal.

Figura 9. Pasos para construir un paisaje fractal. En la geometría euclidiana se enseña que hay una relación determinada entre, por ejemplo, área que ocupa una figura y la longitud de la línea que encierra a dicha área. Así, por ejemplo, para un cuadrado, la longitud de su perímetro elevada al cuadrado es igual a 16 veces el área encerrada. En efecto, supongamos que el lado del cuadrado es de 3 cm. Entonces el perímetro es:

perímetro = 4 x 3 cm = 12 cm.

Si se eleva al cuadrado se obtiene:

perímetro² = (12 cm)² = 144 cm².

Por otro lado, el área del cuadrado de lado 3 cm es:

área = (3 cm)² = 9 cm².

Pero:

144=16x9,

por lo que vemos que:

En un cuadrado, el perímetro al cuadrado es igual a 16 veces el área encerrada.

Si se trata de un círculo, la longitud del perímetro elevada al cuadrado es igual a cuatro veces (la letra griega pi) por el área encerrada:

Recuérdese que el número (pi) es igual a 3.14159…

De manera general, el cuadrado del perímetro de una figura geométrica es igual al área encerrada, multiplicada por un número. Este número depende de la forma particular de la figura que se esté tratando: para el cuadrado el número es 16 y para el círculo 4.

Un tipo de relación análoga se encuentra entre el volumen de un cuerpo y el área de la superficie que lo encierra. En efecto, se puede demostrar que en una figura cúbica el cubo del área es igual a 216 veces el cuadrado del volumen encerrado. Por ejemplo, si el lado de un cubo mide 2 cm, entonces el área total del cubo es 6 veces el área de cada cara, ya que tiene 6 caras. Pero el área de cada cara es (2 cm) x (2 cm) = 4 cm². Por tanto:

área total del cubo = 6 x 4 cm² = 24 cm².

Elevemos ahora este valor al cubo:

área³ = (24 cm²)³ = 13824 cm6.

Por otro lado, el volumen del cubo se obtiene elevando al cubo la longitud de su lado:

volumen = (2 cm)³ = 8 cm³.

Elevando al cuadrado este valor:

volumen² = (8 cm³)² = 64 cm6.

Pero:

13824 = 216 x 64,

por lo que:

Para otro tipo de figuras, el factor que multiplica al (volumen)² no es 216, este coeficiente depende de la figura particular de que se trate.

En el caso de las figuras que son fractales, las relaciones que obtuvimos no se satisfacen. Consideremos, por ejemplo, el caso del cerebro de los mamíferos; se sabe que su corteza presenta numerosas circunvoluciones. De mediciones hechas con mucha precisión resulta que la relación entre el volumen del cerebro y el área de la superficie que lo encierra no sigue el patrón mencionado arriba para las figuras geométricas regulares. Se encuentra ahora que el cubo del área ya no es proporcional al volumen elevado al cuadrado, sino que:

donde A es un número, análogo al 216 de la ecuación (3), pero el exponente a (alfa) no es igual a 2 como en la ecuación (3) sino que tiene un valor entre 2.73 y 2.79.

Se puede demostrar que de esta relación puede inferirse que la superficie que encierra al cerebro es fractal. Este resultado se ha explicado en relación con las necesidades que la evolución va creando para los mamíferos.

De hecho, cuando en una figura se satisface la relación (3) entre su área y su volumen, la figura es euclidiana. Si no, como en el caso del cerebro que se está considerando, entonces es fractal.

Otro ejemplo del campo biológico se da en la estructura nasal de algunos animales. La membrana que cubre el hueso de la nariz es tal, que la relación entre área y volumen encerrado no sigue un patrón geométrico euclidiano, sino fractal. Ciertos animales tienen esa membrana con un área muy grande para el volumen que encierran. La membrana podría estar relacionada con el sentido del olfato y, por ejemplo, en el caso de los camellos su gran área les ayudaría a localizar; husmeando, el agua tan escasa en el desierto.

La descarga y el nivel de las crecidas de los ríos son otro ejemplo de fractales. Resulta que estas cantidades, tomadas anualmente, tienen valores muy persistentes. Se ha intentado dar, infructuosamente, diversas explicaciones a este hecho. Aparentemente la única explicación que tiene visos de conformarse con los resultados experimentales es que estas cantidades se comportan como fractales.

También se han aplicado las ideas de los fractales a la economía. Un análisis detallado del comportamiento en el cambio de precio de las mercancías muestra que su estructura es análoga a la de un fractal. Esto se debe a que al cambiar de escalas temporales la determinación de los cambios, se encuentran estructuras similares.

En lingüística también se producen estructuras fractales. Se ha estudiado las relaciones que sigue en un idioma la frecuencia en el uso de las palabras. Pues resulta que este comportamiento es fractal. Uno de los parámetros de este fractal da la medida de qué tan rico es el uso del vocabulario a través de la frecuencia relativa del uso de palabras poco comunes.

Se ha determinado que los fractales también se dan en la teoría de los circuitos eléctricos y en la teoría de la información, por mencionar sólo algunos campos. Se han abierto de esta manera vastos horizontes de estudio y aplicación que apenas empiezan a explorarse.

El hecho de que en las figuras regulares, las que trata la geometría euclidiana, la relación entre el cuadrado del perímetro y el área (véanse las ecuaciones (1) y (2) de la página 28), o bien, entre el área al cubo y el cuadrado del volumen (véase la ecuación (3) de la página 29) se dé con exponentes que son números enteros (por ejemplo, el 3 del área al cubo y el 2 del cuadrado del volumen) se debe a que se está tratando con una, dos y tres dimensiones. Sin embargo, cuando se trata de fractales (véase la ecuación (4) de la página 30), entonces, como vimos arriba, ya no se tienen estas relaciones con números enteros en los exponentes. Por tanto, los fractales son figuras que no corresponden a una dimensionalidad entera.

Lo que está ocurriendo es que la geometría euclidiana, con sus dimensiones enteras, no logra alcanzar la esencia de las formas irregulares. Considérese un ovillo de cuerda. Si se le observa desde muy lejos (figura lO(a)) se le verá como un punto, es decir, una figura de dimensión nula. Si el observador se acerca verá que el ovillo ocupa un espacio parecido a una esfera, o sea, de tres dimensiones (figura 10(b)). Si el observador se sigue acercando advertirá con detalle la cuerda que forma el ovillo y éste se transforma, en realidad, de dimensión uno (figura 10(c)). Si seguimos acercándonos, es decir; nos disminuimos imaginariamente para apreciar la estructura microscópica de la cuerda, la cuerda empieza a verse nuevamente de tres dimensiones, porque se empezará a apreciar las fibras que lo componen, que podrán verse como columnas tridimensionales. Así se puede continuar. De esta manera, se aprecia que no se puede hablar de la dimensionalidad de la cuerda de una manera "objetiva". Todo depende de la perspectiva del observador, esto es, de la escala en que se haga la observacion.

Mandelbrot dio un paso muy atrevido al proponer que se asignara a los fractales dimensiones que no fueran números enteros. La dimensión fraccionaria propuesta constituyó una manera de poder medir de otra forma características no definidas claramente. Por ejemplo, el grado de irregularidad de una línea, como la bahía, o la aspereza de una superficie. Mandelbrot propuso la forma de calcular la dimensión de un objeto fractal y demostró que el número que así se obtiene no depende de la escala en que se hacen las observaciones. Recuérdese que si se asignan dimensiones enteras, entonces, como en el caso del ovillo de cuerda, la dimensión va cambiando al cambiar la escala de observación.

Figura 10.a) De lejos, un ovillo se ve como un punto. Su dimensión es 0; b) más de cerca vemos el ovillo como una esfera. Su dimensión es 3; c) todavía más cerca vemos la cuerda del ovillo. Su dimensión es 1.

Figura 11. La forma de una rama es fractal.

Figura 12. Un rayo tiene forma de fractal. Por tanto, el grado de irregularidad de un fractal es el mismo a medida que se cambia de escala. Es decir; hay una irregularidad regular, valga la expresión.

Como ilustración mencionamos que la curva de Koch (figura 7(d)) tiene una dimensión igual a 1.2618.

Una de las características de un fractal es que conserva la misma forma si se le ve en distintas escalas, como en el caso de las líneas asociadas al movimiento de una partícula browniana (figuras 5 y 6). Esta característica de los fractales se llama auto similitud.

Es posible construir figuras fractales siguiendo un procedimiento bien determinado, o como se dice más técnicamente, un algoritmo, por ejemplo, el procedimiento para construir la curva de Koch. De la misma manera se puede construir una superficie que se parece mucho a la terrestre (figura 9). Este algoritmo ha sido utilizado en la filmación de películas con el fin de crear superficies. Se ha demostrado que la superficie terrestre tiene una dimensión fractal de 2.7, hecho que han utilizado muy provechosamente los geólogos.

Otros empleos son los de fabricar patrones semejantes a los del crecimiento de las especies biológicas (figura 11) o las de una descarga eléctrica como un rayo (figura 12).

En capítulos posteriores trataremos en detalle algunos de los casos mencionados, en los que aparecen objetos fractales.

VI. MÁS SOBRE FRACTALES.

SimilitudEN EL capítulo anterior se vio que un fractal es una figura que mantiene su forma si se le cambia de escala. En el presente capítulo consideraremos con más detalle esta importante propiedad.

Las famosas muñecas rusas están formadas por una muñeca grande en cuyo interior se halla otra muñeca, similar a la grande, pero de menor tamaño. Dentro de esta segunda muñeca hay otra similar, pero de tamaño aún menor. Un conjunto contiene cinco o seis muñecas, todas similares, pero cada una de menores dimensiones. Al pasar de una muñeca a la otra se está cambiando la escala. Al cambiar de escala, las muñecas en conjunto son similares. Si se pudiera tener un conjunto muy grande, infinito, de muñecas, todas iguales pero una más pequeña que la anterior, tendríamos un fractal. Sin embargo, no se puede construir este conjunto porque llega un momento en que resulta imposible tallar una muñeca lo suficientemente pequeña. El conjunto, por lo tanto, constituye una aproximación a un fractal.

Otro ejemplo de similitud parcial es el caso de una etiqueta colocada, por ejemplo, en una caja de chocolates. En la etiqueta está dibujada la misma caja con su etiqueta que, a su vez, muestra la caja de chocolates con la etiqueta, etc. Nótese que al cambiar de escala, o sea en el dibujo que está en una etiqueta, lo que se ve es similar al objeto original. Si se pudiera seguir así un número muy, pero muy grande de veces, de hecho infinito, entonces habríamos formado un fractal. Esta similitud no se puede llevar al infinito, por razones claras.

Otro caso es el de una caricatura en la que un pez se come a otro más chico; éste a otro todavía más chico y así sucesivamente.

En el caso en que un objeto tiene la misma forma al cambiar la escala, es decir, que es similar al anterior, y se cambia la escala un número infinito de veces y se sigue obteniendo una figura similar a las anteriores, se dice que el objeto es autosimilar. Un fractal es un objeto autosimilar. Un ejemplo, como ya se vio, es la trayectoria de una partícula browniana (figura 5).

Otro ejemplo de similitud se da cuando una persona se coloca entre dos espejos paralelos y observa las imágenes de su cuerpo. Pero estas imágenes no son todas iguales, sino que una es más pequeña que la otra. Si los espejos se hallan situados en forma perfectamente paralela, entonces el número de imágenes es infinita y así tenemos un conjunto autosimilar.

La autosimilitud es una idea que ya había sido sugerida en muchas ocasiones a lo largo de la historia. Por ejemplo, en el siglo XVII, el pensador alemán Gottfried Wilhelm Leibniz (1646- 1716) propuso que una gota de agua contenía todo un universo, que a su vez contenía gotas de agua más pequeñas; cada una de estas pequeñas gotas encerraba a su vez un universo que tenía en su interior otras gotas de agua, todavía más pequeñas y cada una de ellas…

Esta autosimilitud y otras muchas que se sugirieron fueron desechadas con el tiempo ya que no se pudieron comprobar experimentalmente. En una gota de agua no hay ningún universo en el sentido propuesto por Leibniz.

Fue hasta la década de 1960 y de 1970 que Mandelbrot volvió a proponer esta idea, pero en un contexto completamente distinto de los anteriores. Se ha demostrado que la autosimilitud se presenta en gran variedad de fenómenos y situaciones muy diversas, como veremos en los capítulos siguientes.

EN EL capítulo IV citamos a Poincaré cuando aludía a las condiciones iniciales. En el presente capítulo analizaremos en detalle esa cuestión.Consideremos un fenómeno físico bien conocido, la caída de los cuerpos. Una piedra cae al soltarla debido a que experimenta una fuerza, la de gravedad, que está dirigida hacia el centro de la Tierra. Con base en las leyes de Newton se puede encontrar que la trayectoria que sigue la piedra es una línea recta vertical.

Sin embargo, la misma piedra sujeta a la misma fuerza (su peso) también puede moverse a lo largo de otra trayectoria. Por ejemplo, si la lanzamos hacia arriba formando cierto ángulo con la horizontal, entonces se moverá a lo largo de la trayectoria mostrada en la figura 13, que resulta ser una parábola.

Nos podemos hacer la siguiente pregunta: si en los dos casos la misma piedra estuvo sujeta a la misma fuerza, ¿por qué en un caso se movió a lo largo de una línea recta vertical y en el otro a lo largo de una parábola? Como podemos apreciar, a pesar de ser la misma piedra y la misma fuerza, hubo una diferencia.

· En el primer caso se soltó la piedra, lo que significa que en el instante inicial su velocidad fue nula.

· En el segundo caso se le dio a la piedra, en el instante inicial, una velocidad dirigida hacia arriba, como se muestra en la figura 13.

Por tanto, en los dos casos hubo condiciones iniciales diferentes y, en consecuencia, las trayectorias seguidas fueron distintas, a pesar de que en ambos casos la piedra estuvo sujeta a la misma fuerza, la gravedad.

Este ejemplo nos ilustra un hecho muy importante: para conocer el tipo de evolución que sigue un sistema se necesita conocer, además de las leyes que lo rigen (en los casos de arriba, las de Newton y la fuerza de la gravedad), las condiciones iniciales del sistema. Bajo las mismas leyes, diferentes condiciones iniciales producen distintas evoluciones en el tiempo.

La cuestión a que se refirió Poincaré tiene que ver con lo siguiente. Tomemos dos piedras iguales. Soltemos la primera piedra desde cierto punto, digamos el A, sobre el suelo (figura 14(a)). Al mismo tiempo soltemos la segunda piedra desde el punto B, que está muy cercano al A. Nos damos cuenta de que, no obstante que en ambos casos las velocidades iniciales de las piedras son iguales (cero), sus posiciones iniciales no son iguales ya que las soltamos desde dos puntos distintos, aunque difieren muy poco. Decimos que las condiciones iniciales de ambas piedras no son las mismas, aunque sí muy parecidas.

Figura 13. Una piedra lanzada hacia arriba, formando un ángulo con la horizontal, describe una trayectoria parabólica.

Figura 14. Cuando dos cuerpos caen a partir del reposo y desde posiciones muy cercanas, no se separan mucho en sus trayectorias.Veamos qué pasa con las posiciones que van ocupando las dos piedras en sus caídas. Si nos fijamos medio segundo después de haber soltado las piedras veríamos (figura 14(b)) que están en las posiciones C y D, respectivamente. Nos damos cuenta de que la distancia entre los puntos C y D también es muy pequeña (de hecho es igual a la de los puntos iniciales A y B). En consecuencia, si la diferencia de condiciones iniciales es muy pequeña, entonces al transcurrir el tiempo la diferencia entre las posiciones de las dos piedras sigue siendo muy pequeña. Es decir, en este caso, las trayectorias que siguen son muy cercanas.

Veamos ahora otra situación. Supongamos que soltamos las dos piedras iguales desde puntos cercanos a la cima de una montaña (figura 15). La primera en la cima C, y la otra desde el punto A de la figura, es decir, un lugar que no es ya la cima, pero muy cercano a ella. ¿Qué ocurre ahora con las trayectorias de las piedras? Pues la primera se quedará en la cima mientras que la segunda rodará por la ladera de la montaña. En consecuencia, después de cierto intervalo, digamos 3 segundos, la separación entre las posiciones de ambas piedras será muy grande: una en la cima y la otra abajo. En este caso, nuevamente las condiciones iniciales de las dos piedras son muy parecidas pero ahora sus posiciones, al transcurrir el tiempo, difieren marcadamente. Es decir, con el paso temporal en este caso no se conservan las posiciones muy cercanas unas de otras.

Figura 15. Dos piedras que caen desde puntos distintos de una montaña y a partir de posiciones muy cercanas, se separan mucho a lo largo de sus trayectorias.Otro ejemplo se ilustra en la figura 16, en que se observa dos bolas de billar que inciden sobre una mesa que tiene varios botadores fijos. Las posiciones iniciales de las bolas son ligeramente distintas. Vemos que aun cuando las velocidades iniciales de las bolas sean las mismas, las trayectorias que siguen son completamente diferentes.

Figura 16. Ilustración de que variaciones pequeñas en las posiciones iniciales producen trayectorias muy separadas.De los casos que hemos considerado podemos afirmar que hay dos tipos de situaciones:

1) Condiciones iniciales muy parecidas producen condiciones finales también muy parecidas, y

2) condiciones iniciales muy parecidas producen condicicnes finales completamente diferentes.

Ahora bien, para determinar la evolución de un sistema cuando el tiempo transcurre debemos conocer las leyes que lo rigen, así como sus condiciones iniciales. Si fuera posible determinar con TODA precisión estas condiciones iniciales entonces podríamos saber en cualquier instante las características que tiene el sistema. A esto se refería Laplace (véase capítulo IV) cuando decía que si se le daban las condiciones iniciales del Universo podría determinar el futuro.

Sin embargo, en una situación real no podemos afirmar que se puedan determinar con TODA precisión las condiciones iniciales. Al medir estas cantidades siempre se cometerán errores, que son inevitables. Por lo tanto, lo más que se puede hacer es dar las condiciones iniciales en forma aproximada. Estas condiciones iniciales diferirán de las verdaderas condiciones iniciales del sistema en muy poco si los errores cometidos son pequeños. ¿Qué podemos decir acerca de la trayectoria que seguirá el sistema?, ¿podemos predecirla?

De lo que se ha visto puede ocurrir una de dos posibilidades:

1) Si estamos en un caso en que diferencias de condiciones iniciales producen condiciones finales muy parecidas, entonces podremos predecir qué ocurre con el sistema, con el transcurso del tiempo, también con un error pequeño. En este caso la separación entre las trayectorias es muy pequeña y la predicción que se haga será muy parecida a la trayectoria real.

2) Si se está en el caso en que pequeñas diferencias en las condiciones iniciales producen condiciones finales muy distintas, entonces la trayectoria real que siga el sistema se separará muy marcadamente de la trayectoria que podamos predecir. En este caso nuestra predicción está muy lejos de la realidad, por lo que no hay posibilidad de hacer predicción válida alguna.

En la cita de Poincaré mencionada en el capítulo IV, este científico se refirió precisamente a estas dos posibles situaciones.

En el próximo capítulo se considerarán las consecuencias de estas posibilidades.

Los casos de las figuras 15 y 16 son ejemplos físicos de dependencia muy sensible de las condiciones iniciales.

VIII. CAOS. FENÓMENOS NO LINEALES

A LO largo de muchos años, en el estudio que varias ciencias han hecho de diferentes fenómenos se han encontrado situaciones que no ha sido posible describir de manera satisfactoria. Por ejemplo, en el caso de la meteorología un problema muy importante es poder predecir el clima que prevalecerá no sólo al día siguiente, sino una semana, un mes, un año después. Sin embargo, a pesar de que esta ciencia se ha desarrollado bastante y mucha gente ha trabajado en ella durante más de un siglo, este tipo de predicciones no ha podido llevarse a cabo de manera efectiva.En la física podemos mencionar el fenómeno de la turbulencia. Cuando un fluido se mueve a lo largo de un tubo, en ciertas condiciones el fluido lo hace de manera muy tranquila y regular; se dice que el flujo es laminar y sus propiedades sí han podido ser determinadas. Sin embargo, en otras circunstancias, el flujo se vuelve turbulento: empiezan a aparecer primero pequeños remolinos, después remolinos más y más grandes y el movimiento del fluido se vuelve muy irregular. Se dice que el flujo ha entrado en turbulencia. Este efecto no se había podido entender en más de cien años de estudio de la hidrodinámica.

En la economía no se han podido entender los motivos por los cuales en cierto momento el índice de la Bolsa de Valores empieza a subir y luego desciende. En muchas ocasiones parece ser un fenómeno del azar.

Los casos anteriores ilustran algunos de los problemas que habían quedado sin solución. Sin embargo, con el advenimiento de la teoría del caos se han podido entender diferentes aspectos de estos fenómenos, antes incomprensibles.

Una cuestión muy importante, común a diferentes fenómenos, es la posibilidad de que se pueda hacer predicciones. Por ejemplo, si se sabe que hoy está lloviendo, se quisiera predecir si lloverá mañana o si lloverá pasado mañana. Es decir, una cuestión es la posibilidad de poder predecir lo que ocurrirá en el futuro si sabemos en qué situación nos encontramos ahora.

En los últimos 20 años se ha desarrollado una novedosa forma de abordar este tipo de situaciones. Resulta que muchos fenómenos completamente distintos, como la turbulencia, el clima, el índice de la bolsa, las señales electrónicas, ciertas reacciones químicas y otras más, tienen comportamientos que, vistos desde perspectivas apropiadas, son muy parecidos. Debido a este hecho, trataremos un caso muy especial para ilustrar el fenómeno del así llamado caos. Consideraremos un problema importante en la ecología, a saber, cómo evoluciona en el transcurso del tiempo una población determinada, por ejemplo de los insectos. Si conocemos el número de insectos este año, nos podemos preguntar ¿cuántos insectos habrá el año próximo, el siguiente, y así sucesivamente?

Con el estudio que se haga se quisiera poder encontrar una regla que nos dijera que si este año hay, por ejemplo, en un determinado lugar 10 500 insectos, el próximo año habrá 12 750. Si se puede descubrir esta regla, entonces aplicándola de año en año se podrá conocer la población en cualquier año futuro. En matemáticas una regla de este tipo se llama función. ¿De qué depende ésta? Pues debería hacerlo de las condiciones en que vive la población. No dará lo mismo si se trata de un lugar desértico o de una selva; si la población dispone de muchos alimentos o si más bien son escasos. Es decir; de alguna manera en la función tiene que aparecer esta información. Además, la población que vaya a haber el año siguiente dependerá de la población que existe en este año. Encontrar esta función se llama hacer o construir un modelo.

La función más sencilla es la siguiente. Se supondrá que la población crecerá el año siguiente en un porcentaje fijo de la población del año actual. Por ejemplo, si la población crece año con año 10%, se tiene la siguiente situación: supongamos que en el presente año hay 10 000 insectos; entonces el año próximo aumentará en 10% este número, así, habrá un aumento de:

0.1 x 10 000 = 1000,

y por tanto, el número de insectos que habrá el año próximo será igual al número que hay en el presente año (10 000) más el aumento que ocurrió (1000), o sea:

10 000 +1000=11 000 insectos.

El siguiente año habrá un aumento de 10% de 11 000, o sea aumentará en:

0.1 x 11000 = 1100,

y el número que habrá será:

11 000 +1100=12 100.

De esta manera se puede calcular el número de insectos del año que se quiera. Sin embargo, hacerlo a un plazo de 150 años, por ejemplo, sería muy engorroso. Pero puede abreviarse este procedimiento como sigue. Nos damos cuenta de que se puede encontrar la población del año siguiente (11000 en nuestro ejemplo) haciendo la siguiente operación:11000=1.1 x 10 000.

Aquí, 10 000 es la población inicial. De la misma forma, la población en el segundo año (12 100) se puede obtener a partir de la población en el primer año (11 000) haciendo la siguiente multiplicación:

12 100 =1.1 x 11000

.

Vemos entonces que la población en cualquier año se encuentra multiplicando 1.1 por la población del año anterior. O equivalentemente, la población del año siguiente se puede encontrar multiplicando 1.1 por la población del año presente:

La población de un año cualquiera se introduce como dato para encontrar la población del año siguiente. Repitiendo o iterando esta operación tantas veces como se quiera, se encontrará la población de cualquier año futuro. La operación que acabamos de encontrar es la función a la que nos referimos arriba.

De lo que acabamos de explicar nos damos cuenta de que si se conoce la función y la población inicial, entonces es posible determinar con precisión la población en cualquier año futuro.

Se puede abreviar el procedimiento presentado de la manera siguiente: la letra x será la población en cierto año y la letra y la población del año siguiente. Entonces:

y = 1.1 x

Para obtener y se multiplica 1.1 por x. El 1.1 proviene del hecho que se supuso que el crecimiento sería de 10% anual. Sin embargo, no siempre será así, podrá haber otras posibilidades. Si así fuera, el 1.1 se sustituirá por otro número. De manera general, este otro número se representará con la letra q. Así, la función se puede escribir:

El valor numérico que tenga el factor q que aparece en esta expresión dependerá de las condiciones en que ocurra el aumento de la población. En la forma en que se establece el modelo considerado, el valor de q varía de 0 a 4.

Se puede representar la información contenida en esta expresión de manera gráfica. En una gráfica, en el eje horizontal (figura 17) se miden los valores de x y en el eje vertical los valores de y. La expresión (5) queda representada por una línea recta. Mientras mayor sea el valor de q, mayor será la inclinación de la recta. Debido a que la gráfica de la ecuación (5) es una recta se dice que la expresión (5) es lineal.

Una consecuencia de la aplicación de esta función es que, al transcurrir el tiempo, la población crecerá de manera indefinida; llegará un momento en que será tan grande que el número de individuos de la especie no cabría en el planeta. Es claro que un modelo como el que acabamos de presentar no puede describir de manera correcta las variaciones reales de una población. Si ésta crece mucho, llegará un momento en que los alimentos no alcancen para todos y, por tanto, la pcblación empezará a descender. Este efecto debe considerarse, por lo que la función dada por la expresión (5) se deberá modificar para que tome en cuenta que una población puede crecer, pero hasta cierto punto; más allá deberá reducirse. Por otro lado, si la población es pequeña, entonces tendrá mucho alimento disponible y crecerá.

Lo anterior significa que la gráfica de la figura 17 deberá ser reemplazada por otra en la que para valores pequeños de x, o sea de la población, la curva suba, mientras que para valores muy grandes de x la curva disminuya. Esta gráfica se deberá ver como se muestra en la figura 18. Para que la curva disminuya, necesariamente tendrá un máximo; es decir, la curva deberá tener la forma de una campana invertida. El lector se dará cuenta de que esta curva ya no es una línea recta. Por tanto, a esta situación se le llama no lineal.

Figura 17. Gráfica del modelo que muestra la población de insectos del año próximo (y) determinada por la población del año presente (x). En este momento la población crece sin cesar.Una forma matemática de representar la curva de la figura es la siguiente:

Esta expresión implica que, dado el valor de la población en el presente año (valor representado por x), se obtendrá el valor y de la población del año siguiente. Por conveniencia se han tomado x y y como la fracción entre los valores cero y uno, por tanto 0 q y. El valor cero representa la extinción de la población y el valor uno el máximo valor posible de la población.

Lo que nos está diciendo la ecuación (6) es que si se da x, para obtener el valor de y las operaciones que hay que hacer son:

1) De 1 le restamos x: [(1 -x)],

2) el resultado lo multiplicamos por x: [x (1 -x)]

3) este último resultado lo multiplicamos por q: [qx (1 – x)].

Así se obtiene el valor de y

Por ejemplo, si q = 2.5 y el valor de x es 0.7, obtenemos sucesivamente que:

Figura 18. Modificación del modelo de la figura 17 para tomar en cuenta el hecho de que llega un momento en que la población no puede crecer indefinidamente.

1) 1 - x = 1 – 0.7 = 0.3

2) x (1-x) = 0.7x0.3 = 0.21

3) qx (1 - x) = 2.5 x 0.21 = 0.525

El valor de la población y al año siguiente es 0.525.

Si ahora se usa como valor inicial de la población el valor que acabamos de encontrar, o sea 0.525, siguiendo el procedimiento se obtiene que la población al tercer año será 0.6234. Siguiendo esta iteración se encuentran sucesivamente los siguientes valores de la población en años sucesivos (se deja al lector verificar que estos valores efectivamente se obtienen):

0.5869, 0.6061, 0.5968, 0.6016, 0.5992,

0.6004, 0.5998, 0.6001, 0.6000, 0.6000,

0.6000, 0.6000, 0.6000, 0.6000,…

Estos resultados nos indican que a partir de cierto momento la población llega a un valor que ya no cambia con el tiempo. En nuestro caso, la población llega al valor 0.6000. En el caso que acabamos de tratar, se empezó con la población inicial de x = 0.7 y se terminó con la de 0.6000. Si en lugar de haber empezado con 0.7 se hubiera empezado con el valor inicial de x = 0.25 (para el mismo valor de q de 2.5), siguiendo el mismo procedimiento iterativo se obtendrían los siguientes valores:

0.4688, 0.6226, 0.5874, 0.6059, 0.5970,

0.6015, 0.5992, 0.6004, 0.5998, 0.6001,

0.6000, 0.6000, 0.6000, 0.6000,…

¡Se llega al mismo valor final de 0.6000! O sea, si se empieza con otra condición inicial se llega al mismo valor final. Así se comience con el valor que sea, para este caso de q = 2.5, siempre se llegará al mismo valor final de 0.6.Este resultado nos indica varias cosas acerca de la ecuación (6). En primer lugar, la población no crece indefinidamente por más iteraciones que se hagan. En segundo lugar, después de algunos años se alcanza un valor que NO depende de cuál haya sido el valor de la población inicial. Es decir, el valor 0.6 no depende de la condición inicial. Se logra así una población estacionaria: la misma año con año.

Si se vuelve a repetir este procedimiento pero para otro vabr de q en la ecuación (6) se obtendrá otro valor final. Por ejemplo, si se usa para q el valor de 2.7, el valor final que se obtiene es 0.6296. Nótese que:

para q 2.5 se obtiene como valor final 0.6

para q 2.7 se obtiene como valor final 0.6296.

A medida que q aumenta de valor, el valor final también aumenta su valor.

Vayamos ahora al otro extremo, el de un valor de q pequeño, por ejemplo 0.4. Si se empieza con una población de 0.3, entonces los valores de la población que se van obteniendo son los siguientes:

0.0840, 0.0308, 0.0119, 0.0047, 0.0019, 0.0007,

0.0003, 0.0001, 0.000, 0.000,…

El valor final al que se llega es cero. ¿La población se extingue! De hecho, para los valores de q menores o iguales que 1, la población se extingue con el tiempo, sin importar cuál sea su valor inicial.Ahora nos vamos al extremo de valores grandes de q. Por ejemplo, usemos para q el valor de 3.3 y el inicial de la población de 0.6. Así se van obteniendo los siguientes valores:

0.7920, 0.5436,

0.8187, 0.4898,

0.8247, 0.4772,

0.8233, 0.4801,

0.8237, 0.4779,

0.8236, 0.4795,

0.8236, 0.4794

0.8236, 0.4794

0.8236, 0.4794,…

Ahora no se obtiene un solo valor final que se vaya repitiendo año con año, sino que se va pasando del valor 0.8236 al de 0.4794 sucesivamente. Es decir; ahora la población en un año tendrá el valor de 0.4794 y al año siguiente el de 0.8236; el año siguiente se repetirá el valor de 0.4794 y luego, nuevamente el de 0.8236, y así sucesivamente. Esto significa que ahora se tienen dos valores finales posibles y que el valor de 0.4794 se alcanza no cada año sino cada dos años. Lo mismo ocurre con el otro valor de 0.8236. Es decir, el ciclo ahora dobló su valor de un año a dos; es decir, aparece ahora una periodicidad de 2 años. Nótese que los valores 0.8236 y 0.4794 no dependen del valor inicial que se escogió. Si en lugar de 0.6 se hubiera tomado otro valor, llegaríamos a los mismos valores finales (0.8236 y 0.4794); esto siempre y cuando se mantenga el mismo valor de q o sea, 3.3. Se dice que estamos en condiciones de periodo dos.Para el valor de q = 3.5, con la condición inicial de 0.6, se obtienen, después de varias iteraciones, no dos valores finales sino cuatro, que son 0.3028, 0.8260, 0.5001 y 0.8750.

Estos cuatro valores se van repitiendo, en el orden dado. Ahora esto corresponde al período 4.

Si se sigue aumentando el valor de q, se obtienen ocho valores finales. Para q =3.55 por ejemplo, éstos son:

0.3548, 0.8127, 0.5405, 0.8817

0.3703, 0.8278, 0.5060, y 0.8874 Esta situación corresponde al periodo 8.

Para q =3.651, ahora los valores finales serán 16, que ya no escribiremos. Al seguir aumentando q se obtienen, sucesivamente, 32, 64, 128,… valores finales.

Si ahora se escoge para q el valor de 3.6, resulta que por más iteraciones que se hagan no se llega a un valor final, en el sentido de que este valor (o valores) se repita como en los casos mencionados arriba. Ahora se encuentra una sucesión de números que no se repiten y que tienen toda la apariencia de una sucesión escogida al azar. Si se cambia la condición inicial, pero se mantiene el valor de q 3.6, se obtiene otra sucesión con números distintos de los anteriores y que tampoco adquiere valores finales que se repiten constantemente.

Figura 19. Gráfica de los valores finales que se obtienen con referencia a la población como función del parámetro q y que muestra dos tipos de regímenes: el periódico (estable) y el caótico.Estos resultados pueden observarse haciendo la siguiente gráfica (figura 19) En el eje horizontal mediremos los valores de q; en el eje vertical se medirá(n) el(los) valor(es) final(es) que se obtenga(n)para el correspondiente valor de q. Así,

para q = 2.5, cuyo valor final = 0.6000 le corresponde el punto A;

para q = 2.7, cuyo valor final = 0.6296 le corresponde el punto B;

para q =0.4, cuyo valor final = 0 le corresponde el punto C;

para q = 3.3, cuyos valores finales = 0.8236 y 0.4794 le corresponden los puntos D y E;

para q = 3.5, cuyos valores finales no los escribiremos, le ccrresponden los puntos F, G, H, I, etcétera.

Los valores de q para los cuales no se obtienen valores finales, se marcarán en la gráfica con una línea completa, ya que todos los valores son posibles.

De la gráfica se puede observar lo siguiente, a medida que va aumentando el valor de q:

Para q menor o igual que 1, los valores son nulos; hay extinción de la población.

Para q entre 1 y 3, solamente hay un solo valor final, el del estado estacionario, que va aumentando a medida que q aumenta. En este intervalo la gráfica es la línea curva KL

Al seguir aumentando q, en L empieza a aparecer una bifurcación que da dos valores finales. Así q entre 3 y 3.45 tiene dos valores finales; estamos en la región del periodo 2. La gráfica en este intervalo consiste en dos líneas curvas, la LR y la LS.

Si q sigue aumentando, para el valor de 3.45 (aproximadamente) aparecen otras dos bifurcaciones y ahora se tendrán cuatro valores finales. De hecho entre 3.45 y 3.54 estaremos en la región del periodo 4 y la gráfica muestra cuatro líneas curvas, que ya no nombraremos.

Al seguir aumentando q, aparecen nuevas bifurcaciones y nuevas líneas curvas hasta que, finalmente, cuando q adquiere el valor de 3.5699 ya no hay valores finales fijos y se tiene una región con manchas que se llama caótica. En esta región y adquiere cualquier valor.

Como se puede apreciar en la figura, dentro de la región caótica aparecen regiones que sí tienen valores fijos. Estas son las regiones blancas de la figura. En efecto, para q alrededor del valor 3.84 aparece una región con valores finales bien determinados. Ahora se obtienen tres valores: 0.1494, 0.4879 y 0.9594. Al seguir aumentando q hay una bifurcación y por ejemplo, para q 3.846, ahora hay seis valores finales. Al seguir aumentando q siguen las bifurcaciones, hasta que se llega a una nueva región caótica.

Podemos entonces afirmar que al ir aumentando q, se pasa por los siguientes regímenes:

extinción un solo valor final periódicos con periodicidades de 2, 4, 8, 16,… caótico periódicos con periodicidades de 3, 6,… caótico,

Estos resultados se obtuvieron con el estudio de la función dada por la ecuación (6). Sin embargo, hay muchas otras funciones, distintas de ésta, pero cuyas gráficas tienen la misma forma cualitativa mostrada en la figura 19. Resulta que para todas estas funciones distintas el comportamiento de los valores finales es el mismo que se explicó en este capítulo. Este comportamiento es característico de las funciones no lineales.

En capítulos posteriores analizaremos algunas consecuencias de este comportamiento.

EN ESTE capítulo se examinará una forma diversa de considerar al fenómeno caótico. Regresemos al caos de la población que tratamos en el capítulo anterior. Vimos que si el valor del parámetro q de la ecuación (6) es suficientemente pequeño, entonces, sea cual sea el valor inicial de la población, es decir, el valor inicial de x, después de cierto número de iteraciones se llega a un valor final que ya no cambia al seguir iterando. Recordando que cada iteración nos da el valor de la población un año después, concluimos que si q es suficientemente pequeño, después de cierto tiempo se llega a una población final que ya no varía al transcurrir el tiempo.Si q aumenta, ocurre que después de ciertas iteraciones la cantidad x adquiere dos valores. En una iteración adquiere el primero, y en la siguiente, el segundo, y estos dos valores se van alternando. Esto significa que después de cierto tiempo, en un año la población tiene un valor y al siguiente el segundo valor. En el tercero la población vuelve a tener el primer valor, en el cuarto el segundo valor, y así sucesivamente. Por lo tanto, el primer valor final lo adquiere la población cada dos años; lo mismo ocurre con el segundo valor, la población lo va adquiriendo cada dos años. Este era el régimen que se llama de periodicidad dos.

Al seguir aumentando el valor de q se llega a un régimen final en el que hay cuatro posibles valores finales de la población, que se van alternando. Por tanto, cada uno de estos valores se va adquiriendo cada cuatro años. Estamos en el caso de la periodicidad cuatro.

Podemos así continuar, hasta que se llegue al régimen caótico, en que cada año la población va adquiriendo cierto valor que ya no se repite.

Ahora bien, lo anterior significa que, antes de entrar en el régimen caótico, el periodo va aumentando de 1 a 2 años, a 4 años, a 8 años, etc., a medida que el valor de q va aumentando. Llega cierto momento en que ya no se puede hablar de periodo, se ha entrado en el régimen caótico.

Otra forma de presentar estos resultados es en términos de la frecuencia y no del periodo. Estas dos cantidades están íntimamente relacionadas. El periodo es el tiempo que tarda algún fenómeno en volverse a repetir, por ejemplo, el tiempo en que tarda la Tierra en dar una vuelta alrededor de su eje es el periodo de su rotación. Como sabemos este periodo es de 24 horas. Es claro que para poder hablar de periodo el fenómeno debe ser repetitivo, esto es, periódico.

La frecuencia de un fenómeno periódico es el número de veces que se repite en un segundo, en un minuto o en otra unidad de tiempo. Si un tocadiscos da 33 vueltas por minuto, esto significa que su frecuencia es de 33 revoluciones por minuto, abreviado 33 rpm.

Un ejemplo de fenómeno repetitivo es cuando un cuerpo se mueve alrededor de un círculo. Supongamos que el cuerpo tarda 5 segundos en dar una vuelta; su periodo es de 5 segundos. Por lo tanto, en un segundo el cuerpo habrá dado (1/5) de vuelta; su frecuencia es (1/5) = 0.2. De este ejemplo vemos que si el periodo tiene cierto valor, llamémosle T, entonces su frecuencia es igual a (1/T). La frecuencia es igual al inverso del periodo.

Regresando al caso de la población que estudiamos antes, llegamos a la conclusión de que al ir aumentando el valor de q el periodo aumenta a 2, luego a 4, luego a 8, y así sucesivamente, hasta llegar al régimen caótico. Expresando esto en términos de frecuencia, vemos que si para un valor de q solamente hay un periodo esto equivale a un valor de la frecuencia.

Figura 20. Gráficas que muestran las frecuencias características que gobiernan el fenómeno para valores recientes de q. A medida que q crece, aumenta el número de frecuencias.Al aumentar el valor de q, el periodo aumenta al doble y por tanto, la frecuencia disminuye entonces a la mitad.

Al seguir aumentando el valor de q, el periodo aumenta cuatro veces, por lo que la frecuencia disminuye cuatro veces.

Al continuar aumentando el valor de q, el periodo aumenta ocho veces, por lo que la frecuencia disminuye ocho veces, etcétera.

En consecuencia, si para cada valor de q se hiciera una gráfica de la frecuencia que corresponde al fenómeno, se encontraría la sucesión de gráficas de la figura 20. Cada gráfica de esta sucesión corresponde a un valor de q. Vemos entonces que los picos de las gráficas, a medida que q aumenta, van apareciendo a la mitad del valor de la frecuencia anterior. Cuando se llega al régimen caótico, entonces ya no hay ningún pico, ya que no hay periodo, y por tanto, no hay ninguna frecuencia característica.

Una forma de obtener resultados experimentales, como en el caso de la turbulencia, es por medio de análisis de frecuencias del fenómeno en cuestión. Este es el motivo por el cual introdujimos la explicación en términos de esta cantidad.

UNA de las más grandes metas de la ciencia es ser capaz de predecir fenómenos. Veamos con un poco de detalle lo que esto significa.Después de investigar a fondo un fenómeno específico, se han podido establecer los mecanismos que rigen este fenómeno. Por ejemplo, el caso del movimiento de los planetas alrededor del Sol fue estudiado por Newton, quien demostró que, si hay una fuerza entre cuerpos que tienen masa, dada por la ley de la gravitación universal que propuso, entonces, de acuerdo con sus leyes de movimiento los planetas deberían girar alrededor del Sol en elipses. Newton estableció ciertas ecuaciones matemáticas que describen el fenómeno y, a partir de la solución de sus ecuaciones, encontró las elipses. Es decir, Newton pudo hacer una predicción. Esta forma de proceder se llama en física construir un modelo. De alguna forma este modelo refleja matemáticamente las características físicas del sistema: en este caso, de la relación entre los planetas y el Sol.

Pero esto no es todo. Por medio de sus resultados Newton pudo considerar lo siguiente: si se llega a saber dónde se encuentra un planeta en determinado momento, se podrá saber dónde estará en cualquier otro instante de tiempo. Es decir, si se conocen las condiciones iniciales del planeta se puede determinar su trayectoria en el futuro. Aplicadas estas ideas al movimiento del cometa Halley, este científico inglés predijo en el siglo XVIII, que el cometa debería regresar cada 76 años, hecho que en efecto ha ocurrido; las dos últimas apariciones fueron en 1910 y en 1986.

Sin embargo, para poder especificar las condiciones iniciales es necesario medirlas con algún aparato. Como resultado de la medición de cualquier cantidad se obtiene un número. Pero este número contiene incertidumbres, ya que en el proceso de medición en que lo obtenemos hay factores que, en general, no se pueden controlar. Por ejemplo, si se mide el peso de un cuerpo con una balanza, pueden ocurrir errores en la lectura de la aguja, debido a alguna vibración qué produzca el paso de un vehículo, o a causa de alguna corriente de aire, etc. Es decir, siempre que se mide algo hay errores. Por tanto, ccmo resultado de una medición se debe dar el número obtenido así como los límites de los errores que se puedan cometer.

Así, por ejemplo, como resultado de una medición de peso se dirá que el peso del cuerpo de interés se encuentra entre 54.5 kg y 54.8 kg. El "verdadero" valor del peso está dentro de este intervalo. El intervalo:

54.8 kg – 54.5kg = 0.3kg

es un cálculo del error cometido al hacer la medición.

Por supuesto que mientras menores sean los errores que se cometan, mejor será el resultado de la medición. Lo más que se puede hacer es lograr que el intervalo dentro del cual caen las mediciones disminuya, pero no se puede eliminar.

En general, podemos afirmar que no se puede hacer una medición con precisión absoluta. Siempre se tendrá un intervalo de error dentro del cual cae el "verdadero" valor. Los límites de error experimental son estimaciones cuantitativas de la importancia de las perturbaciones que muchos factores externos, prácticamente imposibles de controlar, provocan en la medición. La determinación del intervalo de error experimental es parte del trabajo cotidiano de un científico experimental. Mientras menor sea el intervalo de error, más precisa será la medición efectuada.

Como consecuencia del hecho de que una medición contiene errores, ocurre lo siguiente: supongamos que se lanza hacia abajo una piedra desde 7 m de altura sobre el suelo (figura 21(a)) y queremos predecir dónde estará la piedra después de 2 segundos. Si tenemos un modelo necesitaremos introducir las condiciones iniciales; en este caso, una es la altura sobre el suelo. Supóngase que al medir la posición inicial de la piedra se encuentra que los errores experimentales la sitúan entre los puntos A y B de la figura, con un intervalo de 0.12cm. El modelo que se tiene puede entonces predecir que después de 2 segundos, la piedra se encontrará a una altura de 1.5 m sobre el suelo. Ahora supondremos que se produce una de las dos situaciones siguientes:

1) La piedra deberá estar en un intervalo de 0.14 cm entre los puntos C y D (figura 21(b))

2) La piedra deberá estar en un intervalo de 2.15 cm entre los puntos C y D (figura 21(c)).

Si el modelo con el que se trabaja da lugar a los resultados del inciso (2) entonces no se puede hablar de que el modelo predice dónde estará la piedra después de 2 segundos, ya que los límites de error se magnificaron: de 0.12 cm a 2.15 cm. Este resultado casi nos dice que la piedra puede estar, después de 2 segundos, en cualquier lugar. Claramente esto no es lo que llamaríamos una predicción.

Figura 21. Al transcurrir el tiempo, el error inicial en la determinación de la posición de la piedra (a) puede quedar dentro de un intervalo análogo al inicial (b) o puede crecer mucho (c).Por otro lado, en el caso del inciso (1) vemos que los errores se mantuvieron muy parecidos a los de la determinación inicial. Se considera que en este caso el modelo ha predicho la posición de la piedra. No es posible hacer una mejor predicción.

Si se hace un experimento para determinar la posición de la piedra, los límites de error deberán ser análogos a los hechos en el momento en que se determinó la posición inicial.

En consecuencia, si los parámetros del sistema que se está considerando son tales que la propagación de los errores no se amplifica, entonces el modelo sí predice el comportamiento futuro del sistema (éste sería el caso del inciso (1)). Si ocurre que los límites de error se amplifican (como en el caso del inciso (2)), entonces el modelo no es capaz de predecir el comportamiento futuro del sistema.

Ahora trataremos esta cuestión de la predicción para el caso que se consideró en el capítulo VIII, es decir, la forma en que evoluciona una población dada por la ecuación (6), es decir, para el caso no lineal.

Consideremos el caso de q 2.5 y tratemos dos condiciones iniciales muy cercanas: 0.25 y 0.27. A continuación presentamos las primeras iteraciones:

En la última columna se presenta el cálculo de la diferencia entre los valores de cada renglón.

Se puede observar que, en primer lugar, la diferencia entre los valores iniciales es 0.27 – 0.25 0.02. En segundo lugar, si se observa la columna de diferencias podemos afirmar que éstas nunca son mayores que 0.02, la diferencia inicial (excepto en el primer renglón, en que es de 0.024, que es parecido a 0.02), sino que disminuyen a medida que progresamos en la iteración hasta que finalmente son prácticamente nulas. Esto último es una manifestación de algo que ya conocemos. No importa cuales sean las condiciones iniciales, para el caso de q = 2.5, siempre se terminará con el valor final de 0.6. En consecuencia, en este caso el modelo sí es capaz de hacer una predicción, ya que los límites de error iniciales no se amplifican, sino que prácticamente se llega al mismo resultado (0.6) sin importar cuál haya sido el valor inicial de la población.

Por otro lado, supóngase que el valor de q es igual a 3.6 y se tratan dos condiciones iniciales, por ejemplo, 0.60 y 0.63; si uno se pregunta cuáles son las poblaciones en las iteraciones 98, 99 y 100, se obtienen los siguientes valores:

En primer lugar, vemos que la diferencia entre los valores iniciales es 0.63 – 0.60 = 0.03. En segundo lugar observamos que para estas iteraciones, las diferencias no son del mismo tamaño que la inicial. Estas diferencias llegan a ser mucho mayores que 0.03 y además son muy variables, la primera es de 0.1154, luego es 0.0838 y enseguida crece fuertemente a 0.2122. Podemos afirmar entonces que si la situación es tal que q =3.6, los límites de error iniciales no nada más se amplifican, sino que se vuelven azarosos. Por tanto, en este caso el modelo no es capaz de predecir la situación futura de la poblacion.

Del análisis de estos dos casos concluimos que: a) el modelo es capaz de hacer predicciones, en el sentido que arriba mencionamos, si los parámetros del sistema (en nuestro caso el valor de q) son tales que ocurre un comportamiento periódico, y b) que el modelo no es capaz de hacer predicciones si los parámetros son tales que se está en la región caótica.

Por otro lado nos damos cuenta de que, para cualquier valor del parámetro q, la regla para hacer iteraciones está completamente determinada. Esto significa que el modelo es determinista. si uno da el valor de q y la condición inicial de x, siempre obtendrá el mismo valor para la iteración 127, digamos. En consecuencia, este modelo es determinista y presenta dos tipos de regímenes: el periódico y el caótico. Puede parecer a primera vista que hay una contradicción entre estos términos. Sin embargo, como se ha ilustrado, éste no es el caso.

En este punto conviene hacer una aclaración muy importante. El modelo constituye la descripción de una parte de la naturaleza: puede ser descrito en términos matemáticos o no. Así el modelo dado en el capítulo VIII trata de representar un fenómeno, el de la variación de la población de insectos. El modelo es el que puede ser determinista o no, puede ser caótico o no. En nuestro caso el modelo sí es determinista, porque se puede determinar cuantas veces se quiera el valor de la población en el instante que se quiera (o sea la iteración que se quiera) habiendo dado el parámetro q y la condición inicial de x.

No hay que confundir entre el modelo que trata de representar a cierta realidad con la realidad misma.

Se ha ilustrado un hecho muy importante. Un modelo determinista, como el de la ecuación (6), en ciertas condiciones de los valores de los parámetros (por ejemplo q) puede predecir el comportamiento futuro y los errores en las condiciones iniciales no se amplifican. En otras condiciones, para otros valores de los parámetros, el modelo no puede predecir el comportamiento futuro; ahora los errores en las condiciones iniciales se amplifican y además el comportamiento se vuelve azaroso. En el primer caso (donde sí se pueden hacer predicciones) el sistema está en un régimen periódico. En el segundo caso (donde no se pueden hacer predicciones) el sistema está en un régimen caótico. Nótese que ambos tipos de comportamientos ¡se dan en el mismo sistema!

EN LA figura 22(a) se muestra una porción amplificada de la gráfica de la figura 19. Considérese la región QPRT que ccrresponde al periodo tres. Si se amplifica esta porción se obtiene la figura 22(b).Ahora tomamos la región KLMN de esta última figura, la amplificamos y se encuentra la figura 22(c).

Se observará que la figura 22(c) se parece a la 22(b); a su vez, la 22(b) se parece a la 22(a). Si se siguieran haciendo amplificaciones a escalas cada vez más y más grandes, se obtendrían figuras que se parecerían unas a otras.

Por tanto, recordando lo que se presentó en los capítulos V y VI, vemos que la estructura geométrica de las gráficas de la figura 19 es autosimilar, y por lo tanto forman un fractal.

Lo anterior ilustra el hecho de que hay una relación entre caos y fractales.

Figura 22. Varias amplificaciones de la gráfica de la figura 19 muestran que ésta es autosimilar.

Vamos a formar una secuencia de números de la siguiente forma. Empecemos con el cero y el uno; si los sumamos nos da:

0+1 = 1.

Sumemos ahora el 1 de la derecha con el anterior 1 del lado izquierdo:

1+1 = 2.

Ahora sumemos este 2 con el 1 que está a la izquierda, antes del signo igual:

1+2 = 3

y seguimos formando la secuencia, sumando el resultao con el último número del lado izquierdo:

2 + 3 =5

3 + 5 = 8

5 + 8 = 13,

y así sucesivamente.De esta manera se forma la secuencia llamada de Fibonacci, que es,

0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89,…

Esta secuencia tiene características aritméticas muy interesantes y, sin haberse pretendido, tiene aplicaciones importantes, como veremos.

En primer lugar, multipliquemos cada número de la secuencia por el número 1.6. Así se obtiene la siguiente secuencia:

0, 1.6, 1.6, 3.2, 4.8, 8.0, 12.8, 20.8, 33.6,…

Si ahora redondeamos cada uno de estos números al entero más cercano encontramos:

0, 2, 2, 3, 5, 8, 13, 21, 34,…

que a partir del segundo 2 es ¡precisamente la secuencia de Fibonacci! (a excepción de unos términos iniciales y posiblemente algunos posteriores). Esto es, resulta que la secuencia de Fibonacci es autosimilar.Ahora vamos a construir otra secuencia, a partir de la de Fibonacci, como sigue. Tomamos un número de la secuencia de Fibonacci y lo dividimos entre el siguiente. Si empezamos con el segundo, que es 1, y lo dividimos entre el tercero, que también es 1, nos da:

Ahora dividimos el tercero, que es 1, entre el cuarto, que es 2, y nos da:

Al dividir el cuarto, que es 2, entre el quinto, que es 3, nos da:

Si seguimos así obtenemos los siguientes números:

etc. Si seguimos así nos daremos cuenta de que todos los demás cocientes se van acercando al número 0.618. Este último recibe el nombre de la media dorada. Otra manera de obtenerlo es como sigue:Sumemos 1 con 1, que nos da 2. Tomemos su inverso:

Sumemos 1 a este número

Tomemos su inverso:

El lector se dará cuenta que lo que hizo es la operación siguiente:

Ahora repetimos el procedimiento con 0.666. Le sumamos 1, que nos da 1.666 y tomamos su inverso:

Nótese que lo que se ha hecho hasta ahora es:

Continuando de esta manera se obtienen las siguientes formas. Le sumamos 1 a 0.6 y obtenemos 1.6. Su inverso es:

Este valor también se puede escribir como sigue:

Si se continúa con este procedimiento llega un momento en que se obtiene el número 0.618. Continuando, le sumamos 1 y obtenemos 1.618. Su inverso es:

¡Otra vez 0.618! Por tanto, al continuar con el procedimiento obtendremos todo el tiempo 0.618. En la figura 23 se muestra la forma de encontrar este número 0.618, que recibe el nombre de la media dorada.A este tipo de quebrados se les llama fracciones continuas. Por lo tanto, la media dorada se obtiene también como una fracción continua. En la figura 23 vemos que es geométricamente autosimilar.

La secuencia de Fibonacci fue obtenida por primera vez en 1202 por el matemático italiano Leonardo de Pisa, hijo de Bonacci (en italiano, figlio de Bonacci, o Fibonacci, nombre que se le quedó), al tratar la cuestión del crecimiento de una población de conejos. Se hizo la pregunta de cuántas parejas de conejos habrá después de cierto número de temporadas de crianza, esto es, cómo se multiplican los conejos. Para simplificar supuso lo siguiente:

1) Se empieza con una pareja inmadura.

2) Los conejos maduran una temporada después de haber nacido.

3) Las parejas de conejos maduras producen una nueva pareja cada temporada de crianza.

4) Los conejos nunca mueren.

Figura 23. La sucesión de operaciones para obtener la media dorada es autosimilar. De acuerdo con estas reglas, el número de conejos en una generación es igual a la suma de las parejas de conejos que hay en las dos generaciones anteriores. Si se empieza con una pareja, después de una temporada se produce una nueva pareja. Por tanto, al final de la temporada hay 1 + 1= 2 parejas de conejos. Si se sigue de esta manera se encuentran los siguientes números de parejas en las sucesivas temporadas:

1, 1, 2, 3, 5, 8, 13, 21,34,…

que es precisamente la secuencia de Fibonacci.Otra manera de ver lo anterior es como sigue: vamos a llamar con el número 0 a una pareja inmadura y con el 1 a una pareja madura. Por tanto, después de una temporada una pareja inmadura (0) producirá una pareja madura (1), o sea, donde hay un 0 1. Además, una pareja madura (1) produce una pareja inmadura (0) y, por lo tanto, después de esta temporada existirán la pareja madura (1) y la inmadura (0). En consecuencia, después de una temporada donde hay un 1 10. Con esta regla de transformar unos y ceros, veamos qué se obtiene al transcurrir las temporadas.

Si empezamos con 0 1; este 110; el último 110, y el 0 se transforma en 1, por lo que el 10 101. Transformando cada uno de estos números de acuerdo con la regla que dimos:

10110110

Este último número se transforma, a su vez, en:

1011010110101

y éste a su vez en:

101101011011010110110,

y así seguimos indefinidamente. De esta forma se obtiene la secuencia siguiente0, 1, 10, 101, 10110, 10110101, 1011010110110,…

llegando después de muchas temporadas, al número:

1011010110110…

¿Es esta secuencia autosimilar? En este número vamos a subrayar las parejas "10":

10 1 10 10 1 10 1 10…

Si en lugar de cada pareja "10" subrayada sustituimos ahora un "1", y en lugar de cada "1" no subrayado sustituimos un "0", encontramos lo siguiente:

10110101…

que es la secuencia (A).

Figura 24. Una pareja inmadura se muestra en blanco y otra, madura, en negro. Son los resultados que se obtienen en cada temporada.Esta secuencia la podemos ver gráficamente como sigue (figura 24). Dibujemos una pareja inmadura en blanco, y una pareja madura en negro. Al principio hay sólo una pareja inmadura (renglón 1). Después de una temporada, esta pareja llega a la madurez (renglón 2) y, además de seguir viviendo, produce una pareja inmadura después de una temporada. Por tanto, en la tercera temporada (renglón 3) hay una pareja madura y una inmadura. Siguiendo con este razonamiento, se muestran en la figura 24 las poblaciones en varias temporadas posteriores. Si ahora representamos una pareja inmadura (en blanco) con el "0" y a una madura (en negro) con el "1", se van obteniendo las siguientes secuencias

0

1

10

101

101 10

10110101

que son precisamente las secuencias que vimos arriba. El lector se dará cuenta de que una pareja inmadura (0) produce una pareja madura (1), o sea, 0 1. Además, después de una temporada, una pareja madura (1) produce una inmadura (0), por lo que al final de la temporada quedan la madura (1) y la inmadura (0), o sea, 1 10. Estas transformaciones son precisamente las que se usaron arriba

UNA consecuencia obtenida al aplicar el concepto de la autosimilitud fue lograr la predicción de la existencia de una nueva fase de la materia, a saber, los cuasicristales. Haremos una breve revisión de algunos conceptos referentes al estado sólido.La materia se encuentra a nuestro alrededor formando diferentes fases: la gaseosa, la líquida y la sólida.

En la fase gaseosa, los átomos o moléculas se mueven y giran totalmente al azar. Esto da como consecuencia que el gas no tenga ninguna estructura.

En un líquido los átomos también están desordenados. En un sólido se dan varias posibilidades. En un caso importante los átomos se encuentran situados al azar, o sea desordenados; éste es un sólido amorfo. Un ejemplo son los vidrios.

En otros sólidos, los átomos se encuentran formando redes periódicas, dando lugar a un cristal. Muchas sustancias sólidas conocidas son cristales, como la sal de mesa, formada por átomos de cloro y de sodio (figura 25) o los diamantes. En un cristal los arreglos son periódicos, lo que significa que se repiten. Además, en un cristal hay simetrías, lo que significa que si se traslada el cristal a determinada distancia, entonces el patrón se repite. Por ejemplo, en la figura 26 se muestran redes cristalinas en dos dimensiones (debido a que se encuentran en un plano, el de la hoja). Si se traslada cualquiera de ellas adecuadamente, se vuelve a repetir la red.

Figura 25. Esquema de un cristal. Nótese que cada celda se va repitiendo.

Figura 26. Simetrías de un cristal en dos dimensiones: (a) simetría de 180°=360°/2; (b) simetría de 90°=360/4; (c) simetría de 120°=360°/3 y (d) simetría de 60&#/6. No hay simetría de 360°/5=72°.

Figura 27. Una celda en que los átomos ocupan los vértices de un hexágono tiene simetría de 60°=360°/6.Nos damos cuenta de que cada una de estas redes tiene una simetría. Esto quiere decir que si se gira la red por cierto ángulo alrededor de un punto que esté en el centro del "azulejo", se vuelve a recuperar la red. Por ejemplo, en el caso de la figura 27, que está formada de "azulejos" hexagonales, si se gira el patrón alrededor del punto C en un ángulo de 60°, el punto A cae en el punto B, que es un punto de la red. Si el ángulo que se girara fuera de 45° digamos, entonces el punto A caería en el punto D, que no es punto de la red, y ésta no se reproduciría. Decimos que la red hexagonal tiene simetría de 60° = 360°/6. Para los casos de la figura 26, al girar el punto A alrededor de C al ángulo anotado a continuación, llega al punto B, que es un punto de la red. Las simetrías son entonces:

a) figura 26(a): 180°= 360°/2; b) figura 26(b): 90° = 360°/4; c) figura 26(c): 120°= 360°/3; d) figura 26(d): 60° = 360°/6.

En la teoría del estado sólido se demuestra que, en el caso de dos dimensiones, éstas son las únicas posibles simetrías.

Un caso prohibido es la simetría de 5, o sea la que resultaría de un giro de 360&3176/5 = 72°. La demostración es la siguiente: supóngase que los puntos A y B sean puntos de una red, en que la distancia AB sea la mínima en el cristal (figura 28(a)). Los puntos A y B están entonces ocupados por átomos. Si hubiera simetría de 72°, esto querría decir que si se gira el cristal, con centro en el punto A, por un ángulo de 72° (figura 28(b)) entonces el punto B caería en el punto C, que debería ser ocupado por un átomo. De la misma forma, al girar el cristal por un ángulo de 72° alrededor del punto B (figura 28(c)), el punto A caería en el punto D, que también debería ser ocupado por un átomo. En consecuencia, los puntos C y D también serían puntos de la red cristalina (figura 28(d)). Vemos que la distancia CD es menor que la distancia AB. Pero se partió del hecho de que la mínima distancia entre dos átomos es la distancia AB. Por lo tanto se llega a una contradicción, hecho que indica que no puede darse este tipo de simetría.

Lo que hemos mencionado para el caso de dos dimensiones, también se aplica en el de tres dimensiones. No todas las simetrías son posibles.

Durante muchos años así lo pensaron los científicos e ingenieros. Sin embargo, en 1984 se anunció el descubrimiento de la fase de una aleación de aluminio-manganeso que tiene simetría de 72°. Esto se descubrió por medio del patrón de difracción de electrones mostrado en la figura 29. La muestra se bombardea con un haz de electrones y se registran en una película las direcciones de los electrones que salen de la muestra.* Solamente diremos que este patrón refleja las simetrías que tiene la sustancia. Se puede ver en la figura 29 que si se gira el patrón alrededor del centro un ángulo de 72º, se vuelve a recuperar el patrón original. Es decir, hay simetría de 72°.

Figura 28. Demostración de que la simetría de 72° = 360°/5 no es posible. La pregunta que inmediatamente surgió fue: ¿cómo es posible llenar el plano con cierta figura de manera completa? Si nos fijamos en la figura 26(b) vemos que con la celda cuadrada es posible llenar completamente un plano. Por este motivo es que ocurre la simetría 4. Es posible llenar el plano con cada una de las forma de la figura 26. ¿Cómo sería posible llenar el plano para que se obtenga una simetría de 72°?

Una manera de llenar un plano con esta simetría es la mostrada en la figura 30. A primera vista la figura da la impresión de ser periódica. Sin embargo, a diferencia de lo que pasa con las formas de la figura 26, si nos fijamos con detenimiento, veremos que ahora ya no hay periodicidad. A este tipo de estructura se le llama cuasicristal.

Se han descubierto también cuasicristales de tres dimensiones, mas no hablaremos de ellos.

Figura 29. Patrón de difracción de electrones en una muestra de aluminio-manganeso que tiene la simetría de 72° = 360°/5.

Figura 30. Forma en que se puede llenar todo el plano con figuras que tiene la simetría de 72°. Nótese que esta estructura no es periódica.Pero, ¿qué tiene que ver todo esto con la autosimilitud? Para contestar esta pregunta vamos a construir, en primer lugar, una red de una dimensión, es decir; a lo largo de una línea recta. Para este fin consideremos primero una red cuadrada como la que se muestra en la figura 31(a). Ahora tracemos una línea recta (figura 31(b)) que forme con el eje horizontal un ángulo de 58.280. Esta línea es la LK. Al lector que sepa trigonometría le diremos que este ángulo es tal que su tangente es igual a (1/0.618) = 1.618, donde 0.618 es la media dorada de la que se trató en el capítulo anterior. Es decir, el ángulo de 58.28° está relacionado con la media dorada.

Figura 31. Procedimiento de construcción de un cuasicristal a lo largo de una línea recta. En el texto se ilustra la importancia de la media dorada para esta constucción.La línea recta LK cruza varios cuadrados de la red, como por ejemplo, el ABCD. Ahora bien, cada vez que la línea entre en un cuadrado, desde el vértice superior izquierdo se trazará una línea perpendicular a la línea recta. Así, en el cuadrado ABCD, el vértice superior izquierdo es D; desde D se traza la línea DQ, perpendicular a la línea LK De esta manera se forman en la línea los puntos Q, P, R, T,S,… y resulta que las distancias QP, RT, TS sólo adquieren dos valores. Las distancias QP, RT, TS son iguales entre sí; asimismo, las distancias PR, SV, WX,… son también iguales entre sí. De las dos distancias que se forman, una es más grande que la otra. Por ejemplo, PR es menor que QP. Resulta que la relación entre estas dos distancias diferentes que así se forman es:

¡igual a la media dorada! Si llamamos longitud grande igual a "1" y a la pequeña igual a "0", entonces las longitudes en las que se divide la línea transversal, a partir de Q, son (figura 31(c)):

1011010110110…

que es precisamente la secuencia de Fibonacci, que se trató en el capítulo anterior (véase (A) de la página 72). Si ahora consideramos la línea LK y en los puntos Q, P, R,… se colocan átomos, se forma un cuasicristal en una dimensión.Para los casos de dos y tres dimensiones se puede hacer algo análogo. Sin embargo, esto implica consideraciones en las que no entraremos y solamente diremos que se puede hacer con ayuda de una computadora. Para el caso de dos dimensiones lo que se obtiene es el arreglo mostrado en la figura 32. Si uno se fija con cuidado, los puntos de esta red no forman una red periódica. Resulta que estos puntos corresponden a los vértices de la red mostrada en la figura 30. Nótese que esta red cubre completamente todo el plano pero no es periódica.

Por otro lado, el patrón de difracción de electrones que produce una red como la mostrada en la figura 32 es ¡precisamente el patrón mostrado en la figura 29! En consecuencia, el patrón de la figura 29 obtenido experimentalmente, corresponde a una red con simetría de 72°.

Figura 32. Cuasicristal construido en dos dimensiones siguiendo el procedimiento correspondiente a la figura 31 en un plano.Podemos afirmar que las redes que se construyeron en las figuras 31(c) y 32 son cuasicristales, en una y dos dimensiones, respectivamente.

De la manera en que se construyeron estos cuasicristales vemos que llevan inmersos dentro de sus estructuras una característica de autosimilitud, que se encuentra en la secuencia de Fibonacci.

[Nota *]* Para más detalles de cómo se encuentra una estructura microscópica a partir de un patrón de difracción, véase E. Braun, Arquitectura de sólidos y líquidos, Fondo de Cultura Económica. La Ciencia desde México, núm. 26, 1987.

UNO de los notables descubrimientos de Newton fue la ley de la gravitación universal, según la cual si dos cuerpos tienen masa, cuando están cerca uno del otro hay una fuerza de atracción entre ellos. Así, por ejemplo, la Tierra atrae a la Luna y el Sol a la Tierra. Para nuestros propósitos, lo importante de esta ley es que nos indica, en primer lugar, que la fuerza entre los cuerpos depende de la distancia entre ellos. No da lo mismo tener dos cuerpos muy cercanos uno del otro que muy separados. Mientras mayor sea la distancia entre los cuerpos menor será la fuerza entre ellos, ya que a medida que la distancia entre dos cuerpos sea mayor, menor será el efecto que uno ejerza sobre el otro.En segundo lugar, la ley de la gravitación universal nos indica cómo depende la fuerza de la distancia. Supongamos que dos cuerpos están a una distancia de un metro y la fuerza tiene determinado valor. Si la distancia entre estos mismos cuerpos aumenta al doble, o sea a 2 m, entonces la fuerza disminuye a la cuarta parte. Si la distancia aumenta al triple, o sea a 3 m, la fuerza disminuye a la novena parte, etcétera.

La cuarta parte de la fuerza es igual a 1/4; pero 4 = 2², o sea, 2 elevado a la potencia 2; por lo que la cuarta parte es igual a 1/2².

La novena parte de la fuerza es igual a 1/9; pero 9 = 3², o sea, 3 elevado a la potencia 2; por lo que la novena parte es igual a 1/3², etc. En consecuencia: si la distancia aumenta 2 veces, la fuerza disminuye 1/2² veces; si la distancia aumenta 3 veces, la fuerza disminuye 1/3² veces; si la distancia aumenta 4 veces, la fuerza disminuye 1/4² veces, etcétera.

Esto último se expresa diciendo que la disminución del valor de la fuerza es como el cuadrado de la distancia. En forma abreviada, usando lenguaje matemático lo anterior se expresa diciendo que la fuerza depende en forma inversamente proporcional al cuadrado de la distancia. Inversamente quiere decir que al aumentar la distancia disminuye la fuerza.

Ahora bien, si en lugar de haber considerado la distancia en la escala de metros la hubiéramos tomado en la escala de kilometros, la forma en que varía la fuerza con la distancia no cambia, sigue disminuyendo en razón al cuadrado de la distancia. Si se toma una escala en miles o de millones de kilómetros (como ocurre en el caso del sistema planetario), la dependencia de la fuerza con la distancia sigue siendo la misma. Por tanto, como el mismo comportamiento ocurre sin importar la escala, este fenómeno es autosimilar.

Existen otros fenómenos en la naturaleza en los que la dependencia de la distancia no es como el cuadrado, que acabamos de considerar, sino que dependen de otra potencia. Además, puede ocurrir que la fuerza no disminuya al aumentar la distancia, sino que aumente. Por ejemplo, podemos considerar un resorte: si éste se estira sabemos entonces que ejerce una fuerza que trata de regresarlo a su posición original (se dice de equilibrio). Mientras mayor sea la distancia que se estire, mayor será la tuerza que el resorte ejerza. Lo mismo ocurre cuando se comprime, mientras mayor sea la distancia que se le comprima, mayor será la fuerza que ejerza.

Además, resulta que: si la distancia aumenta al doble, la fuerza aumenta al doble; si la distancia aumenta al triple, la fuerza aumenta al triple, etcétera.

O dicho de otra manera: si la distancia aumenta 2 veces, la fuerza aumenta 2 veces; si la distancia aumenta 3 veces, la fuerza aumenta 3 veces, etcétera.

Vemos ahora que el 2, o el 3, son 21 y 31, respectivamente, cantidades elevadas a la potencia 1.

En este caso vemos que la fuerza aumenta como la distancia. Usando lenguaje matemático se abrevia esta información diciendo que la fuerza es proporcional a la primera potencia de la distancia.

En este caso, también hay autosimilitud.

Hemos hablado de relación entre fuerzas y distancias. Sin embargo, en muchos fenómenos alguna cantidad depende de una variable (no necesariamente la distancia), ya sea:

·inversamente, lo que quiere decir que al aumentar el valor de la variable disminuye el valor de la cantidad, o bien

·en forma proporcional, lo que quiere decir que al aumentar el valor de la variable aumenta el valor de la cantidad.

Además, la dependencia entre la cantidad y la variable de la que depende puede darse por medio de alguna potencia, que no necesariamente tiene que ser siempre ni 2 (como en la ley de la gravitación universal) ni 1 (como en el resorte). Puede ser con otro valor numérico, ya sea entero o no.

Cuando la dependencia de una cantidad de su variable es como la que acabamos de explicar se dice que el fenómeno esta regido por una ley de potencias. En todos estos casos existe la autosimilitud.

EL ANÁLISIS de la estructura de diferentes obras musicales ha demostrado que la selección de las notas que han hecho diferentes compositores, en distintas épocas, tiene algunos elementos comunes. Trátese de uno de los Conciertos de Brandemburgo de Bach, del Cuarteto de cuerdas # 3 de Babbit, de obras de piano de Scott Joplin, todas estas obras tienen la misma forma si se considera la estructura en términos de frecuencias. Explicaremos esto a continuación.En el análisis auditivo de diversas obras musicales una cantidad que se ha estudiado es la potencia de audio de la música. Esta cantidad es, en esencia, la energía que se emite en forma de ondas sonoras cada segundo, cuando se ejecuta la obra musical. Al analizar cómo está estructurada esta cantidad, en términos de la frecuencia, se obtiene lo que se llama su espectro.

¿Cómo dependen de la frecuencia los espectros de las diferentes obras musicales?

Los análisis hechos de diferentes obras musicales han mostrado que sus espectros dependen de la frecuencia, que llamaremos con la letra f, como (1 /f). Si recordamos lo que se analizó en el capítulo anterior vemos que este espectro es una ley de potencia que, en el lenguaje matemático, depende de la frecuencia en forma inversa a la primera potencia de f (ya que el exponente de la f en (I/f) es 1). Por lo tanto, como ya se describió, este espectro es autosimilar y en consecuencia, contiene una estructura fractal.

Un espectro del tipo mencionado en el párralo anterior recibe el nombre de espectro rosa.

¿Por qué Bach y muchos otros compositores escogieron el espectro rosa? La realidad es que ningún músico oyó hablar jamás de estas ideas, ni mucho menos las escogió de manera deliberada. Para entender lo que sucede explicaremos cómo se haría música con otro tipo de espectro.

Una forma sería como sigue: cada nota que se escribe es tal que su posición y duración no dependen para nada de las notas anteriores ni de su duración. En este caso se dice que la composición es completamente al azar o estocástica. Un ejemplo de este tipo de música se presenta en la figura 33(a). El espectro de la potencia de audio de este tipo de música es el mismo para cualquier valor de la frecuencia, lo que significa que el valor de la potencia es el mismo para cualesquiera valores de la frecuencia, o sea, que se trata de una cantidad constante. Matemáticamente, el espectro depende de la frecuencia (1/f0), ya que f0 = 1. A un espectro de este tipo se le llama blanco. Si se tocara este tipo de música en un instrumento la oiríamos sin estructura; además daría la impresión de que de una nota a otra siempre habría una sorpresa.

Otro tipo de espectro, yéndose al otro extremo, es el que depende de la frecuencia (1/f²), espectro llamado brown o café, nombre que se le dio porque está asociado al movimiento browniano que se trató en el capítulo IV. En la figura 33(b) se presenta música que tiene el espectro café. En la música cada nota y su duración dependen en grado considerable de las notas anteriores. Por lo tanto, la sensación que se tiene al escucharla es que después de haber tocado unas notas las que siguen son previsibles.

Figura 33. (a) Ejemplo de música blanca. (b) Ejemplo de música café. (c) Ejemplo de música rosa.La música que tiene espectro rosa, o sea (1/f), se encuentra, por así decirlo, entre los casos de música al azar (espectro blanco) y música determinista (espectro café). En este caso las notas y su duración no son ni muy previsibles ni muy sorprendentes. Un ejemplo de este tipo de música se muestra en la figura 33(c).

Regresando a la pregunta que se hizo arriba: ¿por qué los compositores usaron efectivamente espectros rosas, o sea una ley de potencias (1/f) para componer su música?, se puede afirmar que los compositores han intentado, y por cierto muchos de ellos logrado, componer música interesante. La cuestión se debería plantear como sigue: ¿por qué la música interesante tiene un espectro rosa? La respuesta podría ser que la música con este tipo de espectro resulta ser ni muy previsible (espectro café) ni muy sorprendente (espectro blanco). El científico holandés Balthazaar van de Pol afirmó en una ocasión que la música de Bach es grandiosa porque es inevitable y al mismo tiempo sorprendente, lo que significa que su espectro es rosa.

Debido a que la música que tiene un espectro rosa es autosimilar, tiene estructura similar en diferentes escalas de frecuencias. Lo que ocurre en una escala de frecuencias debe ocurrir en cualquier otra escala de frecuencias. Si se grabara una composición de este tipo en cinta magnética a cierta velocidad y se tocara a distintas velocidades, lo que se oiría sería similar a lo grabado. Esto contrasta con lo que ocurre con la voz humana, pues cuando se toca una grabación a una velocidad, por ejemplo al doble de lo que debiera hacerse, se oye muy chillona. Una forma de exhibir la autosimilitud es con ayuda de un aparato electrónico que genere sonidos de las frecuencias que uno desea. Si se produce un sonido que sea la superposición de 2 notas, siendo cada nota una octava (de frecuencia doble) de la anterior y se empieza con una nota de 10 Hertz (Hz), (1 hertz = 1Hz = 1/seg), las siguientes 11 notas serían de frecuencias:

20 = 2 x l0, 40 = 4 x10, 80 = 8 x 10, 160 =16 x 10,

320 = 32 x 10, 640 = 64 x 10, 1280 = 128 x 10,

2560 = 256 x 10, 5120 = 5l2 x l0, 10 240 =1024 x 10 y

20 480 = 2 048 x 10, todas en unidades Hz.

Ahora cambiemos cada una de estas notas por otras que sean de frecuencias mayores por un semitono (que corresponde a la diferencia entre dos notas sucesivas de un piano); la frecuencia del semitono se obtiene de la nota anterior multiplicando por 1.05946. Ahora se tocará el sonido que es la superposición de las frecuencias siguientes:

10 x 1.0594 = 10.6, 20 x 1.05946 = 21.2,

40 x 1.05946 = 42.38, 80 x 1.05946 = 84.76,

160 x 1.05946 = 169.51, 320 x 1.05946 = 339.03,

640 x 1.05946 = 678.06, 1 280 x 1.05946 = 1356.11,

2560x 1.05946 = 2712.22, 5120 x 1.05946 = 5424.44,

10240 x 1.05946 = 10848.88 y 20480 x 1.05946 = 21697.74 Hz

Este sonido se oirá con un tono más alto que el anterior.

Si se aumenta otra vez la frecuencia de cada una de las notas en un semitono, la superposición de los nuevos sonidos producirá un sonido de tono aún más alto. Si se repite 12 veces el proceso de aumentar en un semitono cada uno de los componentes del sonido, resulta que el sonido que se produce es ¡indistinguible del original! Esta es una demostración musical de la autosimilitud.

EL FENÓMENO de la turbulencia ha sido estudiado por un buen número de científicos a lo largo de más de 150 años. Desafortunadamente durante casi todo este tiempo no se le pudo dar una explicación satisfactoria. No fue sino hasta el decenio 1980-1990 que finalmente se ha empezado a entender el fenómeno de la turbulencia en términos de caos.Cuando el agua de un río fluye por su cauce sabemos que existen diferentes formas de flujo. Si la velocidad del agua es pequeña, entonces este flujo es regular; cuando el agua pasa por alguna piedra que está en el río, simplemente la rodea y el flujo continúa de manera regular. Se dice que el flujo es laminar, ya que su movimiento ocurre como si un conjunto de láminas de agua fluyera una sobre otra.

Sin embargo, al aumentar la velocidad del agua llega cierto momento en que el flujo se vuelve altamente irregular. Nos damos cuenta de que al bordear la piedra se producen remolinos. Si la velocidad del agua es mucho más alta todavía, aparecen remolinos dentro de los remolinos. En estas condiciones el flujo del agua es turbulento.

La descripción inicial de estos fenómenos, que corresponden a la hidrodinámica, fue hecha aplicando las leyes del movimiento de Newton a los fluidos. De esta manera se encontró una ecuación que resultó ser no lineal. En la bibliografía técnica esta ecuación recibe el nombre de Navier-Stokes. Como ha ocurrido con la mayoría de las ecuaciones no lineales, la ecuación de Navier-Stokes no se ha podido resolver de manera exacta.

En el caso en que la velocidad del líquido es muy reducida, el término no lineal de la ecuación de Navier-Stokes resulta ser extraordinariamente pequeño y es posible no tomarlo en cuenta, obteniéndose así una ecuación lineal, que sí se ha podido resolver. Bajo estas condiciones nos encontramos en el régimen laminar. Las propiedades de los flujos laminares se han obtenido y se conocen bastante bien. De hecho, gran parte de la tecnología basada en la hidrodinámica se ha desarrollado a partir de las soluciones de la ecuación de Navier-Stokes linealizada.

Un ejemplo de turbulencia ocurre cuando se calienta un pocillo de agua en una estufa. Como se sabe, si se deja calentar el agua un tiempo suficiente, ésta aumenta su temperatura y empieza a verse un movimiento en el agua, que recibe el nombre de convección. La causa de la convección se debe a que la porción de agua más cercana a la flama se calienta y por tanto su volumen aumenta. Al ocurrir esta dilatación, esta agua se vuelve más ligera que el agua más fría de arriba. Por tanto, el agua fría es más pesada y se mueve hacia abajo, desalojando a la caliente, que a su vez se mueve hacia arriba. De esta forma se genera un movimiento tipo circular de abajo hacia arriba y de arriba hacia abajo.

A medida que continúa aumentando la temperatura, el movimiento se hace muy irregular y, cuando esto sucede, se dice que ha empezado la turbulencia.

En la década de 1980-1990 se hicieron varios trabajos muy cuidadosos sobre la turbulencia debida a variaciones de la temperatura. Para estudiar este fenómeno se encierra un líquido en una cápsula muy pequeña y se mantiene una diferencia de temperatura fija entre las superficies superior e inferior de la cápsula. La superficie inferior se mantiene más caliente que la superior. Esta diferencia de temperatura causa que el líquido en la parte inferior se expanda, volviéndose más ligero que el de arriba. Éste empieza a bajar y el de abajo sube, es decir, ocurre la convección. Si las longitudes del recipiente tienen valores bien determinados, el movimiento del líquido se realiza alrededor de trayectorias cilíndricas (figura 34).

Después de cierto tiempo, si no cambia la diferencia de temperatura entre ambas caras, el movimiento se hace estacionario, lo que quiere decir que el giro se vuelve periódico; el líquido tarda cierto tiempo en dar una vuelta completa. En el experimento se mide este tiempo o periodo de flujo.

El experimento se lleva a cabo cambiando gradualmente la diferencia de temperaturas entre las caras de la cápsula. Para cada valor de esta diferencia se espera el tiempo necesario hasta que se llega a una situación estacionaria y se registra el periodo del movimiento.

Figura 34. En determinadas circunstancias el movimiento de convección se da en trayectorias cilíndricas.Lo que se encontró es que al aumentar la diferencia de temperaturas llega un momento en que aparecen dos periodos, es decir, hay dos tiempos de giro, y no nada más esto, sino que uno de los tiempos es igual al que había anteriormente, y el otro tiene valor doble respecto al primero. Esto significa que se presenta un fenómeno de bifurcación (véase el capítulo VIII).

Al seguir aumentando la diferencia de temperatura llega otro momento en que parecen cuatro tiempos, o sea cuatro periodos, es decir, se produce otra bifurcación. Continuando de esta manera se encuentran las características que estudiamos en el capítulo VIII, sobre el camino al caos. Hemos de decir que en este caso particular la diferencia de temperatura entre las caras de la cápsula es el análogo de la cantidad q con la que se trabajó en la ecuación (6) del capítulo VIII. Una mayor diferencia de temperatura corresponde a un valor mayor de este parámetro.

Figura 35. Frecuencias características que aparecen al aumentar continuamente la diferencia de temperaturas: (a) hay dos frecuencias; (b) hay cuatro frecuencias, y (c) Caso en que hay turbulencia. Las frecuencias son muchísimas. Se ha llegado al régimen caótico.Una forma -que resultó adecuada- de presentar los resultados fue haciendo un análisis no de periodos sino de frecuencias. En la figura 35 se muestra una sucesión de las frecuencias que aparecen para cada valor fijo de la diferencia de temperatura, o sea, del valor q. En primer lugar, cuando el valor de la diferencia es suficientemente pequeño, sólo hay una frecuencia (o sea, un solo periodo); al aumentar esta diferencia, llega un momento en que aparecen dos frecuencias (figura 35 (a)), una igual a la anterior y la otra igual a la mitad. Al aumentar todavía más la diferencia de temperatura aparecen cuatro frecuencias, la inicial, una igual a la mitad, otra de valor igual a la cuarta parte y otra más igual a la octava parte del valor de la inicial (figura 35(b)). Si la diferencia de temperatura continúa aumentando, van apareciendo más y más frecuencias precisamente con los valores asociados con las bifurcaciones. Finalmente, llega un momento en que hay frecuencias de todos los valores (figura 35(c)). Se ha llegado al régimen caótico. En esta situación, dentro del fluido se inicia el régimen turbulento. Por tanto, se ha demostrado que la turbulencia está asociada precisamente al caos que describirnos en el capítulo VIII.

Se han realizado diversos experimentos análogos, con condiciones que generan turbulencias. Los análisis de los resultados obtenidos, bajo el punto de vista que acabamos de considerar, indican que al iniciarse la turbulencia es cuando empieza el caos. La relación entre turbulencia y caos en un fluido es terna de investigación activa en la actualidad.

EN LOS sistemas biológicos existe un variado número de ritmos. Uno de los más conocidos es el latido del corazón; otro es el ritmo de sueño, que se presenta en los animales y en el hombre. Ambos, en general, están asociados a los llamados relojes biológicos.La forma acostumbrada de estudiar este tipo de fenómenos ha sido investigar el órgano biológico que lo produce y estudiar con todo detalle su comportamiento biológico, químico y físico. Así se han obtenido los conocimientos que han permitido el gran avance de la medicina. Sin embargo, esta forma de proceder no ha sido suficiente. A partir de los años ochenta se ha dado un nuevo enfoque en la investigación de los fenómenos biológicos, a saber, dirigir el estudio a las propiedades globales de los sistemas considerándolos no lineales. El lector se dará cuenta de que ésta es precisamente la manera corno se ha tratado otro tipo de fenómenos, la turbulencia por ejemplo.

Entre lo primero que se investigó fue el movimiento de los ojos de las personas afectadas de esquizofrenia. Si una persona normal observa la oscilación del péndulo de un reloj de pared, por ejemplo, sus ojos siguen el péndulo continuamente, como si estuvieran ligados al movimiento. En contraste, cuando un esquizofrénico ve la oscilación del péndulo, sus ojos realizan una serie de movimientos erráticos cuyo origen es de conocido.

Se ha creído que la causa de estas fluctuaciones se debe a las variaciones de las señales que provienen del sistema nervioso central, que es el que controla los músculos de los ojos. Se ha supuesto que estas fluctuaciones se deben a perturbaciones al azar que afligen el cerebro de los esquizofrénicos. Si las señales de entrada tienen ruido, se esperaría que los resultados también mostraran ruido.

Al estudiar este fenómeno usando las novedosas ideas del caos, se encontró que este tipo de comportamiento se podría entender de otra forma.

Resulta que el movimiento del ojo puede considerarse un fenómeno no lineal. En el sistema del ojo hay varios parámetros, análogos al parámetro q del capítulo VIII, que son la masa del ojo, la viscosidad de los líquidos dentro del ojo, etcétera.

Se ha descubierto que en el movimiento del ojo hay varios regímenes, tanto de orden como de caos, dependiendo de los valores de los parámetros. Para algunos valores de los parámetros (que equivalen a valores pequeños de q en el capítulo VIII) el movimiento del ojo es regular. Al aumentar estos valores, o sea el grado de no linealidad (que equivale a aumentar el valor de q en el capítulo VIII), empieza una secuencia de doblamiento de periodo y bifurcaciones, que finalmente lleva a un régimen caótico, en el que el ojo se mueve tal como se informa que ocurre con los esquizofrénicos.

En consecuencia, el movimiento irregular de los ojos de los esquizofrénicos parece que no se debe a señales enviadas al azar por el cerebro, sino que es consecuencia inevitable de excesiva no linealidad en su sistema ocular; por supuesto que entonces la forma de evitarlo sería disminuirla. Sin embargo, todavía no se ha podido hacerlo en la práctica, y por tanto, la cuestión sigue abierta. La irregularidad en el movimiento de los ojos se presenta no sólo en los esquizofrénicos sino también en otros pacientes con enfermedades neurológicas.

La forma de proceder que hemos reseñado, en la que los detalles particulares no desempeñan el papel principal en el comportamiento del sistema, sino en la que el punto crucial es reconocer que el fenómeno está regido por el comportamiento global, ha empezado a dar frutos.

El caso del corazón merece atención especial, pues en él se dan varios tipos de ritmos, que se han investigado en forma aislada y han sido categorizados. Es posible distinguirlos en los electrocardiogramas. Sus irregularidades han sido reconocidas como signos de alguna enfermedad. Sin embargo, sólo recientemente se ha empezado a analizar su dinámica.

Muy importante es la fibrilación, que causa miles de muertes súbitas al año. En muchos casos, éstas se deben al bloqueo de las arterias, que a su vez causan la muerte del músculo que bombea la sangre. Sin embargo, no se sabe a qué se debe.

En un corazón normal los músculos se contraen y relajan de manera periódica, mientras que cuando ocurre la fibrilación los músculos del corazón se contorsionan sin coordinación alguna y no pueden bombear sangre. En un corazón normal las señales eléctricas viajan de manera coordinada a lo largo del órgano. Cuando la señal llega, cada célula se contrae; enseguida la célula se relaja durante un intervalo determinado, dentro del cual no puede volver a contraerse. En cambio, cuando hay fibrilación la onda se esparce sin coordinación con el resultado de que el corazón nunca está del todo contraído ni del todo relajado.

Una forma de ayudar a un paciente que ha sufrido un ataque de fibrilación es aplicarle una corriente eléctrica -un shock eléctrico-, con lo que a menudo su corazón vuelve a trabajar normalmente.

En un corazón afectado de fibrilación cada una de sus partes puede estar funcionando normalmente. Las autopsias de las personas que murieron por esta causa muestran que los músculos no están dañados y que, sin embargo, el conjunto del corazón no funcionó.

El corazón es un sistema complejo, que ha empezado a ser estudiado desde un ángulo distinto: el del caos. Se ha encontrado que su actividad eléctrica presenta secuencias de doblamiento de periodos hasta llegar a un régimen caótico, comportamiento similar al de otros sistemas que desarrollan caos. Resulta que cuando se presenta la fibrilación se está en un régimen caótico, y al dar un shock eléctrico los parámetros del corazón se modifican y éste regresa a un régimen que ya no es caótico, por lo que su comportamiento vuelve a ser regular.

Por lo tanto, se ve que la modificación de algún parámetro relacionado con el funcionamiento del corazón, como por ejemplo un cambio en la conductividad de los músculos o en el tiempo de llegada de alguna señal, puede alterar el régimen en que se encuentra el órgano. Esto correspondería a modificar el parámetro q del capítulo VIII. La consecuencia es que este cambio puede hacer que el órgano sano pase por una bifurcación y tenga un nuevo comportamiento cualitativo. Como sabemos, al pasar una bifurcación aparecen nuevos periodos de oscilación que no siempre pueden ser sanos, pues dan otros dos ritmos al corazón.

El comportamiento caótico de algún sistema biológico no siempre está relacionado con alguna enfermedad. Aunque pueda parecer increíble, se ha empezado a considerar el caos como fuente de salud. Los sistemas no lineales tienen la capacidad de regulación y de control. Si a un sistema que se comporta linealmente se le produce una pequeña perturbación, entonces se comportará de manera cercana a como lo haría si no se le hubiera perturbado. Sin embargo, si se da la misma perturbación a un sistema no lineal, éste tiende a volver a su condición inicial. Recuérdese que en el sistema no lineal que se vio en el capítulo VIII los valores finales que adquiría la variable x no dependían de sus valores inicales. Entonces, si el sistema está en un instante dado en el valor final y a la siguiente iteración, o sea al siguiente instante de tiempo, se le da un valor distinto del final, después de varias iteraciones, es decir, después de cierto tiempo, regresa al valor que tenía, que es el valor final correspondiente al valor de q. Por tanto, para un valor fijo de q el sistema siempre tenderá a tener un valor final de su variable; se puede decir que, pase lo que pase, está "condenado" a terminar con ese valor.

Ahora bien, si un sistema llegara siempre a un valor final de sus variables, sin importar el valor de sus parámetros (q, en el caso que hemos tratado), entonces este sistema no podría ajustarse a cambios. Sin embargo, los seres vivientes deben poder adaptarse a los cambios. Por tanto en un sistema como el tratado, si las circunstancias externas hacen que el valor de q se altere, entonces los valores finales que adquirirá la variable x serán distintos de los que tenía antes del cambio. Si el sistema biológico es capaz de vivir con los nuevos valores finales significa que se ha podido adaptar a las nuevas circunstancias. Si no, desaparecerá.

El hecho de que muchos sistemas biológicos sean no lineales y se comporten caóticamente ha permitido la posibilidad de adaptación. Algunos investigadores han sugerido que para que estos sistemas sobrevivan bajo nuevas circunstancias tendrán que desarrollar estructuras fractales. Por ejemplo, las fibras conductoras del corazón o las redes que forman los bronquios tienen estructura fractal que permite una gran variedad de ritmos.

Por lo tanto, se puede llegar a la sorprendente conclusión de que el caos permite la salud, mientras que si un sistema fuera totalmente pronosticable, al ocurrir cualquier cambio se enfermaría y poco después desaparecería.

De estas consideraciones se obtiene una sugerencia muy interesante: cuando una enfermedad se debe a la inadaptabilidad del organismo a los posibles nuevos ritmos debidos al cambio de circunstancias, el tratamiento debería consistir en ampliar sus capacidades para que estos nuevos ritmos fueran capaces de darse. Esta idea puede abrir una nueva forma de tratar ciertas enfermedades.

EN EL curso de biología del bachillerato se estudia el cerebro humano, y una característica que de inmediato se percibe es que su forma no es lisa sino extremadamente convolucionada, con muchos pliegues y arrugas. ¿Por qué el cerebro tiene esta forma tan rara?El volumen cerebral de los mamíferos presenta gran variación, entre 0.3 mililitros (ml) y 3 000 ml. La corteza cerebral de los animales grandes está muy convolucionada, sin importar su posición en la escala de la evolución. Resulta que la proporción de materia blanca respecto a la materia gris es casi la misma en todos los mamíferos. A fin de mantener esta proporción, el material de un cerebro grande necesariamente tiene que estar acomodado en pliegues, de otra manera no cabría en el cráneo.

Del examen microscópico del cerebro se observa que, a medida que aumenta la amplificación, se va encontrando más y más detalles, y las estructuras más chicas se parecen a las más grandes. O, en otras palabras, se produce la similitud al cambiar de escala. El cerebro tiene estructura fractal. La dimensión fractal de la superficie del cerebro es mayor que 2, lo que implica que esta superficie necesita más espacio para llenarse; no es suficiente con la dimensión igual a 2.

La característica de los fractales, como la similitud, se encuentra en distintos sistemas y órganos anatómicos, por ejemplo en la red vascular, las arterias, las redes neurales, los ductos pancreáticos, la placenta, los bronquios, etc. Como ejemplo mencionaremos que las arterias humanas tienen una dimensión fractal de 2.7 y en el sistema digestivo el tejido presenta ondulaciones dentro de ondulaciones, a lo largo de muchas escalas.

Los vasos sanguíneos que van desde la aorta hasta los capilares se ramifican y dividen. Cada división se vuelve a ramificar y dividir. Esto continúa hasta que los conductos se vuelven tan angostos que las células de la sangre sólo pueden circular, por decirlo así, en fila, una después de la otra. La estructura de este sistema tiene carácter fractal. Por necesidades fisiológicas, los vasos sanguíneos tienen que apretar y comprimir una línea extremadamente larga y hacerla caber en un área muy pequeña; a su vez el sistema circulatorio debe comprimir una superficie de área muy grande en un volumen limitado. La sangre es un bien precioso para el cuerpo y el cuerpo no puede "gastar" mucho en espacio. La única forma en que la sangre puede circular de tal forma que ninguna célula esté separada de un vaso sanguíneo más allá de tres o cuatro células, es que el sistema tenga estructura fractal. Esto significa que el cuerpo tuvo que desarrollarse de tal forma que una línea, una vena por ejemplo, pueda cubrir casi completamente una superficie. La única forma en que esto puede ocurrir es mediante una estructura fractal. Habrá que mencionar que, aunque los vasos sanguíneos barren y casi cubren una superficie relativamente grande no ocupan, con todo y la sangre, más de 5% del cuerpo. Esta forma eficiente de estructurarse se debe a la evolución biológica.

La estructura fractal tan exquisita que se forma en el cuerpo de las venas y de las arterias no es única. El cuerpo tiene muchos otros sistemas así de eficientes, que se deben a la evolución. Los pulmones deben empacar la máxima área posible dentro del mínimo volumen. Hay que mencionar que la capacidad de cualquier ser vivo de absorber oxígeno depende del área de la superficie de sus pulmones; mientras mayor sea esta area, mayor será la capacidad de absorción. En el ser humano los pulmones ocupan un área de alrededor ¡ 100 m²! (equivalente al área de un cuadrado de 10 m de lado) y éstos ocupan un volumen corporal relativamente pequeño.

La idea de los fractales ha empezado a tener una incidencia muy importante en el estudio de la anatomía. De hecho, la forma en que tradicionalmente se clasificaban diferentes partes del cuerpo, a pesar de su mucha utilidad, no explica completamente lo que ocurría. Fue hasta que se empezó a usar la idea de los fractales, o sea de estructuras que presentan similitud a muchas escalas, que se pudo entender mejor cómo estaban diseñadas. La descripción fractal pudo explicar las observaciones experimentales. De esta manera se descubrió que el sistema urinario es fractal, el ducto biliar en el hígado es fractal y la red de fibras del corazón que conduce los impulsos eléctricos a los músculos que se contraen también es fractal. Con esta red, que los cardiólogos denominan red de His-Purkinje, se desarrolló una importante línea de investigación. Como se vio en el capítulo XVII, el espectro de frecuencias del corazón presenta, en ciertas condiciones, un comportamiento caótico, que sigue leyes fractales. La única forma de explicar este comportamiento fue suponer que la red de His-Purkinje tiene una estructura fractal: un laberinto que se rarnifica de tal forma que es autosimilar a escalas cada vez más y más pequeñas.

¿Cómo pudo la naturaleza desarrollar una estructura tan complicada? Mandelbrot ha mencionado que si sólo pensamos dentro del contexto de la geometría de Euclides que se nos enseña en la escuela (véase el capítulo II), entonces efectivamente las estructuras anatómicas son complicadas. Pero como fractales es posible describiras de manera extremadamente sencilla, con muy poca información. Recordemos, por ejemplo, que las instrucciones para construir la curva de Koch (véase el capítulo V), que es un fractal, son unas cuantas y además sencillas. Se ha descubierto que las instrucciones para la formación de cada uno de los órganos y de los sistemas de nuestro cuerpo están codificadas en la molécula del ácido desoxirribonucleico (ADN), donde se encuentra toda la información genética de los seres vivos. Si en esta molécula se encontrara la información específica de cada una de las ramificaciones, entonces además de ser una forma muy poco eficiente, la información de todas las estructuras no cabría en la molécula como la conocemos. Una forma más eficiente sería tener codificada sólo la instrucción que se debe iterar para formar un órgano como el pulmón, por ejemplo. Recuérdese que una manera de producir un fractal es dando una instrucción que se debe repetir o iterar un número muy grande de veces. De esta forma sencilla se puede entender cómo el ADN contiene la información que produce sistemas y órganos fractales. Esta forma eficiente de guardar información se ha obtenido a través del proceso de evolución.

En la actualidad, el estudio de la forma en que se encuentran codificadas las instrucciones iterativas para producir las diversas partes del cuerpo es un tema de investigación en la biología.

VAMOS a construir un fractal de la siguiente forma. Tomemos una línea recta de cierta longitud (figura 36(a)) que supondremos que es de valor uno. Dividamos ahora esta línea en tres partes iguales y quitemos la parte central (figura 36(b)). Cada segmento de los que quedaron tiene ahora longitud igual a (1/3).Enseguida repetimos el mismo procedimiento con cada uno de los segmentos restantes, obteniendo la figura 36(c). Cada uno de los segmentos tiene una longitud de (1/9) (un tercio de un tercio). Por tanto ahora se tienen cuatro segmentos de longitud (1/9) cada uno.

Si se repite este procedimiento con cada uno de los segmentos obtenidos, se encuentran sucesivamente las líneas mostradas en la figura 36 (d). En cada paso se va encontrando un número mayor de segmentos, pero cada uno de menor longitud.

Si se llevara a cabo este procedimiento un número muy grande de veces, se llegaría a obtener un "polvo" formado de un número extraordinariamente grande de segmentos, cada uno de longitud pequeñísima.

Figura 36. Procedimiento para construir el polvo de Cantor. Supongamos que la longitud de la línea original, la de la figura 36(a) es igual a 1. La longitud de cada línea de la figura 36(b) es entonces igual a (1/3). Por tanto, como hay dos líneas, la longitud total de las líneas de la figura 36(b) es:

En la figura 36(c) hay 4 líneas y cada una tiene de longitud:

Por tanto, la longitud total de las líneas de la figura 36(c) es:

En el primer renglón de la figura 36(d) hay ocho líneas y cada una con una longitud igual a:

En consecuencia,la longitud total de las líneas de este renglón es:

Continuando de la misma manera vemos que en el segundo renglón de la figura 36(d) hay 16 líneas, cada una con una longitud de:

La longitud total es:

En el tercer renglón de la figura 36(d) hay 32 líneas, cada una tiene de longitud:

La longitud total es:

En resumen, vemos que las longitudes totales de las líneas de las figuras 36(d) son, sucesivamente:

1, 0.667, 0.444, 0.296, 0.1975, 0.132,…

Cada vez que pasamos de una figura a otra la longitud total va disminuyendo, pero el número de líneas va aumentando (de l a 2 a 4 a 8 a l6 a 32 a…).Si así continuáramos indefinidamente, el número de líneas crecería sin límite y la longitud total sería cada vez más y más pequeña.

Este conjunto de segmentos se denomina el polvo de Cantor. Ahora comparemos los segmentos en el primer y segundo renglones de la figura 36(d). Nos damos cuenta de que ambas figuras son similares; lo mismo sucede al comparar el segundo y el tercer renglones. Esto nos indica que el polvo de Cantor es un fractal, con una dimensión de 0.63, que es un número comprendido entre 0 y 1. Esta dimensión es mayor que 0, ya que el polvo es mucho más que un punto (dimensión 0) y mucho menos que una línea continua (dimensión 1).

Figura 37. Procedimiento para construir una empaquetadura de Sierpinski. Uno se puede preguntar si es posible construir un fractal análogo al polvo de Cantor, pero en lugar de que sea en una dimensión, que ocurra en dos dimensiones. La respuesta es positiva.

Tomemos como base un triángulo con los tres lados iguales, o sea equilátero (figura 37(a)). Enseguida dividimos cada lado en dos partes iguales y construimos otros tres triángulos idénticos al anterior y los unirnos como se muestra en la figura 37(b), dejando en blanco la porción central, que tiene la forma del mismo triángulo con el que iniciamos la construcción. Enseguida eliminamos el triángulo central.

En el siguiente paso dividimos cada lado de cada triángulo en dos partes iguales y formarnos los triángulos mostrados en la figura 37(c). Asimismo quitamos los triángulos blancos.

Continuando de esta manera se llega a configurar un objeto como el mostrado en la figura 37(d). Si se sigue así indefinidamente se construirá un objeto que recibe el nombre de empaquetadura (gasket en inglés) de Sierpinski. Nos damos cuenta de que este objeto tiene agujeros en todas las escalas, y que es autosimilar, por lo que es un fractal. La dimensión fractal que tiene la empaquetadura de Sierpinski es 1.58. Nótese que esta figura es más que una línea recta (dimensión 1) y menos que una superficie (dimensión 2).

Supongamos que la longitud del lado del triángulo de la figura 37 (a) sea igual a 1. El perímetro de este triángulo es igual a la suma de sus tres lados, o sea:

3 x 1 = 3.

La longitud de cada línea de la figura 37(b) es (1/2) Por tanto, cada triángulo negro tiene un perímetro de:

En vista de que hay tres triángulos negros, su perímetro total es:3 x 1.5 = 4.5.

La longitud de cada línea de la figura 37(c) es:

Cada triángulo negro de esta figura tiene un perímetro de:

En vista de que hay nueve triángulos negros, su perímetro total es:9x 0.75= 6.75.

En la figura 37(d), la longitud de cada línea es:

En consecuencia, cada triángulo negro tiene un perímetro de:

Dado que hay 27 triángulos negros, su perímetro es:27 x 0.375 = 10.125

.

De estos cálculos apreciamos que al pasar de una figura a la siguiente, el perírnetro de los triángulos negros va aumentando: 3, 4.5, 6.75, 10.125,… Sin embargo, también vemos que de una figura a la otra, el número de huecos también aumenta, por lo que el área total de los triángulos negros va disminuyendo. Si se siguiera este procedimiento indefinidamente, concluiríamos que la empaquetadura de Sierpinski ¡tiene un perimetro infinito pero su área es de cero!

Se puede, asimismo, iniciar la construcción en dos dimensiones con un cuadrado, en lugar de iniciarla con un triángulo. Al cuadrado se le quita al centro un cuadrado de lado igual a (1/3) del lado original. En seguida se remueven los centros de los ocho cuadrados que quedan y así se continúa.

También se puede construir el análogo en tres dimensiones (figura 38). Su construcción se inicia con un tetraedro regular (pirámide cuyas caras son cuatro triángulos equiláteros). Unimos cuatro pirámides de modo que en el interior quede en blanco una pirámide igual a ellas; ésta se elimina. Continuando de esta manera se obtiene la versión tridimensional de la empaquetadura de Sierpinski. La dimensión de esta construcción es igual a 2, que es menor que 3 en la cual se construyo. Resulta claro, ya que la generalización tridimensional no llena completamente el espacio. Este objeto, llamado esponja de Menger tiene ¡área superficial infinita y volumen nulo!

Nos damos cuenta de que las construcciones de Cantor, Sierpinski y Menger son objetos muy calados, que tienen longitud (Cantor), área (Sierpinski) y volumen (Menger) prácticamente nulos, ya que en el límite infinito casi no existen ni segmento, ni triángulo, ni pirámide, respectivamente. Desde este punto de vista matemático, tales construcciones son patológicas.

Figura 38. Esponja de Menger. Supongamos que la masa del triángulo de la figura 37(a) es igual a 1. Cada triángulo de la figura 37(b) tiene entonces una masa igual a (1/4). Corno solamente quedan tres de estos triángulos, la masa total en le figura 37(b) es:

La masa de cada triángulo negro de la figura 37(c) es la cuarta parte de la de un triángulo negro de la figura 37(b). Corno la masa de este último triángulo es (1/4), la masa de cada triángulo negro de la figura 37(c) es:

Dado que en la figura 37(c) hay nueve triángulos negros, cada uno de masa igual a (1/16), la masa total en esta figura es:

La masa de cada triángulo negro de la figura 37(d) es la cuarta parte de la de un triángulo negro de la figura 37(c). En vista de que la masa de este último triángulo es igual a (1/16), la masa de cada triángulo negro de la figura 37(d) es:

n la figura 37(d) hay 27 triángulos negros y cada uno de ellos tiene una masa de (1/64). Dado que hay 27 de estos triángulos, en la figura 37(d) hay una masa de:

Ahora bien, vemos que los triángulos de cada una de las figuras incluidas en la figura 37 están dentro del área del triángulo original (figura 37(a)). Por tanto, la sucesión de triángulos de la figura 37 va teniendo cada vez menos y menos masa (1, 0.75, 0.5625, 0.4219,…) y éstas están encerradas en la misma área. En consecuencia, la sucesión de figuras que da lugar a la empaquetadura de Sierpinski se va volviendo cada vez más y más ligera. En el límite en que el número de pasos es extraordinariamente grande, el número de triángulos es también muy grande pero la masa total encerrada es muy pequeña, ¡casi nula! La empaquetadura de Sierpinski es notablemente ligera.

Figura 39. El punto R se llama ramal. Otra característica importante de esta construcción es la siguiente. Consideremos una curva corno la que se muestra en la figura 39; al punto R se le llama punto ramal. De acuerdo con el "sentido común" uno podría pensar que una curva no puede consistir solamente de puntos ramales. Sin embargo, si consideramos el perímetro, o sea, la línea que encierra la empaquetadura de Sierpinski, ésta es una línea formada solamente por puntos ramales. Es decir, en cada punto sale un ramal de la curva. Por supuesto, esto ocurre en el caso en que se ha iterado un número muy grande de veces.

Las empaquetaduras de Sierpinski, tanto en dos como en tres dimensiones, son modelos de muchas estructuras construidas por el hombre, así corno de varios fenómenos naturales. Un caso interesante se dio en la ingeniería civil, cuando Gustave Eiffel construyó su famosa torre en París, Francia, en 1889 (figura 40). Esta construcción de 335 m de altura tiene cuatro lados y cada lado tiene la forma de una letra A. Los cuerpos de cada parte de la A no están construidos con vigas sólidas, llenas, sino con armaduras gigantescas. Si uno se fija con detalle en cada una de estas armaduras, se dará cuenta de que están formadas, a su vez, de otras armaduras, que están formadas de armaduras, que a su vez son armaduras, que a su vez… Así se obtiene una estructura autosimilar que constituye un fractal. Si compararnos una armadura y una viga cilíndrica llena con la misma capacidad de carga, la armadura resultará muchísimo más ligera que la viga. Eiffel sabía que las armaduras, cuyos miembros las integran a su vez armaduras, son todavía más ligeras. Así, vemos que la Torre Eiffel es una aproximación a la empaquetadura de Sierpinski en tres dimensiones. Además, se trata de una estructura muy ligera, igual que en el caso de Sierpinski.

Figura 40. La estructura de la Torre Eiffel se acerca a una esponja de Menger. Otro punto importante y crucial con respecto a la capacidad de carga de una estructura es que, mientras más puntos ramales tenga una estructura, mayor será la resistencia que pueda soportar. Resulta que la Torre Eiffel cuenta con muchos puntos ramales. El famoso arquitecto estadunidense Buckminster Fuller, diseñador de los domos geodésicos muy populares en la década 1960-1970, sabía que la capacidad de carga reside no en la masa total de la estructura sino en los puntos ramales que tenga. Mientras más puntos ramales tenga una estructura más se acercará al ideal de una empaquetadura de Sierpinski y mayor será la carga que pueda soportar.

De esta forma se pueden lograr estructuras muy ligeras que son capaces de soportar cargas muy grandes. Mientras más se acerquen a una empaquetadura de Sierpinski o a una esponja de Menger, mejor se logrará este efecto.

EL COMPORTAMIENTO de un sistema complejo, al que en general rigen leyes no lineales, puede entenderse, como vimos, en términos de regiones periódicas y de regiones caóticas. En el capítulo VIII estas regiones quedan delimitadas por valores precisos de los parámetros característicos del sistema. En el ejemplo tratado en el capítulo VIII, el sistema está representado por un solo parámetro, q. En la figura 19 podríamos colorear los valores de q que dan lugar a un comportamiento periódico con un color, rojo, por ejemplo, y con otro, azul digamos, los valores de q que dan un comportamiento caótico.Sin embargo, en muchos sistemas no es uno sino varios los parámetros que lo conforman. En este caso, el comportamiento es similar al que estudiamos, pero hay una diferencia. El hecho de que haya varios parámetros hace que la frontera entre un tipo de comportamiento, periódico, y otro, caótico, no sea tan fácil de definir. Para aclarar lo que ocurre, supongamos que un sistema está regido por una ecuación no lineal, similar a la ecuación (6) del capítulo VIII,que tenga dos parámetros, que llamaremos p y r. Procediendo de manera análoga a corno se hizo en el capítulo VIII, dados valores específicos de p y r, por ejemplo p 2.1 y r= 0.43, se obtendría el tipo de comportamiento que sigue este sistema. Si se cambian los valores p y r (equivalente a cambiar el valor de q) se vuelve a encontrar el tipo de comportamiento, y así se continúa para todas las posibilidades de p y de r.

Podemos presentar los resultados de este procedimiento de la forma siguiente: consideremos dos ejes perpendiculares (figura 41) en los que uno de los ejes, el horizontal, marque los valores de p, y el vertical los de r. Para un conjunto de valores de p y de r dados (en la figura, para el valor p = a y r= b) marcamos el punto P. Ahora bien, si este par de valores de los parámetros da como resultado un comportamiento periódico del sistema, entonces el punto P lo marcamos de negro, por ejemplo. Si el comportamiento del sistema para esta pareja de valores resulta ser caótico, entonces marcamos el punto P con otro tono, blanco, por ejemplo. De esta manera se obtiene una figura corno la de la figura 42. Observamos que las regiones blancas y negras están entremezdadas.

Figura 41: Gráfica para el caso en que haya dos parámetros que describan el sistema.Si quisiéramos ver en detalle la frontera entre una región negra y una blanca adyacente, esto es, si amplificáramos la región encerrada en la figura 42, obtendríamos lo que se ve en el figura 43; si ahora amplificáramos cualquier región de la figura 43, se encontraría una figura similar a la figura 43.

Continuando de esta manera, al ir yendo a escalas cada vez más pequeñas se muestra la gran complejidad de la separación entre dos regiones adyacentes, la negra y la blanca. De hecho, se puede uno dar cuenta de que al cambiar de escala hay similitud en las figuras que se van obteniendo. Por tanto, estas figuras son fractales.

Si el sistema estuviera regido por más de dos parámetros, la representación de lo que ocurre ya no la podríamos hacer en dos dimensiones, sino en un número mayor, cosa que no haremos.

Figura 42. Las regiones negras corresponden a valores de los parámetros para los cuales hay un comportamiento estable. Las regiones blancas corresponden a comportamientos caóticos.

Figura 43. Amplificación de la zona encerrada en la figura 42. Consideremos corno ejemplo de un sistema complejo la red eléctrica de una región del país. Este sistema es oscilatorio y un gran problema es saber lo que le ocurre si por algún motivo se presenta una perturbación, como puede ser alguna variación en el voltaje o la falla de una parte del sistema.

Cuando el sistema está funcionando en forma estable, los valores de los parámetros tendrán ciertos valores a los que corresponderá un punto en una región como la negra de la figura 42, que llamamos Q. Si ocurre alguna perturbación en la red, entonces los valores de los parámetros cambian y por tanto el punto Q ya no describe al sistema perturbado, sino que será otro punto el que lo represente, digamos el T. Si éste cae dentro de una región negra, entonces bajo los efectos de la perturbación, el sistema seguirá funcionando de forma periódica, será estable. Pero ¿qué ocurre si el punto T cae en una región blanca? En este caso el comportamiento del sistema será caótico y habrá problemas.

Si el comportamiento del sistema está representado por gráficas análogas a las de las figuras 42 y 43, entonces una pequeña variación en los parámetros p y r puede pasar al sistema de una región negra (estable) a otra blanca (caótica), que esté en su vecindad. Nótese que los puntos de una región negra están muy cercanos, de hecho entremezclados, a los de las regiones blancas.

En general, el dominio en el cual un sistema complejo se comporta de manera estable se adivina a partir de un conjunto pequeño de datos. En el funcionamiento cotidiano de estos sistemas, el comportamiento se extrapola de modo que cubra una variación muy estrecha de valores de los parámetros. Sin embargo, esta extrapolación no está completamente justificada. ¿Qué ocurre si al extrapolar se pasa de una región negra (estable) a una blanca (caótica)? Nótese que una pequeña variación puede cambiar completamente el comportamiento del sistema.

Un problema que debe tratarse al considerar el diseño de un sistema no lineal, como la red eléctrica, es poder conocer con detalle la frontera entre las regiones estables (negra) y caótica (blanca), la frontera entre la calma y la catástrofe. Dentro de los sistemas conocidos esta frontera todavía no se conoce con exactitud. Este problema es abierto. Es claro que, una vez conocida esta frontera, se podrá saber a ciencia cierta cuándo los comportamientos serán seguros y se podrán tomar las providencias necesarias para evitar caer en una región caótica.

XXI. EL CAOS ORDENA LA LINGÜÍSTICA. LA LEY DE ZIPF

EN TODO texto escrito hay palabras que se repiten. Por ejemplo, la preposición "de". Así, en un texto se puede contar cuántas veces aparece "de" y se encuentra un número. Si éste se divide entre el número total de palabras del texto, se obtiene su frecuencia y, de esta manera, la frecuencia de cada palabra que aparece en un escrito.Ahora se enlistan las palabras del texto colocando en primer lugar la palabra que aparece con mayor frecuencia; en segundo la palabra con segundo valor de frecuencia, y así sucesivamente. Al lugar que ocupa una palabra en ese texto se denominará rango de la palabra. Supongamos que en un texto la palabra de más frecuencia es "de"; en la lista ocupará el primer lugar y por tanto tendrá el primer rango. Si el artículo "el" tiene segundo valor de la frecuencia ocupará el segundo lugar en la lista y tendrá rango dos, etcétera.

Del estudio de diferentes textos en varios idiomas se encuentra que existe una relación entre la frecuencia de una palabra y su rango. En efecto, mientras mayor sea el rango de una palabra, menor será la frecuencia con la que aparece en el texto. Esto es claro, ya que mientras mayor sea su rango, más abajo estará la palabra en la lista, lo que significa que menor será su frecuencia. ¿Cómo depende la frecuencia del rango? Pues resulta que depende en forma inversa (porque disminuye a medida que el rango aumenta) de la primera potencia del rango. Si denotamos con la letra f la frecuencia y con la letra r al rango, entonces la relación matemática es que f depende de r como (1/r) (véanse los capítulos XIV y XV). Este resultado se llama la ley de Zipf.

Nos damos cuenta de que esta dependencia es precisamente la misma que se obtiene para otros fenómenos que ya estudiamos y que recibe el nombre de dependencia (1/f). Como ya se vio, esta dependencia es la de una ley de potencias; en este caso la potencia -1, matemáticamente hablando. Y ya Sabemos que esta ley de potencias implica un comportamiento autosimilar.

La ley de Zipf también da la dependencia de la frecuencia de ocurrencia de una palabra con respecto al número de palabras que se usen, o sea, a la amplitud del vocabulario utilizado. Mientras menor sea el vocabulario, mayor será la frecuencia de las palabras en los primeros rangos. Así por ejemplo, en un texto en español con un vocabulario de alrededor de 10 000 palabras, las frecuencias de las palabras de mayor rango, como "de", "el", "y", son 0.11, 0.06, 0.33, respectivamente.

La dependencia que indica la ley de Zipf se encuentra no solamente en muchos de los idiomas modernos, sino también en lenguajes especiales como la hagioantroponomía, que estudia el empleo del nombre de los santos como sobrenombres o apodos de personas; también lo estudia en su uso relativo a los apellidos de familias.

La ley de Zipf tiene vigencia no solamente en el lenguaje en general sino en la obra de escritores en particular. Por ejemplo, en el caso de un buen escritor cuyo vocabulario activo sea de, digamos, unas 100 000 palabras, las palabras que ocupan los primeros 10 lugares en la lista llenan alrededor de 25% del texto, es decir, la frecuencia total de estas 10 palabras es de 0.25. En contraste, en un texto en el que se usara una décima parte de aquel vocabulario (unas 10 000 palabras), como el de un periódico, el porcentaje apenas crece a 30%. Esto se debe principalmente a que el escritor no podría evitar el uso de palabras como "de", "el", "y", "a", etc., las que generalmente ocupan los primeros rangos en cualquier texto.

Una de las formas de entender el origen de la ley de Zipf ha sido considerada con razonamientos como los que siguen: es cierto que los lenguajes han sido producidos por el cerebro humano que genera su estructura; se ha hecho el análisis de modelos dinámicos de lingúística acerca de los cuales existe mucho material que ha sido descubierto por la psicología cognoscitiva, lo que ha permitido hacerse algunas ideas acerca de la forma como procesa la información un agente biológico, como el cerebro humano.

Se ha descubierto que esta dinámica presenta comportamientos caóticos como los que describimos en el capítulo VIII. Esto no debería extrañarnos ya que, como vimos, una de las características de un régimen caótico es que puede generar variedad, mientras que cuando está dentro del régimen periódico, o sea regular, se produce la confiabilidad, ambas características necesarias en el lenguaje. La variedad permite que haya innovación, mientras que la confiabilidad permite que haya orden.

Consecuencia de construir el lenguaje con una dinámica que produzca un régimen caótico es que la estadística que resulta con respecto a las palabras sigue la ley de Zipf.

De hecho, este resultado se puede ver de manera más general. En vista de que muchos tejidos, órganos y sistemas biológicos son fractales, dan lugar a comportamientos caóticos que producen una ley, la de Zipf en el caso lingüístico, que tiene estructura fractal.

TODOS los días se ven en la sección financiera del periódico gráficas que muestran el comportamiento del índice de precios de la bolsa de valores, como la que aparece en la figura 44, que muestra alzas y bajas aparentemente sin regularidad, al azar.Para mucha gente, en particular las que invierten dinero en la bolsa de valores, es de interés poder predecir la tendencia y, si fuera posible, el precio de las acciones, ya que si tuvieran esta información podrían comprar o vender con ventaja y así ganar dinero.

Desde hace mucho tiempo los economistas han intentado estudiar y comprender los movimientos de precios en la bolsa de valores. ¿De qué depende que una acción suba o baje?

Los economistas han supuesto, en general, que la variación de los precios de algún producto, por ejemplo el algodón, tiene dos componentes: una de largo alcance, en el que los precios se regirían por fuerzas económicas profundas como la apertura de rutas comerciales, inventos que utilizaran el producto, una guerra, alguna innovación tecnológica que modificara el uso del producto, una revolución, etc. Esta tendencia a largo alcance, meses, años o décadas, quedaría determinada de manera muy clara.

La otra componente del precio sería de corto alcance: los precios variarían al azar, debido a un número muy grande de causas, muchas de las cuales no se podrían determinar con precisión. Estos vaivenes, llamados fluctuaciones, son transitorios. Se ha pensado que casi no hay relación entre los dos ritmos de largo y de corto alcance.

Figura 44. Gráfica de los índices de precios en la bolsa de valores de un periódico determinado. Parece que las alzas y bajas no tienen regularidad alguna.

Figura 45. Curva gaussiana Se ha considerado que las variaciones de los precios, a largo alcance, siguen una ley determinada, como la que se muestra en la figura 45 y que grafica la probabilidad del cambio en el precio de, por ejemplo, el algodón. Esta curva, llamada curva gaussiana, tiene forma de campana y nos dice que la mayoría de los cambios ocurrirá cuando el precio esté dentro de los límites marcados entre los valores A y B, alrededor de un valor promedio. Así, por ejemplo, la probabilidad del valor C, muy lejano del intervalo AB, es muy pequeña. La distribución gaussiana se utiliza en muchos campos en los que hay variables al azar. Por ejemplo, si se miden las longitudes de los clavos de un paquete que nominalmente deberían tener una longitud de 20 cm, se encontraría que no todos tienen efectivamente esta longitud. Resulta que, si el paquete es grande, la distribución de longitudes toma una forma gaussiana, centrada alrededor de 20 cm. Es decir, la mayoría de los calvos tiene una longitud, si no de 10 cm, sí muy cercana a 20 cm. Una longitud de 45 cm tiene una probabilidad extraordinariamente pequeña de ocurrencia. Este es el significado que tiene la distribución gaussiana.

Sin embargo, en el intento de sobreponer los precios que el algodón adquirió de 1880 a 1958 se encontró que no seajustaban a una curva gaussiana. Se hicieron muchos intentos de hacer este ajuste, todos ellos sin éxito.

El mismo fracaso se alcanza al analizar los precios de diferentes acciones en la bolsa de valores, en la que también se ha pensado que existen dos tipos de ritmos casi independientes entre sí: largo y corto alcance.

Fue Mandelbrot el primero que vio los valores de los precios del algodón desde otra perspectiva, y se preguntó: ¿por qué deberían los precios del algodón, o para el caso de cualquier otra entidad económica, tener una distribución gaussiana? Es más, ¿por qué debería haber una separación tan cortante, como lo que se proponía, entre largo y corto alcance?

Una de las suposiciones implícitas que los economistas hicieron al trabajar con la distribución gaussiana es que los precios cambian continuamente. Esto significa que si hay una variación en el precio de una acción de $100 a $40, entonces el precio debe pasar por todos los valores intermedios, o sea, la acción debe adquirir los valores de $87.5, $55, $49.75, etc. Esto desde luego no es cierto. Mandelbrot hizo la suposición de cambios discontinuos en los precios y llegó así a la predicción de la distribución de precios que se muestra en la figura 46, en la cual se dibuja la gráfica, en el eje vertical, de una cantidad relacionada con la variación de precios, y en el eje horizontal, de los precios. La predicción hecha es la curva continua y los valores de los datos que tenía de las variaciones de los precios del algodón se muestran por medio de puntos. El conjunto de puntos marcados con 1 corresponde a cambios positivos de los precios diarios del algodón. El conjunto de puntos marcado con 2 corresponde a cambios positivos de los precios mensuales; el conjunto marcado con 3 corresponde a cambios de los precios anuales. Los conjuntos 4, 5 y 6 corresponden a cambios negativos en los precios diarios, mensuales y anuales, respectivamente.

Figura 46. Comparación entre la variación de precios en distintas circunstancias (conjuntos de puntos) con las predicciones (líneas continuas). Cada línea corresponde a una escala de tiempo distinta.Nótese que los distintos conjuntos de puntos corresponden a escalas de tiempo muy diferentes. Si se copiara esta gráfica en un acetato transparente y se trasladara la curva predicha (línea continua), se superpondría en cada uno de los conjuntos empíricos formados por los puntos. Es decir, la misma predicción resulta ser válida a lo largo de diferentes escalas: diaria, mensual y anual. No hay diferencias entre las escalas temporales como se ha pensado. Esto significa que hay similitud y que la estructura de los precios es fractal. Si en lugar de hacer una gráfica como la de la figura 44, en que se muestran las fluctuaciones de los precios de las acciones en la bolsa de valores a lo largo de un día, se hiciera la gráfica a lo largo de un mes, o de un año, se encontrarían gráficas que tienen la misma forma, o sea, son similares.

Doyne Farmer, Norman Packard y James McGill en Nuevo México, EUA, han llevado este análisis de la economía mucho más adelante, considerando que la dinámica que rige los fenomenos económicos es no lineal. Un efecto de ésta es que una causa pequeña puede producir efectos muy grandes. Un ejemplo es la conocida fábula del camello muy cargado al que, en cierto momento, se le añade una pajita y se rompe su espalda. La paja es en extremo liviana, pero el peso extra que añade tiene una consecuencia fuera de toda proporción. Esto se debe a que su efecto NO queda determinado por una simple relación entre el peso de la paja y el peso del camello, sino a una interacción muy complicada entre todos los factores que afectan al camello, como los objetos que ya está cargando, si durmió bien la noche anterior, la temperatura del desierto, etc. Es decir, una pequeña causa puede ejercer un gran efecto.

Si en un fenómeno hay una relación directa entre la causa y el efecto, y si ocurre que al aumentar la causa al doble el efecto aumenta al doble, entonces la relación es lineal. Claramente, en el caso de la fábula la relación entre el peso de la paja y el efecto sobre el camello no es lineal.

Si se considera el patrón de tráfico de vehículos en una ciudad grande y se quisiera poder hacer predicciones, una manera de proceder sería aprender todo lo que se pudiera sobre cada vehículo individual, todas sus velocidades y todos los sentidos de las calles, etc. Sin embargo, esta forma de proceder no permitiría hacer predicciones de tráfico. Si un conductor frena porque un niño se le atraviesa, podrían darse repercusiones a varios kilómetros de distancia. Es decir, este fenómeno es no lineal.

Si, por otro lado, se observa el tráfico desde cierta altura, por medio de un helicóptero, uno se podría dar cuenta de que hay un flujo y sería posible hacer predicciones a futuro, por lo menos para intervalos cortos. Nótese que el observador del helicóptero no necesita información detallada acerca de las características de cada uno de los vehículos.

Las personas que manejan las acciones en la bolsa de valores son análogas a los coches y por medio de relaciones no lineales, como las que consideramos en el capítulo VIII, se pueden entender tendencias a corto alcance del comportamiento de los precios de las acciones de la bolsa de valores.

Debido a que la dinámica de los precios es no lineal, como ya sabemos, en estos casos existe un régimen caótico. Entender este hecho ha permitido a algunas personas hacer predicciones a corto alcance, de unos cuantos días, sobre el comportamiento de los precios. Es más, en 1991, Farmer, Packard y McGill fundaron una compañía, The Prediction Company (Compañía de Predicciones) que se dedica a analizar la evolución en el tiempo de los precios de diferentes acciones de la bolsa de valores. Se basan en la teoría del caos, algunos de cuyos elementos se trataron en el capítulo VIII. Son capaces de hacer predicciones que abarquen unos cuantos días sobre el comportamiento de precios, y los resultados se los proporcionan a sus clientes.

Para tener una idea de cómo trabajan, diremos que toman como base lo siguiente: regresando al tema tratado en el capítulo VIII, estudiaremos el caso en que q = 3.6 y como valor inicial de x tomemos 0.6. Como vimos, este valor de q corresponde a la región caótica. Al iterar en la misma forma que se hizo en el capítulo VIII, los valores dex que se obtienen, como lo puede comprobar el lector son, sucesivamente: 0.6, 0.756, 0.664, 0.803, 0.569, 0.883,… 0.437, 0.886, 0.364, 0.834, 0.499, 0.900,…

Supongamos que se nos diera el valor de 0.437, con éste podríamos predecir que los siguientes tres valores de x son: 0.886, 0.364, 0.834. Si por algún motivo, como es lo que ocurre en el caso de la economía, no se conoce la función (6) con cuya ayuda encontramos estos números, entonces hay procedimientos matemáticos más complicados para encontrar los resultados, no de todas, pero sí de las iteraciones inmediatas. Con este espíritu proceden en The Prediction Company.

La manera matemática completa como se han podido hacer predicciones no está todavía suficientemente desarrollada. Fundamentar y completar este trabajo todavía tomará tiempo. Sin embargo, llevan una gran delantera sobre quienes analizan la evolución de precios a la manera tradicional.

The Prediction Company mantiene en secreto los procedimientos que utiliza en sus predicciones. Lo que se puede decir es que han ganado mucho dinero -ellos y sus clientes- en la bolsa de valores.

Se podría pensar que si toda la gente que participa en la bolsa de valores supiera que, por ejemplo, el jueves el precio de una acción va subir, entonces el miércoles antes del cierre todos comprarían, y por tanto, el precio subiría no el jueves, sino el miércoles, y por tanto, la predicción no serviría. Es decir, el comportamiento en la bolsa de valores es tal, que si uno encuentra un patrón, al actuar lo elimina. Esto no ocurre en un fenómeno físico.

Sin embargo, la filosofía de los miembros de la compañía de la que estamos hablando es otra. Lo que pasa es que si se dice que se tiene una nueva idea, lo prudente sería esperar a ver si efectivamente ocurre. Dejar pasar cierto tiempo y no actuar. Si todo funciona bien, quien la emplee tendrá buenas ganancias y, en el momento en que los demás quieran aprovechar esta idea, deja de funcionar. El resultado neto es que el primero en idear y usar tal sistema sí ganó dinero.

EN EL capítulo V se mencionó el hecho de que con fractales es posible imitar mapas. Al igual que con cualquier fractal, como se recordará, se da una regla y ésta se itera un número muy grande de veces. Así se logra con ciertos algoritmos de manera muy realista el dibujo de un mapa, de un relieve geográfico y de líneas costeras. Se puede escoger la dimensión fractal que deba tener la figura. Cuando esta dimensión adquiere el valor mínimo, igual a 2, el relieve es extremadamente liso. A medida que esta dimensión aumenta, el relieve aparece más y más "corrugado" y empieza a aparecer un relieve natural. Las iteraciones se hacen con un programa de computadora, en el que se añade una rutina para simular la iluminación a partir de cierta dirección si el observador está localizado en determinado punto fijo. De esta forma se encuentran relieves y líneas costeras como las que se muestran en la figura 47.Una de las grandes ventajas de lograr imitar este tipo de características geográficas es la siguiente: si, por ejemplo, se quisiera transmitir con ayuda de un aparato electrónico de un lugar a otro y a través de un satélite la imagen de una montaña, lo que se haría de primera intención sería tomar una fotografía de la montaña, dividirla en una serie de pequeños cuadros (llamados pixeles) y luego transmitir las tonalidades de cada uno. Esto implica codificar y enviar una cantidad muy grande de información. Si se puede lograr su imitación por medio de un fractal, entonces lo único que se debe transmitir es la figura inicial o iniciador y el algoritmo que se debe repetir. Del otro lado de la línea de comunicación se harán las iteraciones y se obtendrá la figura de la montaña. Se debe apreciar que esta novedosa manera de transmitirinformación es muy práctica, ya que lo que se envía es mínimo en comparación con los resultados.

Figura 47. Composiciones fractales que producen relieves geográficos y líneas costeras.

DESDE tiempos inmemoriales el hombre ha observado el cielo y los cuerpos celestes que en él se encuentran, entre ellos la Luna y el Sol. Diversos pensadores llegaron a la conclusión de que estos cuerpos celestes giran alrededor de la Tierra. Posteriormente, después de observar durante mucho tiempo, seguramente siglos, se descubrió que había otros cuerpos celestes, que ahora llamamos planetas, que también se mueven en el firmamento. A diferencia de los planetas, las estrellas, otro conjunto de cuerpos, parecen estar fijas.No entraremos en la historia de cómo se descubrió que el Sol y los planetas no giran alrededor de la Tierra, sino que junto con nuestro planeta, todos lo hacen alrededor del Sol. En el siglo XVI, el astrónomo Tycho Brahe construyó en Dinamarca un observatorio con aparatos muy novedosos, aunque todavía no se disponía de telescopios. Las observaciones que hizo Tycho fueron muy precisas. Así, compiló larguísimas tablas numéricas de las posiciones de los planetas entonces conocidos (Mercurio, Venus, Marte, Júpiter y Saturno). Su ayudante Johannes Kepler trabajó durante muchos años tratando de entender lo que significaban los números medidos por Tycho, y finalmente, después de 17 años de intenso trabajo numérico pudo expresar de manera sucinta que:

a) Los planetas se mueven alrededor del Sol a lo largo de órbitas elípticas.

b) Cuando un planeta da una vuelta alrededor del Sol, su velocidad va cambiando. Descubrió la forma en que se produce esta variación de la velocidad. De esta manera era posible predecir su posición.

c) De dos planetas, el que se encuentra más lejos del Sol tarda más tiempo en dar una vuelta completa alrededor del astro. Dicho en otras palabras, mientras más lejano esté el planeta, mayor será la duración de su año.

Los resultados obtenidos de las observaciones hechas por Tycho, son llamadas las tres leyes de Kepler.

Fue Isaac Newton quien pudo ofrecer una explicación fundamental de las tres leyes de Kepler. Con base en el trabajo de Galileo Galilei, propuso sus famosas tres leyes de movimiento, así como la ley de la gravitación universal. Esta última describe la forma en que dos partículas se atraen por el mero hecho de tener masa. Para poder extraer las consecuencias físicas de sus leyes, Newton tuvo necesidad de inventar una herramienta matemática, que hoy se llama cálculo diferencial e integral. De esta manera el científico inglés demostró que las tres leyes de Kepler son, de hecho, consecuencia de sus leyes. Newton publicó estos descubrimientos en su tratado Philosophiae naturalis principia mathematica ("Los principios matemáticos de la filosofia natural"), que constituye una de las hazañas intelectuales más excelsas del pensamiento humano y base fundamental y paradigma de la física moderna y la ciencia en general.

Newton presentó sus leyes en forma matemática, las llamadas ecuaciones de Newton que, junto con la ley de la gravitación universal, fueron suficientes para describir el movimiento de los cuerpos del Sistema Solar.

Después de Newton, un buen número de científicos se ocuparon en deducir otras consecuencias de sus ecuaciones. Sin embargo, lo que efectivamente hizo el sabio inglés fue considerar solamente el sistema compuesto por el Sol y un solo planeta. Es así que descubrió, al resolver las ecuaciones que había propuesto, las tres leyes de Kepler. De esta manera, demostró que cada planeta gira alrededor del Sol siguiendo indefinidamente una trayectoria elíptica.

De hecho, lo que Newton suponía es que el efecto de los demás planetas sobre el que estaba estudiando era ínfimo. Se puede pensar que esta suposición es adecuada ya que la masa de cualquier planeta es muchísimo menor que la del Sol, cuya influencia es preponderante sobre cualquier planeta. Por tanto, resolvió lo que se llama el sistema de dos cuerpos: el Sol y un planeta, y demostró que este sistema de dos cuerpos es un sistema estable.

Si se añade un segundo planeta al sistema bajo estudio tendremos un sistema de tres cuerpos. Se tienen ahora tres cuerpos atrayéndose mutuamente. En este caso cada planeta ya no sigue rigurosamente una órbita elíptica. Es cierto que el efecto de un planeta sobre el otro es mucho más pequeño que el del Sol, apenas una pequeña perturbación. Cada planeta continúa girando alrededor del Sol siguiendo su órbita muy parecida a una elipse. Su trayectoria exacta depende de su distancia al otro planeta, pues resulta afectado en distintos instantes por una fuerza gravitacional distinta. Estas perturbaciones distorsionan la trayectoria elíptica que tendría si sólo existiera el Sol.

Las ecuaciones de Newton, al tomar en cuenta las fuerzas gravitacionales entre tres cuerpos, no han podido ser resueltas en forma exacta hasta el día de hoy. Por tanto, no se puede de escribir y precisar la trayectoria que seguirá cada cuerpo, con presición ilimitada y durante todo el tiempo.

El problema se vuelve mucho más complicado si se añade otro planeta más; y cada vez que se añade otro el asunto se enreda todavía más. Lo mejor que se ha podido hacer es calcular, en primer lugar, los efectos más importantes, como el de la influencia preponderante del Sol, y luego, paso a paso, ir tomando en cuenta las influencias, menos importantes, de los demás planetas. Se tiene la esperanza de que este tipo de aproximaciones vaya llevando gradualmente a la solución exacta. Sin embargo, al aplicar este procedimiento al Sistema Solar resulta que se requieren cantidades extraordinarias de cálculos, lo que limita su utilidad como instrumento matemático. Por ejemplo, si se desea saber qué ocurriría con el Sistema Solar dentro de algunos miles de millones de años o mirar hacia atrás, para tratar de descubrir sus orígenes.

Antes del advenimiento de las calculadoras mecánicas y de las computadoras modernas, se partía de suponer aproximaciones plausibles que daban las predicciones de las posiciones planetarias con un nivel de precisión dado. Sin embargo, si se quería lograr una mayor precisión había que hacer un número mayor de cálculos. En la actualidad, teniendo a nuestra disposición una capacidad de cálculo impresionante, se pueden obtener resultados antes imposibles. Esto ha sido de importancia vital para, por ejemplo, lanzar al espacio y controlar las trayectorias de los satélites artificiales y de las naves que han visitado otros planetas, como el Voyager 2. La calidad de las observaciones y de los cálculos es lo suficientemente alta como para poder conocer el futuro cercano y el pasado reciente del Sistema Solar, con un grado considerable de confiabilidad. Se ha podido observar así la forma como las trayectorias de los planetas se desarrollan a lo largo de muchísimo tiempo para tratar de encontrar señales de inestabilidad. Se ha estudiado la historia de la órbita terrestre para encontrar evidencias de pequeñísimos tambaleos y cambios en su órbita que hayan podido afectar el clima y la historia geológica de nuestro planeta.

Sin embargo, estos cálculos han demostrado también lo que Poincaré (véase el capítulo IV) entendió pero no pudo probar: que las ecuaciones formuladas por Newton contienen una riqueza tal que el mismo Newton y los científicos que le siguieron no fueron capaces de extraer; se ha demostrado que engloban no sólo lo predecible sino también comportamientos caóticos. La naturaleza de las ecuaciones de Newton refleja el comportamiento de los sistemas físicos, en los que se puede pasar de un tipo de movimiento aparentemente ordenado, periódico y predecible a uno irregular e impredecible, esto es, caótico. Las ecuaciones que rigen los movimientos de un sistema de 3 cuerpos son no lineales. También lo son en el caso de 4, 5 o más cuerpos.

Con ayuda de la investigación numérica de las ecuaciones de Newton aplicadas a varios cuerpos, se ha descubierto que en el Sistema Solar hay regímenes de orden y de caos. Se ha encontrado evidencia de caos dinámico en las órbitas de la faja de asteroides situada entre Marte y Júpiter; en el movimiento a tumbos que efectúa Hiperión, uno de los satélites de Saturno, y en los anillos de los planetas exteriores, entre otros. Las últimas evidencias numéricas de que se tienen informes muestran trazas de caos en el movimiento de Plutón, y aun en la trayectoria de la Tierra. Se calcula al Sistema Solar una existencia de aproximadamente de 4 000 000 000 años con una forma muy parecida a la actual, mas no se trata de un sistema tan tranquilo o pronosticable, como un buen reloj. Nada garantiza que el futuro de los planetas, incluida la Tierra, no traiga sorpresas. La pregunta aún sin respuesta sería: ¿es el Sistema Solar estable?

En los siguientes capítulos analizaremos con algo de detalle las características caóticas de algunos de los cuerpos del Sistema Solar.

MARTE yJúpiter se localiza un cinturón de asteroides, integrado por rocas de dimensiones diversas y que giran alrededor del Sol. Quizá los componentes de un planeta que no llegó a formarse. El tamaño de estas rocas es mucho menor que el de cualquiera de los planetas conocidos: un ejemplo es Gaspra, fotografiado en 1991 por la nave Galileo a una distancia de 5 300km; mide 19 por 12 por 11 kilómetros.Se considera que el cinturón de asteroides contiene varios millones de cuerpos y se podría pensar que en el espacio que ocupa las rocas chocan continuamente entre sí. Sin embargo, el volumen del cinturón es tan grande que la distancia común entre dos asteroides es de varios millones de kilómetros, por lo que los acercamientos y las colisiones entre ellos son muy raros.

Debido a que el tamaño de los asteroides es mínimo en comparación con el de los planetas vecinos, cada uno de ellos es, de hecho, una sonda que casi no ejerce fuerza alguna sobre aquéllos pero que sí experimenta sus efectos. Por eso son de interés para el presente estudio pues cosas extrañas ocurren en los asteroides. Cada uno de ellos está sujeto, además de la fuerza atractiva del Sol, a las ejercidas por Marte y Júpiter, lo que causa que su trayectoria alrededor del Sol sea ondulada. Se podría uno preguntar si, a lo largo de tiempos muy gran- des, tales perturbaciones, que son relativamente pequeñas, se pudieran acumular y causar cambios radicales en sus órbitas.

Figura 48. Gráfica del número de asteroides a distintas distancias del Sol. A mediados del siglo pasado se empezó a estudiar la trayectoria de varios asteroides y se descubrió un hecho interesante. Al medir su distancia al Sol se encontró que había algunas para las cuales prácticamente no había asteroides. Con más detalle, si se hace una gráfica en la que se enumere la cantidad de asteroides situada a cada distancia (figura 48) se encuentra que a ciertas distancias del Sol casi no hay asteroides sino brechas. En la gráfica se ha usado como unidad de distancia la unidad astronómica (abreviada u.a.), que equivalee a la distancia del Sol a la Tierra, unos 150 000 000 km. Así, por ejemplo, a las distancias de aproximadamente 2.5 u.a., 2.8 u.a., 2.9 u.a., 3.3 u. a., no hay asteroides.

Figura 49. Movimiento de un asteroide que tiene con Júpiter una resonancia de 3:1. Ahora bien, como se vio en el capítulo anterior, la tercera ley de Kepler nos indica que hay una relación entre la distancia de un cuerpo al Sol y el tiempo en que completa su órbita, esto es, su año, o su periodo orbital. Por tanto, también se puede contar el número de asterorides que tienen determinado periodo orbital. En este caso conviene tomar como unidad el año de Júpiter (aproximadamente 4 333 días, el año joviano). La escala de tiempos se muestra en la misma figura 48. De ésta vemos que a la distañcia de 2.5 u. a., a la que le corresponde un periodo orbital de (1/3) que es igual a 1444 días, casi no hay asteroides. De la misma gráfica vemos que tampoco hay gran número de asteroides en los periodos orbitales de (2/5) (2.8 u. a.), (3/7) (2.9 u. a.), (1/2) (3.3 u a) de años jovianos, etcétera.

Lo curioso de este descubrimiento es que, como se ve, las brechas se dan en periodos que son cocientes de números enteros: el periodo de (1/3) es el cociente de 1 entre 3; el periodo de (2/7) es el cociente de 2 entre 7, etc. A estos periodos se les llama resonancias; a (1/3) se le llama la resonancia de 3:1; a (2/7), la resonancia de 7:2, y así sucesivamente.

La figura 49 muestra lo que ocurre a un asteroide cuyo periodo se halla en la resonancia 3:1 con Júpiter. En la figura (a) el planeta y el asteroide están a la mínima distancia. En (b), (c) y (d) vemos las posiciones de Júpiter después de cada vuelta completa del asteroide. Después de 12 años estos cuerpos volverán a estar nuevamente a la mínima distancia (figura 49(d)). Queda claro que el asteroide y el planeta se acercan casi a las mismas posiciones en intervalos regulares. Al transcurrir el tiempo, durante millones de años, estas coincidencias acumulan efectos que pueden ser perceptibles y que podrían modificar el tamaño de la órbita del asteroide. La cuestión que se planteó fue si estas resonancias podrían causar inestabilidades en las órbitas de los asteroides que estan en resonancia y que, en consecuencia, sus órbitas aumentaran tanto que tomaran una nueva órbita en la que no hubiera ninguna resonancia. Quedaría claro entonces que si alguna vez hubo algún asteroide en resonancia, después de mucho tiempo habría cambiado de órbita y la población de asteroides en resonancia disminuiría.

Desde el siglo pasado se trató de resolver esta cuestión buscando soluciones a las ecuaciones de Newton ajustadas al sistema asteroide, Marte y Júpiter. Sin embargo, por el motivo que se mencionó en el capítulo anterior, sólo se pudo hacer entonces para intervalos de tiempo muy pequeños, alrededor de 10 000 años, con el resultado de que en estos intervalos de tiempo no ocurría ninguna modificación de la órbita del asteroide.

No fue sino hasta la década 1970-1980 que, disponiéndose ya de computadoras electrónicas, fue posible hacer cálculos que cubrieran intervalos de tiempo mucho mayores. Se supuso que se colocaban 300 asteroides a las distancias correspondientes a la resonancia 3:1. Cada uno con diferente posición y velocidad. Las diferencias entre estas condiciones iniciales eran tales que diversos asteroides tenían posiciones iniciales distintas. Se inició el cálculo de las órbitas que seguiría cada uno de estos objetos durante dos millones de años y se halló que, para ciertas condiciones iniciales, las órbitas que seguían los asteroides no cambiaron de tamaño en dos millones de años. Es decir, estas condiciones daban lugar a órbitas estables. Además, se descubrió que para otro tipo de condiciones iniciales, en ciertos instantes las órbitas cambiaban abruptamente su tamaño. Estas condiciones iniciales corresponden a regiones caóticas.

En la figura 50 se muestra la gráfica del tamaño de la órbita de un asteroide de la región caótica en la resonancia 3:1, con el transcurso del tiempo. Podemos apreciar que, en los instantes marcados por las flechas, el tamaño de la órbita crece desmesuradamente. Se ve que un asteroide puede permanecer alrededor de 150 000 años en una órbita reducida y de pronto cambiarla notablemente. La nueva órbita es tan grande que, al recorrerla, el asteroide cruza las órbitas de Marte y la Tierra. Con el tiempo, puede ocurrir que el asteroide y uno de estos dos planetas choquen. De esta manera, los asteroides cuyas órbitas caen inicialmente en la zona caótica de la resonancia 3:1, gradualmente van desapareciendo creándose así la brecha en el cinturón.

Figura 50. Variación en el tiempo de los tamaños de las órbitas de asteroides en la zona caótica.Lo anterior también explica el hecho de que sobre la Tierra han caído meteoritos cuya composición química es parecida a la de los del cinturón de asteroides. Hasta épocas recientes no se había podido explicar cómo éstos podrían llegar hasta nuestro planeta. Por tanto, se puede pensar que la zona del cinturón de asteroides, con distancias que corresponden a la resonancia 3:1, es la fuente de algunos de los numerosos meteoritos caídos en nuestro planeta.

En la misma figura 50 vemos que si el asteroide no experimenta ninguna colisión, después de cierto tiempo vuelve a alterarse el tamaño de su órbita y cambia a otra órbita de tamaño parecido al que tenía originalmente. Al seguir transcurriendo el tiempo vuelve a recorrer una órbita muy grande. Posteriormente cambia a una pequeña y así sucesivamente.

Lo interesante de este descubrimiento es saber que en ciertas circunstanaas y con determinadas condiciones iniciales el comportamiento de un cuerpo del Sistema Solar puede ser caótico. Esto es lo que había intuido Poincaré a principios de siglo sin haberlo podido demostrar. Las ecuaciones de Newton incluyen este tipo de dinámica.

DESDE tiempos inmemoriales los hombres se dieron cuenta de que la Luna completa una vuelta alrededor de su eje en el mismo tiempo que le lleva dar una vuelta alrededor de la Tierra. Por este motivo siempre vemos su misma cara; la cara oculta de la Luna fue conocida cuando naves espaciales, alrededor de 1975, la fotografiaron. De hecho, todos los satélites de los planetas de nuestro sistema giran sobre su eje al mismo tiempo en que giran alrededor de su planeta. Hay una excepción: el satélite Hiperión de Saturno, que da una vuelta alrededor de su eje en 13 días mientras que gira alrededor de Saturno en 21 días.Nuestra Luna siempre nos presenta la misma cara debido a que la Tierra ejerce una fuerza gravitacional de atracción sobre el satélite que hace que éste se deforme, generando tensiones internas. De esta manera, el giro del satélite se modifica hasta adquirir el mismo ritmo que el que tiene para dar una vuelta alrededor del planeta. Lo que se dijo acerca de la Luna es válido para los satélites de los demás planetas, y así ocurre. Entonces surge la pregunta: ¿por qué Hiperión no ha sincronizado su rotación? Hay dos factores que lo han impedido: su forma elongada y la influencia del satélite Titán de Saturno. Considerémoslas.

Hiperión no tiene la forma casi esférica de los demás satélites planetarios. Su forma es muy especial, con dimensiones de 380 km por 290 km por 230 km. Además, su superficie muestra muchos cráteres. De todos los satélites conocidos, Hiperión es el más irregular.

Su orientación es poco común, pues un satélite así de elongado debería girar alrededor de su eje más corto. El mayor, AB, debería estar situado en el plano de su órbita (figura 51). De esta manera el eje de giro debería hallarse en posición perpendicular al plano de la órbita; sin embargo, se halla inclinado.

La órbita de Hiperión está situada lejos de los famosos anillos de Saturno y muy cercana a la órbita del gigantesco satélite Titán. La distancia de Hiperión a Saturno es de aproximadamente 1 500 000 km. Titán, por sus dimensiones y su cercanía a Hiperión ejerce sobre éste una fuerza considerable y experimenta, por tanto, dos fuerzas de gran magnitud: la ejercida por el planeta y la de Titán. Como resultado, por cada cuatro vueltas que Titán da alrededor de Saturno, Hiperión da sólo tres, es decir, hay una resonancia 4:3. La fuerza ejercida por Titán ha forzado a Hiperión a seguir y permanecer en una órbita estable y, como resultado de estas influencias, la orientación del eje de giro de Hiperión va cambiando, dando tumbos.

Figura 51. Orientación que el eje de giro de Hiperión debería tener.

Figura 52. Eje de giro que, efectivamente, tiene Hiperión. Al resolver, con ayuda de una computadora, las ecuaciones de Newton del sistema de tres cuerpos: Hiperión, Titán y Saturno, se ha encontrado que hay zonas caóticas, análogas a las descritas en el capítulo VIII. Las características del movimiento caótico se refieren a la orientación del eje de giro. La más pequeña desviación de éste, con respecto de una posición perpendicar al plano de su órbita, puede crecer tan rápidamente que, en muy poco tiempo, puede quedar paralelo al plano de la órbita (figura 52) y de ésta, pasar a una nueva orientacion. En el momento presente, Hiperión se halla en una región caótica como la descrita.

De lo anterior, podemos decir que Hiperión sigue un comportamiento que constituye una mezcla de movimientos ordenados y caóticos. La parte ordenada es su trayectoria alrededor de Saturno, mientras que la caótica es la relacionada con el giro alrededor de su eje. De hecho ha sido posible predecir la posición de Hiperión en su órbita por períodos grandes de tiempo. Esto es debido al movimiento ordenado. Sin embargo, la predicción de la dirección del eje de giro no se ha podido hacer con precisión, a causa de lo caótico del movimiento. Las observaciones de la orientación del satélite indican, efectivamente, un movimiento caótico.

Con base en un análisis matemático muy detallado, se ha encontrado que la región de caoticidad en la que se encuentra Hiperión es muy grande, lo cual significa que, aunque se den variaciones en su orientación, lo más probable es que termine en otro punto de la misma región caótica. Sin embargo, Hiperión no siempre estuvo en esta región. Es poco probable que cuando el satélite se formó se haya encontrado en una región caótica. En el pasado distante, el tiempo que tardaba Hiperión en rotar sobre su eje era mucho menor que el que tardaba en dar una vuelta alrededor de Saturno. Es decir, la duración de su día era mucho más corta que la de su año. A medida que las fuerzas de tensión internas fueron acumulando su influencia a lo largo de millones de años, la velocidad de rotación de Hiperión alrededor de su eje iba disminuyendo, es decir, su día iba siendo cada vez más y más grande. De esta forma, llegó un momento en que adquirió una velocidad de giro que correspondía a la zona caótica. En este caso, la velocidad de giro desempeña el papel de la cantidad q del capítulo VIII. Antes de adquirir la velocidad que lo envió al caos, el eje de giro era perpendicular a su órbita, como se ve en la figura 51. Sin embargo, una vez que Hiperión entró a la zona caótica, la estabilidad de su giro se perdió e Hiperión empezó a dar tumbos.

Es posible que otros satélites de formas irregulares hayan estado alguna vez en zonas caóticas. Sin embargo, en cierto momento adquirieron velocidades rotacionales tales que los sacaron de aquéllas y entraron en una zona ordenada en la cual se encuentran hasta el día de hoy.

El estudio de la caoticidad en los satélites es de gran importancia para el desempeño de los satélites artificiales. Como nuestro planeta no constituye una esfera perfecta ni tiene su masa distribuida uniformemente, las órbitas de los satélites artificiales pueden ser afectadas de manera notable, en particular si entran en una zona caótica. Para evitar que den tropiezos en su eje de giro o se desvíen de la órbita planeada, los ingenieros deben estar controlando y ajustando constantemente la posición y la orientación del satélite. De otra forma, los efectos gravitacionales no equilibrados harán que la órbita del satélite se desvíe o que se produzca un movimiento irregular de tal magnitud que impida que cumpla su misión. Para evitar movimientos no deseados se utilizan cohetes pequeños o ráfagas de gases que corrigen las velocidades del satélite. Sin embargo estos dispositivos necesitan combustible y, una vez que se agota, ya no hay manera de hacer las correcciones y la vida útil del satélite llega a su fin.

Después de hacer cálculos muy largos y complicados se han encontrado las órbitas más adecuadas para los satélites artificiales. Se sabe cuáles de ellas son ordenadas y cuáles se hallan en zonas caóticas. Una vez escogida la órbita adecuada es problema de los ingenieros determinar las condiciones de lanzamiento del satélite para que entre, efectivamente, en la órbita con las condiciones previstas. Por supuesto, en este caso se toman en cuenta las perturbaciones que producen al satélite el Sol y la Luna.

Hemos considerado hasta este momento tipos de movimientos irregulares de los satélites debidos a que sus condiciones los colocan en zonas caóticas, pero ¿qué pasa con los planetas?

EN LOS dos capítulos anteriores vimos que los asteroides y algunos satélites planetarios muestran un comportamiento caótico.Viene ahora la siguiente pregunta: ¿pueden también los planetas del Sistema Solar mostrar este tipo de comportamiento?

Como se dijo antes, Newton fue el primero que sentó las bases para estudiar el movimiento de los cuerpos celestes, análisis que se realiza a partir de las ecuaciones de Newton y de la ley de la gravitación universal. En primera instancia, Newton resolvió un problema imaginario: que el Sistema Solar lo integrara sólo el Sol y un planeta. Usando las leyes que propuso pudo resolver con exactitud el problema, obteniendo como resultado las leyes que Kepler había descubierto a partir de las observaciones de Tycho Brahe. Es decir, Newton pudo explicar los hechos observados y expresados en forma sucinta por Kepler. El inglés estuvo consciente de que su trabajo, que por cierto constituye una gran hazaña intelectual, no era suficiente, ya que en realidad un planeta no está sujeto sólo a la fuerza gravitacional del Sol, sino también a la de los demás planetas, satélites y asteroides. Es claro que el efecto preponderante sobre cualquier planeta es el que se debe a la fuerza del Sol, ya que la masa de este astro es muchísimo más grande que la de cualquier otro cuerpo de nuestro sistema; el efecto de los demás planetas y cuerpos del sistema es pequeño en comparación. El planeta gigante, el de mayor masa, es Júpiter, y la masa del Sol es unas 1 050 veces la de Júpiter que, a su vez, es 315 veces más que la de la Tierra.

Newton intentó tomar en cuenta el efecto de los demás planetas sobre sus respectivos movimientos. El conjunto de interacciones gravitacionales de los planetas y el Sol es tan complejo que ni Newton ni nadie hasta la fecha ha podido resolver matemáticamente y de forma exacta las ecuaciones de movimiento para este conjunto de cuerpos. Newton ya se había dado cuenta de ciertas irregularidades en los movimientos de los planetas que le hicieron sospechar que se podría romper el orden del Sistema Solar, a menos que sus órbitas fueran corregidas en momentos determinados y concluyó que la intervención divina era necesaria para mantener el Sistema Solar como lo conocemos.

Años más tarde Laplace, a quien ya nos referimos en un capítulo anterior, en un alarde de dominio de las matemáticas, demostró que aun si hubiese algunas desviaciones en los parámetros de las órbitas planetarias, resultaba que eran pequeñas y se autocorregían, es decir, que existía la tendencia a que se eliminaran. Laplace concluyó que estas perturbaciones no se podían acumular a lo largo de millones de años de modo que produjeran las inestabilidades capaces de desquiciar el Sistema Solar. Las posibles desviaciones de las órbitas de los planetas se dan dentro de límites muy estrechos, por lo que nuestro sistema, como lo conocemos, permanecerá casi igual para siempre. Es dentro de esta línea que escribió el párrafo que citamos en el capítulo IV.

Figura 53. Frecuencias del movimiento de Júpiter. Sin embargo, a pesar de su gran optimismo, Laplace no pudo explicar todos los detalles de los movimientos conocidos de la Luna, por ejemplo. Sus cálculos mostraban discrepancias con las observaciones que, a pesar de ser pequeñas eran significativas y no encontró forma de resolverlas.

En última instancia, resulta que los cálculos de Laplace y sus conclusiones sólo podían dar cuenta de lo que ocurriría en el Sistema Solar a lo largo de unos miles de años.

Posteriormente, Poincaré fue el que se dio cuenta, como ya lo mencionamos, de que podrían ocurrir comportamientos, que hoy llamamos caóticos, si se consideraban intervalos muchísimo más grandes. Como ya ejemplificamos en varios casos, a pesar de que el comportamiento de un sistema parezca regular y ordenado en determinado intervalo de tiempo, puede ocurrir que efectivamente sea caótico y de repente muestre algunas características erráticas. Poincaré llegó a la conclusión de que, hasta su época, el problema de la estabilidad del Sistema Solar no había sido resuelto. El problema concreto era que calcular su evolución a partir de las ecuaciones de Newton y de su ley de la gravitación universal por varios miles de millones de años requería de un esfuerzo imposible de concretar a principios de siglo. Una computadora lo suficientemente poderosa puede sin embargo realizar estos cálculos por el método que se llama integración numérica. Sin embargo, se requieren tiempos extraordinariamente grandes de cálculo. Cualquier cálculo directo debe proceder en incrementos de tiempo lo suficientemente pequeños como para poder seguir el curso de cada uno de los planetas.

Así, debe tomar en cuenta que Mercurio da una vuelta alrededor del Sol en 88 días, mientras que Plutón lo hace en 249 años. Además, debido a que nada importante ocurre en periodos de varios miles de años se debe seguir el cálculo de la evolución del Sistema Solar durante varios millones de años para intentar encontrar comportamientos de largo plazo. Al mismo tiempo hay que considerar tiempos pequeños y grandes. Para desarrollar este programa se debe trabajar en la computadora durante muchísimo tiempo.

No fue sino hasta 1984 que el astrónomo estadunidense Gerald Sussman desarrolló un método y construyó un sistema de computación especial para lograr los requerimientos necesarios. La máquina que construyó podía calcular la situación de los constituyentes del Sistema Solar unos 100 millones de años hacia el futuro. En colaboración con otro científico, Jack Wisdom, trabajaron en el cálculo numérico de la evolución del Sistema Solar. Descubrieron que el movimiento de Júpiter muestra muchísimas frecuencias, como se observa en la figura 53; si gira en un órbita periódica pura sólo mostraría una frecuencia única y la gráfica se vería con una sola línea vertical. Las frecuencias que aparecen en el movimiento del planeta se deben a las interacciones que sobre él ejercen los demás cuerposdel Sistema Solar. Con el método propuesto por Laplace, este tipo de efectos no se logró descubrir.

Sussman y Wisdom hicieron dos corridas con el planeta Plutón, en cada caso en posiciones ligeramente distintas. En la primera Plutón tenía determinada posición y en la siguiente corrida una ligeramente distinta. En ambas, los demás planetas y cuerpos del Sistema Solar tenían las mismas condiciones iniciales. Encontraron que las dos trayectorias estudiadas se separaban muy rápidamente. Como ya sabemos, esto indica una situación caótica.

Lo anterior significa que los astrónomos sólo podrán predecir dónde se encontrará Plutón dentro de unos miles de años con un pequeño error, pero no dónde estará en 50 000 000 de años. Esto se debe a que para poder predecir su posición en el futuro hay que conocer su posición actual sin ningún error, cosa imposible. El hecho de que se encuentre en una zona caótica no significa necesariamente que en algún momento se vaya a separar del Sistema Solar, pues hacer predicciones en estas condiciones no es posible. Resulta que Plutón ha seguido su actual órbita durante muchos millones de años.

Otros cálculos, usando otras técnicas numéricas, han posibilitado remontarse a 100 000 000 000 de años en el futuro. Nuevamente se ha encontrado que Plutón efectivamente se halla en una zona caótica.

En los últimos años, Jacques Laskar, en Francia, con ayuda de las técnicas de cálculo más nuevas, realizó lo que Sussman y Wisdom hicieron con Plutón, pero abarcando todo el Sistema Solar. Es decir, considerando dos situaciones en las que los planetas y el Sol diferían muy poco en sus posiciones y velocidades iniciales. Dicho en otras palabras hizo dos corridas; en una de ellas consideró al Sol y a los planetas en determinadas posiciones y velocidades iniciales y calculó las posiciones que cada cuerpo tendría en los próximos 200 000 000 de años. En seguida volvió a repetir el cálculo, pero cambiando ligeramente las posiciones y velocidades iniciales del Sol y los planetas. Encontró que las órbitas que seguirían los planetas en los dos casos empezaban a separarse cada vez más. Esto es una manifestación de que el Sistema Solar está también en una región caótica.

La conclusión de estos estudios es que más allá de varios miles de años no se puede predecir las posiciones que tendrán los planetas, y en particular la Tierra. Este tema es de activa investigación en la actualidad. Entre las cuestiones que se estudian se halla la relación entre caos y estabilidad. Puede ser posible que, a pesar de que no se puedan hacer predicciones precisas para muchos millones de años, la caoticidad de los movimientos de los cuerpos del Sistema Solar sea limitada. La cuestión de si éste seguirá grosso modo el curso que ha mantenido hasta ahora, sin grandes alteraciones, sigue siendo un problema abierto. El significado de su movimiento caótico, pese a los avances que hemos reseñado, es todavía un misterio que no ha sido aclarado.

HEMOS presentado una visión del desarrollo de nuevas ideas, de los fractales y del caos, que tienen aplicación en varios campos del conocimiento: la física, la biología, la ingeniería, la música y la lingüística entre otros. Éstas han abierto la posibilidad de entender fenómenos que con anterioridad no habían sido tratados satisfactoriamente. Esta gama de fenómenos se comporta en formas análogas. Un hecho interesante es que hay una aparente universalidad en la descripción de fenómenos que son de distinta naturaleza. Se ha descubierto que los detalles particulares de los fenómenos no tienen gran importancia.Un hecho interesante es que muchos de los elementos necesarios para el desarrollo de las teorías de los fractales y del caos ya se tenían desde hace más de un siglo por lo menos. Sin embargo, los pocos científicos que algo vislumbraron no tuvieron eco y sus ideas quedaron en el olvido.

Una característica común a los fenómenos estudiados -provenientes de distintas ramas del conocimiento- es que se trata de fenómenos no lineales. Este parece ser el punto crucial. Todos los fenómenos no lineales tienen un comportamiento que muestra, en ciertas circunstancias que analizamos con detalle, el caos. En consecuencia, una vez que se analiza un caso, sus resultados nos permiten conocer importantes propiedades cualitativas de otros casos.

No hemos podido presentar una revisión de todos los casos en que se han aplicado las ideas de fractales y de caos. La variedad de aplicaciones es considerable y crece día con día, de modo que no es posible incluirlas todas. Sin embargo, hemos tratado un gran número de situaciones muy diferentes y todavía hay mucho por hacer en este campo.

La manera novedosa de tratar los fenómenos que hemos reseñado en el libro consiste en estudiar sus características en términos de los valores que pueden adquirir los parámetros del sistema. Esta forma de análisis global ha permitido descubrir que para ciertos valores de estos parámetros el comportamiento es estable mientras que para otro conjunto de valores es caótico.

Las ideas desarrolladas acerca de los fractales y del caos tienen gran importancia, no sólo conceptual sino de aplicación práctica, por ejemplo, en la hidrodinámica y la aviación, en la economía y la bolsa de valores, y en muchos otros casos.

Un elemento de importancia vital para el desarrollo que hemos presentado ha sido la moderna computadora digital. Con su ayuda es que se ha podido extraer el contenido de fractales y de caos de las distintas situaciones.

La creación de los nuevos métodos para tratar los fenómenos que hemos considerado ha dado oportunidad de que se haya producido un trabajo interdisciplinario entre matemáticos, físicos, químicos, ingenieros, economistas, músicos, médicos, biólogos, que han realizado con gran motivación. De esta manera se han obtenido logros considerables.

La utilización de las ideas de fractales y de caos ha tenido mucha repercusión en la descripción de fenómenos muy complejos. En particular, la geometría fractal ha resultado ser la que describe, posiblemente, la mayoría de los objetos que hay a nuestro alrededor, en contra de la idea que se tenía durante siglos de que las formas más comunes son las descritas por la geometría euclidiana. ¡Estas han resultado ser las excepciones!

De la misma manera, el caos parece estar en todos lados: en la columna de humo de un cigarrillo, en el clima, en el movimiento de los automóviles, en las avenidas de alta velocidad, en los seguros, en la teoría política, en astronomía. El caos ha eliminado barreras y fronteras entre disciplinas. El caos es una ciencia de la naturaleza global de los sistemas.

Hemos considerado el análisis de situaciones que pueden parecer raras o, más bien, poco familiares. Sin embargo, viéndolas con mayor detenimiento resultan ser de gran simplicidad.

Es así que hemos presentado una vista panorámica de un tema que está causando una revolución en el pensamiento científico contemporáneo: el de los fractales y del caos.

Este libro se terminó de imprimir y encuadernar en el mes de diciembre de 1996 en la Impresora y Encuadernadora Progreso, S A. de C. V. (IEPSA), Calzada de San Lorenzo, 244; 09830 México, D.F. La formación y tipografía se hicieron en el Taller de Composición del FCE y estuvieron a cargo de Angelina Peña Urquieta. Se tiraron 7 000 ejemplares.La Ciencia desde México es coordinada editorialmente por MARCO ANTONIO PULIDO y MARÍA DEL CARMEN FARÍAS.

Durante el último cuarto de siglo se ha venido generando una revolución en el mundo de las ideas científicas: el estudio de los fractales y el caos. Las aplicaciones de tales teorías son verdaderamente enormes e incluyen la física, las matemáticas, la biología, la medicina, la economía la lingüística y otras muchas gamas del saber humano. En todas ellas se dan situaciones que, tratadas con los procedimientos en uso, no pueden ser explicadas satisfactoriamente. El propósito del presente libro es ofrecer una explicación somera, accesible a todos, de los antecedentes de dicha revolución científica. Se tratará en un principio el concepto de fractal sólo para descubrir que la mayoría de las figuras que existen a nuestro alrededor son fractales y que la excepción son las figuras geométricas. Después, tras hacer una revisión de la mecánica clásica de Newton y de las ecuaciones que la describen, pasaremos a estudiar el concepto del caos. El comportamiento de un cuerpo puede ser estable o caótico dependiendo de sus parametros iniciales. Creencia común de los científicos es que una teoría que describe los fenómenos de la naturaleza pueda predecir el desarrolío futuro del sistema que trata, cosa que, veremos, no es tan exacta como se pensaba y esto tiene numerosas aplicaciones en la astronomía y aun en la medicina, el estudiar el comportamiento dinámico de un órgano tan importante como el corazón.La relación estrecha entre los fractales y el caos puede ser empleada, asimismo, para tratar de explicar el movimiento de la Bolsa de Valores, la elaboración de mapas, la estabilidad del Sistema Solar y en fin una gama de fenómenos muy vasta. La última palabra sobre estos temas aún no ha sido dicha y queda mucho camino por recorrer…

Eliezer Braun, autor de varios libros de esta colección, es también uno de los que mayor número de ejemplares ha vendido. Estudió en la Facultad de Física de la UNAM y obtuvo su doctorado en la Universidad de Leyden, Holanda. Su actividad principal es la enseñanza tanto en la UNAM como en la UAM lztapalapa.

13/08/2007
