La tragedia de la Luna

Isaac Asimov

La tragedia de la Luna

Publicado con autorización de Doubleday & Company, Inc. New York

Escaneado por: Dom

Corregido por: mí

© 1973 by Isaac Asimov

© Ed. Cast.: Alianza Editorial S. A., Madrid, 1979

Calle Milán, 38; Teléfono 200 00 45

Printed in Spain

Dedicado a:

Algunos de los lugares que han inspirado algunos de los ensayos aquí incluidos:

La Bread Loaf Writers’ Conference (cap. 13)

El Instituto del Hombre y la Ciencia (cap. 14)

El S.S. Statendam (caps. 2 y 16)

y

El University Hospital (cap. 12)

Introducción

Douglas W. Jerrold, un autor inglés del siglo XIX, oyó en cierta ocasión que un amigo suyo, escritor pronunciadamente mediocre, iba a dedicarle un libro. Una mirada de melancolía cruzó por su rostro. Sacudió la cabeza y dijo: «¡Arma terrible la que tiene el hombre en sus manos!»

Con dedicatorias claramente inscritas en más de un centenar de libros míos, la triste observación de Jerrold me viene a veces al pensamiento y me enerva. Nunca pido permiso antes de estigmatizar a alguien o algo sobre la página de la dedicatoria, y a veces pienso con vergüenza que algún buen amigo mío podría no desear que le colocaran tan conspicuamente en la picota. (En cierta ocasión fui bendecido por una enérgica carta exigiendo la supresión de una dedicatoria, que fue suprimida en consecuencia; pero ésa es otra historia.)

Además, las dedicatorias suelen ser también harto escuetas y misteriosas. Dedicamos un libro «a fulanito de tal, por su ayuda», y en seguida todos quieren saber cómo y cuándo ayudó y cuál era la dificultad a resolver. ¿Qué nos dio? ¿Dinero, una coartada, una palabra amable? Lo más probable es que uno no llegue nunca a saberlo.

Permitidme, pues, que consagre algunas páginas a explicar la dedicatoria.

I

En 1971 me persuadieron, muy en contra de mi voluntad, para que asistiese a la Conferencia de Escritores de Bread Loaf, Vermont, y disertara ante los estudiantes reunidos sobre cómo escribir ensayo. Mis protestas, en el sentido de que no sabía cómo escribir esa clase de literatura, porque lo hacía instintivamente, fueron despachadas con desdén.

Lo cierto es que, mal que bien, conseguí arreglármelas para dar unas cuantas conferencias y que me divertí a conciencia. Lo único que me cogió de sorpresa fue el hecho de que cada miembro del profesorado tenía que dar una de las conferencias vespertinas y, según iba asistiendo a ellas, descubrí que cada cual leía de sus propios trabajos.

Yo no había llevado nada mío para leer, pero durante los primeros diez días había escrito un artículo sobre Ruth (la heroína del libro bíblico del mismo nombre) para los libros del Reader’s Digest y pensé que podría repetir el meollo del ensayo. Resultó, sin embargo, que me fui alejando del tema (me ocurre a menudo, pues mis charlas no las preparo de antemano), y al cabo de un rato me encontré soltando un solemne sermón -sin intención alguna, os lo aseguro.

Tengo por costumbre no mirar nunca al público. Me fijo en el espacio que está sobre sus cabezas. Pero escucho, y por los sonidos que oigo guío la charla. Y lo que busco siempre con gran ansiedad, sin conseguirlo prácticamente jamás, es un silencio de muerte. Esta vez lo conseguí, y logré pronunciar la mejor (o, más bien, la más eficaz) conferencia de toda mi carrera. Al final coseché una prolongada ovación.

Algo así no puedo dejar que se pierda. Para mí (y, con certeza, para cualquiera que escriba tanto como yo) es regla cardinal que nada se eche a perder. Así que escribí una versión de la conferencia con el título de «Perdido en la no traducción» (cap.13), y luego un tratamiento exhaustivo que se publicó como libro para jóvenes, La historia de Rut (Doubleday, 1972)

Pero no puedo dedicar el libro al escenario de los hechos, con exclusión de todo lo demás. El poeta John Ciardi, que dirigió la conferencia de escritores durante muchos años, es un viejo amigo mío y causa de mi presencia allí. Alto y grande, con una orgullosa nariz de dimensiones aristocráticas y una tronante voz de bajo que podría hacer sonar la guía telefónica como gran literatura, presidió las veladas nocturnas con ingenio y buen humor.

«Adiós, oh poeta menor», declamé grandilocuentemente al término de la conferencia.

«Adiós, oh pelmazo mayor», respondió sin perder compás y sepultándome bajo una avalancha de risas.

Todo discurrió lo bastante bien como para que en 1972 volviera a repetir, ocasión que menciono en los primeros párrafos de «A través del microcristal» (cap. 9).

II

El Instituto del Hombre y la Ciencia, en Rensselaerville, Nueva York, es el «seminario al norte de Nueva York» mencionado en los primeros párrafos de «Lo antiguo y lo último» (cap. 14). Estuve allí en la primera semana de julio de 1972.

Evité cautamente identificarlo de modo más preciso, porque pensé que los organizadores quizá no desearan ver mezclado su nombre con el tipo de ensayos informales que escribo. Me equivocaba. Hace justamente una semana (mientras escribo esto) el Instituto escribió al Magazine of Fantasy and Science Fiction identificándose como el lugar de marras y pidiendo permiso para preparar sesenta ejemplares de «Lo antiguo y lo último» para uso propio.

Pero hay más, y es que en una carta personal dirigida a mí, el director fue tan amable de decir que en aquella ocasión había subestimado yo la excelencia de mi charla. (Gracias a Dios, no soy modesto, porque si lo fuera, os privaría de interesantes retazos de información como éste.)

Una vez más, lo pasé inesperadamente bien. La señorita Duncan MacDonald (una bella mujer, a pesar de su nombre) fue quien me invitó a asistir, quien se encargó de organizar las sesiones semanales, y quien me pidió que diese la charla con escasísima antelación. Y fue Beardsley Graham quien dio la charla sobre video-cassettes que inspiró la mía.

Estoy agradecido a ambos.

III

El S. S. Statendam es el barco donde hice el crucero descrito con perfecta exactitud (suprimiendo unos pocos vuelos retóricos) en «El crucero y yo» (cap.16). El buque era lujoso, y los oficiales y la tripulación no pudieron ser más cooperativos y amables.

Los reporteros de a bordo no parece que se divirtieran, pero ése era su problema. Yo lo pasé en grande, y lo mismo sucedió -a mi entender al menos- con todos los demás participantes en los seminarios, a título de ponentes u oyentes. La organización general fue sin duda bastante pobre, pero todos disfrutamos, y eso hay que agradecérselo a Richard C. Hoagland, quien (como se dice en el capítulo) me embarcó en el asunto.

IV

Mi estancia en el University Hospital, tal como se describe en los párrafos primeros de «Cirujano, cirujano, la garganta córtame» (cap. 12), fue completamente involuntaria. Estuve allí durante una semana exactamente e, innecesario es decirlo, el placer de mi estancia fue limitado.

Sin embargo, tenía que ser; y salí bien del asunto. Mi gratitud se dirige al Dr. Paul R. Esserman, el internista que detectó la enfermedad; al Dr. Manfred Blum, el endocrinólogo que la analizó, y al Dr. Carl A. Smith, el cirujano que la subsanó.

Y, por supuesto, a todas las enfermeras y demás personal del hospital, pues hicieron cuanto estuvo en su mano para que todo fuese sobre ruedas; y especialmente a Renée Vales, una bella enfermera haitiana, que me cogió la mano durante toda esa primera y larga noche post-operatoria, cuando no podía ni dormir ni (cosa aún peor), escribir a máquina.

La tragedia de la Luna

A) Sobre la Luna

1. La tragedia de la Luna

Esta mañana había luna llena en el cielo. Me desperté cuando el amanecer iluminaba el cielo de un azul pizarra (como es mi costumbre, porque soy madrugador) y al mirar por la ventana que da al oeste la vi: un ancho disco amarillo sobre un fondo azul pizarra uniforme, colgando, inmóvil, sobre una ciudad que aún soñaba al amanecer.

Por lo general no me afectan fácilmente los estímulos visuales, porque soy relativamente insensible a cuanto acontece fuera del interior de mi cráneo, pero esta escena penetró en mí.

Me encontré maravillándome de la buena suerte de la Tierra por tener una luna tan grande y tan hermosa. Supongamos, pensé, que la Luna girase alrededor de la hermana gemela de la Tierra, Venus; supongamos que no fuese Venus, sino la Tierra, la que careciera de un satélite. ¡Cuánta belleza habríamos perdido! Y cuán inútil hubiera sido perderla en beneficio de Venus, cuya capa de nubes ocultaría para siempre a la Luna, aunque hubiera sobre el planeta seres inteligentes capaces de observarla.

Pero luego, mientras desayunaba, seguí pensando…

La belleza, a fin de cuentas, no lo es todo. Supongamos que la Tierra careciese de luna. ¿Qué pasaría?

Para empezar, la Tierra sólo tendría mareas solares, mucho menores que las actuales. Tendría un día más corto, porque la fricción de la marea no la habría desacelerado tanto. Quizá se habría formado, durante las convulsiones de parto del sistema solar, de un modo algo distinto al faltar un núcleo secundario que se estuviera formando al mismo tiempo (si es que la cosa fue así). O bien la vida podría haber evolucionado de modo distinto sin la captura de un gran satélite hace 600.000 años (si eso fue lo que sucedió).

Pero ignoremos esto. Supongamos que la Tierra se formó tal y como se ha formado, que la vida evolucionó tal y como ha evolucionado, que el día sigue siendo lo que es y que la menor intensidad de las mareas no tiene una importancia crucial. Y ahora supongamos que el hombre primitivo (¿hace 25.000 años?) levantó su mirada interrogante al cielo…

¡Y no encontró Luna alguna!

¿Qué habría sucedido?

Voy a proponer la tesis de que, de no haber habido Luna, la historia de la humanidad hubiera sido muy, muy distinta, y para bien; especialmente si esa luna hubiera estado circundando a Venus. El hecho de que la Tierra tenga, efectivamente, una Luna y Venus, no, puede ser la causa de que la humanidad quizá esté acercándose al fin de sus días en tanto que sociedad tecnológica.

No estoy bromeando. Sed indulgentes conmigo…

Dejemos por ahora la Luna donde está, e intentemos imaginar qué pensaba el hombre primitivo que hacían los objetos en el cielo.

Para empezar, debe de haber sido consciente de que el Sol salía, se movía a lo largo del cielo, se ponía y luego se elevaba a la mañana siguiente, repitiendo de modo indefinido el proceso. La única explicación racional posible de lo que veía era suponer que el Sol giraba alrededor de la Tierra una vez al día.

De noche aparecían las estrellas y la observación revelaría que ellas también giraban alrededor de la Tierra una vez por día, aunque manteniendo fijas sus posiciones relativas.

El hombre podría haber argumentado también que el cielo permanece quieto y que la Tierra gira sobre su eje. Pero ¿por qué iba a hacerlo? La hipótesis de la rotación terrestre no habría explicado ni tanto así mejor las observaciones. Al contrario, habría suscitado la cuestión de por qué la Tierra parece inmóvil cuando en realidad estaba moviéndose, cuestión imposible de contestar para cualquier hombre prehistórico.[1]

Observaciones cuidadosas mostrarían que, en realidad, el Sol no se mueve alrededor de la Tierra en exacta correlación con las estrellas. El Sol tarda cada día cuatro minutos más en completar el círculo, lo que significa que el Sol deriva de Oeste a Este sobre el fondo de estrellas cada día y que describe una circunferencia completa alrededor del cielo en 365 ¼ días.

Lo cierto es que podríais explicar el movimiento del Sol frente a las estrellas igual de bien suponiendo que la Tierra gira alrededor del Sol en 365 ¼ días. Digo igual de bien, pero no mejor. Y, una vez más, necesitaríais explicar por qué la Tierra permanece inmóvil si, de hecho, gira alrededor del Sol.

¿Dónde entra la Luna? La Luna es un objeto que salta a la vista casi tanto como el Sol. También sale y se pone a diario; y también se rezaga en relación con las estrellas: en realidad, mucho más que el Sol. Describe una circunferencia sobre el fondo estelar en sólo 27 1/3 días.

El movimiento de la Luna puede describirse igual de bien, pero no mejor, si imaginamos que la Tierra gira alrededor de ella en 27 1/3 días.

Olvidemos ahora el escaso poder de persuasión de que la Tierra se mueve sin que nadie se percate de ello. Supongamos que pudiera suceder (como de hecho sucede) y preguntemos simplemente esto: si imaginamos que la Tierra gira alrededor del Sol para explicar los movimientos solares, y que gira alrededor de la Luna para explicar los movimientos lunares, ¿qué movimiento describe realmente? Porque ambos no puede describirlos a la vez, ¿no es cierto?

Pero entonces supongamos que un loco primitivo, con la imaginación de un novelista de ciencia ficción, sugiriera que la Luna gira alrededor de la Tierra en 27 1/3 días, mientras que la Tierra y la Luna, esta última girando todavía de un modo uniforme, dan juntas una vuelta en torno al Sol en 365 ¼ días. Esto explicaría limpiamente el movimiento aparente y las fases de la Luna, y también el movimiento aparente del Sol.

Pero ¿imagináis que alguno de sus oyentes aceptaría un sistema tan complicado sobre la base de lo conocido en tiempos prehistóricos? ¿Por qué iban a existir dos centros en el universo? ¿A santo de qué iban a girar unos objetos en torno a la Tierra y otros en torno al Sol?

Era posible explicar el movimiento y las fases de la Luna además del movimiento del Sol, suponiendo que éste y aquélla se movían independientemente, a velocidades distintas, en torno a un centro común: la Tierra. Y eso no era fácil si uno suponía que la Tierra y la Luna se movían en órbitas independientes alrededor del Sol, o que la Tierra y el Sol lo hacían en órbitas independientes alrededor de la Luna.

Sólo la Tierra se prestaba fácilmente a hacer las veces de centro común para ambos cuerpos; lo cual, junto con su evidente inmovilidad, debió de fijar la noción geocéntrica («centrado en la Tierra») en la mente de cualquier astrónomo capaz de elucubrar sobre tales cosas. Para el observador ordinario, la obvia inmovilidad de la Tierra debía de ser suficiente.

Mucho después de que fueran cuidadosamente estudiados los movimientos del Sol y de la Luna en relación con las estrellas[2], se estudiaron y analizaron los movimientos de los planetas Mercurio, Venus, Marte, Júpiter y Saturno. Puede que estos estudios no se hicieran, en detalle, hasta la aparición de la primera gran civilización basada en la escritura: la sumeria.

Se descubrió que los planetas de movían frente a las estrellas de un modo mucho más complicado que el Sol y la Luna.

Pensad en Marte, Júpiter y Saturno. Cada cual hace un recorrido completo del cielo, pero más lentamente que el Sol. Marte emplea algo menos de dos años en completar el circuito, Júpiter, algo menos de doce y Saturno, algo menos de treinta.

Pero en vez de moverse lentamente a lo largo del cielo estrellado en una dirección fija Oeste-Este, como hacen el Sol y la Luna, cada uno de los tres planetas cambia periódicamente de dirección y se mueve de Este a Oeste contra el fondo de estrellas durante un periodo relativamente breve. Estos movimientos retrógrados se producen a intervalos aproximadamente anuales (tiempo terrestre) para cada planeta.

Los sumerios y sus sucesores en Babilonia se contentaron con descubrir los movimientos sin explicarlos. Cuando los griegos empezaron a interesarse en la astronomía, en el siglo V a.C., no podían dejar que la cuestión muriera allí. Se rompieron la cabeza intentando elaborar sistemas que permitiesen a Marte, Júpiter y Saturno girar en torno a la Tierra, pero explicando al mismo tiempo el cambio periódico de dirección. Surgieron así esquemas más y más elaborados que culminaron en el de Ptolomeo, durante el siglo II de nuestra Era.

Se trataba por fin de un caso donde la hipótesis de que la Tierra y los demás planetas giraban alrededor del Sol suponía una diferencia. Una Tierra móvil explicaría el movimiento retrógrado de Marte, Júpiter y Saturno de modo mucho más simple y lógico que una Tierra estacionaria. Si la Tierra y Júpiter, pongamos por caso, giraban ambos alrededor del Sol, la Tierra debería completar un círculo en un año, mientras Júpiter lo hacía en doce. La Tierra se movería más rápidamente. Cuando la Tierra estuviese en el mismo lado del Sol que Júpiter, lo adelantaría, y Júpiter parecería moverse hacia atrás en los cielos.

Desgraciadamente, la hipótesis de que cada uno de los planetas gira alrededor del Sol en órbitas independientes deja fuera de juego a la Luna. La Luna debe girar alrededor de la Tierra, lo cual exigiría dos centros para el universo. Los planetas podrían todos ellos circundar al Sol en órbitas independientes excepto la Luna. Todos los planetas, incluida la Luna, podrían girar alrededor de la Tierra en órbitas independientes. Si yo hubiese sido un griego, habría votado por un universo geocéntrico y no heliocéntrico («centrado en el Sol»). El geocéntrico me hubiera parecido más sencillo.

No sé si este argumento en relación con la Luna influyó efectivamente sobre los griegos. Jamás lo he visto escrito en parte alguna. Sin embargo estoy convencido de que tuvo que surtir su efecto[3].

Con que hubiera algún objeto en el cielo que girase claramente alrededor de otro tal y como gira la Luna alrededor de la Tierra, los hombres tendrían que aceptar forzosamente la noción de dos o más centros para el universo, sin ver nada anómalo en aceptar un universo heliocéntrico en el que la Luna se comporta de forma geocéntrica.

En realidad existe tal objeto; dos para ser más exactos. Los planetas Venus y Mercurio nunca abandonan las proximidades del Sol, en lo cual, contrastan claramente con los otros planetas.

La Luna, Marte, Júpiter y Saturno se mueven todos sobre el fondo estelar de tal suerte que, en un momento u otro, pueden estar a cualquier distancia dada del Sol, incluso en un punto del cielo exactamente opuesto a la posición del astro rey. (Lo anterior vale para la Luna, por ejemplo en cada fase de plenilunio, como cuando la vi esta mañana.)

No así en el caso de Venus y Mercurio. Venus, por ejemplo, se aleja más y más del Sol hasta separarse 47º (la mitad de la distancia entre horizonte y cenit), pero eso es todo. Tras haber alcanzado esa separación de 47º comienza a acercarse otra vez al Sol. Por último se mezcla con el brillo solar y posteriormente, tras unas semanas, puede verse al otro lado del Sol. Vuelve después a alejarse hasta una separación máxima de 47º para iniciar a continuación el retroceso. Y así, una y otra vez.

Cuando Venus está a un lado del Sol es el lucero vespertino. Puesto que nunca está a más de 47º, jamás brilla más de tres horas después del crepúsculo. Para entonces, o antes, se ha puesto. Estando en el otro lado del Sol es el lucero del alba, que jamás sale antes de tres horas previas al amanecer.

En cuanto a Mercurio, permanece incluso más próximo al Sol, sin alejarse nunca más de la mitad que Venus, sin ponerse nunca después que una hora y media terminado el crepúsculo, cuando es una estrella vespertina, y sin salir más de hora y media antes de que aparezca el Sol cuando es estrella matutina.

Sería bien lógico suponer que tanto Venus como Mercurio giran alrededor del Sol, pues eso explicaría simultáneamente y sin dificultad sus movimientos con todo detalle.

¡Qué fácil es decirlo! En primer lugar, no era trivial identificar a Venus, estrella vespertina, con Venus, el lucero del alba. Haría falta ser un astrónomo muy avezado para ver que una estrella está presente en el cielo sólo cuando está la otra ausente y que ambos objetos son, por esa razón, el mismo planeta. Además, Venus y el Sol nunca eran visibles al mismo tiempo, porque cuando el Sol estaba en el cielo, Venus no podía ser vista (a lo sumo, entrevista y no siempre, sabiendo el lugar exacto a donde mirar). El consecuencia, la conexión entre Venus y el Sol no era obvia ni inmediata. El captarla exigió un nivel astronómico nada elemental; y la situación con respecto a Mercurio era aún peor.

Así y todo, hacia el 350 a. C. El astrónomo griego Herakleides Ponticus sugirió efectivamente que Venus y Mercurio giraban alrededor del Sol. Y si dos de los planetas giraban alrededor del Sol, ¿por qué no el resto, incluida la Tierra? Hacia el 280 a. C. Otro astrónomo griego, Aristarco de Samos, dio el paso y propuso un universo heliocéntrico.

Pero a esas alturas, el geocentrismo se había fosilizado en el pensamiento griego. Aristarco no podía negar, además, que cuando menos la Luna debía permanecer en órbita alrededor de la Tierra. De modo que no se abandonó el concepto geocéntrico y los astrónomos griegos elaboraron ingeniosos esquemas para permitir que Venus y Mercurio girasen alrededor de la Tierra, sin alejarse mucho del Sol.

Os preguntaréis si, después de todo, le interesa al hombre de la calle, y a la historia, el que los filósofos fallasen a favor del geocentrismo o del heliocentrismo. ¿A quién le importa que la Tierra gire alrededor del Sol o viceversa?

Desgraciadamente importa, y mucho. Para el individuo medio de los tiempos antiguos (¡y de ahora también!) el cielo y todo cuanto contiene son cosas de importancia menor (excepto, quizá, el Sol). Es la Tierra lo que cuenta, y sólo la Tierra. Y sobre la Tierra, sólo cuenta la humanidad. Y entre los hombres, sólo hay el país de uno, la ciudad de uno, la tribu, la familia, el individuo mismo. La persona media es geocéntrica, antropocéntrica, etnocéntrica y egocéntrica.

Si los líderes intelectuales del mundo -quienes piensan, hablan, y escriben y enseñan- coinciden en que el universo es efectivamente geocéntrico, todos los demás centrismos tenderán a seguirse de modo mucho más natural.

Si todo el universo gira alrededor de la Tierra, ¿quién podrá dudar que la Tierra es la parte más importante de la creación y el objeto para el cual se hizo el resto del universo? Y si la Tierra tiene esa importancia central, ¿no será por y para el hombre, que es a todas luces el gobernante de la Tierra? Y si la humanidad es el gobernante de toda la creación, el objeto para el cual se formó toda ella, ¿por qué aceptar entonces cortapisas y restricciones sobre sus actos? La humanidad es rey, su deseo ley, y no puede errar.

En ese supuesto, las religiones que están centradas en la Tierra y en el hombre cobran más sentido intelectual también.

Al Imperio Romano le fue más fácil hacerse cristiano porque la filosofía pagana y el cristianismo eran igual de geocéntricos y, por tanto, antropocéntricos. Hubo un refuerzo mutuo en esta importantísima cuestión y la cristiandad -que hizo dogma central de la geocentricidad y la antropocentricidad- recabó la ayuda de Aristóteles, Ptolomeo y pensadores griegos similares para impresionar a aquellos intelectuales que se mostraron remisos a conformarse con la sola palabra de la Biblia.

Y puesto que la geocentricidad no es, de hecho, una imagen precisa del universo, toda investigación científica se tornó indeseable. Cualquier investigación que intentara ir más allá de Aristóteles y Ptolomeo, y descubrir una imagen no geocéntrica del universo que pudiese explicarlo mejor, se hizo peligrosa para la religión revelada.

Aunque el sistema ptolemaico se había hecho insostenible hasta el extremo de convertirse en un estorbo, no fue sino en el siglo XVI cuando el astrónomo polaco Nicolás Copérnico se atrevió a presentar nuevamente una teoría heliocéntrica, prefiriendo incluso diferir su publicación hasta 1543, seguro ya de que iba a morir pronto en cualquier caso. Y luego transcurrió todo un siglo antes de que el mundo intelectual de Europa occidental aceptara plenamente el heliocentrismo frente a la resistencia religiosa. Bruno hubo de perecer en la hoguera y Galileo tuvo que retractarse antes de que expirara la geocentricidad.

Pero ni aun así quedó asegurada la victoria. Los viejos hábitos mueren con inusitada lentitud, y sea cual fuere la ciencia que se enseñe en las escuelas, la mayor parte de la población de las naciones «avanzadas» sigue creyendo que el hombre es la medida de todas las cosas, el gobernante de la creación, y que puede hacer cuanto guste.

Henos aquí, por tanto, en las últimas décadas del siglo XX destruyendo todavía el reino vegetal y animal y asolando el medio inanimado -todo ello según nuestro descuidado capricho y por el placer de la comodidad del momento. El claro indicio de que tal actitud acabará con la humanidad -incapaz de vivir sin una ecología operativa- parece rebotar sobre el liso muro de aquellas mentes que ven un universo construido exclusivamente por y para la humanidad y por ninguna otra razón.

A mi entender, pues, todo esto se remonta a una geocentricidad que fue remachada sobre la mente del hombre por el brillante intelecto de los filósofos griegos, influidos, entre otras cosas, por el hecho de que la Luna gira alrededor de la Tierra.

Pero supongamos que la Luna no girara alrededor de nuestro planeta, que girara alrededor de Venus, y que fuese la Tierra, no Venus, quien careciese de luna.

Imaginemos que fuese nuestra Luna, con el mismo tamaño, las mismas características y la misma distancia respecto al centro de Venus. Y para evitar la confusión, llamemos a este satélite Cupido, en tanto que fiel compañero de Venus.

El período de Cupido alrededor de Venus sería una pizca mayor que su período alrededor de la Tierra, pues Venus tiene una masa algo inferior a la de ésta, y en consecuencia, un campo gravitatorio ligeramente menos intenso. Sin entrar en pormenores, digamos que Cupido gira alrededor de Venus en treinta días.

No nos preocupemos -aquí, al menos- por el efecto que esto tendría en Venus. Preguntémonos sólo cómo afectaría el cielo de la Tierra.

En primer lugar, el cielo de la Tierra carecería perpetuamente de Luna, con lo cual la observación mejoraría no poco. Nunca habría una Luna brillante que diferenciara las estrellas menos nítidas de su vecindad.

En segundo lugar, la propia Venus sería el objeto más brillante de los cielos -después del Sol- y sin duda el objeto más brillante, con mucho, en el cielo nocturno. Bella y ostensible como es en el cielo presente, Venus sería impar en un cielo privado de Luna. Se estudiaría con una admiración que ningún otro objeto del cielo podría despertar.

En tercer lugar, y aquí viene lo más importante, Cupido sería visible para nosotros a medida que circundase a Venus. Su luminosidad dependería de su posición en relación con el Sol y la Tierra, como acontece con la luminosidad de la propia Venus. En todo momento (suponiendo que tuviese el tamaño y las características de la Luna) Cupido tendría exactamente 1/100 de la luminosidad de Venus.

Lo cual significa que en el momento de mayor brillo Cupido resplandecería en nuestro cielo con una magnitud de + 0,7. Sería un objeto de primera magnitud, aproximadamente tan luminoso como el planeta Saturno o la estrella Arcturus.

¿Estaría Cupido tan cerca de Venus como para ser ahogado en su destello? Depende de dónde estuviese localizado Cupido en su órbita venusiana. Cuando estuviera en el punto más alejado de Venus, y éste más cerca de nosotros, Cupido distaría de Venus 0,6º, ligeramente más que la anchura del Sol. No tendríamos dificultades para ver a Cupido cuando se encontrara a esa distancia de Venus, ni siquiera cuando estuviera bastante más cerca, sobre todo si supiésemos que estaba allí y lo buscáramos.

Esto nos lleva a la cuestión crucial. Sin Luna en el cielo, no habría ningún objeto cuyos movimientos sólo pudieran explicarse suponiendo que gira alrededor de la Tierra.

Al contrario, en Venus y Cupido veríamos algo que sería interpretado fácil e incluso inevitablemente como un planeta doble. Cupido permanecería quince días a un lado de Venus y quince al otro, alternando. A lo largo de una serie continua de noches en las que Venus fuese estrella vespertina veríamos a Cupido atravesar ocho ciclos completos.

No cabría error. Nadie podría dudar de buena fe que Cupido estaba girando en torno a Venus.

El siguiente paso sería anotar que el brillante lucero del alba presente en el cielo antes del amanecer iba también secundado por un compañero que se comportaba como Cupido. Con Cupido de ayudante en ambos casos, la identidad de la estrella vespertina y la estrella matutina sería obvia desde el comienzo. No podrían existir dos objetos diferentes tan espectacularmente semejantes en el detalle.

Esto significa que desde el comienzo mismo de la observación de los cielos el hombre primitivo vería claramente que Venus iba de un lado del Sol al otro y de éste al primero, exactamente igual que Cupido viajaba de un lado de Venus al otro y de éste al primero. Y habiéndose percatado de que los luceros matutino y vespertino eran el mismo, sería imposible dejar de ver que Venus, llevando consigo a Cupido, giraba alrededor del Sol.

Además, cuando los observadores comprendieran que Mercurio oficiaba también de estrella vespertina y matutina, con un período más corto que el de Venus, habrían de concluir que Mercurio giraba alrededor del Sol, y en una órbita más cercana que la de Venus.

Detectada la heliocentricidad de Venus y Mercurio, no sería difícil aventurar que los otros planetas hacían lo propio, incluida la Tierra. No habría Luna que confundiese las cosas; y aunque la hubiese, el caso de Cupido sería prueba convincente de que la Tierra podía tener una Luna girando en torno suyo y, sin embargo, moverse ambos también alrededor del Sol.

Los astrónomos griegos, y posiblemente los sumerios antes que ellos, habrían visto que el suponer que la Tierra gira alrededor del Sol explicaría fácilmente los exasperantes movimientos retrógrados de Marte, Júpiter y Saturno. Eso, junto con los movimientos visiblemente heliocéntricos de Mercurio y Venus-Cupido, habría superado sin duda el obstáculo de la aparente inmovilidad de la Tierra, como acabó sucediendo con Copérnico.

Se sigue de ahí que la teoría heliocéntrica habría quedado establecida posiblemente hacia el 2000 a. C., y en ningún caso tan tardíamente como en el 300 a. C.

Pero hay más, y es que la revolución de Cupido alrededor de Venus y la de Venus alrededor del Sol habrían permitido captar de modo relativamente fácil el concepto de gravitación universal. No era sólo que los objetos cayesen hacia la tierra. Todo ejercía una atracción. El Sol y Venus lo hacían visiblemente y, en ese caso, ¿por qué no todos los demás también?

Tengo para mí que Aristóteles hubiese sido perfectamente capaz de hacer el trabajo de Newton si hubiese inventado el cálculo y no se le hubiese anticipado ya algún otro pensador.

La naturaleza heliocéntrica del universo, tal como la verían los astrónomos e incluso algún profano que contemplase a Venus, Cupido y el Sol con un poco de perspicacia, haría evidente que la Tierra era sólo un mundo entre muchos y que podría no ser el centro y cúspide de la creación. El mundo de la humanidad y, por tanto, la humanidad misma, sería sólo una pequeña parte de la creación, sin ocupar para nada un puesto de privilegio.

Sin duda alguna, nada impediría que surgieran sistemas religiosos centrados en el hombre y la Tierra, pero no hubieran tenido posibilidades de captar el sector académico de la sociedad, salvo que fuesen modificados para permitir la pluralidad de mundos y aceptar al hombre como parte pequeña de un todo mucho mayor.

Puesto que tanto la ciencia como la religión estarían entonces en el buen camino, no habría hostilidad fundamental entre ambos. Al contrario, habría un mutuo refuerzo.

La religión sería progresiva, ávida por aprender cosas del universo tal como es, cierta de que no podría haber conflicto entre lo material y lo espiritual. Por otra parte, la ciencia aceptaría más fácilmente los imperativos morales. Reconocería la necesidad de comprender el pequeño nicho humano, tanto en el universo astronómico como en la biológica Tierra.

La ciencia experimental y la tecnología estarían quizá de dos a cuatro mil años más avanzados que hoy; y una Tierra saludable podría estar estableciendo ya los comienzos de un imperio galáctico o, quizá, tendiendo puentes hacia otras inteligencias.

En vez de ello, puede que nuestro lapso vital sea el último que sea vivido en una sociedad tecnológica por culpa de la tragedia de la Luna, del hado que la emplazó en nuestro cielo y no a Cupido en el de Venus.

Por eso nunca más seré capaz de mirar a la hermosa Luna llena, colgando al amanecer en el cielo occidental, sin sentir una punzada… si no fuera porque la historia tiene otro lado, que es el que recojo en el capítulo 2.

2. El triunfo de la Luna

La noche pasada (cuando escribo esto), sobre la cubierta del trans-atlántico holandés-americano S. S. Statendam, a siete millas de Cabo Kennedy, contemplé al «Apolo 17» elevarse en los aires como la mayor luciérnaga de la creación (véase cap. 16). Encendió el cielo de horizonte a horizonte, convirtiendo el océano en una masa líquida naranja grisácea y el cielo en un cuenco de cobre invertido del que habían sido borradas las estrellas.

Se elevó lentamente sobre su cola de fuego, y estaba ya muy arriba cuando el primer estruendo llegó hasta nosotros (unos cuarenta segundos tras la ignición) y nos sacudió salvajemente.

La humanidad hacía su sexto intento de alcanzar la Luna y de situar sobre ella al undécimo y duodécimo hombre. Fue el último lanzamiento de la serie Apolo (y el único nocturno, increíblemente espectacular por eso, y un encanto presenciarlo). Puede que pasen decenas de años antes de que la humanidad vuelva a la carga, tras establecer una estación espacial que permita alcanzar la Luna con más facilidad, economía y elaboración.

Y mientras estaba, en cubierta contemplando cómo el «Apolo 17» se convertía en una estrella entre las estrellas, en medio de un cielo recién oscurecido, mientras la hirviente plataforma brillaba abandonada sobre la línea de costa, un espasmo de culpa me corrió por el cuerpo.

No hacía mucho había escrito «La tragedia de la Luna» (véase capítulo l), donde describí cómo y por qué el hombre habría avanzado mucho más sólo con que la Luna hubiese girado alrededor de Venus en vez de hacerlo alrededor de la Tierra. Sin embargo, ése era sólo un lado de la historia. La Luna ha tenido sus triunfos también, si aceptamos al hombre como medida de todas las cosas; porque en tres crisis del desarrollo humano fue la Luna la que constituyó, de un modo u otro, la fuerza motriz. En el capítulo 1 las descarté a la ligera, pero ahora desharemos el entuerto.

Para empezar, el hombre puede que ni siquiera existiese si la Tierra no hubiese tenido Luna. La tierra firme podría haber quedado deshabitada.

La vida nació en el mar hace unos tres mil millones de años o más, y allí permaneció, como poco, durante el 80 por 100 de su historia total sobre este planeta. La vida está adaptada principalmente a las capas superficiales del océano, y gracias sólo a un poder de adaptación versátil a lo largo de muchas generaciones logró colonizar los confines de dicha región: hacia abajo las zonas abisales, hacia afuera los ríos y lagos de agua dulce, y hacia afuera y arriba la tierra y el aire.

De entre esas provincias, la tierra firme tuvo que ser, a su manera, la más exótica: tan imposible para la vida marina como lo es para nosotros la superficie de la Luna. Si imaginamos una criatura marina primitiva lo bastante inteligente como para haber especulado sobre la vida terrestre, podemos estar seguros de que le hubiese aterrorizado la perspectiva. Sobre la Tierra un organismo estaría sometido al pleno y eterno tirón de la gravedad, a brutales oscilaciones de temperatura, tanto diarias como anuales, a la aplastante necesidad de obtener y retener agua en un medio esencialmente falto de ella, a la urgencia de conseguir oxígeno de un aire seco y resecante en vez de obtenerlo de una suave solución acuosa.

Esa criatura marina podría imaginarse a sí misma emergiendo del mar en un traje terrestre lleno de agua, con ganchos mecánicos para sostenerse contra la gravedad, aislamiento frente a cambios de temperatura, etc.

La vida marina de hace quinientos millones de años carecía, sin embargo, de la tecnología necesaria para conquistar el continente. Lo único que podía hacer era adaptarse durante cientos o miles de generaciones hasta el punto de poder vivir a pecho descubierto sobre tierra firme.

Pero ¿qué fuerza la llevó a ello, a falta de una decisión deliberada de hacerlo?

Las mareas.

La vida se diseminó hacia las orillas del océano, donde el agua marina subía por las pendientes continentales y retrocedía luego dos veces al día. Y miles de especies de algas marinas, gusanos, crustáceos, moluscos y peces subían y bajaban con las mareas. Algunos quedaron varados en la orilla al retirarse el mar; de ellos un número exiguo logró sobrevivir, porque por alguna razón resultaron ser los más capaces de soportar la pesadilla de la existencia terrestre hasta el retorno del agua, curativa y vivificante.

Surgieron así especies adaptadas a soportar temporalmente las condiciones del continente, y la continua presión de la competencia hizo que se incrementara el valor de supervivencia de la capacidad de soportar las condiciones de tierra firme durante períodos cada vez más largos.

Al final surgieron especies que podían permanecer indefinidamente sobre la Tierra. Hace unos cuatrocientos veinticinco millones de años la vida vegetal empezó a verdear tímidamente en los bordes del continente. Caracoles, arañas e insectos entraron en escena para aprovecharse de esa nueva fuente de alimento. Hace unos cuatrocientos millones de años, ciertos peces reptaban con miembros de reciente factura sobre las húmedas llanuras pantanosas.

(En realidad, descendemos de criaturas de agua dulce que probablemente llegaron a soportar la tierra como resultado de la desecación periódica de lagunas, pero sólo pudieron completar la colonización gracias a que las mareas habían poblado ya los continentes y producido una ecología de la cual formar parte.)

Y, naturalmente, las mareas son el producto de la Luna. El Sol también engendra las suyas, de una magnitud que casi alcanza la mitad de las lunares; pero ese trajín secundario de agua salada representa un impulso menor hacia la tierra, y de haber dado lugar algún día a la colonización de los continentes hubiese sido mucho más tarde.

Hace cientos de millones de años, cuando la vida terrestre estaba en plena evolución, la Luna se hallaba seguramente más cerca de la Tierra, y las mareas eran bastante más grandes. Es incluso posible que la Luna fuese capturada muy entrada ya la evolución de la vida, y que fuese el largo período de mareas gigantes subsiguiente el que dio el empujón necesario para la colonización de la tierra firme *.

El segundo efecto crucial de la Luna vino alrededor del período paleolítico, cuando los hombres eran primates recolectores de alimento, quizá sin mucho más éxito que otros del mismo orden. Los antepasados primitivos del hombre eran ya las criaturas terrestres con más cerebro de todas cuantas han existido, pero cabe argumentar que los cerebros no son de suyo el mejor modo de asegurar la supervivencia. El chimpancé no tiene tanto éxito, en el esquema evolutivo de las cosas, como la rata, ni el elefante tanto como la mosca.

Para que el hombre conociera el éxito, para que se estableciese como gobernante del planeta, era necesario que utilizara el cerebro como algo más que un artilugio para hacer un poco más eficaz la rutina diaria de obtener comida y evadirse de los enemigos. El hombre necesitaba aprender a controlar su medio, esto es, a observar y generalizar y crear una tecnología. Y para aguzar su mente hasta tal punto, necesitaba enumerar y medir. Sólo enumerando y midiendo podía empezar a captar el concepto de un universo que podía ser entendido y manipulado.

Hacía falta algo que impeliera hacia la numeración, al igual que antes había hecho falta algo que impulsara hacia la tierra firme.

El hombre necesitaba percatarse de algo ordenado que pudiese aprehender, algo lo bastante ordenado como para permitirle predecir el futuro y darle un criterio sobre el poder del intelecto.

Un modo simple de captar el orden es observar algún ritmo fijo y cíclico en la naturaleza. El ciclo más simple y más visible es la alternancia de día y noche. Hubo de llegar el momento en que algún hombre (o antepasado humanoide) comenzara a tener el conocimiento consciente de que el Sol se levantaría con certeza en el Este tras haberse puesto en el Oeste. Lo cual sería tanto como tener conciencia del tiempo, en lugar de soportarlo pasivamente. El momento en que un suceso podía ser localizado como «hace tantos amaneceres» o «dentro de cuantos amaneceres» sería, sin duda, el comienzo de la medición del tiempo y aun de cualquier cosa.

Sin embargo, el ciclo día-noche carece de sutileza y es demasiado drástico, demasiado blanco-o-negro (literalmente) para sintonizar con lo mejor del hombre. Cierto que observando muy de cerca habríase advertido que el día y la noche se alargaban y acortaban en lo que hoy llamaríamos un ciclo anual. El hombre podría haberlo asociado con la altura cambiante del Sol de mediodía y con un ciclo de estaciones.

Tales cambios serían, por desgracia, difíciles de captar, de seguir y de medir. La longitud del día y la posición del Sol tenían que ser difíciles de observar en tiempos primitivos; las estaciones dependen de muchos factores que, en plazos cortos, tienden a oscurecer su naturaleza puramente cíclica; y en los trópicos, donde el hombre evolucionó, todos estos cambios son mínimos.

Pero está la Luna, la visión más dramática de los cielos. El Sol es glorioso, pero no puede ser contemplado. Las estrellas son puntos inmóviles de luz. La Luna, por el contrario, es un objeto de luz suave y brillante que cambia de forma periódicamente.

La fascinación de esa forma cambiante, acompañada de una posición mudable en el cielo con relación al Sol, tenía por fuerza que atraer la atención. La lenta muerte del creciente lunar al fundirse con el Sol naciente, y el nacimiento de una luna nueva a partir del fuego solar del crepúsculo puede que dieran a la humanidad el primer impulso hacia el concepto de muerte y renacimiento, tan central en muchas religiones.

El nacimiento de cada luna nueva (llamada así todavía), como símbolo de esperanza, pudo muy bien excitar las emociones del hombre primitivo hasta el punto de moverle a calcular con antelación la llegada de esa luna nueva, para así saludarla con júbilo y fiesta.

Sin embargo, las lunas nuevas llegan con separación suficiente para que el asunto exija un ejercicio de cálculo; y la cuenta es lo bastante extensa como para recomendar el uso de muescas en un trozo de madera o hueso. Además, el número de días no carece de variación. A veces el intervalo es de veintinueve días entre dos lunas nuevas, a veces de treinta. Con un cálculo continuado emerge, sin embargo, una pauta regular.

Una vez establecida la pauta, acabará por observarse que cada 12 lunas nuevas incluyen un ciclo de estaciones (es más fácil contar y entender 12 lunas nuevas que trescientos sesenta y cinco días). Pero tampoco este ajuste es exacto. Con 12 lunas nuevas las estaciones van ganando terreno. De vez en vez hay que añadir una decimotercera luna nueva.

Por otro lado, de cuando en cuando la Luna entra en eclipse. (Puesto que los eclipses lunares pueden ser vistos en todo el mundo al mismo tiempo, mientras que los eclipses solares aproximadamente iguales en número sólo pueden verse en zonas restringidas, desde un punto dado de la Tierra vemos más eclipses lunares que solares.)

El eclipse de la Luna, su muerte relativamente rápida en el momento de máxima madurez (el eclipse siempre se produce cuando la Luna es llena), y su renacimiento igualmente rápido, deben haber ejercido enorme impacto en los pueblos primitivos. Sin duda debió de ser importante saber cuándo se iba a producir tan importante ocasión, y los cálculos hubieron de alcanzar un superior nivel de finura.

No es maravilla, pues, que los primeros conatos de comprender el universo se centrasen en la Luna. Stonehenge puede haber sido un observatorio primitivo que sirviera como ingente dispositivo para predecir eclipses lunares de modo preciso. Alexander Marshak ha analizado las muescas sobre huesos antiguos y sugerido que eran calendarios primitivos que marcaban las lunas nuevas.

Hay, pues, buenas razones para creer que el hombre fue en primer lugar movido al cálculo y la generalización por la necesidad de seguir la pista a la Luna; que los calendarios provinieron de la Luna y, de ellos, las matemáticas y la astronomía (así como la religión); y que de ahí surgió todo lo demás.

Así como la Luna hizo posible al hombre, en tanto que ser físico, merced a sus mareas, también lo convirtió en ser intelectual a través de sus fases.

¿Y qué más? Prometí tres crisis; para la tercera, avancemos todavía más en el tiempo, hasta un punto donde la civilización humana estaba en plena carrera.

Hacia el tercer milenio a. C., la primera gran civilización, la de los sumerios, en las estribaciones inferiores del valle formado por los ríos Tigris y Eúfrates, estaba en su apogeo. En ese clima seco el cielo nocturno era uniforme y brillantemente visible, y existía una casta sacerdotal que disponía del ocio necesario para estudiar los cielos y de la motivación religiosa para hacerlo.

Fueron ellos con toda probabilidad quienes observaron por primera vez que aunque la mayor parte de las estrellas mantenían sus posiciones noche tras noche indefinidamente, cinco de las más brillantes cambiaban periódicamente de posición, noche tras noche, en relación con el resto. Tal fue el descubrimiento de los planetas, que ellos distinguieron mediante nombres de dioses, hábito que ha persistido hasta el presente. Observaron que el Sol y la Luna también cambiaban periódicamente de posición con referencia a las estrellas, por lo cual fueron considerados planetas también.

Los sumerios fueron acaso los primeros en empezar a seguir los movimientos de todos los planetas en vez de limitarse a los de la Luna, y en intentar la tarea mucho más complicada de generalizar y sistematizar el movimiento planetario antes que el movimiento lunar. Esta labor fue continuada por las civilizaciones posteriores que heredaron sus tradiciones, hasta que los caldeos, dueños del valle del Tigris-Eúfrates en el siglo IV a. C., elaboraron un sistema bien desarrollado de astronomía planetario.

Los griegos tomaron la astronomía de los caldeos y la reelaboraron en un sistema que Claudio Ptolomeo expuso en su forma final durante el segundo siglo d. C.

El sistema ptolemaico situaba a la Tierra en el centro del universo. Se suponía que la Tierra estaba rodeada por una serie de esferas concéntricas. La más interior contenía a la Luna, la siguiente a Mercurio, la siguiente a Venus, al Sol, Marte, Júpiter y Saturno, en ese orden. La esfera más externa sostenía a las estrellas fijas. A este esquema primario vinieron a añadirse numerosas modificaciones sutiles.

Consideremos ahora los objetos celestes uno por uno Y veamos qué impresión pudieron causar al observador primitivo. Supongamos primero que sólo existiesen estrellas en el cielo.

En ese caso no habría razón alguna para que ningún astrónomo, sumerio o griego, supusiera que se trataba de cosas distintas de lo que parecían ser: puntos luminosos sobre un fondo negro. El hecho de que nunca cambiaban su posición relativa, ni siquiera tras largos períodos de observación, hacía verosímil la hipótesis de que el cielo era una esfera sólida y negra que circundaba a la Tierra, estando las, estrellas clavadas en ese cielo sólido a modo de pequeñas chinchetas luminosas.

Tampoco sería descabellado suponer que el cielo y las estrellas allí clavadas eran una mera cubierta, y que la Tierra, y sola ella, constituía el universo esencial. Había de ser necesariamente el mundo por excelencia, la única cosa existente donde el hombre podía habitar.

Cuando se descubrieron y estudiaron Mercurio, Venus, Júpiter y Saturno, el panorama no cambió en lo esencial. Los planetas se movían de modo independiente, por lo cual no podían estar fijos en el cielo. Cada uno de ellos debía estar empotrado en una esfera distinta, una dentro de otra, y todas ellas tenían que ser transparentes, porque las estrellas seguían siendo visibles.

Sin embargo, esos planetas no eran más que otras tantas estrellas para el observador primitivo. Eran más luminosas que las otras y se movían de modo diferente, pero debían ser sólo puntos luminosos adicionales. Su existencia no era menoscabo para la idea de la Tierra como único mundo.

Pero ¿y el Sol?

El Sol, obligado era admitirlo, es único en los cielos. No es un punto de luz, sino un disco luminoso muchos millones de veces más brillante que cualquier estrella. Cuando lucía en el cielo, lo pintaba de azul y barría de él cualquier otro punto de luz.

Con todo, aunque el Sol era mucho más, no era muy diferente. Todas las estrellas y planetas, y el Sol también, estaban constituidos por luz, mientras que la Tierra era oscura. Los cuerpos celestes no sufrían modificación alguna, mientras que sobre la Tierra todo se corrompía, se desintegraba y cambiaba. Los cuerpos celestes se movían en círculos, mientras que los objetos en la Tierra o ascendían o caían. El cielo y la Tierra parecían fundamentalmente distintos.

Alrededor del 340 a. C. Aristóteles formuló la distinción de un modo que se mantuvo durante dos mil años. La Tierra, dijo, está hecha de cuatro elementos básicos: tierra, agua, aire y fuego. Sin embargo, los cielos y todo cuanto en ellos se contiene estaban compuestos de un quinto elemento, peculiar en sí mismo y completamente distinto de los cuatro elementos terrestres. Este quinto elemento era el «éter», que proviene de una palabra griega cuyo significado es «brillante».

Este brillo o luminosidad, que parecía tan fundamental en los cuerpos celestes en contraste con los terrestres, se extendía también a los habitantes temporales de los cielos. Los meteoros sólo existían momentáneamente, pero eran destellos de luz. Los cometas podían ir y venir y poseer extrañas formas, pero eran formas luminosas.

Todo, según parecía, conspiraba para mostrar que los cielos eran una cosa aparte y que la Tierra era el único mundo.

… Excepto la Luna.

La Luna no casaba. Al igual que el Sol, es más que un mero punto de luz. Puede incluso ser un disco luminoso completo, aunque aun entonces es cientos de miles de veces menos brillante que el Sol. No obstante, al contrario que el Sol o cualquier otra cosa en los cielos, la Luna cambia de forma regularmente.

Tarde o temprano tuvo que surgir la pregunta: ¿por qué cambia de forma la Luna?

Indudablemente, el primer pensamiento del hombre sería que lo aparente era real: que una luna nueva nacía cada mes de los fuegos del Sol.

Algún sumerio anónimo puede, sin embargo, que tuviera sus dudas. El estudio completo y cuidadoso de la posición de la Luna en relación con el Sol tuvo que demostrar bien a las claras que la parte luminosa de la Luna era siempre la parte que se encontraba cara al Sol.

Veríase entonces que a medida que cambiaba la posición de la Luna en relación con el Sol, éste iluminaba partes algo distintas, y este cambio progresivo se traducía en los cambios de fase que vemos desde la Tierra.

Interpretando las fases de la Luna de este modo, resultaría que la Luna. era una esfera cuyo brillo provenía únicamente de reflejar la luz solar. Sólo la mitad de la esfera era iluminada por el Sol en cada momento, y este hemisferio iluminado cambiaba de posición para dar lugar a la sucesión de fases.

De hacer falta una prueba adicional, cabía encontrarla en el hecho de que durante la fase creciente podía adivinarse el resto del cuerpo. de la Luna en una tenue luminosidad rojiza. Estar estaba, allí, sólo que no era iluminada en ese momento por el Sol.

En tiempos de los griegos, el hecho de que la Luna sólo brillaba por luz reflejada del Sol era aceptado sin discusión.

Esto era tanto como decir que la Luna no era un cuerpo intrínsecamente luminoso, como parecían ser todos los demás cuerpos celestes. Era un cuerpo oscuro, como la Tierra. Brillaba por luz reflejada, como aquélla. (El tenue fulgor rojizo de la Luna oscura durante la fase creciente proviene en realidad de la luz terrestre que incide en esa parte de la Luna.)

Por otro lado, el cuerpo de la Luna, al contrario que el del Sol, mostraba marcas claras y permanentes, manchas oscuras que viciaban su luminosidad. La Luna, a diferencia de los otros cuerpos celestes, era visiblemente imperfecta, como la Tierra.

Cabía suponer, pues, que la Luna, cuando menos, era un mundo como el de la Tierra; que la Luna, cuando menos, podía tener habitantes como la Tierra. Por eso, en los tiempos antiguos fue la Luna (y sólo la Luna) la que brindó al hombre el concepto de una multiplicidad de mundos. Sin la Luna, puede que dicho concepto no hubiese surgido hasta la invención del telescopio.

Señalemos que Aristóteles no situó a la Luna en la misma categoría que a la Tierra, sino que la consideró compuesta de éter. Cabía pensar que la Luna, al estar más cerca de la Tierra que ningún otro cuerpo celeste, absorbía algunas de las imperfecciones de los elementos terrestres, adquiriendo manchas y perdiendo la capacidad de brillar con luz propia.

La astronomía griega avanzó luego un paso más. Alrededor del 250 a. C. Eratóstenes de Cirene utilizó métodos trigonométricos para calcular el tamaño de la Tierra. Llegó a la conclusión de que la Tierra poseía una circunferencia de 40.000 kilómetros y, por lo mismo, un diámetro de 12.800. Lo cual es en esencia correcto.

En el 150 a. C. Hiparco de Nicea utilizó métodos trigonométricos para determinar la distancia a la Luna. Decidió que la distancia entre la Tierra y la Luna era aproximadamente treinta veces el diámetro de la Tierra. También esto es esencialmente cierto.

Combinando el trabajo de Hiparco con el de Eratóstenes, la Luna estaba a 384.000 kilómetros de la Tierra, y para poseer el tamaño aparente que poseía debía tener algo más de 3.200 kilómetros de anchura. ¡Todo un mundo! Dijera lo que dijera Aristóteles, era un mundo, al menos por su tamaño.

No es maravilla, pues, que hacia la época en que Claudio Ptolomeo publicó su gran síntesis de la astronomía griega, Luciano de Samosata escribiera un relato popular acerca de un viaje a una Luna habitada. Y de concebir la Luna como un posible mundo a suponer que otros cuerpos celestes también lo eran, había sólo un paso, y no difícil.

Mas sólo la Luna -únicamente la Luna- está lo bastante cerca de la Tierra para que su distancia pueda ser calculada mediante métodos trigonométricos basados en observaciones simplemente oculares. Sin la Luna hubiera sido imposible conseguir conocimiento alguno de la distancia y el tamaño de ningún cuerpo celeste antes de inventarse el telescopio. Y sin el gusanillo de conocer la distancia y el tamaño de la Luna ¿habría existido el ansia de explorar los cielos, incluso tras haber sido inventado y utilizado el telescopio para fines militares?

En 1609, Galileo pone por vez primera el telescopio al servicio de la astronomía.

Galileo estudia los cielos y descubre que a través de su telescopio los planetas -aparentemente puntos de luz cuando eran observados a simple vista- resultaban ser esferas de luz bien perfiladas. Es más: también Venus estaba situada con respecto a la Tierra de manera tal que mostraba fases semejantes a las de la Luna; fases que, además, se vinculaban plenamente con su posición relativa al Sol.

La conclusión parecía inevitable. Todos los planetas semejantes a estrellas -Mercurio, Venus, Marte, Júpiter y Saturno- eran mundos como la Luna. Aparecían como simple puntos de luz porque estaban mucho más lejos que la Luna.

Lo cual no era de suyo fatal para el criterio aristotélico, pues cabía alegar que los planetas (y la Luna) seguían estando compuestos de éter, por muy grandes o no luminosos que fueran.

Lo que realmente destruyó el concepto etéreo de una vez y para siempre fueron las observaciones de la Luna hechas por Galileo. (Lo primero que miró fue, en efecto, la Luna.) Galileo vio allí montañas y áreas oscuras y suaves que interpretó como mares. La Luna era claramente, visiblemente, un mundo como la Tierra. imperfecto, áspero, montañoso.

No es extraño, por tanto, que con este segundo golpe asestado por la Luna el concepto de la pluralidad de mundos diese otro gigantesco paso hacia adelante. El siglo XVII vio el comienzo de un género de novelas cuyo argumento eran los viajes tripulados a la Luna, género que evolucionó hacia formas cada vez más sofisticadas y que no ha cesado hasta el presente.

Diréis, sin duda, que Galileo habría demostrado la pluralidad de mundos, mediante el telescopio, aun en el caso de no haber existido la Luna, y que la resistencia de los aristotélicos se habría quebrantado a medida que se fueran perfeccionando los telescopios y se inventaran otros instrumentos.

Supongamos que fuera así. Los escritores de ciencia ficción podrían haber soñado entonces con vuelos a Marte o Venus en vez de a una Luna inexistente… Pero los sueños son sólo sueños, después de todo. ¿Habría intentado el hombre convertir en realidad los vuelos espaciales de no haber existido la Luna?

La Luna está a menos de 400.000 kilómetros de nosotros. Venus, en cambio, se encuentra a 40 millones de kilómetros, incluso cuando está en el punto más cercano (a intervalos de un año y medio). Es decir, cien veces más lejos que la Luna. En sus momentos de mayor aproximación, Marte está más lejos todavía. Cada treinta años aproximadamente, cuando se encuentra más cerca, está a 55 millones de kilómetros.

Tres días tardamos en llegar a la Luna. En llegar a Venus o Marte tardaríamos medio año por lo menos.

Para alcanzar la Luna los hombres han tenido que adoptar medidas heroicas. ¿Sería razonable esperar que hubiesen tomado desde el principio esas mismas medidas para alcanzar Venus o Marte?

No, es la Luna -y sólo la Luna- la que hizo posible los vuelos espaciales. En primer lugar, al hacemos ver que existen otros mundos además del nuestro, y ofreciéndonos luego un fácil trampolín con el cual pulir nuestras técnicas y desde el cual emprender a la larga el asalto, mucho mayor, a los mundos más distantes.

El triple triunfo de la Luna es, por tanto, éste: que hizo posible la existencia del hombre; que hizo posible el desarrollo de las matemáticas y la ciencia; y que hizo posible que el hombre trascendiera la Tierra y conquistara el espacio.

Si de acuerdo con el argumento del capítulo 1 concluí que habría sido de gran utilidad para el hombre el hecho de poseer Venus una luna corno la nuestra, en este capítulo niego cualquier deseo de perder la que nos pertenece.

Lo ideal habría sido que ambos planetas estuvieran acompañados por una luna.

3. La Luna sobre Babilonia

No hace mucho me hallaba una mañana en el Estado de Nueva York, tras haber dado una conferencia la noche anterior en una universidad local. Quería iniciar temprano el regreso a casa y me sentí un poco contrariado cuando vi que la gasolinera junto al motel estaba cerrada, aunque ya eran las nueve menos cuarto de la mañana.

Exhalando un suspiro, se lo comenté entre dientes a la señora situada tras el mostrador de la recepción del motel mientras pagaba la cuenta, a lo cual ella, con una aguda nota de sorpresa, me preguntó:

–¿No está abierta?

–Temo que no, – dije.

–Pues debiera estarlo -repuso, adoptando un gesto de irritación-. Mi hijo es el encargado y va a oírme.

Incómodo por ser la involuntaria causa de una tempestad familiar, busqué una excusa suavizadora y dije rápidamente:

–Es que es domingo.

–No importa -replicó bruscamente-. Somos adventistas del Séptimo Día.

–Ah, sí -dije, sonriendo-. El domingo fue ayer, ¿no es verdad?

Me miró sorprendida durante un momento; luego rió y dijo:

–Sí, ayer fue domingo. – Con la risa se evaporó su rabia. Y, como su hijo apareció en aquel momento, eché gasolina y todo quedó en nada.

Pero eso me recordó nuestra semana de siete días y alguna de sus peculiaridades, por lo cual, si el amable lector tiene a bien esperar un momento…

Como todos sabemos, el año se compone de doce meses, cada uno de los cuales tiene de veintiocho a treinta y un días en secuencia irregular. Tres de cada cuatro años tienen trescientos sesenta y cinco días, y trescientos sesenta y seis días el cuarto.

El resultado es un calendario que varía de año a año con arreglo a una pauta intrincada. Lo cual hace inevitable el claro despilfarro de esfuerzo que supone preparar y distribuir un calendario nuevo diferente cada año. Y lo que es peor, la pauta del año crea confusión en los detalles de las fechas de año a año, dando lugar a molestias personales y gastos comerciales.

Y el «malo» en este caso no es ni el día ni el mes, sino la semana.

El día, el mes y el año se fijan todos ellos mediante ciclos astronómicos. El día es el período que la Tierra emplea en girar alrededor de su eje; el mes es el período de 29,53 días que tarda la Luna en dar una vuelta alrededor de la Tierra y completar su ciclo de fases; el año es el período de 365,25 días que la Tierra tarda en girar en torno al Sol y las estaciones en completar su ciclo. El calendario que utilizamos actualmente es una tosca aproximación proyectada para alinear esas unidades poco conmensurables, de manera que haya exactamente doce meses en el año y de veintiocho a treinta y un días cada mes.

¿Y de dónde proviene la semana?

La Luna atraviesa su ciclo de fases en 29,53 días, y hay cuatro momentos del ciclo en los que las características de la fase son suficientemente notables para tener nombre propio. Cuando la Luna es prácticamente un disco perfecto de luz es «luna llena» y cuando está tan cerca del Sol que no puede verse sino, a lo sumo, como una finísima uña de creciente, es «luna nueva». Yendo desde la luna nueva a la luna llena y de vuelta desde la luna llena hasta la nueva, hay dos puntos donde está iluminada exactamente la mitad del disco lunar visible. Esos dos momentos son los «semilunios». Pero es costumbre hablar de «primer cuarto» o «cuarto creciente» durante el período en que la Luna visible se encamina hacia la plenitud, porque viene tras haberse consumado una cuarta parte del ciclo. La media Luna en el estadio de luna menguante es, por razones análogas, «tercer cuarto» o «cuarto menguante».

Naturalmente el momento de la luna nueva era celebrado como comienzo de cada mes en un calendario estrictamente lunar como el que tenían los babilonios. En tal calendario la luna llena llegaba invariablemente a mediados del mes, y puede que fuese también objeto de homenajes. Parece ser que los babilonios tenían un festival de plenilunio, llamado sappatu.

Los babilonios fueron los líderes culturales del Oriente Próximo a lo largo de todo el período anterior a las conquistas de Alejandro Magno, y su modo de vida repercutió sin duda en otros pueblos. Una forma de la palabra sappatu entró en el lenguaje hebreo y, a su través, en el idioma inglés, en la forma de «sabbath».

Durante el periodo previo al exilio babilónico de los judíos, el término «sabbath» puede que significara estrictamente el festival de plenilunio, y a veces se utiliza en los libros anteriores al exilio como una especie de antónimo del festival de novilunio. Recordemos, a título de ejemplo, aquel pasaje en que una mujer, habiendo muerto su hijo de insolación, quiere llevarlo al milagroso profeta Eliseo, y su marido le dice: «¿Por qué has de ir donde él hoy? No es novilunio ni sábado» (II Reyes, 4:23).

Es muy posible que hubiera también ceremonias para marcar las dos fases de semilunio, con lo cual existiría un total de cuatro festivales lunares cada mes que acaso recibieran el nombre de sábados.

Sucede que esos cuatro puntos en el ciclo de fases lunares equidistan en el tiempo. El lapso temporal de un punto al siguiente, de la luna nueva al primer cuarto, del primer cuarto a la luna llena, de ésta al tercer cuarto y de éste a la luna nueva, es en cada caso justamente una cuarta parte del mes lunar o aproximadamente 7,38 días.

Con vistas a los festejos populares es difícil manejar fracciones de día. El número entero más próximo es el 7, y la tendencia debió ser a una celebración lunar cada siete días. Con esta distribución tenemos un período de siete días construido en el calendario, La palabra inglesa week proviene de un término teutónico cuyo significado es «cambio» (de la fase lunar, naturalmente). La conexión es más nítida en alemán, donde Woche significa semana y Wechsel significa cambio.

Naturalmente, la semana de siete días no coincide exactamente con las fases lunares. Si comenzamos con la luna nueva a mediodía del día 1, el cuarto creciente llega alrededor de las nueve de la tarde del día 8, la luna llena aparecerá aproximadamente a las nueve de la mañana del día 16 y el cuarto menguante se produce bien pasadas las tres de la tarde del día 23. Si los cambios de fase se celebran cada siete días sin falta, la celebración cae en los días 1, 8, 15 y 22, de manera que los dos últimos se desfasan un día.

Con este sistema celebraríamos la próxima luna nueva día y medio antes de tiempo, y si continuamos inflexiblemente con el período de siete días, la tercera luna nueva sería celebrada con tres días de anticipación, y así sucesivamente.

Existen dos soluciones por las que los babilonios pudieron haber optado:

1) Flexibilizar el período semanal con el fin de hacerlo coincidir siempre con las fases de la Luna. Una solución sería adoptar semanas de siete días junto a semanas de ocho, que sumadas diesen una media de 7,38 días a la semana. Dentro de un mismo mes las semanas podrían tener, por ejemplo, una pauta de 7, 8, 7, 8 y en el siguiente una pauta de 7, 8, 7, 7. Si los meses continúan alternándose de este modo, la semana podría continuar alrededor de treinta años antes de perder la sincronización con las fases de la Luna. Y en eso también hay precedentes, porque los babilonios adoptaron un mes flexible, que unas veces tenía veintinueve días y otras treinta; y un año flexible, que a veces tenía doce meses y otras trece, para que así el calendario pudiera continuar adaptado a las estaciones.

2) Por otra parte, los babilonios pudieron haber mantenido inflexible la semana como un período fijo de siete días indefinidamente, olvidando la vinculación de la semanas con las fases lunares. La luna nueva, la luna llena y los cuartos habrían caído entonces en cualquier día de la semana, y lo que comenzara como un período lunar de tiempo habría adquirido luego una existencia independiente.

Parece ser que los babilonios optaron por la segunda solución, lo cual es sorprendente si se tiene en cuenta su modo de registro en relación con el mes y el año.

Puestos a buscar el motivo de esta inflexibilidad en relación con el período semanal, debemos probablemente remitirnos a la naturaleza del número 7.

Los babilonios fueron los grandes astrónomos de los días prehelénicos, y no ignoraban la existencia de siete cuerpos brillantes en el cielo, que se movían sobre el fondo de las estrellas fijas. Eran el Sol, la Luna, Mercurio, Venus, Marte, Júpiter y Saturno. (Para los cinco últimos utilizamos los nombres de dioses romanos; los babilonios usaron los nombres de sus propias divinidades.)

La coincidencia entre los siete días de un cambio de fase y los siete planetas en el cielo parece haber sido demasiado para los babilonios, que no pudieron resistirse a equiparar cada uno de los siete días con un planeta específico. En tales condiciones, una semana de ocho días, a falta de un octavo planeta, habría supuesto una anomalía intolerable. En la difícil elección entre los planetas como grupo y uno de ellos (la Luna), ganaron los planetas Y como es muy probable que los babilonios designaran cada día de la semana con el nombre de un planeta diferente, esto contribuyó aún más a establecer la semana inflexible de siete días.

Los judíos, durante su exilio babilónico, en el siglo VI a. C., hubieron por fuerza de adaptarse a la semana como unidad de tiempo; porque sería difícil vivir y trabajar en Babilonia sin hacerlo. No cabe duda que los de religiosidad más escrupulosa nunca se prestarían a utilizar nombres paganos para los días de la semana, nombrándolos, en cambio, como el primer día, el segundo, etc. A lo largo de la Biblia, tanto en el Antiguo como en el Nuevo Testamento, los días de la semana no llevan nombres, sino sólo números.

Aun cuando los judíos en el exilio no condescendieran con los ritos religiosos de los babilonios, es obvio que tenían que suspender sus negocios cada siete días. (Es difícil no cerrar los comercios cuando así lo hace la gran mayoría, o viceversa, cosa que han comprobado los judíos en muchas ocasiones desde entonces.)

Para plegarse a los usos locales y evitar al tiempo que tal suspensión honrase a lo que ellos tenían por culto idólatra del Sol, la Luna y los planetas, los judíos necesitaban dar a la semana un significado en su propio sistema religioso. Durante el exilio babilonio fue cuando alcanzaron su forma moderna los primeros 34 versículos del libro bíblico del Génesis. En esos versículos Dios crea el mundo en seis días y descansa el séptimo. Lo cual proporciona significado judaico a la semana y al hecho de que el séptimo día de la semana sea un día de descanso. (La palabra «sabbath» proviene de otra semítica que significa «reposo».)

Al regresar parte de los judíos babilonios a Judea, llevaron consigo la noción del Sabbath, y la utilizaron como importante distinción entre ellos y quienes vivían a la sazón en aquella tierra.

A pesar de que la Biblia -cuya forma definitiva se crea durante el exilio babilónico y después- sitúa la institución del Sabbath en la creación misma, no hay prácticamente mención de él en los primeros libros históricos (Jueces, I y II Samuel y I y II Reyes), cuyo material es anterior al exilio. Desde un punto de vista ritualista, sólo se hace realmente importante en los libros posteriores al exilio. Así, en el libro de su nombre, Nehemías menciona el quebrantamiento del sábado como prueba chocante de una recaída en el pecado: «Por aquellos días observé en Judá que había quienes pisaban los lagares en sábado…» (Nehemías, 13:15).

A partir de entonces los judíos atribuyeron cada vez más importancia al sábado. Durante los días de la persecución seleúcida, en el siglo II a. C., algunos prefirieron morir o perder batallas antes que violarlo.

Los primeros cristianos fueron judíos, naturalmente, y aunque muchos de los elaborados principios judaicos del siglo I fueron abandonados al diseminarse el cristianismo por todo el Imperio Romano (en especial, la necesidad del rito de la circuncisión), no así con la semana y el sábado.

Finalmente, cuando el Imperio Romano hizo del cristianismo la religión estatal, se adoptó la semana en Occidente como una parte oficial del calendario -y no hasta entonces-. Fue el emperador Constantino I, primer césar cristiano (aunque no fuese realmente bautizado hasta encontrarse en su lecho de muerte), quien en el siglo IV convirtió la semana en parte oficial del calendario romano.

Mas no cabe duda que la semana, como período místico, tuvo que entrar en Occidente en fecha anterior, Los astrólogos occidentales, para dedicar los días a los planetas (y, a través de ellos, a los dioses), utilizaban un sistema que probablemente tomaron prestado de los babilonios. Funcionaba del modo siguiente:

Enumeraremos los planetas en orden de creciente velocidad en relación con las estrellas: Saturno, Júpiter, Marte, Sol, Venus, Mercurio, Luna. Imaginad luego que los planetas tienen a su cargo horas sucesivas del día, por ese orden.

La primera hora del primer día sería Saturno, la segunda hora Júpiter, la tercera Marte y así sucesivamente. Tras siete horas se habría agotado la lista, y la octava sería otra vez Saturno: lo mismo acontece con la décimo quinta y con la vigésimo segunda. La 23 sería Júpiter, la 24 Marte y la 25, que sería la primera hora del segundo día, sería el Sol.

Si el planeta que rige la primera hora de un día específico se vincula a la totalidad de ese día, el primer día pasa a ser entonces el de Saturno y el segundo el del Sol. De continuar emparejando a los planetas con las horas de acuerdo con este sistema, descubriréis que la primera hora del tercer día está asociada con la Luna y que los siguientes días de la semana están asociados con Marte, Mercurio, Júpiter y Venus, en ese orden. El octavo día está dedicado de nuevo a Saturno y el ciclo recomienza.

Cuando se introdujo la semana como una institución cristiana, resultó que el día de la semana astrológicamente asociado con Saturno era el mismo día que por tradición judaica constituía el séptimo (el sábado). En consecuencia, el día asociado con Saturno fue situado al final. La semana romana comenzaba así en el día asociado con el Sol. Era como sigue: 1) dies Solis (Sol), 2) dies Lunae (Luna), 3) dies Martis (Marte), 4) dies Mercurii (Mercurio), 5) dies Jovis (Júpiter), 6) dies Venerís (Venus) y 7) dies Saturni (Saturno).

Las lenguas romances siguen este esquema para el segundo hasta el quinto día inclusive. En francés esos días son lundi, mardi, mercredi, jeudi y vendredi. En italiano son lunedi, martedi, mercoledi, giovedi y venerdi. En español son lunes, martes, miércoles, jueves y viernes.

En inglés y alemán son los dioses teutónicos los celebrados. En inglés, los dos primeros días de la semana son Sunday y Monday, mientras que los alemanes tienen Sonntag y Montag. Los días tercero, cuarto, quinto y sexto son para Tiu, Woden, Thor y la diosa Freya, que es la Venus del Norte. En inglés tenemos Tuesday, Wednesday, Thursday y Friday. Los alemanes tienen Freitag para el sexto día y usan sus versiones de los nombres de los dioses, Dienstag y Donnerstag, para martes y jueves.

El miércoles -wednesday en inglés-, que conmemora el dios principal del panteón teutónico, se ha perdido en alemán, donde se dice simplemente Mittwoch, que significa, con bastante sensatez, «mitad de la semana».

Puesto que el dies Saturni romano es el Sabbath de la tradición judaica, ello afecta el nombre del día en las lenguas romances. El séptimo día es sabato en italiano, sábado en español, mientras que en francés y alemán parece ser una especie de compromiso entre Saturno y Sabbath, siendo Samedi y Samstag, respectivamente. (En alemán también se llama al séptimo día Sonnabend, que significa «víspera de Domingo».)

Es extraño que el inglés permaneciera adherido tan paganamente a Saturno frente al Sabbath, pero lo cierto es que los anglosajones llamamos al séptimo día «Saturday».

Los primeros cristianos judíos celebraban el Sabbath como lo hacían los judíos en general, y en el séptimo día también. Sin embargo, al igual que aquellos trataron de distinguirse de los babilonios, también quisieron los cristianos primitivos distinguirse de los judíos no cristianos.

Con ese fin se fijaron en el punto de su doctrina que era absolutamente distinto: la crucifixión, resurrección y carácter mesiánico de Jesús. Por tradición, Jesús fue crucificado un viernes, y resucitó al tercer día, que era domingo. De manera que los primeros cristianos, además de celebrar el Sabbath en el séptimo día, celebraban también la resurrección en el primero, que llamaron día del Señor.

Por ese motivo, los romanos del Imperio cristiano no sólo llamaron al día dies Solis, sino también dies Dominica, y ese hábito se ha conservado también, puesto que el primer día es domingo en español, domenica en italiano y dimanche en francés. El inglés y el alemán siguen conmemorando estólidamente al Sol a pesar de todo, con Sunday y Sonntag.

A medida que el cristianismo se hizo más gentil y menos judaico, el énfasis fue desplazándose más y más del séptimo al primer día, y el domingo no sólo se convirtió en el día del Señor, sino que también acabó vinculándose a todo tipo de costumbres sabáticas. Se transformó en el día semanal de descanso, en el día en que los negocios mundanos debían cesar, en el que la asistencia a la iglesia era deseable o incluso obligatoria, etc.

Naturalmente, hay una incoherencia. La historia de la creación descrita en el Génesis explicita con bastante claridad que el Sabbath es el séptimo día de la semana. «Y, habiendo rematado Dios en el día séptimo la obra que hiciera, en ese día séptimo descansó de toda la labor realizada, y bendijo Dios al día séptimo y lo declaró santo…» (Génesis, 2:2-3).

Y tampoco hay duda alguna de que el séptimo día es el que nosotros llamamos sábado. Los calendarios utilizados en los Estados Unidos comienzan siempre la semana con el domingo como primer día y la terminan con el sábado como séptimo.

Algunos cristianos se mostraron molestos por reservar para el primer día rituales de culto que Dios había parecido reservar para el séptimo. En 1844 un grupo de cristianos se organizaron en una secta denominada adventistas, una secta que esperaba el no muy lejano y quizá inminente segundo advenimiento (aparición) de Jesús. Sintiendo también que debían adherirse a las palabras literales del Génesis antes citadas, insistieron en celebrar el Sabbath en el séptimo día, no en el primero, esto es, el sábado y no el domingo. En consecuencia, adoptaron el nombre de «Adventistas del Séptimo Día» (como la señora de la recepción del motel a quien me referí en la introducción de este capítulo).

Y no son ésos los únicos cristianos que celebran el sábado como el Sabbath. Hay también Baptistas del Séptimo Día, según creo, y aún otras sectas.

Todas estas sectas del «Séptimo Día» se agrupan, junto con los judíos, bajo la rúbrica de «sabatarios», y crean un problema. En una sociedad como los Estados Unidos del siglo XX, las costumbres religiosas son bastante laxas. Cualquiera puede observar el día que prefiera como sábado, o no observar ninguno.

Sin embargo, como parte de la tradición heredada de una época anterior y más estricta, el domingo tiene un trato legal distinto del de los demás días. Los comercios cierran ese día, aunque no cierren ningún otro. E incluso hay ramos en que el cierre es legalmente obligatorio.

¿Qué ocurre entonces con los sabatarios, que se sienten forzados a cerrar los comercios en sábado por razones religiosas y se ven obligados por la ley a descansar también el domingo aunque ese día no tiene significado alguno para ellos? ¿Dónde está la justicia para los sabatarios?

¿O qué os parece el hecho de que una vez establecido un Sabbath en cualquier día y fijado un principio de descanso para un día fijo de la semana en el que todo el mundo levanta el vuelo como un grupo de robots, el hábito se extiende fácilmente a dos días por semana e incluso tres? Entonces una persona como yo, que no observa día específico de descanso, sino que muy probablemente (cuando se le permite) trabaja de modo firme e industrioso siete días a la semana, descubre que no puede recibir correo en domingo y que no puede dirigirse a sus editores ni en sábado ni en domingo. ¿Dónde está la justicia para los no sabatarios?

Estas dificultades, por muy importantes que sean para individuos concretos, son, desde luego, triviales para el mundo en general.

Lo que es mucho más importante es que la semana, surgida en Babilonia por razones que ahora se nos antojarían triviales [4] y llegada hasta nosotros a través de una serie de giros muy improbables de la historia, crea ahora interminable confusión.

Porque pensemos: normalmente es importante saber en qué día de la semana cae una fecha específica. Si es domingo, quizá no aceptéis una invitación que sí aceptaríais en caso de ser martes. Uno se lo piensa antes de ir a un restaurante sin reserva previa una noche de sábado, pero no un miércoles. Una noche determinada de la semana puede ser noche de póquer; otro día de la semana puede ser el día de la novia o el día de la mujer a los efectos de ir a bailar. La lista es inacabable.

Sin embargo, dada una fecha al azar, es imposible decir sin cálculos considerables (o sin consultar un calendario) qué día de la semana es.

Sólo hay una palabra para describir esta situación: estupidez, porque no tiene razón de ser.

Permitidme que os dé la razón básica de por qué no pueden predecirse los días de la semana sin gran complicación. Hay trescientos sesenta y cinco días en un año (trescientos sesenta y seis en un año bisiesto) y 7 x 52 = 364. Esto significa que en un año corriente hay cincuenta y dos semanas y un día. En un año bisiesto hay cincuenta y dos semanas y dos días.

El día 1 de un año común de trescientos sesenta y cinco días puede caer, supongamos, en domingo, de manera que sería el primer día de la primera semana de ese año. En tal caso, el penúltimo día del año, el día 364, sería el último de la semana 52 y caería en sábado, Esto significa que el 1 de enero (día 1) caería en domingo y el 30 de diciembre (día 364) caería en sábado. Pero queda todavía el día 365, que es el 31 de diciembre, y que caería en domingo [5]. Entonces el 1 de enero del año siguiente cae en lunes.

Si el año es bisiesto y el 1 de enero es domingo, el día 364 sería el 29 de diciembre (porque el 29 de febrero habría entrado como día 60, empujando al 1 de marzo, que habitualmente ocupa ese puesto, a la posición de día 61, y así sucesivamente hasta el final). Quedarían entonces dos días más, el 30 y el 31 de diciembre, que caerían en domingo y lunes respectivamente, y el primero de enero del año siguiente caería en martes.

Esto es cierto de cualquier fecha del año, no sólo del primero de enero. Cualquier fecha caerá un día más tarde en la semana respecto al año anterior, y a veces dos, si el 29 de febrero se ha colado entre medias.

Para daros un ejemplo arbitrario: tomemos la fecha del 17 de octubre de 1971. Cayó en domingo. En 1972 el 17 de octubre cayó en martes (el 29 de febrero se interpuso). En años sucesivos, el 17 de octubre caerá en miércoles, jueves, viernes, domingo, lunes, martes, miércoles, viernes, sábado, domingo, lunes, miércoles, jueves, viernes, sábado, lunes, martes, miércoles, jueves, sábado, domingo, lunes, martes, jueves, viernes, sábado, domingo.

El 17 de octubre no vuelve a caer en domingo y en el año anterior a un bisiesto hasta 1999, veintiocho años después de 1971 [6], por lo cual la pauta comienza a repetirse. Si lográis retener en la memoria esta pauta de 28 miembros, tendréis un esquema para saber el día de la semana de cualquier fecha de cualquier año desde que se estableció el calendario gregoriano (en 1752 en Gran Bretaña y las colonias americanas). Pero sólo podréis hacerlo si cada cuarto año es sin falta un año bisiesto.

Ahora bien, en el calendario gregoriano hay tres ocasiones cada cuatro siglos en que el cuarto año no es un año bisiesto. La ocasión siguiente será el 2100 de nuestra Era, y cada vez que surge esa excepción hay que revisar ligeramente la pauta de 28 miembros.

Con lo cual la cuestión candente es ésta: ¿cómo podríamos eliminar del calendario esta especie de sinsentido (junto con algunos otros problemas no tan indignantes)?

No es difícil, y os mostraré cómo hacerlo en el siguiente capítulo.

4. La excusa de la semana [7]

A lo largo de los últimos años he aparecido ocasionalmente en charlas televisivas. No lo bastante como para convertirme en una celebridad nacional, desde luego, pero sí lo suficiente como para dar a algunas personas la incierta sensación de casi reconocerme cuando me ven.

El reconocimiento al que me refiero se ve facilitado por las patillas y el pelo largo que ahora gasto, lo cual me proporciona un aspecto más bien leonino. Añádase a eso una especie de expresión feroz en la que caigo de modo natural cuando pienso -lo cual suele acontecer a todas horas- y me imagino que me convierto en alguien difícil de olvidar.

Sea como fuere, bajaba yo hace poco en un ascensor, con una señora mayor como único acompañante a bordo. Me clavó la vista y luego, utilizando el privilegio de la edad, dijo abruptamente:

–Usted es alguien famoso. Lo sé. ¿Cuál es su nombre?

Tratando de sonreír amablemente, dije:

–Soy Isaac Asimov, señora.

Y ella, secamente:

–¿Quién?

¡Ah, la fama! Diréis que episodios como éste me deberían enseñar a no sacar los pies del tiesto y a ser más comedido a la hora de exponer mis conceptos revolucionarios en ese u otro campo. Pero, de algún modo, no es así.

Por ejemplo, quiero continuar el capítulo anterior con otro dedicado al análisis de una reforma del calendario, y de pasada pretendo daros mis ideas sobre el tema, que considero superiores a las de cualquier otra persona en el mundo. Eso es humildad, y lo demás son cuentos.

Los reformistas del calendario objetan seriamente al calendario que todos utilizamos actualmente y que algunos incluso aman. En primer lugar está la dificultad (ya explicada en el capítulo 3) de que el calendario cambia cada año. Hay siete años distintos de trescientos sesenta y cinco días, porque el primero de enero puede caer (y periódicamente cae) en cada uno de los siete días de la semana. Del mismo modo, hay siete años bisiestos diferentes. Puesto que hay un año bisiesto cada cuatro años, los calendarios varían cada año con arreglo a una pauta compleja, hasta pasar un período de veintiocho años. Después, la pauta comienza a repetirse.

Así, los calendarios para 1901, 1929, 1957, 1985, 2013, 2041, 2069 y 2097 son todos idénticos. Todos ellos son años comunes donde el primero de enero cae en martes. En todos el 4 de julio es un jueves, y Navidad un miércoles. (Diferencias superficiales las hay, desde luego. Ni en 1901 ni en 1973 fue fiesta el «Día del Armisticio», por ejemplo, pero sí en 1935.)

En esta pauta de veintiocho años hay veintiún años comunes, comenzando tres en cada uno de los días de la semana, y siete bisiestos, uno por cada día de la semana. Si guardáis los calendarios de veintiocho años sucesivos, tendréis un «calendario perpetuo de veintiocho años».

Podéis colgar los 28 en la pared por su orden y pasar de uno al siguiente cada año, completando el círculo completo al cabo de veintiocho años y volviendo luego a comenzar.

El sistema funcionará mientras cada cuarto año sea un año bisiesto sin falta. Entre 1900 y 2100 no hay fallo, pero en general tres de cada cuatro años de siglo par no son años bisiestos, por lo cual hay entonces siete años comunes seguidos, como sucedió desde 1897 a 1903 inclusive. Para conseguir un verdadero calendario perpetuo que case con el sistema gregoriano al uso necesitaríamos 2.800 calendarios sucesivos, desde, digamos, el 1601 de nuestra Era hasta el 4400. Después, las cosas se repiten exactamente desde el 4401 hasta el, 7200, y así sucesivamente.

Convendréis en que la idea no es precisamente práctica, sobre todo porque, tras cierto número de ciclos, el actual calendario gregoriano se desfasa un día respecto del Sol, con lo cual habrá que sustraer un año bisiesto.

Pero la cosa tiene remedio. Pensemos un poco.

Lo más sencillo es numerar simplemente los días. Podríamos empezar en algún punto conveniente y enumerarlos correlativamente y sin límite. No hay cuidado de quedarnos sin números porque son infinitos, y si consideramos únicamente los días, sin preocuparnos de las semanas, los meses o los años, no necesitamos para nada el calendario. Nos limitamos a recordar que nacimos el día tal y tal, que nos casamos el día tal y tal, que dimos un gran golpe en la Bolsa el día tal y tal, etc. La gran ventaja, aparte la abolición de todos los calendarios, sería el hecho de que sabríamos en cualquier momento el número de días entre dos acontecimientos por simple sustracción.

Tal sistema puede que se os antoje totalmente impensable, demasiado matemático y despersonalizado. Pero eso es exactamente lo que hacemos en el caso de los años. Nos limitamos a enumerarlos de modo indefinido, y vamos ya casi por el número 2.000. Y aquí también cabe hablar de despersonalización, pues hubo un tiempo en que todos los años eran identificados como aquel en que Fulano era arconte o cónsul, o el año tal y cual del rey equis.

La ventaja de enumerar sin más los años era, sin embargo, tan grande, que se abandonaron todos los pequeños toques personales utilizados para identificarlos (pues, aunque se tratase de una costumbre cariñosa y humana, generaba inacabables confusiones a la hora de llevar registros ordenados). Resta, sin duda, la cuestión de dónde empezar la cuenta. Es preciso encontrar algún hito importante en el cual coincida el mundo en general. En el caso de los años, ese hito fue el nacimiento de Jesús.

No sólo los años se enumeran mediante este sistema, sino también los días, aunque no lo creáis. A finales del siglo XVI un erudito francés, Joseph Justus Scaliger, propuso numerar los días y eligió como día primero el 1 de enero del 4713 a. C. según el calendario gregoriano [8]. Llamó a esos días numerados «días julianos» en honor a su padre, Julius Caesar Scaliger.

Los astrónomos usan actualmente el día juliano, pues consideran conveniente trabajar sólo con días en sus cálculos El día que escribo estas palabras es el día juliano 2.441.252.

Pero ahí está el problema. Si conservamos la numeración correlativa de los años es porque nos encontramos aún en números de cuatro dígitos, fáciles de manejar; y no hará falta añadir un quinto dígito hasta dentro de ocho mil años. Pero en el caso de los días estamos ya en siete dígitos, y eso es poco conveniente. Incluso alguien tan aficionado a los números como yo debe admitir que la identificación de los días mediante siete dígitos es pasarse un poco.

Además, el ciclo de estaciones (un año para un ciclo completo) es demasiado importante para la economía mundial y para los asuntos humanos personales como para ser ignorado. El año hay que dejarlo.

Pero, en ese caso, ¿por qué no combinar el año y el día, dando a cada uno un número y nada más? Cada año tendría sus días numerados de 1 a 365 (ó 366 si se trata de un año bisiesto). Podríamos hablar del 72 de 1944, o del 284 de 1962, o del 366 de 1984, identificando así cada fecha de modo único e inconfundible. En realidad, seguirá habiendo seis o siete dígitos a manejar, pero estaremos pensando en días y años por separado, lo cual entraña una diferencia psicológica.

Con una numeración día-año semejante seguiríamos sin necesitar un calendario. De hecho, con el sistema actual sólo lo necesitamos cuando surge la cuestión del día de la semana. Al consultar un calendario uno se pregunta exclusivamente dos tipos de cuestiones: 1) ¿qué día de la semana es el 28 del mes que viene? o 2) ¿cuál es la fecha del próximo martes? Si no nos importase en qué día de la semana cae una fecha, jamás consultaríamos el calendario.

Pero no podemos librarnos de la semana. Está demasiado enraizada en nuestro modo de vida. Por Dios, ¿qué haríamos sin el fin de semana?

Hemos de conservar, pues, la semana y tener un calendario donde todos los días del año se ordenen en siete columnas.

Supongamos que el año tuviese exactamente trescientos sesenta y cuatro días. En ese caso los trescientos sesenta y cuatro días se ordenarían en siete columnas, cada una de las cuales estaría compuesta por 52 elementos. Si el día 1 fuese un domingo, los días 8, 15, 22, 29, 36…, 358 caerían todos en domingo; los días 9, 16, 23, 30, 37…, 359 caerían todos en lunes, y así sucesivamente. El día 364 caería en sábado y con él terminaría el año, por lo cual el día primero del año siguiente comenzaría en un domingo y todo volvería a empezar de nuevo.

En tal supuesto, un solo calendario, con todos los días numerados y divididos en cincuenta y dos semanas completas, serviría para cualquier año a perpetuidad (suprimiendo cambios en las longitudes del día y del año a lo largo de los eones).

Pero el año no tiene trescientos sesenta y cuatro días, sino 365 1/4, con lo cual cada año tiene por lo menos trescientos sesenta y cinco días y a veces trescientos sesenta y seis.

¿Podemos ignorar esos días de sobra y pretender que trescientos sesenta y cuatro componen un año? ¿Qué más da un día o dos aquí y allá? Pero si intentamos hacerlo, el año se desfasa con respecto a las estaciones. Si el equinoccio de primavera es el 21 de marzo de este año, caerá el 22 de marzo al año siguiente (o el 23 si el año siguiente es bisiesto), y así sucesivamente. Tras doscientos noventa y dos años, el equinoccio de primavera (o cualquier otro hito astronómico de las estaciones) habrá cumplido un ciclo completo, retornando al 21 de marzo.

Factible es, desde luego. Los antiguos egipcios ignoraban los años bisiestos, dejando que el año quedase un cuarto de día corto respecto del Sol cada año, con lo cual los hitos de las estaciones recorrían un ciclo anual completo cada mil cuatrocientos sesenta años. Rehusaron cambiar el sistema, aunque sabían que estaba sucediendo y aunque sabían cómo evitarlo. La tradición, ya sabéis. Pues bien, abajo la tradición. Mantengamos un año de trescientos sesenta y cuatro días sin abandonar los días 365 y 366. Todo cuanto necesitamos es negarnos a asignar esos días adicionales a ningún día de la semana.

Consideremos el día 365 como un día no asignado a semana alguna. Viene simplemente al final y cuenta como una fiesta, que deberá llamarse «Día del Año». En los años bisiestos hay también el día 366, que es otra fiesta, llamada «Día Bisiesto», sin atribuírsele a un día de la semana. De este modo, tras el Día del Año (y tras el Día Bisiesto, en los años bisiestos) pasamos cada año al día primero del siguiente, que sigue siendo un domingo, aunque en este caso hayan pasado ocho días (o nueve en un año bisiesto) desde el domingo previo, que era el día 358. En tal calendario, los días 365 y 366 pueden situarse entre paréntesis a la derecha de las siete columnas, sin permitírseles intromisión en la semana.

Aunque este calendario de años, semanas y días (sin meses, reparad bien) nunca ha sido sugerido seriamente -ni siquiera yo lo sugiero en serio-, todos los calendarios repetitivos que han sido propuestos sobre una base anual deben hacer uso de un Día del Año y de un Día Bisiesto, no asignados a ningún día de la semana. Sólo así podemos evitar que la semana de siete días desfase el calendario y haga cada año distinto del precedente.

Pero es en esta roca donde zozobra la reforma del calendario. Hay muchas corporaciones religiosas influyentes que no quieren ni oír de un día suelto, no asociado a ningún día de la semana. El Sabbath debe celebrarse sin falta cada siete días, y si una vez al año dos domingos (o dos sábados, si sois sabatarianos, o dos viernes, si musulmanes) están separados ocho o nueve días, los cielos religiosos aparentemente se derrumbarán.

Si queréis mi opinión, considero que esta excusa de la semana es una excusa débil para oponerse a una reforma del calendario [9]. Sin intentar preparar una verdadera lista de los millones de compromisos que han hecho las diversas religiones en interés de la eficacia, sugiero simplemente las palabras de Jesús: «El sábado fue hecho para el hombre, y no el hombre para el sábado» (Marcos, 2:27).

Es posible que algún día quienes ven al sábado retornar con el interminable tic-tac de un metrónomo cedan en interés de la cordura.

Tomar un año entero como unidad tiene sus pegas, porque si bien se incluye el ciclo completo de estaciones, ignora cada estación por separado. Yo, por ejemplo, estoy acostumbrado a cuatro estaciones de características harto diferentes, cada una con su efecto sobre la agricultura, el comercio, el transporte, las vacaciones, el consumo, etc. Sería útil que el calendario tuviera debidamente en cuenta las distintas estaciones.

Lo natural parece que es utilizar los meses a tal fin. El mes se adaptó originalmente para marcar el ciclo de las fases de la Luna, y nada tenía que ver con las estaciones. Sin embargo, ahí están.

Tradicionalmente son doce los meses, por el accidente de la longitud del ciclo de las fases lunares. La desgracia, sin embargo, es que doce meses iguales en un año de trescientos sesenta y cuatro días (el único tipo de año que tiene sentido dentro de un calendario repetitivo) tienen cada uno 30 1/3 días, o 4 1/3 semanas. Dicho con otras palabras, los meses de un año de doce meses son imposibles de cuadrar ni con días ni con semanas.

Lo extraño, empero, es que un año de trece meses sería perfecto a tal fin, puesto que 364 = 13 x 28, y 28 = 7 x 4. En un año de trece meses, cada mes duraría justamente cuatro semanas y, naturalmente, veintiocho días. Cada mes tendría el siguiente aspecto:

D L M M J V S

1 2 3 4 5 6 7

8 9 10 11 12 13 14

15 16 17 18 19 20 21

22 23 24 25 26 27 28

El aspecto de este mes no es del todo extraño. Tres veces cada veintiocho años febrero tiene ese aspecto. Febrero de 1970, concretamente, fue así.

Si cada mes fuese así, la disposición sería fácil de retener en la memoria. Nos haríamos a la idea de que el 17 caía siempre en martes y el 13 siempre en viernes (¡perdón!) el primero siempre en domingo, y así sucesivamente. Al cabo de un tiempo, no necesitaríamos para nada el calendario.

Pero ¿qué hacemos con el décimo tercer mes? Una posibilidad fue la que se propuso en el Calendario Fijo Internacional que durante algún tiempo, hace algunas décadas, logró cierta publicidad. El décimo tercer mes (llamado Sol) fue situado entre el sexto y el séptimo, junio y julio, respectivamente. En este calendario el Día del Año aparecía como 29 de diciembre y el Día Bisiesto como 29 de junio, sin asignarlos -naturalmente- a ningún día concreto de la semana.

No es posible hacer un calendario que, trabajando con días, semanas y meses, sea más simple que el Calendario Fijo Internacional, y es lástima que posea un defecto tan grande corno para inhabilitarlo. Trece meses no pueden dividirse equitativamente por cuatro, con lo cual no hay un número entero de meses por estación. En el Calendario Fijo Internacional hay tres meses y una semana por estación, y eso introduce una irregularidad que contrarresta todas las uniformidades.

Un año de doce meses tiene la ventaja de ser divisible en cuatro estaciones, con tres meses para cada una. En un año de doce meses es imposible conseguir que cada mes sea exactamente igual a su predecesor y sucesor, como acontece en el Calendario Fijo Internacional, pero esta desventaja se considera trivial en comparación con su exactitud estacional.

Así, pues, manteniendo las estaciones, ¿cómo podernos hacer que el calendario sea lo más simple y repetitivo posible? Puesto que hay cincuenta y dos semanas en un año de trescientos sesenta y cuatro días, tocan a trece semanas por estación. Trece semanas son noventa y un días, y éstos pueden ser distribuidos a lo largo de tres meses de una forma lo más igual posible dando al primer mes treinta y un días y a los otros dos treinta. Este es el aspecto que tendría el período de tres meses:

D L M M J V S

1 2 3 4 5 6 7 Enero

8 9 10 11 12 13 14 Abril

15 16 17 18 19 20 21 Julio

22 23 24 25 26 27 28 Octubre

29 30 31

1 2 3 4 Febrero

5 6 7 8 9 10 11 Mayo

12 13 14 15 16 17 18 Agosto

19 20 21 22 23 24 25 Noviembre

26 27 28 29 30

1 2 Marzo

3 4 5 6 7 8 9 Junio

10 11 12 13 14 15 16 Septiembre

17 18 19 20 21 22 23 Diciembre

24 25 26 27 28 29 30

Con este calendario nos basta y nos sobra, pues representando un período de tres meses, el cuarto coincidiría exactamente con el primero. Si el mes de arriba fuese enero, el del medio febrero y el de abajo marzo, el mismo calendario trimensual serviría para abril, mayo y junio, luego para julio, agosto y septiembre y, finalmente, para octubre, noviembre y diciembre, año tras año tras año.

Tal calendario perpetuo trimensual se denomina «Calendarlo Mundial», y hay movimientos activos que lo apoyan. En el Calendario Mundial, el Día del Año cae el 31 de diciembre, y el Día Bisiesto, el 31 de junio, y ambos carecen de equivalencia con días de la semana.

Otra ventaja del Calendario Mundial es que los meses son de forma familiar: no hay ninguna secuencia trimensual en nuestro calendario que sea exactamente igual a la del Calendario Mundial (porque no hay nunca dos meses de treinta días seguidos), pero hay meses sueltos que sí son iguales. Agosto de 1971 fue exactamente igual que el mes superior de la secuencia trimensual, septiembre de 1971 igual que el mes del medio y septiembre de 1972 igual que el de abajo.

El Calendario Mundial es, hasta ahora, indudablemente el mejor calendario repetitivo, en el sentido de que exige la mínima modificación del sistema actual. Sin embargo, hay algunas mejoras que me gustaría sugerir, pues aunque requieren modificaciones adicionales, desembocan en lo que tengo por el calendario más simple y más racional posible, donde se toman en cuenta tanto las semanas como las estaciones.

En primer lugar, hay cuatro puntos naturales, desde la perspectiva astronómica, donde podría comenzar el año: los dos solsticios y los dos equinoccios. Estos puntos no se encuentran distribuidos uniformemente a lo largo del año, porque la órbita terrestre alrededor del Sol no es perfectamente circular, pero podemos situarlos en el 21 de diciembre, el 21 de marzo, el 21 de junio y el 21 de septiembre del actual calendario, sin errar en más de un día o dos.

Cualquiera podría servir como punto de partida. El 21 de diciembre el sol está en su punto cenital más bajo visto desde el hemisferio Norte, y lo mismo es cierto para el 21 de junio en el hemisferio Sur. El 21 de marzo está a punto de reanudarse el crecimiento de las plantas en el hemisferio Norte, y lo mismo cabe decir del 21 de septiembre en el hemisferio Sur.

Sin embargo, al elegir entre los cuatro puntos tiene sentido dar preferencia al hemisferio Norte, pues la gran mayoría de la raza humana vive allí.

En cuanto a la alternativa del 21 de diciembre y el 21 de marzo, el primero es el comienzo de la espiral ascendente del Sol y el segundo el de la vegetación, y de los dos, el más destacado es aquél. Además, el 21 de diciembre está más cerca del comienzo del año utilizado por nosotros actualmente. En consecuencia, propongo el 21 de diciembre como, comienzo del año, pues de ese modo los períodos sucesivos de tres meses casarán muy exactamente con las estaciones.

El modo más sencillo de provocar el comienzo en un 21 de diciembre es elegir un año determinado, suprimir el 20 de diciembre once días del calendario, y llamar al siguiente día 1 de enero.

Si prescindir de once días es un cambio demasiado drástico (aunque hay precedentes en la Historia: el Imperio británico, con sus colonias americanas, prescindió de once días en 1752), tengo otra propuesta. Adoptemos el Calendario Mundial y, por un momento, omitamos tanto el Día del Año como el Día Bisiesto. Cada año común moveremos los días del año un día hacia atrás con respecto al Sol, y dos días en años bisiestos. Si adoptáramos el Calendario Mundial el 1 de enero de 1979, por ejemplo, y omitimos todos los Días del Año y todos los Días Bisiestos, el 1 de enero de 1988 caería en el solsticio de invierno (21 de diciembre de 1987, con arreglo al calendario actual). De ahí en adelante, la fecha permanecería indefinidamente en el solsticio de invierno con tal de situar apropiadamente los Días del Año y los Días Bisiestos.

Hecho eso, una segunda modificación conllevaría la eliminación de los meses. Los meses carecen de verdadera relación con las estaciones; están vinculados, de modo irrelevante e impreciso, con la Luna. El Calendario Mundial restringe las variaciones en la conexión entre fecha y día de la semana, pero no del todo. El quinto día del mes nunca puede ser lunes, miércoles, viernes ni sábado, pero podría ser domingo, martes y jueves. Cualquier otra fecha podría caer en cualquiera de tres días de la semana, según el mes. Buen avío, ¿no?

¿Por qué no abandonar completamente los meses y conservar sólo las estaciones? Cada estación de cada año, año tras año, tendría el siguiente calendario.

D L M M J V S

1 2 3 4 5 6 7

8 9 10 11 12 13 14

15 16 17 18 19 20 21

22 23 24 25 26 27 28

29 30 31 32 33 34 35

36 37 38 39 40 41 42

43 44 45 46 47 48 49

50 51 52 53 54 55 56

57 58 59 60 61 62 63

64 65 66 67 68 69 70

71 72 73 74 75 76 77

78 79 80 81 82 83 84

85 86 87 88 89 90 91

El cuadro anterior, repetido exactamente cuatro veces cada año, sería el único calendario que necesitaríamos.

Observad de entrada que cualquier día de la semana cuyo número sea exactamente divisible por 7 es un sábado; si el resto es 1 es un domingo, si 2 un lunes, y así sucesivamente. Andando el tiempo no necesitaríais hacer ninguna división, simplemente recordarías el esquema; y en caso de duda podríais mirar el calendario, siempre idéntico.

A este calendario, que tengo por original salvo error, lo llamo Calendario Mundial Estacional, y es el calendario más simple posible que preserva tanto semanas como estaciones. Su miseria es que parece «ridículo». ¡Un mes de noventa y un días! Pero imaginaos: con sólo saber el número tendríamos conocimiento de cuán avanzada está la estación. El día 5 está siempre a principios de la estación de cualquier estación, mientras que el 40 está siempre a mitad de la estación y el 83 a finales.

Otro paso simplificador sería eliminar los nombres de las estaciones. Porque de todos modos son muy provincianos. Lo que es primavera y verano en los EE. UU. es otoño e invierno en la Argentina, y viceversa. Y hay muchas regiones de la Tierra donde las cuatro estaciones no casan realmente, donde hay una o más estaciones húmedas y secas, o, como en Hawai, donde no hay en realidad estaciones.

¿Por qué no dar a las estaciones letras en lugar de nombres? Las letras carecen de connotaciones. Llamaremos A a la primera estación del año. Podría ser invierno en los EE. UU., verano en la Argentina, una estación húmeda en Ghana y una temporada como otra cualquiera en Hawai Luego seguirían B, C y D.

Según el Calendario Mundial Estacional, mi cumpleaños sería el A-2; o, si realmente quiero situarlo en el día correcto, tras tener en cuenta el cambio en Año Nuevo desde el primero de enero (gregoriano) al 21 de diciembre (gregoriano) sería el A-12. (No olvidéis que el Día del Año no se cuenta como un día de la semana. El Día del Año es D-92, y el Día Bisiesto, cuando lo hay, es B-92.)

Si queréis podéis entreteneros en construir una tabla de conversión del calendario gregoriano al Calendario Mundial por Estaciones, teniendo en cuenta que el 21 de diciembre gregoriano es el 1 de enero en el Calendario Mundial por Estaciones. Descubriréis que es harto sencillo reescribir la historia para adecuar todas las fechas al Calendario Mundial por Estaciones… ¿Se os ocurre nada más simple que tome en cuenta tanto las semanas como las estaciones? A mí, no.

B) Sobre otros pequeños mundos

5. El mundo de Ceres

Hace algunos años, un amigo me llamó para decirme que acababa de leer un artículo donde se me mencionaba (debido a mis vulgarizaciones) como «el Leonard Bernstein de la ciencia».

De puro halago casi salto de la silla, pero recordando mi pose de empedernida autoestima justo a tiempo, logré recomponer el ingenio lo bastante como para responder envarado: «¡No es cierto! Bernstein es el Isaac Asimov de la música».

Pero desde entonces he escuchado y contemplado las apariciones de Bernstein en la televisión con un aire complacido y posesivo, y ayer (mientras escribo esto) le oí dirigir y comentar una serie de poemas sinfónicos de Gustav Holst, llamados Los planetas. Y en atención a su joven auditorio, Bernstein recitó la lista de planetas.

Oyéndole, me sorprendió que se olvidara de uno. No era su culpa; todo el mundo se olvida de él. Yo mismo lo omito cuando enumero los nueve planetas, porque hace el número cuatro y medio.

Me estoy refiriendo a Ceres, un mundo pequeño pero respetable [10] que no merece el desprecio que recibe.

Ceres fue descubierto el 1 de enero de 1801 por el astrónomo italiano Giuseppe Piazzi. Su órbita se encuentra entre las de Marte y Júpiter, y es un mundo sorprendentemente pequeño, de pocos cientos de millas de diámetro. Sin embargo, no hay regla que diga que un planeta debe superar cierto tamaño, y a pesar de su pequeñez Ceres habría sin duda entrado en la lista de planetas, de haber quedado en eso el descubrimiento de Piazzi.

Sin embargo a los seis años se descubrieron otros tres planetas pequeños, cuyas órbitas estaban, como la de Ceres, entre Marte y Júpiter.

¿Debían incluirse los cuatro en la lista de planetas? La lista de planetas de gran tamaño ascendía a siete a la sazón (Neptuno y Plutón no habían sido descubiertos todavía); elevarla a once por la suma de esos cuatro habría dado extraordinaria preeminencia a los pequeños mundos.

Y aunque los astrónomos se hubieran decidido a agregarlos, en 1845 se produjo el descubrimiento de un quinto planeta semejante. Y tras ello se sucedieron con celeridad nuevos hallazgos. En 1866 se conocían 88 pequeños planetas entre las órbitas de Marte y Júpiter; actualmente se tiene noticia de más de 1.600, y con seguridad quedan miles más por descubrir.

Sencillamente no tendría sentido incluir todos esos cuerpos en la lista de planetas, y por eso no se hizo con ninguno de ellos.

Casi al principio, cuando sólo se conocían cuatro de los pequeños planetas, el astrónomo anglo-alemán William Herschel había sugerido llamarlos «asteroides» («semejantes a estrellas»), pues eran tan pequeños que en los telescopios de la época aparecían como puntos de luz, igual que las estrellas, y no corno pequeñas esferas, como los otros planetas.

La propuesta fue aceptada, y cada vez se hizo más natural hablar de los asteroides como algo muy distinto de los planetas. La gente recita la lista de planetas por su orden, desde Mercurio a Plutón, y luego añade: «Y, naturalmente, existe luego el cinturón de asteroides entre Marte y Júpiter.»

Pero ¿no podemos siquiera tomar un asteroide como representante del resto e incluirlo en la lista? ¿El mayor? ¿Ceres?

El problema es que el tamaño se interpreta habitualmente en función del diámetro, y en cuestión de diámetros Ceres no parece sobresalir. Tiene un diámetro de unos 780 kilómetros, pero el asteroide que le sigue en tamaño tiene un diámetro de 480 kilómetros aproximadamente y el tercero unos 380. Luego hay seis asteroides más con diámetros de 160 kilómetros, y no menos de 25 con diámetros superiores a los 96. Se trata de una progresión suave, donde Ceres ocupa el primer lugar, pero sin predominar especialmente.

Pero supongamos que atendemos al volumen, que crece con el cubo del diámetro. Ceres tiene un volumen de 248 millones de kilómetros cúbicos, que es igual al volumen de los 15 asteroides siguientes juntos.

La masa total de los miles de asteroides descubiertos y por descubrir se calcula en una décima parte aproximadamente de la masa de la Luna. En tal supuesto, un décimo de la masa asteroidea total se concentra en el mundo singular de Ceres. Vistas así las cosas, no hay duda de que Ceres predomina.

Añádase a esto el hecho de que Ceres posee una órbita casi circular, y que esa órbita se encuentra más o menos en la posición media de todas las órbitas de los asteroides conocidos… y no habrá ya dudas. Parece perfectamente justo considerar a Ceres, por tamaño y posición, como cuerpo profundamente representativo de los asteroides, e incluirlo en la lista de los planetas. Quizá podríamos enumerarlo en quinto lugar, como «Ceres, etcétera».

Una vez que empecemos a establecer puestos de avanzada en otros mundos del sistema solar, puede que Ceres adquiera gran importancia. Razonémoslo.

Desde el punto de vista científico, una de las razones más importantes para aventurarse en el espacio es establecer un observatorio astronómico más allá de la atmósfera terrestre o de cualquier atmósfera. A esos efectos se requiere un mundo sin aire.

Podríamos construirnos un mundo tal en forma de una estación espacial, pero inevitablemente se hallaría en la vecindad de la Tierra. La estación espacial podría hacer importantes estudios terrestres, de eso no hay duda; mas el principal anhelo de los astrónomos será el de explorar los confines distantes del espacio. Para lo cual sería ideal que no existiese ningún objeto próximo que cubriera la mitad del cielo o anegara periódicamente la estación astronómica con radiación.

Teniendo esto en cuenta, se comprueba que en el sistema solar interno no hay ningún cuerpo decente sin atmósfera que cumpla ese propósito. Mercurio está demasiado cerca del Sol; los satélites de Marte están demasiado cerca de Marte. Ni siquiera el otro lado de la Luna es completamente ideal para la exploración del espacio sideral, por la intensa radiación solar que hay presente durante la mitad del tiempo.

No olvidemos, claro está, los asteroides ocasionales que se aventuran dentro de la órbita de Marte. Todos ellos carecen de aire, y ninguno está asociado con un planeta. Sin embargo, todos ellos tienden a acercarse al Sol tanto como la Tierra, y en casi todos los casos mucho más aún. Lo cual podría conferirles un valor especializado. El asteroide Icaro se aproxima más al Sol que el propio Mercurio, y una estación astronómica situada sobre su diminuto cuerpo podría ser inapreciable para el estudio de Venus, Mercurio y el Sol. Sin embargo, ninguno estaría mejor adaptado para el estudio del espacio profundo que la Luna.

En los confines exteriores del sistema solar hay diversos cuerpos sin aire que poseen el mérito de estar lejos del Sol y la desventaja de estar lejos de la Tierra y, en consecuencia, en posición difícil de alcanzar y aprovisionar.

Plutón puede carecer de aire, pero es el más alejado de todos y, sean cuales fueran sus ventajas, habría una tendencia irrefutable a buscar algo más próximo. La mayoría de los satélites de los planetas exteriores carecen de atmósfera, pero tienen el mismo inconveniente de estar cerca de sus planetas. Son útiles como bases para el estudio de estos últimos, pero no ideales para el estudio de los espacios siderales.

De todos los satélites pertenecientes a planetas exteriores los de Júpiter son los más próximos, y entre ellos los cuatro más externos están de 21 a 24 millones de kilómetros del planeta, por término medio. (Júpiter-VIII se aleja hasta una distancia de 32 millones de kilómetros de Júpiter, pero luego regresa hasta situarse a unos 13 millones de kilómetros.) Esos satélites más exteriores son pequeños y probablemente sean asteroides capturados.

Pero si vamos a ocuparnos de los asteroides, ¿por qué no desplazarnos al propio cinturón de asteroides? Allí encontraremos cuerpos 320 millones de kilómetros más próximos a nosotros que los satélites de Júpiter, pero que no están cerca de ningún objeto grande. Los asteroides son los cuerpos sin aire, aislados y más próximos que tenemos al alcance.

Y puestos a elegir entre ellos, ¿por qué no elegir Ceres? Nunca está a menos de 160 millones de kilómetros de ningún cuerpo mayor que él, y tiene unas dimensiones suficientes como para poseer al menos algo de gravedad: 3,5 por 100 de la terrestre. Tengo por muy posible que Ceres llegue algún día a ser el centro astronómico del sistema solar.

Consideremos ahora a Ceres como un mundo.

Pequeño es, desde luego, pero no tanto como parece. El área superficial de Ceres es aproximadamente tan grande como Alaska y California juntas, que no es poco.

Espacio sobrado, no sólo para estaciones astronómicas, sino para alojamientos turísticos.

¿Y qué ofrecerá Ceres como mundo turístico? No estoy seguro de hasta qué punto será proyectado industrialmente, ni en qué medida cabe pensar en instalaciones recreativas partiendo de una gravedad baja (pero no cero). Lo que no admite duda es una cosa: el cielo no cambiará, y podemos intentar imaginar desde ahora cómo será el cielo de Ceres y cuáles podían ser las vistas astronómicas más interesantes que se le ofrezcan al turista con sólo mirar hacia arriba.

En primer lugar, estará el Sol. La distancia media de Ceres al Sol es de 414 millones de kilómetros. Ceres está 32 millones de kilómetros más cerca del Sol en el perihelio y 32 millones más lejos en el afelio, pero la diferencia no es excesiva. A simple vista el Sol no cambiará notablemente de aspecto a lo largo del año cereano (que, dicho sea de paso, dura 4,6 años terrestres),

Ceres está aproximadamente 2,8 veces más lejos del Sol que la Tierra, y esto significa que el Sol parecerá tener un diámetro de unos 11' de arco, aproximadamente un tercio de su diámetro visto desde la Tierra. Lo cual quiere decir que parecerá mucho menor que visto desde la Tierra, pero sin perder el aspecto de un globo nítido.

Su área aparente en el cielo de Ceres será sólo un octavo de su área en el cielo terrestre, o lo que es lo mismo, ofrecerá ocho veces menos luz, calor y radiación de todo tipo.

Ahora bien, vista desde Ceres, cada porción del globo solar será igual de brillante que vista desde la Tierra. El menor brillo del Sol de Ceres no se debe al hecho de ser más tenue por unidad de área, sino a que el área es menor. Por otro lado, aunque la radiación queda reducida a un octavo para cuando llega a Ceres, el hecho de no existir allí atmósfera implica que la radiación solar dura no es absorbida. Rayos ultravioleta, rayos X, partículas cargadas, etc., alcanzarán la superficie de Ceres en mayor cantidad que la que incide sobre la superficie de la Tierra tras la absorción verificada en la atmósfera.

Puesto que nadie se aventurará sobre la superficie anaeróbica de Ceres a falta de un traje espacial, se utilizará indudablemente un cubrerrostro emplomado y teñido para reducir el peligro de la radiación solar. Aun así, se rogará encarecidamente a los turistas de Ceres que no se dejen engañar por la tenue luz ni miren demasiado tiempo directamente al Sol.

Una cuestión importante es saber la velocidad de rotación de Ceres. Porque si Ceres gira demasiado rápido, su utilidad como observatorio astronómico disminuye, dado que los astrónomos tendrían que perseguir a los objetos celestes en su loca carrera por el espacio.

Por desgracia, no es fácil determinar los períodos de rotación de los diversos asteroides. Ni podemos hacer una conjetura razonable partiendo simplemente del diámetro, pues en general el tamaño no tiene mucho que ver con el período de rotación. El período no sólo depende del tamaño, sino de los efectos de marea que provocan los campos gravitatorios vecinos, y de las interacciones electromagnéticas que pudieron ocurrir hace tiempo.

Icaro, por ejemplo, que puede tener un diámetro apenas inferior a un kilómetro y medio, parece rotar en dos horas o así. Eros, que tiene 24 kilómetros de largo (tiene forma de ladrillo), parece rotar en algo más que cinco horas.

Un cálculo reciente es que Ceres rota en un tiempo apenas superior a las nueve horas. En aras de la simplicidad, supongamos que el eje de rotación no está inclinado, sino en ángulo recto con el plano de revolución en torno al Sol, y que Ceres rota en la dirección usual de Oeste a Este.

Si estas suposiciones son correctas, todo cuanto ocupa el cielo de Ceres parecerá moverse de Este a Oeste a ritmo 2,7 veces superior al del cielo terrestre. El Sol, por ejemplo saldrá por el Este y se pondrá en el Oeste cuatro horas y media después, saldrá de nuevo cuatro horas y media más tarde y así sucesivamente.

¿Algo más de interés en el cielo de Ceres, aparte del Sol? Nada, desde luego, que ostente el aspecto de un globo visible.

Ceres no tiene satélite y no está cerca de planeta alguno. Podríais pensar que el cinturón de asteroides está espesamente poblado de cuerpos que pululan todos alrededor de Ceres, pero erraríais. Es dudoso que en ningún momento haya ningún objeto de tamaño superior a dos o tres kilómetros en un radio de 16 millones de kilómetros alrededor de Ceres. Alguno de los otros grandes asteroides puede que en ocasiones se acerque lo bastante como para verlo a simple vista, pero siempre aparecerá como un punto estelar (efectivamente, «asteroide»), nunca singularmente brillante y, desde luego, nunca de forma globular.

Pero ¿y los planetas? Me refiero a los verdaderos planetas, los de gran tamaño.

Cuatro de ellos, Mercurio, Venus, Tierra y Marte, están más cerca del Sol que Ceres. Quiere decirse que desde Ceres siempre se verán como estrellas vespertinas y matutinas que nunca se alejan más allá de una cierta distancia del Sol. Cuanto más cerca del Sol está situado el planeta, más estrecho es su abrazo con el Sol, visto desde Ceres.

Tal sucede con Venus vista desde la Tierra (véase capítulo 1). Venus nunca se aleja más de 47º del Sol, ya sea al Este o al Oeste. En su punto de elongación máxima al este del Sol, aparece a 47º de altura en el cielo occidental en el momento del crepúsculo. En el punto de elongación máxima al Oeste del Sol, aparece con una altura de 47º en el cielo oriental en el momento de amanecer.

En el primer caso es la estrella vespertina y continúa hundiéndose hacia el horizonte tras el crepúsculo, poniéndose tres horas después del Sol. En el segundo caso es la estrella matutina, que se eleva tres horas antes del amanecer y continúa ascendiendo por el cielo hasta la salida del Sol, cuyo brillo borra su presencia. Cuando Venus no está en elongación máxima, se pone menos de tres horas después del crepúsculo y sale menos de tres horas antes del amanecer.

Ninguno de los cuatro planetas interiores, vistos desde Ceres, tiene una elongación máxima igual a la de Venus desde la Tierra. La elongación máxima de Marte es de unos 36,9º, la de la Tierra 22,2º la de Venus 15,2º y la de Mercurio 9,7º. A medida que el Sol se mueve desde el horizonte oriental al occidental en cuatro horas y media, arrastra consigo a todos esos planetas. Los situados al Oeste de él salen y se ponen antes que el Sol; los situados al Este salen y se ponen después que él.

En la Tierra, la dispersión de la luz operada por la atmósfera hace que los planetas próximos al Sol no puedan ser vistos cuando aquél está en el cielo. Sobre el mundo sin aire de Ceres no hay dispersión de la luz: el cielo permanece negro y los planetas son visibles aun estando el Sol en el cielo. Mas no sería agradable inspeccionar las partes del cielo vecinas al Sol, y debido a la luz solar y a su efecto sobre el iris otros objetos menores de la vecindad solar aparecerán débiles y difusos. Una vez que el Sol se ponga, las estrellas y los planetas parecerán abrillantarse, y será entonces cuando resulte agradable y fácil contemplar el cielo.

Imaginemos ahora una configuración muy rara, en la que Mercurio, Venus, la Tierra y Marte están al este del Sol y todos ellos en su elongación máxima.

Cuando el Sol se pusiera y los turistas saliesen a mirar el cielo, los cuatro planetas estarían alineados en el Oeste, si suponemos que los turistas se hallan más o menos en el ecuador de Ceres. Mercurio estará a un décimo del camino desde el horizonte hasta el cenit, Venus a una sexta parte del camino, la Tierra a una cuarta parte y Marte a dos quintas partes.

Todos ellos irán declinando y uno tras otro se pondrán. Si seguimos trabajando con un período de rotación cereana de nueve horas, Mercurio se pondrá seis minutos después que el Sol, Venus cuatro minutos tras Mercurio, la Tierra cinco minutos tras Venus y Marte diez minutos tras la Tierra. Quienquiera que contemple esa sarta de perlas hundiéndose tendrá la viva sensación de que el cielo está girando (o, quizá, que es Ceres el que rota). Me pregunto si no sentirá vértigo,

Si todos los planetas se alinearan al Oeste del Sol, saldrían todos ellos antes que él en orden inverso. Primero Marte, luego la Tierra, Venus y Mercurio. Finalmente, seis minutos después de Mercurio, saldría el Sol. Y no habría aurora preliminar, pues no hay atmósfera. Hace un minuto el cielo estaría negro y al siguiente habría un pequeño fragmento de fuego líquido sobre el horizonte oriental.

(El fenómeno de un amanecer sin aurora puede verse desde la Luna, y sería más espectacular en el lado oculto, sin Tierra alguna en el cielo. Sin embargo, el amanecer es lento en la Luna, y el Sol tarda toda una hora en levantar la esfera completa sobre el horizonte desde que asoma el borde superior. En Ceres, y suponiendo la rotación de nueve horas, el Sol, más pequeño, estaría entero sobre el horizonte siete segundos tras despuntar. ¡Caray!)

Naturalmente, la cadena de cuatro planetas sería una ocasión extraordinaria. Lo normal es que uno o más de los cuatro planetas estén al Este y uno o más al Oeste, a distancias variables.

¿Qué brillo presentaría la cadena de planetas? El brillo de cada planeta variará de acuerdo con su posición respecto a Ceres y al Sol. En el punto de elongación máxima cada planeta aparecerá como un «semiplaneta». Sí se está moviendo hacia el lado lejano del Sol, la fase crecerá hacia el «planeta lleno», pero el tamaño del globo planetario se reducirá. Si está moviéndose hacia el lado próximo del Sol, el tamaño del globo planetario aumentará, pero la fase irá reduciéndose a un «planeta creciente». En el momento en que el planeta se encuentre bien adentrado en la fase de creciente, el área de la parte iluminada será máxima y el planeta tendrá máximo brillo.

Mercurio sólo tendría una quinceava parte del brillo que observamos desde la Tierra en una fase cualquiera, porque está más lejos de Ceres que de la Tierra. Sin embargo, ganaría un poco por el hecho de no estar oscurecido en Ceres por ninguna atmósfera. En conjunto, tendría una magnitud de 1,4 (aunque os advierto que mis cálculos son aproximados, y que no garantizo absolutamente ninguno de mis números).

Pero seguiría siendo brillante, tan brillante como lo que se entiende genéricamente por una estrella de primera magnitud. Estrictamente hablando, sería menos brillante que Mercurio visto desde la Tierra, pero en la práctica parecería más. Mercurio, máximamente visible justo tras el crepúsculo o justo antes del amanecer (tanto en la Tierra como en Ceres), tendría en Ceres la ventaja de ser visto sobre un cielo totalmente negro. Desde la Tierra, Mercurio es observado normalmente al oscurecer o al amanecer, momentos en que la neblina del horizonte empaña aún más la visión.

En el caso de los otros planetas interiores, Venus tendría una magnitud de -0,4, la Tierra de +0,3 y Marte 2,0 [11]. Los cuatro luceros vespertinos/ matutinos parecerían estrellas luminosas y no diferirían mucho en brillo. Venus y la Tierra serían algo más brillantes que Mercurio y Marte, pero no lo suficiente como para impedir que los turistas agruparan las estrellas matutinas/ vespertinas en cuarteto.

Sin embargo, ninguna de ellas sería tan brillante como lo es Venus desde la Tierra. Para nosotros, Venus tiene una magnitud de -4,3 en su fase más brillante.

¿Y qué hay de los otros planetas, los más alejados: Júpiter, Saturno, Urano, Neptuno y Plutón?

No estarán vinculados al Sol, pero podrían divisarse en cualquier momento de la noche y a cualquier altura en el cielo; incluso en el cenit (si estuviésemos en el ecuador de Ceres y no hubiese inclinación axial). En tales condiciones, cuanto más cerca del cenit a medianoche estuviera un planeta, más cerca estaría de Ceres y más brillante su aspecto.

Empezaremos con Júpiter. Cuando Júpiter está en su cenit en el cielo de medianoche de Ceres (cosa que acontece cada siete años y medio) está a una distancia de 320 millones de kilómetros. Brilla entonces con una magnitud de -4,1 y es casi tan brillante como Venus desde la Tierra en los momentos de su máxima luminosidad. Durante un año aproximadamente de cada vez, Júpiter es el objeto más brillante en el cielo de Ceres, exceptuando el Sol, naturalmente.

En su máxima luminosidad Saturno tendrá una magnitud de -1,3 y también será más brillante que cualquiera de las estrellas matutinas/ vespertinas de Ceres. Se encontrará en su máxima luminosidad durante un período de varios meses cada cinco años y medio.

Sin embargo, cuando lleguemos a los planetas situados más allá de Saturno apenas vale la pena molestarse. No están mucho más cerca de Ceres que de la Tierra. Ceres puede estar 240 millones de kilómetros más cerca de cualquier planeta exterior que la Tierra, pero 240 millones de kilómetros no es mucho cuando uno está barajando distancias de miles de millones de kilómetros.

Urano, que tiene un brillo máximo equivalente a una magnitud de 5,7 cuando es visto desde la Tierra, parecerá alcanzar, a intervalos de cinco años, un brillo de 5,1 visto desde Ceres. Este brillo adicional se debe más a la falta de aire de Ceres que a la mayor cercanía de Urano. Urano sería divisado desde Ceres como una estrella difusa, pero igual ocurre desde la Tierra.

En cuanto a Neptuno y Plutón, serían tan invisibles (sin instrumentos) desde Ceres como desde la Tierra.

¿Alguna otra cosa de interés en los cielos de Ceres? ¿Y los satélites de los planetas? Si nuestra Luna estuviese sola en el cielo de Ceres (habiéndose puesto ya la Tierra o no habiendo salido aún), podría tener un brillo máximo equivalente a una magnitud de 4,7. Parecería más brillante que Urano y podría discernirse como una débil estrella vespertina/ matutina. Desgraciadamente, la Tierra está en su vecindad, y ambas no se separan nunca más de 5’ de arco, vistas desde Ceres. La luminosidad setenta veces superior de la Tierra sepulta a la Luna, que probablemente no podría discernirse a simple vista.

El destino de la Luna vista desde Ceres es precisamente el de los satélites de Júpiter vistos desde la Tierra. Los cuatro grandes satélites de Júpiter -Io, Europa, Ganímedes y Calixto- tienen magnitudes de 5,3, 3,7, 4,9 y 6,1, respectivamente. Serían observables a simple vista como objetos difusos si Júpiter no estuviese presente con un fulgor 3.000 veces más potente.

Desde la Tierra, la máxima separación de esos cuatro satélites con respecto a Júpiter varía de 1' de arco para Io a 10' de arco para Calixto. Desgraciadamente, Calixto, el satélite más lejano y por eso el de más probable visión a través del destello de Júpiter, es también el de brillo más débil. En consecuencia, los grandes satélites de Júpiter no son visibles a simple vista, aunque basta una pequeña ayuda para conseguirlo; fueron fácilmente detectados con el telescopio original y muy primitivo de Galileo.

Desde Ceres, los satélites de Júpiter son a la vez más brillantes y más distantes de su planeta. La magnitud de los cuatro satélites vistos desde Ceres es de 3,7 para Io, 4,1 para Europa, 3,3 para Ganímedes y 4,5 para Calixto. Cualquiera de ellos, solitario en el cielo, sería fácilmente visible como objeto de brillo medio.

Su máxima separación de Júpiter, vistos desde Ceres, variaría entre 2' de arco para Io y 18' para Calixto. Creo, por tanto, que cabría discernir a Calixto, porque estaría separado de Júpiter nada menos que por 3/5 partes de la anchura de la Luna llena vista desde la Tierra. Ganímedes nunca se separaría de Júpiter más de 10' de arco, pero también sería visible como un objeto de tercera magnitud.

Naturalmente, los dos satélites sólo serían visibles bajo condiciones favorables: cuando Júpiter está en (o cerca de) su momento de máxima aproximación a Ceres, y cuando Ganímedes y Calixto están en su momento de máxima separación de él.

Me atrevo incluso a aventurar que una de las principales vistas recomendadas a los turistas en estaciones apropiadas serían los satélites de Júpiter. No sería una vista espectacular, pero incluso en Ceres sería poco corriente, e imposible del todo desde la Tierra.

6. El reloj del cielo

Hace años, en una fiesta, me presentaron a un tipo espigado, de pelo rebelde y rostro afilado. Las palabras de la presentación fueron: «John Updike – Isaac Asimov.»

Me puse a pensar furiosamente. En la presentación no había indicios para determinar si era él, John Updike, el escritor. De serlo, sentía que lo mejor era decir algo apropiadamente modesto, como conviene a un escritor de segunda fila cuando saluda a otro de primera. Pero si se trataba de algún otro John Updike, de un vendedor de coches de segunda mano, por ejemplo, sería absolutamente embarazoso dar luego marcha atrás.

Updike (que era él, el escritor) no tenía, naturalmente, semejante problema; cualquiera que lleve el nombre de Isaac Asimov tiene que ser el escritor. Así, mientras yo proseguía con mis vacilaciones, dijo con una clara nota de asombro en la voz:

–Dígame, ¿cómo escribe usted todos esos libros?

Me quedé con la penosa sensación de haberle dejado hacer el primer avance a causa de mi arrogancia. Nada de cuanto pude hacer después sirvió.

Resolví que la próxima vez que me encontrara con un escritor famoso sería yo el primero en hacer el comentario humilde de rigor. Tres días después, sólo tres, vi a Max Shulman, el humorista, en otra fiesta. Nunca me lo habían presentado, pero lo reconocí por fotografías suyas que había visto.

Me apresuré a ir hacia él y con humildad congraciadora empecé a decir:

–Señor Shulman, ¿puedo presentarme? Mi nombre es Isaac Asi…

Y él, con una clara nota de asombro en la voz:

–Dígame, ¿cómo escribe usted todos esos libros?

Abandoné. Quiero ser humilde, pero el mundo no me deja… y además me hace siempre la misma pregunta.

En ciencia, la pregunta que me hacen más a menudo, una y otra vez, en persona, por teléfono, por carta, es:

–¿Cómo puede estar usted seguro de que las cosas no pueden sobrepasar la velocidad de la luz?

Pues bien, he contestado esta pregunta en diversos lugares muchas veces, y no volveré aquí sobre ella. Las explicaciones previas no han logrado acabar con la pregunta, y una más tampoco lo conseguirá.

Abordaré, en cambio, otro aspecto de la cuestión. ¿Cómo fue determinada la velocidad de la luz? O mejor, ¿qué hizo pensar a las gentes que la luz tenía una velocidad definida?

Si en la Antigüedad las personas llegaron a pensar alguna vez en el concepto de la velocidad de la luz, debió de ser con la sensación de que era infinita. Si aparecía luz, aparecía en todas partes inmediatamente. Cuando las nubes se abrían y el sol atravesaba el velo que antes escondía su gloria, uno no veía a la luz abriéndose camino hacia abajo por la avenida de la atmósfera, golpeando primero el pico de una montaña y rodando por la ladera como un torrente de agua. Alcanzaba el valle tan pronto como la cumbre.

Lo que tuvo que conmover en primer lugar el concepto de la infinita velocidad de la luz fue el asunto del sonido. Luz y sonido eran las dos grandes avenidas al mundo externo. El ojo veía y el oído escuchaba, y nadie dudaba de que tanto el sonido como la luz hacían honestamente su trabajo. Si uno veía algo a lo lejos, ese algo estaba realmente en el lugar donde se veía en el momento de divisarlo. Si se escuchaba algo a distancia, ese algo estaba realmente en el lugar donde se escuchaba en el momento de oírlo.

A distancias moderadas lo anterior era bastante cierto para cualquier propósito práctico, pero al aumentar la lejanía perdían comba ambos sentidos. El sonido sufría un retraso. Si uno observaba a un hombre cortando madera, por ejemplo, la visión del contacto de hacha y madera y el sonido de ese contacto debieran llegar juntos, y así sucedía estando cerca. Pero a cierta distancia el sonido llegaba después de la visión, y cuanto mayor la distancia, mayor el retraso.

Con eso sólo quedaba ya claro que, fuese o no infinita la velocidad de la luz, la del sonido no lo era. El sonido tardaba tiempo en viajar, y eso era plenamente claro para los sentidos. Y si el sonido viajaba a una velocidad finita, ¿por qué no la luz?

La velocidad del sonido, aunque no infinita, tenía que ser muy grande. En el lapso entre la visión de una acción distante y su respectivo sonido ningún material conocido por los hombres de la era preindustrial podía cubrir la distancia. El sonido viajaba, evidentemente, a cientos de kilómetros por hora.

(Sólo alrededor de 1738 fue medida con precisión aceptable la velocidad del sonido. Científicos franceses emplazaron cañones sobre dos colinas separadas unos 27 kilómetros. Dispararon el cañón de una de las colinas y midieron el intervalo entre fogonazo y sonido en la otra. Luego dispararon el otro cañón y midieron el mismo intervalo desde el otro lado. Ambos intervalos fueron promediados para así cancelar el efecto del viento, pues se sabía que el sonido era transportado por los movimientos de moléculas de aire. Conocida la distancia entre los cañones y medido el lapso temporal, podía calcularse la velocidad del sonido. La velocidad del sonido en el aire a 0º C -pues la velocidad aumenta con la temperatura y es diferente en otros medios- resulta ser de 1.191,6 kilómetros por hora, o 331 metros por segundo.)

Puesto que el sonido se rezagaba muy por detrás de la luz, era claro que ésta debía viajar a velocidades muy superiores a ese millar corto de kilómetros por hora. Pero, por lo mismo, tenía que ser mucho más difícil de medir que la del sonido.

En un alarde de arrojo superior a todo sentido del deber, el científico italiano Galileo intentó medir la velocidad de la luz a principios del siglo XVII.

El método que utilizó fue el siguiente:

Galileo se encaramó sobre un promontorio, al tiempo que un ayudante ocupaba otro situado aproximadamente a una milla. Ambos llevaban linternas cubiertas. La idea era que Galileo descubriría la suya. Tan pronto como el ayudante viera el destello de luz descubriría la propia.

Galileo razonaba así. Al descubrir su luz, el rayo tardaría cierto tiempo en llegar al otro pico. Cuando lo hiciera, el ayudante descubriría su luz, que volvería a tardar cierto tiempo en llegar hasta Galileo. El tiempo entre el momento en que Galileo descubriera su linterna y el momento en que viera la luz de su ayudante representaría el tiempo que tardó la luz en viajar de una elevación a la otra y volver.

Conociendo la distancia entre los promontorios y midiendo el lapso temporal, Galileo pensaba estar en condiciones de poder calcular la velocidad de la luz.

Efectivamente hubo un lapso temporal, y por un momento las cosas parecieron prometedoras; pero Galileo probó entonces con otras distancias, esperando que el lapso temporal se incrementaría en proporción a la lejanía, y no fue así. Permaneció idéntico, fuese corta o larga la distancia entre las linternas. Y podríamos apostar a que si Galileo y su ayudante se hubiesen encontrado a dos metros el uno del otro habría habido exactamente el mismo lapso temporal, entre el destello de Galileo y su visión del ayudante, que cuando estuvieran a una milla, o a 10.000.

Era claro que el intervalo de tiempo que estaba midiendo Galileo no representaba el tiempo que tardaba la luz en viajar de A a B y vuelta a A, sino sólo el tiempo que tardaba el ayudante en percatarse del destello y en hacer que sus músculos se moviesen para producir el destello de retorno. Galileo estaba midiendo la velocidad de reacción humana, y no la velocidad de la luz.

Del hecho de que no había variación en el lapso temporal con la distancia, Galileo hubo de concluir que el tiempo que tardaba el rayo de luz en su viaje no contribuía perceptiblemente al resultado. La velocidad de la luz no podía medirse de este modo, porque era muy superior a la del sonido. La velocidad de la luz podía incluso ser infinita, a juzgar por los experimentos de Galileo.

Si la luz viajaba muy aprisa, aunque su velocidad no fuese infinita, entonces podría ser que ninguna distancia terrestre bastara para producir un retraso perceptible en la propagación luminosa. Pero sí, quizá, las distancias siderales. Si alguien pudiera subirse al cielo (en vez de a una colina) y apagar y encender una estrella cuando se le ordenara, el intervalo entre la orden y el ver a la estrella encenderse (o apagarse) representaría el tiempo que tardó la luz en hacer el viaje de ida y vuelta.

¡Bravo por la brillante idea! En tiempos de Galileo nadie sabía a qué distancia se encontraba ningún cuerpo celeste (excepto la Luna). Y aun conociendo las distancias de los cuerpos celestes, nadie podía alcanzarlos (ni siquiera la Luna). Y aunque alguien pudiera alcanzarlos, ¿cómo comunicarse a tan largas distancias y dar la orden de encender una estrella? E incluso aceptando la posibilidad de que alguien pudiera comunicarse, ¿cómo podría encender una estrella o apagarla?

¡Cosas de lunático!

Lo bueno es que fue eso (o casi eso) lo que sucedió exactamente. La velocidad de la luz fue determinada por primera vez por un método que era precisamente análogo a encender y apagar una estrella como señal. Todo empezó con un descubrimiento de Galileo. Y, en efecto, fue cosa de lunas [12].

Vayamos primero con el descubrimiento de Galileo:

En 1609 había oído rumores de que en la lejana Holanda alguien había colocado lentes en ambos extremos de un tubo hueco y logrado hacer que cosas distantes pareciesen más próximas, Galileo no necesitaba más. En un abrir y cerrar de ojos construyó un artefacto similar, un telescopio.

Sin demora apuntó a los cielos. Vio montañas sobre la Luna y manchas en el Sol, y muchedumbres de estrellas, antes invisibles, en las constelaciones.

El 9 de enero de 1610 miró a Júpiter; a través del telescopio parecía más un pequeño globo que un mero punto luminoso. Cerca de él, a cada lado y en la misma línea recta, había tres objetos pequeños con forma de estrellas. El 13 de enero divisó un cuarto.

Los contempló noche tras noche, y comprobó que cada uno de ellos se movía hacia atrás y hacia adelante de un lado de Júpiter al otro, moviéndose cada cual una distancia fija hacia cada lado. Imposible pasar por alto lo que estaba viendo. Júpiter era circundado por cuatro cuerpos más pequeños, cada uno en su propia órbita. Y las cuatro órbitas se veían casi de canto desde la Tierra.

Galileo anunció inmediatamente su descubrimiento, y el astrónomo alemán contemporáneo Johannes Kepler llamó «satélites» a los pequeños cuerpos que circundaban a Júpiter. Tomó la palabra del término latino satelles, que, entre otras cosas, designaba al haragán que revolotea alrededor de un rico, halagándole para ser invitado a sus festines.

Los cuatro satélites fueron bautizados con nombres de personajes de los mitos griegos estrechamente vinculados a Júpiter (o Zeus, para ser más precisos). En orden de distancia creciente desde Júpiter eran lo, Europa, Ganímedes y Calixto. Los nombres fueron sugeridos por un astrónomo alemán, Simon Marius, que pretendía haber visto los satélites antes que Galileo. La reivindicación de Marius fue desechada, pero se conservaron sus nombres.

El descubrimiento de Galileo fue importante por dos razones. En primer lugar, suponía encontrar nuevos miembros del sistema solar, miembros desconocidos para los antiguos; y eso nunca había ocurrido hasta entonces. Bastó aquello para derribar la idea, arraigada en el mundo intelectual de la época, de que los filósofos griegos habían llevado a sus últimos extremos todo conocimiento.

Tampoco faltaban, entre la gente culta de principios del XVII, quienes se negaban a apearse de la idea, tan antigua, de que todos los cuerpos celestes, sin excepción, giraban alrededor de la Tierra. Había aquí cuando menos cuatro cuerpos que clara y visiblemente giraban en torno a un objeto distinto de la Tierra. Giraban en torno a Júpiter.

El único modo de negarlo era rehusar la observación, y algunos grandes pensadores de la época fue eso lo que hicieron. Se negaron a mirar a través del telescopio, razonando que si los satélites no habían sido mencionados por Aristóteles es que no estaban allí, y que el buscarlos no haría otra cosa que perturbar la mente.

En tiempos de Galileo no había métodos decentes para medir con precisión intervalos de tiempo. Fue en 1656 cuando el científico holandés Christian Huygens diseñó un método para conseguir que las manecillas de un reloj fuesen movidas por el movimiento uniforme de las oscilaciones de un péndulo.

(El principio del reloj era el descubrimiento, hecho medio siglo antes, de que un péndulo oscila con una periodicidad uniforme, independiente en cierta medida de la amplitud de la oscilación. Este hallazgo fundamental fue hecho por quien ya sabéis [13])

El reloj de péndulo inventado por Huygens fue el primer aparato del cual cabía esperar que midiera el tiempo con precisión de minutos e indefinidamente.

¿O no? ¿Qué seguridad había?

Hasta hace bastante poco la humanidad dependía, para la determinación última del tiempo, de los movimientos periódicos celestes. Había la rotación de la Tierra en relación con el Sol (el día), la revolución de la Luna en torno a la Tierra con respecto al Sol (el mes) y la revolución de la Tierra en torno al Sol (el año).

De todas estas periodicidades la más breve era el día, y para cualquier cosa inferior a él no había nada en los cielos que pudiera servir de cotejo definitivo.

Pero ¿qué ocurriría sí mediante el telescopio se descubriera un período celeste nuevo y más breve? Los movimientos celestes, al no deberse a la mano del hombre serían sin duda completamente exactos, e incluso los mejores relojes humanos, incluso el reloj de péndulo de Huygens, cabría cotejarlos provechosamente con ellos.

Los cuatro satélites de Júpiter parecían venir como anillo al dedo. Io, Europa y Ganímedes pasaban por detrás de Júpiter en cada revolución, puesto que las órbitas se veían casi de canto. Calixto, el más alejado de los cuatro, podía verse a veces sobre o por debajo del globo de Júpiter al pasar por detrás de él, pero por lo general estaba eclipsado.

Io era eclipsado 1 3/4 días, Europa cada 3 1/2, Ganímedes cada 7 1/7 y Calixto cada 16 2/3. El momento del eclipse podía ser detectado con gran precisión, y como los momentos estaban separados por intervalos irregulares, podían obtenerse medidas de todo tipo de períodos temporales desde un día y tres cuartos hasta unos pocos minutos.

Utilizando los mejores instrumentos disponibles, se midieron los intervalos entre eclipses sucesivos de los distintos satélites, y tomando eso como punto de partida y utilizando todo tipo de refinamientos a la hora de hacer el cómputo, se calcularon los tiempos de eclipses para cada uno.

Hecho lo cual, había poderosas razones para pensar que el cielo brindaba un reloj muy preciso para períodos de tiempo breves. Cualquier reloj que se utilizara cabía siempre comprobarlo frente a la configuración de los satélites, y adelantarlo o atrasarlo un poco de acuerdo con lo indicado por las cuatro manecillas del reloj de Júpiter. Sólo que entonces empezaron a suceder cosas muy peculiares. El reloj planetario adelantaba (poco, pero sistemáticamente), para luego, tras varios meses, empezar a atrasar de nuevo. Contemplado durante el tiempo suficiente, adelantaba, perdía, adelantaba y perdía en un período lento pero muy regular. Y ello pese a que se hicieron y rehicieron observaciones muy cuidadosas de los satélites, así como meticulosos cálculos de los futuros eclipses. Los relojes persistían en ese alternar, lento y regular de adelantos y atrasos. Es más, si había varios relojes, todos ellos adelantaban y atrasaban simultáneamente, aunque desde cualesquiera otros criterios no parecían ni adelantar ni atrasar.

En 1675, fecha en que el astrónomo ítalo-francés Giovanni Domenico Cassini había hecho ya observaciones de los satélites de Júpiter con precisión sin precedentes, sólo podía concluirse que el reloj del cielo no era de fiar. Sí uno promediaba los intervalos entre eclipses y tomaba esa media como norma, resultaba que los eclipses a veces se adelantaban y a veces se retrasaban unos cuantos minutos. Pasaban de madrugadores a remolones (y viceversa) de un modo gradual y periódico, y nadie sabía por qué.

Hasta que en 1675 el astrónomo danés Claus Roemel estudió el problema.

En 1619, Kepler había elaborado un modelo preciso del sistema solar, con todas las órbitas planetarias en su lugar. Los astrónomos habían aprendido a manejar el modelo, y Roemer conocía muy bien las posiciones relativas de la Tierra y Júpiter en cualquier momento dado. Roemer utilizó las observaciones y cálculos de Cassini y decidió emparejar los eclipses con las posiciones planetarias.

Resultó que los eclipses se adelantaban al máximo cuando la Tierra y Júpiter se encontraban al mismo lado del Sol y distaban lo mínimo entre sí.

Estando más cerca del Sol que Júpiter, la Tierra se mueve mucho más aprisa en su órbita que él. Por tanto, adelanta a Júpiter y, curvándose en su órbita, se aleja de él. Y a medida que la distancia entre Júpiter y la Tierra crece, se retrasa más y más la detección de los eclipses de los satélites.

Los eclipses sufren un retraso máximo cuando la Tierra y Júpiter se encuentran en lados directamente opuestos del Sol y a su máxima distancia. (Naturalmente, cuando la Tierra y Júpiter se hallan a lados opuestos del Sol, Júpiter está demasiado cerca del Sol en el cielo terrestre para ser observado. Sin embargo, los resultados de las observaciones de Júpiter cuando sí es visible no dejaban para Roemer ninguna duda de lo que estaba aconteciendo mientras aquél se ocultaba en la vecindad del fuego solar.)

A medida que la Tierra sigue luego galopando y empieza a aproximarse de nuevo a Júpiter, la detección de los eclipses empieza a adelantarse.

En resumen: cuando la Tierra se encuentra a máxima distancia de Júpiter, el momento del eclipse era, según los cálculos de Roemer, veintidós minutos posterior al momento del eclipse cuando la distancia era mínima.

Roemer entrevió una posible solución. Supongamos que la luz viajase a una velocidad muy alta pero finita. Al pasar un satélite por detrás de Júpiter, su luz se cortaría, pero un observador terrestre no vería instantáneamente ese corte (como sería el caso de ser infinita la velocidad de la luz). El rayo de luz continúa viajando hacía la Tierra a velocidad finita, y no es sino cierto tiempo después del momento del eclipse cuando el corte alcanza al observador y se desvanece la luz del satélite.

Cuando Júpiter y la Tierra se encuentran más cerca, la luz de Júpiter y de sus satélites tiene sólo que viajar hasta el punto más próximo de la órbita terrestre. Cuando Júpiter y la Tierra se encuentran más alejados, en lados opuestos del Sol, la luz de Júpiter ha de viajar primero hasta el punto más próximo de la órbita terrestre y luego recorrer además toda la anchura de la órbita hasta alcanzar la posición de la Tierra en el punto alejado.

Si la luz tarda veintidós minutos aproximadamente en recorrer toda la anchura de la órbita terrestre, la conducta de los eclipses de los satélites de Júpiter queda explicada. Basta tener en cuenta la velocidad finita de la luz para que todo cuadre; los eclipses llegan puntuales, ni demasiado pronto ni demasiado tarde.

La cuestión es: ¿a qué velocidad debe viajar la luz para recorrer la anchura de la órbita terrestre en veintidós minutos?

Cuando Kepler proyectó su modelo del sistema solar no conocía la escala. No conocía ninguna de las distancias interplanetarias. De haber conocido una -sólo una-, habría podido calcular el resto. Pero no la conocía.

Sin embargo, Cassini había logrado determinar en 1671 la paralaje de Marte. Con ese dato calculó la distancia de Marte a la Tierra en aquel momento. De ahí, y de la posición relativa de la Tierra y Marte en el modelo de Kepler en ese instante, que era también conocida, logró calcular todas las demás distancias planetarias.

La medición de la paralaje de Marte hecha por Cassini era levemente imprecisa (aunque un trabajo magnífico para ser la primera vez); sus cálculos estimaban la distancia media de la Tierra al Sol en 140 millones de kilómetros. La anchura total de la órbita terrestre (de un punto de ella al Sol y luego a un punto del lado opuesto) era el doble de esa cifra, es decir, 280 millones de kilómetros.

Si la luz lograba cruzar 280 millones de kilómetros en veintidós minutos, tenía que viajar a una velocidad levemente superior a los 212.000 kilómetros por segundo.

Cálculo también excelente para ser el primero. Desde la época de Cassini hemos ido refinando las mediciones de la escala del sistema solar. Sabemos que la distancia media entre la Tierra y el Sol está un pelo por debajo de 150 millones de kilómetros, y sabemos también que la luz cruza la órbita terrestre en algo más de dieciséis minutos, no veintidós. Asimismo, sabemos que la velocidad de la luz es 299.728 kilómetros por segundo. Con todo, y habida cuenta del estado de la ciencia en tiempos de Roemer, es justo celebrar su cifra con todos los honores.

Cuando pensamos en la velocidad de la luz, que es casi un millón de veces la velocidad del sonido, vemos por qué fracasó el valiente intento de Galileo. El tiempo que tarda la luz en recorrer cualquier distancia terrestre es lo suficientemente minúsculo como para ignorarlo. La luz (o cualquier otra cosa que viaje a la misma velocidad, como por ejemplo las ondas de radio) tarda menos de un dieciseisavo de segundo en ir desde Nueva York a Los Angeles.

Sin embargo, para distancias superiores a las de la Tierra el lapso temporal se hace perceptible. La luz tarda entre 1,28 y 1,35 segundos en llegarnos desde la Luna (según en qué parte de la órbita esté la Luna y cuál sea su distancia). Y aproximadamente, como he dicho, la luz emplea una medía de 8,3 minutos en alcanzar la Tierra desde el Sol, y 16,6 minutos en cruzar toda la anchura de la órbita terrestre.

La velocidad de la luz, aunque parezca increíblemente grande por los patrones habituales comienza a adquirir un aura de finitud cuando se consideran distancias aún mayores. La luz emplea más de cinco horas en viajar desde el Sol a Plutón, más de cuatro años desde Alfa Centauri a nosotros, y más de mil millones de años desde el quasar más próximo hasta nosotros.

Considerando que la velocidad de la luz se sabe hoy que es una constante fundamental del universo, es penoso tener que informar que su primer anuncio no creó gran emoción y produjo reacciones encontradas. Roemer anunció su cálculo de la velocidad de la luz en una reunión de la Academia de Ciencias en París, en 1676.

Huygens quedó gratamente impresionado, igual que Isaac Newton. No así el influyente Cassini. Se habían utilizado sus observaciones y cálculos, pero él siguió en sus trece. Cassini rayaba en un conservadurismo patológico, y el trabajo de Roemer se le antojaba excesivo.

Bajo el peso de la oposición de Cassini, el cálculo de Roemer sobre la velocidad de la luz desapareció de la conciencia astronómica durante medio siglo.

Luego, en 1728, el astrónomo inglés James Bradley calculó la velocidad de la luz con otro tipo de observación astronómica completamente distinto. Aunque ambos métodos eran del todo independientes, la cifra de Bradley era del mismo pelaje que la de Roemer, acabando así con el olvido.

Roemer ocupó su nicho en la historia de la ciencia, y desde entonces no se le perdió de vista.

…Pero ahora, antes de despedirme, quisiera señalar dos cosas:

1) El método de Roemer para determinar la velocidad de la luz era casi una repetición cósmica del experimento de Galileo, y realizó lo que, en broma, sugerí antes como imposible. Una estrella, o mejor dicho los puntos con forma estelar de los satélites, eran encendidos y apagados; no por ningún artefacto humano, desde luego, sino por Júpiter y por los hechos de la mecánica celeste; lo cual sirvió igual de bien. Y la idea era «lunática» porque fue la luz de las lunas de Júpiter la que consiguió el truco.

2) Aunque la velocidad de la luz es casi un millón de veces la velocidad del sonido, lo que se determinó en primer lugar fue la velocidad de la luz, y con un adelanto de sesenta años.

C) Sobre el carbono

7. Uno y el único

Estos ensayos pueden complicarme la vida. El escribir sobre cualquier tema que elija hace que parezca una autoridad en cualquier materia. Hace un par de años toqué por ejemplo el tema de la astrología en uno de mis artículos. La consecuencia fue que al punto me identificaran con un experto en el tema, y con un experto que no tenía miedo de hablar claro en contra de la astrología (algo por lo visto no fácil de encontrar).

Hace cosa de un mes invadió mi despacho un periodista, sacó un magnetófono, lo puso en marcha y procedió a hacerme preguntas. Consentí, y hablé bastante enérgicamente sobre el tema del racionalismo y el misticismo, poniéndome del lado del racionalismo, como mis Amables Lectores no ignoran.

Cuando hubimos terminado y el periodista estaba recogiendo, dije impulsivamente:

–Le daré un ejemplo práctico de la diferencia entre misticismo y racionalismo. Un místico aceptaría el hecho de que ese pequeño objeto ha grabado nuestras voces solamente porque usted lo dice. Un racionalista diría: «Déjeme oír las voces antes de creerlo.»

El periodista sonrió y dijo:

–He grabado cientos de entrevistas, y este aparato jamás me ha fallado.

–No lo dudo -dije-, pero, sólo para burlarnos de mi racionalismo, reproduzca la conversación y comprobémoslo.

Con la sonrisa en la cara, accionó una tecla. Había hecho algo mal; del aparato no salió ninguna voz. (Os juro por lo que más queráis que la historia es cierta.)

El periodista estaba molesto, qué duda cabe, pero ni la décima parte que yo. De haberlo dejado marchar, se habría ido a casa y no habría descubierto el desastre hasta varios días después, demasiado tarde para hacer nada. Pero ahora, y en castigo a mi vacuo deseo de mostrar mi gran racionalidad, hube de someterme por segunda vez a toda la entrevista.

Bueno, el caso es que quedó bastante bien.

El incidente me llevó a pensar lo místicos que son incluso los racionalistas. Es imposible verificar todo personalmente; es imposible cerciorarse de que nuestro propio cerebro entiende todas y cada una de las cosas. Muchas de ellas, a falta de mejor proceder, hemos de aceptarlas por pura fe, y a veces repetimos ciertos tópicos tan a menudo que se tornan incuestionables.

Y entonces -como en el caso del magnetófono que no había fallado nunca en cientos de entrevistas- resulta divertido ponerlos en cuestión de cuando en cuando.

Los químicos, por ejemplo, dividen la química en dos secciones: «orgánica» e «inorgánica»; la primera se ocupa de compuestos que contienen el átomo de carbono, y la segunda de compuestos que contienen cualquiera de las otras 104 clases de átomos, excluyendo sólo el de carbono.

¿No es una división extrañamente desigual? Sí, lo es; pero no por lo que podría parecer.

En realidad, hay más moléculas que incluyen el átomo de carbono, muchas más, que de los restantes 104 elementos combinándose entre ellos de cualquier modo concebible y con la única restricción de evitar el átomo de carbono.

Y cualquier descubrimiento adicional no hará sino incrementar aún más la desproporción en favor del carbono.

Además, los compuestos que contienen carbono, algunos con moléculas pequeñas (que en algunos casos poseen las características de moléculas inorgánicas), otros con moléculas medias, otros con moléculas grandes y otros aún con moléculas gigantes, son la base de la vida (motivo por el cual se denominan «orgánicos»).

Aquellos de entre nosotros que no son químicos puede que hayan oído esto, y en tal caso habrán tenido que aceptarlo sin más. Los átomos de carbono pueden formar cadenas y anillos de todos los tamaños y complejidades, y sobre este hecho descansa la complejidad y versatilidad de la vida. Admitido.

Pero el carbono ¿es de veras el único elemento con átomos capaces de combinarse en compuestos lo bastante variados, lo bastante complejos, lo bastante delicados y lo bastante versátiles como para poseer las sorprendentes propiedades que asociamos con la vida? ¿No podría hacerlo también algún otro elemento, quizá con una ayudita? ¿Cómo es que el carbono es tan diferente de todos los demás elementos?

Buena pregunta. Pasemos al tema.

Hay 105 elementos en total, cada uno con su propia variedad de átomos. La pregunta es cuáles de esos 105 diferentes tipos de átomos pueden formar cadenas y anillos de todo tipo, grandes y pequeños, lo bastante versátiles como para constituir la base de la vida.

¿Podemos eliminar a alguno de antemano?

Para empezar, podemos eliminar todos los elementos que carecen de isótopos estables y sólo poseen átomos radiactivos. Porque si suponemos que los átomos radiactivos se conectan en cadenas y anillos, esas cadenas y anillos no pueden en ningún caso sobrevivir. Antes o después uno de los átomos emitirá una partícula muy energética. Lo que queda del átomo retrocederá energéticamente y romperá cualquier cadena o anillo del cual forme parte. Es difícil ver cómo podría construirse la vida sobre moléculas que cambian al azar y a intervalos aleatorios.

Esto suprime 24 elementos de la lista de posibles y deja sólo 81 elementos estables; 81 elementos, entiéndase, que incluyen por lo menos un isótopo no radiactivo, cuyos átomos pueden quizá formar cadenas y anillos.

Sin embargo, resulta que de los 81 elementos, cinco (los gases nobles: helio, neón, argón, kriptón y xenón) están hechos de átomos que no se unen entre sí en ninguna circunstancia [14]. En forma elemental los gases nobles existen en tanto que átomos, y por tanto los eliminamos. Lo cual nos deja 76 elementos estables distintos de los gases nobles, que siguen siendo candidatos a la base de la vida.

Los átomos de esos 76 elementos pueden vincularse entre sí compartiendo electrones unos con otros. La naturaleza de esa compartición depende de cuántos electrones tenga disponibles un átomo para donarlos al fondo compartido, y de cuánto espacio tenga cada átomo para aceptar lotes de electrones. Muchos tipos de átomos tienen muy pocos electrones que donar, pero apetito para aceptar, muchos. En tales condiciones la situación más estable para el elemento es aquella en que se agrupan gran cantidad de átomos con el fin de poder compartir los pocos electrones disponibles. Tenemos entonces una disposición ordenada de átomos, con unos cuantos electrones moviéndose casi libremente de un átomo a otro y proporcionando a cada uno de ellos una pequeña participación de sí mismos.

La presencia de esos electrones móviles hace posible que un conglomerado de átomos de ese elemento conduzca corriente eléctrica y calor con gran facilidad. También confiere al elemento otras propiedades que asociamos con los metales. Y es que cualquier elemento compuesto de átomos que tiendan a compartir unos cuantos electrones móviles es un metal.

Para compartir los electrones móviles, los átomos de un metal deben apilarse muy juntos; se dice entonces que se mantienen unidos mediante un «enlace metálico».

El enlace metálico puede, en efecto, ser poderoso; hace falta mucha energía para separar los átomos de un metal contra la resistencia que conlleva el deseo de permanecer próximos a los electrones móviles. El modo más fácil de añadir energía a los átomos es elevar su temperatura, y una medida de la tenacidad con que se aferran entre sí los átomos es el punto de ebullición: la temperatura a que los átomos son desgarrados y enviados a tropezones al movimiento independiente de un gas. El tungsteno tiene un punto de ebullición de 5.927º C, el más elevado de todos los elementos. La superficie del Sol está justo lo bastante caliente para mantener al tungsteno en estado gaseoso.

Sin embargo, el enlace metálico funciona óptimamente allí donde muchos átomos se aferran entre sí. Dicho enlace proporciona el equivalente de moléculas gigantes, pero no de moléculas pequeñas, y el tejido vivo necesita tanto moléculas pequeñas como grandes. Prescindamos, pues, de todos los elementos metálicos.

Esto representa una gran reducción de las posibilidades, porque elimina 58 elementos y nos deja con los 18 no metales estables (excluidos ya los gases nobles) a título de candidatos para servir como base de la vida.

En esos 18 elementos la capacidad para donar electrones y la aptitud para recibirlos están bastante equilibradas. Dos átomos de un elemento tal pueden donar cada uno un electrón para formar un fondo común de dos electrones a compartir por ambos. La participación en ese fondo común resulta en una estabilidad mayor que la que se produciría si los dos átomos se moviesen independientemente. Para mantener el fondo compartido, los átomos han de permanecer muy próximos; el resultado es un «enlace covalente».

El modo más simple de representar el enlace covalente es situar un guión entre los símbolos de los elementos a que pertenecen los átomos: X-X.

Según el número y la disposición de los electrones que poseen, los átomos pueden formar un número variable de enlaces covalentes con otros átomos. Algunos sólo pueden formar uno; otros, dos; otros, tres, y algunos hasta cuatro. Entre los 18 elementos con que estamos aún tratando existen representantes de todas esas clases, y son enumerados en la tabla 1. En cada clase los elementos se enumeran en orden de creciente peso atómico.

TABLA 1

NO METALES ESTABLES CAPACES DE FORMAR ENLACES COVALENTES

1 enlace 2 enlaces 3 enlaces 4 enlaces

Hidrógeno Oxígeno Boro Carbono

Flúor Azufre Nitrógeno Silicio

Cloro Selenio Fósforo Germanio

Bromo Telurio Arsénico Estaño

Yodo Antimonio

(Quizá observen que algunos de los elementos de la Tabla 1 se consideran comúnmente metales: el estaño, por ejemplo. Sin embargo, en la Naturaleza no hay fronteras, y el estaño tiene también propiedades no metálicas muy marcadas.)

Consideremos los elementos que forman un solo covalente; el hidrógeno, por ejemplo. Dos átomos de hidrógeno, representado cada uno por el símbolo químico H, pueden vincularse así: H-H.

Allí donde sólo hay átomos de hidrógeno, no hay ninguna otra posibilidad. Cada átomo de hidrógeno en la combinación H-H ha gastado su único enlace covalente y no puede formar ya enlaces con ningún otro átomo. Lo cual significa que si reunimos una gran masa de átomos de hidrógeno en condiciones normales de temperatura y presión, se emparejarán en combinaciones bi-atómicas, o moléculas de hidrógeno, muy a menudo simbolizadas simplemente como H2. Pero ahí se acaba la cosa.

Las moléculas de hidrógeno se mantienen unidas por atracciones muy débiles llamadas «fuerzas de Van der Waals», el físico holandés que las estudió en detalle por primera vez. Esas fuerzas son suficientes para mantener unidas a las moléculas y conservar el hidrógeno líquido o incluso sólido; pero sólo a temperaturas muy bajas. Incluso a una temperatura tan baja como -253º C (sólo veinte grados por encima del cero absoluto) hay suficiente intensidad de calor para contrarrestar las fuerzas de Van der Waals y hacer que las moléculas de hidrógeno evolucionen independientemente en forma gaseosa. O lo que es lo mismo, – 253º C es el punto de ebullición del hidrógeno líquido.

No cabe esperar, pues, que los átomos de hidrógeno formen por sí solos ninguna cadena de más de dos átomos. Por muy importantes que sean los átomos de hidrógeno para la vida, no pueden formar el esqueleto de moléculas complejas… por lo cual eliminamos el hidrógeno.

La situación es en realidad idéntica para cualquier átomo de un solo enlace. Flúor, cloro, bromo y yodo son elementos que forman moléculas biatómicas y nada más: F2, Cl2, Br2 e I2.

Claro que cuanto mayor sea la masa de la molécula, mayores serán (en general) las fuerzas de Van der Waals existentes entre ellas, y más elevado el punto de ebullición. Así, la molécula de flúor tiene 19 veces la masa de la molécula de hidrógeno, y el flúor líquido tiene por lo mismo un punto de ebullición de -188º C, 65º más alto que el del hidrógeno. El cloro, con moléculas aún mayores, tiene un punto de ebullición de -35º C; el bromo, de 58º C, y el yodo, de 183º C. A temperaturas ordinarias el flúor y el cloro son gases, el bromo es líquido y el yodo, sólido.

Sea gas, líquido o sólido, ninguno de esos elementos de un solo enlace puede formar una cadena de átomos vinculados por enlaces covalentes, esto es, cadenas de longitud superior a dos átomos. Los cinco elementos de un solo enlace quedan eliminados como posibles bases de la vida.

Pasemos a los elementos con átomos capaces de formar cada uno dos enlaces covalentes. Podéis imaginaros una cadena de átomos de oxígeno, por ejemplo, con el aspecto -O-O-O-O-, y así sucesivamente, con un número arbitrario de átomos. He ahí el primer atisbo de una posible cadena de átomos: breve, media, larga o gigante. Lo malo es que no se da en la naturaleza.

Para comprenderlo hemos de considerar las energías de enlace. Una posibilidad es medir la energía que hemos de verter en una combinación de dos átomos para romper el enlace covalente entre ellos. Otra es medir la energía liberada cuando los dos átomos abandonan la independencia y forman un enlace covalente. Por la ley de conservación de la energía, ambas magnitudes deben ser -y son- iguales, y ése es el contenido energético del enlace covalente.

Las energías de enlace se expresan habitualmente en unidades de «kilocalorías por mol», pero tampoco es necesario que nos echemos esa unidad al morral. Lo único que vamos a hacer es comparar una energía de enlace con otra, y para eso basta el número, sin más.

Por ejemplo, la energía del enlace covalente entre dos átomos de oxígeno (O-O) es 34. (Varía algo con las condiciones, pero 34 es un buen valor representativo.)

Esta propiedad es aditiva. Imaginad cuatro átomos de oxígeno en los ángulos

O-O

de un cuadrado, cada uno vinculado a sus dos vecinos por un enlace:

O-O

Habría cuatro enlaces en total, y la energía total de enlace sería de 4 X 34 = 136.

Supongamos, sin embargo, que dos átomos de oxígeno utilizan ambos enlaces para unirse a otro. Los átomos de oxígeno se encuentran entonces conectados por un «doble enlace» de este tipo: O = O. En este caso la energía de enlace es de 118. Esto no equivale al doble de la energía de enlace de un enlace sencillo, sino aproximadamente a tres veces y media esa energía [15].

Quiere decirse que si cuatro átomos de oxígeno se combinan en una molécula de cuatro átomos con cuatro enlaces simples, la energía de enlace total es 4 x 34 = 136, pero sí se combinan en dos moléculas biatómicas con dos enlaces dobles la energía de enlace total es 2 x 118 = 236.

La tendencia natural es que los átomos adopten las configuraciones que hagan máximas las energías de enlace. (Algo semejante a la tendencia natural de las pelotas a rodar ladera abajo.) En consecuencia, cuando se reúnen muchos átomos de oxígeno juntos, todos ellos, sin excepción, forman la molécula biatómica de doble enlace, expresada usualmente como O2, y a ninguno de los átomos de la molécula le sobra ningún enlace covalente. Sólo las fuerzas de Van der Waals los mantienen juntos, y el punto de ebullición del oxígeno líquido es -183º C.

Esto elimina de inmediato al oxígeno, ¿pero significa que podemos eliminar también a los otros elementos de dos enlaces?

No del todo. En general, cuanto mayores son los átomos menos pueden aproximarse, centro a centro, para formar un enlace covalente, y menor es la energía de enlace. El átomo de oxígeno, que es el más pequeño de los átomos de dos enlaces, puede formar un segundo enlace espectacularmente energético. Un átomo semejante pero mayor, como el azufre, el selenio o el telurio, no puede. El segundo enlace, caso de formarse, no sería particularmente energético, y no hay nada que fuerce a los átomos a una situación de doble enlace en lugar de una situación de enlace simple.

El azufre, por ejemplo, puede formar fácilmente una cadena o anillo de átomos. En el azufre líquido la molécula está formada por un anillo de ocho átomos.

Sin embargo, la cadena o anillo de azufre, por el mero hecho de existir, utiliza todos los enlaces de valencia de que disponen los átomos de azufre en circunstancias ordinarias. (Los átomos de oxígeno o de flúor pueden forzar a los átomos de azufre a donar electrones y formar enlaces covalentes adicionales, pero son efectos limitados que no proporcionan a las cadenas o anillos suficiente versatilidad para las exigencias de las bio-moléculas.)

Podemos, pues, eliminar todos los elementos de dos enlaces y pasar a los de tres.

La situación del nitrógeno es muy semejante a la del oxígeno. El enlace sencillo entre dos átomos de nitrógeno, tiene una energía de 38, pero un enlace doble entre ellos eleva la energía a 100, dos veces y media la del primero.

Y supongamos que el átomo de nitrógeno utilizase sus tres enlaces covalentes para la conexión con otro átomo de nitrógeno, formando un «triple enlace». La energía del enlace se convierte entonces en 225, lo cual representa más del doble que el enlace doble y seis veces la cuantía del enlace simple.

En consecuencia, cuando se juntan varios átomos de nitrógeno, forman inmediatamente la molécula biatómica de triple enlace, y la molécula de nitrógeno resultante, simbolizada habitualmente corno N2, no puede formar ningún otro enlace de valencia. Las moléculas se mantienen agrupadas por fuerzas Van der Waals, y el punto de ebullición del nitrógeno líquido es – 196º C.

El nitrógeno queda eliminado como posibilidad, pero una vez más es preciso estudiar por separado los átomos mayores de la misma clase: fósforo, arsénico y antimonio. Estos elementos pueden formar cadenas de enlace sencillo. (El vapor de fósforo, por ejemplo, contiene moléculas de cuatro átomos.)

Cabe imaginar una cadena de fósforo (-P-P-P-P) en la que cada átomo disponga aún de un tercer enlace de valencia. Este tercer enlace de valencia podría vincularse a otros átomos de fósforo, o a otros tipos de átomos, y cabría concebir moléculas de cualquier nivel de simplicidad o complejidad. Lo cual significa que no podemos eliminar el fósforo como posible esqueleto de tus moléculas de la vida. Ni tampoco podemos eliminar el arsénico y el antimonio a estas alturas.

El boro, el otro átomo de tres enlaces, no pertenece a la familia del nitrógeno, pero tiene también la capacidad de formar cadenas.

Nos resta ahora el grupo final de elementos, los de cuatro enlaces. De entre ellos, el carbono es el de átomo más pequeño. ¿Podemos seguir el camino marcado por el oxígeno y el nitrógeno y considerar dos átomos de carbono unidos por los cuatro enlaces, formando la molécula C2 con un enlace cuádruplo?

No, no podemos. El enlace cuádruplo no existe, y los átomos de carbono sólo pueden unirse entre sí mediante enlaces simples, dobles y triples. En cualquiera de esos casos el átomo de carbono seguirá teniendo enlaces covalentes disponibles para unirse a otros átomos. Aunque dos átomos de carbono estén conectados por un enlace triple, cada cual conserva libre un cuarto enlace. Diríase entonces que las cadenas del carbono no sólo son posibles, sino inevitables.

Pero ¿cuál es el enlace predilecto en los átomos de carbono? La energía de un enlace sencillo entre átomos de carbono es 82, la de un doble enlace 146 y la de un enlace triple 200. Obsérvese que dos enlaces sencillos tienen una energía total de 164 y tres enlaces sencillos una energía total de 246. En consecuencia, los átomos de carbono logran las máximas energías de enlace si se conectan exclusivamente mediante enlaces sencillos.

Las diferencias de energía no son enormes. Pueden existir y existen átomos de carbono conectados por enlaces dobles o triples, y a veces condiciones especiales incrementan las energías de enlace hasta el punto de tornarlos bastante estables. Sin embargo, en la mayoría de los casos los enlaces dobles y triples son relativamente inestables y pueden transformarse con poco esfuerzo en enlaces sencillos.

La situación típica en el caso del átomo de carbono cabe, pues, expresarla de modo muy simple presentándola como una cadena de longitud indefinida -C-C-C-C- donde cada átomo de carbono posee dos enlaces de valencia adicionales para conectarse a otros átomos. Los dos enlaces adicionales pueden ligarse a otros átomos de carbono, formando cadenas ramificadas, o a otros lugares de la cadena, formando anillos.

Esto ofrece todas las posibilidades de complejidad que antes mencioné en conexión con el átomo de fósforo, pero llevadas a un nivel muy superior, puesto que aquí sobran dos enlaces por átomo en vez de uno. La situación es idéntica para los otros miembros de la familia del carbono: silicio, germanio y estaño.

Hemos reducido el número de elementos que pueden servir como base para la vida de los 105 iniciales a ocho solamente. De esos ocho candidatos cuatro tienen tres enlaces (boro, fósforo, arsénico y antimonio) y cuatro tienen cuatro enlaces (carbono, silicio, germanio y estaño).

¿Cómo discernir entre ellos? ¿Hay algún modo de mostrar que unos son candidatos más firmes que otros? ¿Cuáles son los criterios?

En primer lugar, podemos decir que los átomos de cuatro enlaces son sin duda superiores a los de tres enlaces, pues los primeros pueden claramente producir moléculas más complicadas a igualdad de los demás factores,

En segundo lugar, podríamos considerar las energías de enlace simple para cada uno de los ocho elementos. Parece justo pensar que cuanto más altas sean las energías de enlace más estables serán las cadenas y anillos construidos con esos átomos, y más probable que sirvan como base para la vida. En la tabla 2 doy la energía de enlace que conecta a dos átomos de cada candidato [16].

Sí miramos la tabla 2, vemos inmediatamente que, según los dos criterios antes mencionados, el carbono es a todas luces el mejor candidato al fundamento de la vida. Tiene cuatro enlaces, y éstos son mucho más fuertes que los de los demás, formando por eso las cadenas más estables y complicadas con diferencia.

Pero eso sólo significa que el carbono es la mejor de varias posibilidades, lo cual no es suficiente. ¿Hay algún modo de mostrar que es estrictamente la única posibilidad?

TABLA 2

Muy bien; abordemos la situación desde otro ángulo. Los tres tipos más comunes de átomos en el universo son, por orden, el hidrógeno, el helio y el oxígeno. El helio no forma enlaces covalentes, por lo cual podemos olvidarlo. Creo, pues, que todo planeta considerable habrá de tener un predominio de hidrógeno (y helio) o un predominio de oxígeno.

Si es un planeta grande y frío como Júpiter, tenderá a una preponderancia de hidrógeno por el simple hecho de que existe gran cantidad de ese gas. Si es un planeta más pequeño y cálido como la Tierra, y no consigue retener la mayor parte del hidrógeno (y del helio) a medida que se forman, habrá de tener una preponderancia de oxígeno (aunque no necesariamente de oxígeno libre en la atmósfera, desde luego). Es una cosa o la otra.

En tal caso, no basta hablar de cadenas y anillos de átomos de un elemento particular, como si ese elemento existiera aislado. ¿Qué ocurriría con esas cadenas y anillos si estuvieran presentes átomos de otros elementos? En concreto, ¿qué ocurriría si hubiera un exceso de átomos de hidrógeno o de oxígeno, de uno o de otro?

Si los átomos de un elemento forman enlaces más fuertes con el oxígeno o el hidrógeno, o con ambos, que consigo mismos, no tenderán a formar largas cadenas ni anillos.

Considérese el silicio, por ejemplo. Tiene cuatro enlaces y una energía de enlace bastante alta, aunque no tanto como la del carbono. (En la ciencia ficción se ha contemplado a menudo la posibilidad de una «vida de silicio». El enlace simple silicio-silicio posee una energía de 53 pero el enlace silicio-oxígeno tiene una energía de 88 (66 por 100 más fuerte) y el enlace silicio-hidrógeno, de 75 (42 por 100 más fuerte).

En presencia de un gran exceso de oxígeno o hidrógeno, los átomos de silicio no se unen entre sí, sino que lo harán o con el oxígeno o con el hidrógeno. En la Tierra, que tiene exceso de oxígeno, no encontramos enlaces silicio-silicio en la naturaleza. ¡Jamás! Cada átomo de silicio encontrado en la corteza terrestre está vinculado cuando menos a un átomo de oxígeno.

Podemos recorrer toda la lista de elementos enumerados en la tabla 2 y mostrar que todos ellos propenden más a existir en combinación con el oxígeno que consigo mismos, y que no es probable que en la Naturaleza se den cadenas y anillos complicados de dichos elementos.

Hasta que llegamos al carbono. ¿Qué pasa con el carbono?

El enlace simple carbono-carbono tiene una energía de 82. El enlace carbono-hidrógeno tiene una energía de 93 (esto es, 13 por 100 más fuerte), mientras que el de carbono-oxígeno es de 85 (esto es, sólo un 4 por 100 más fuerte).

La diferencia está ahí, pero no es grande. En presencia del oxígeno el carbono formará, efectivamente, enlaces carbono-oxígeno (y, por tanto, arderá), pero sólo si está suficientemente caliente. En presencia de hidrógeno el carbono formará efectivamente enlaces C-H (por lo cual puede convertirse carbón en petróleo), pero no sin gran dificultad.

Ninguno de estos cambios se produce fácil ni rápidamente. Los átomos de carbono tan pronto se conectan entre sí como con hidrógeno u oxígeno. El carbono formará efectivamente cadenas, tanto largas como cortas, rectas como ramificadas; y anillos, tanto simples como complejos; incluso en presencia de un exceso de hidrógeno o de oxígeno (como en la Tierra).

Cabría aún especular con la posibilidad de que otros elementos sirviesen como base de la vida (silicio, oxígeno y fósforo, por ejemplo), pero son posibilidades altamente especulativas e improbables.

Así, pues, si nos atenemos a lo razonable, el carbono es el único elemento capaz de permitir la formación de moléculas, tanto simples como complejas, del tipo que caracterizan a la vida. No ya el mejor, sino el único.

8. Los gemelos inverosímiles

Hace algo más de un año (de cuando escribo esto), dos estimables señoras me pidieron insistentemente en Walker Company que escribiera una sátira sobre los libros de introducción a la vida sexual que a la sazón estaban (y están) infestando el país. Muy en contra de mi criterio me dejé convencer, y un fin de semana, en abril de 1971, me senté y di a luz un escrito llamado El viejo verde sensual. (Un caso de autorradiografía involuntaria, supongo, sólo que yo no soy realmente viejo.)

Fue publicado bajo el transparente seudónimo de «Doctor A.», y estaba casi seguro de que nadie iba a enterarse de que yo era su autor.

¡Oh, infeliz! El «secreto» fue anunciado en la prensa incluso antes de publicarse el libro, y no tardé en encontrarme ante las cámaras de televisión en mi papel de hombre sensual y verde en su tardía juventud. Y ahora está en la calle, como libro de bolsillo, con el «Dr. A.» seguido de mi nombre completo entre paréntesis.

Puesto que el libro no es verde, nunca llegó a la lista de best-seller. Por otra parte, puesto que es divertido, se vende muy bien. Y como no es verde y es divertido, no me avergüenzo lo más mínimo de él.

Lo que estoy consiguiendo (y espero seguir así) es una verdadera avalancha de presentaciones en las que el locutor señala: «… y entre sus libros más debatidos están La Guía de Asimov para la Biblia y El viejo verde sensual».

Lo incongruente de la conjunción siempre es bueno para una carcajada… y eso es lo que se busca, naturalmente.

Las conjunciones incongruentes son divertidas, o perturbadoras, también en la ciencia, y puesto que analicé el carbono en el capítulo anterior, pasaré ahora a hablar de él en conexión con una pareja de gemelos singularmente inverosímiles.

El carbono es uno de los elementos conocidos por los antiguos, porque sus propiedades químicas le permiten existir libre de la Naturaleza, y porque es sólido Y, por tanto, fácilmente detectable. En total hay nueve elementos semejantes y, de ellos, sólo dos son no metales; el carbono es uno y el azufre el otro.

El carbono existe realmente como mineral y puede extraerse de la Tierra. En una de sus formas menos comunes es una sustancia negra y escamosa que puede utilizarse para hacer marcas. Aunque es lo bastante sólido para permanecer de una pieza, suelta pequeños trozos cuando es frotado sobre alguna superficie. El carbono de este tipo (mezclado con arcilla) se utiliza como «mina» de lapiceros, y por eso se le llama grafito, utilizando una palabra griega que significa «escribir».

Sin embargo, no fue el carbono en forma de grafito lo que los antiguos conocieron primero. Es mucho más probable que su primera experiencia con el carbono tuviera que ver con el fuego de madera. Cuando la pila es grande y la ventilación insuficiente, la madera del interior no se quema del todo. Los átomos de la madera distintos de los de carbono (fundamentalmente átomos de hidrógeno)se combinan fácilmente con oxígeno. En realidad son moléculas de hidrógeno combinadas con carbono las que producen los vapores y la danza de las llamas. Los átomos de carbono en sí no se combinan fácilmente con el oxígeno, y cuando los compuestos que contienen hidrógeno se consumen y la llama se extingue, queda un residuo de madera transformada en negro carbono.

En latín esta sustancia negra se llamaba carbo, de donde proviene nuestra palabra carbono. En inglés la palabra coal (carbón) significaba originalmente cualquier ascua encendida, y cuando esas ascuas se acababan carbonizando en una sustancia negra o cuando esa sustancia negra era capaz de formar un ascua, recibía el nombre de charcoal (carbón de leña).

El valor del carbón de leña era que ardía en presencia de aire abundante; pero, al revés que la madera, no liberaba vapores ni daba llama. Tan sólo se ponía al rojo, y ofrecía, eso sí, una temperatura singularmente alta durante bastante tiempo. La alta temperatura era especialmente valiosa en la fundición del hierro, y la producción de carbón de leña se transformó en una industria importante. (Siendo como era tan prodigiosamente derrochadora de madera, dicha industria aceleró la desaparición de los bosques en aquellas áreas donde era importante la metalurgia.)

A lo largo de las eras geológicas, bosques enteros sufrieron lentamente una especie de carbonización natural debido al calor, a la presión y al déficit de oxígeno, motivo por el cual existen hoy espesas capas de carbono en el subsuelo. Es lo que llamamos «carbón».

Algunas formas de carbón son más ricas en carbono que otras. Si calentamos carbón en ausencia de oxígeno, la parte no carbonosa es expulsada y lo que resta se denomina cok o coque.

Otra forma de carbono que con certeza tuvo que haber sido percibida en los tiempos más antiguos es el hollín depositado por el humo y el vapor al quemar madera o aceite. El hollín está compuesto por fragmentos de carbono que quedan al arder los compuestos inflamables que contienen hidrógeno; el hidrógeno captura tan ávidamente el oxígeno, que los átomos de carbono son literalmente desplazados. Este hollín, mezclado con aceite, formó las primeras tintas, de suerte que el carbono es el secreto tanto de la pluma como del lápiz.

Todas esas formas de carbono son negras y quebradizas. El grafito es visiblemente cristalino, mientras que las otras formas no lo son. El carbón de leña, el carbón, el coque y el hollín, en todas sus diversas formas, están hechos, sin embargo, de cristales de tamaño microscópico o sub-microscópico, idénticos siempre a los del grafito. En consecuencia, es perfectamente justo agrupar juntas todas las formas de carbono negro bajo el rubro de «grafito».

Claro que aunque el carbono fuese conocido en su forma elemental desde tiempos prehistóricos, su reconocimiento como elemento en el sentido químico moderno sólo vino cuando los químicos comprendieron qué eran los elementos, en la acepción actual del término.

No fue sino en el siglo XVIII cuando los químicos adquirieron una noción clara de los elementos, comprendiendo entonces que el grafito era un elemento, al estar compuesto exclusivamente por átomos de carbono.

Cambiemos ahora de tercio, al menos aparentemente. Desde tiempos muy antiguos se descubrían de vez en vez guijarros que diferían de todos los demás por ser extremadamente duros. Ninguna otra cosa podía rayarlos, ni las rocas, ni el cristal, ni el metal más agudo. Esos guijarros, por su parte, podían rayar cualquier otra cosa.

Los griegos los llamaron adamas o, en genitivo, adamantos, términos derivados de una palabra que significa «indomable», pues nada podía dejar huella en ellos. La palabra se convirtió en «adamantino», término aún empleado en poesía para designar la característica de dureza, inquebrantabilidad. Luego sufrió también una distorsión gradual, incluyendo la pérdida de la «a» inicial, y se convirtió en «diamante», que es como llamamos hoy a la piedra más dura de todas [17].

En los primeros días de la química, los químicos fueron presa de un furioso deseo de conocer la composición de todas las cosas, incluidos los diamantes. Estos, sin embargo, eran difíciles de manejar, justamente porque eran indomables». No sólo no podían rayarse, sino que no los afectaba casi ningún producto químico, y ni siquiera hacía mella en ellos un calor considerable.

Los químicos, todo hay que decirlo, no estaban tampoco demasiado ávidos de exponer un diamante a la posibilidad de vicisitudes químicas o físicas. Un diamante no podía en ningún caso transformarse en algo más valioso que él mismo, y ¿quién iba a comprar un diamante para luego destruirlo?

Lo que hacía falta era un mecenas, y resultó que Cosme III, Gran Duque de Toscana, cuyo gobierno duró de 1670 a 1723, era acaudalado y estaba interesado en la ciencia. Hacía el año 1695 donó a dos profesores italianos un diamante, y aquellos lo situaron en el foco de una poderosa lente. Los rayos solares concentrados elevaron la temperatura del diamante hasta un nivel superior al de cualquier llama de que disponían los experimentadores… Y el diamante desapareció por completo.

Tal fue su informe; naturalmente, fue recibido con gran escepticismo. A partir de entonces el número de químicos deseosos de repetir el experimento se confinó a quienes estaban dispuestos a arriesgar un diamante, y el experimento tardó ochenta años en volver a repetirse.

En 1771 el químico francés Pierre Joseph Macquer obtuvo un diamante impecable y lo calentó a temperaturas cercanas a 1.000º C. El diamante estaba al rojo vivo, pero cabía distinguir un resplandor aún más brillante a su alrededor. Se mantuvo la temperatura y en menos de una hora el diamante desapareció.

¿Se disipaba sin más el diamante de un modo misterioso, o ardía realmente? Si ardía como las demás cosas, necesitaría un suministro de aire. Un joyero llamado Maillard envolvió, pues, diamantes en una serie de sustancias no combustibles, selló herméticamente el paquete y luego lo calentó en medida suficiente para hacer que el diamante desapareciera. Pero esta vez no desapareció. La conclusión fue que los diamantes arden en el aire como tantas otras cosas, con tal de calentarlas suficientemente.

Más o menos por entonces, el químico francés Antoine Laurent Lavoisier estaba creando los fundamentos de la química moderna, y dejaría bien claro que la combustión ordinaria en el aire equivalía a la combinación con oxígeno de la sustancia quemada. La combustión la convertía en un óxido, y si simulaba desaparecer era porque el óxido era un vapor. Deducíase entonces que el óxido de diamante era un vapor.

Había que atrapar y estudiar el vapor para descubrir algo acerca del diamante. En 1773 Lavoisier, Macquer y algunos otros calentaron un diamante bajo una campana de cristal, utilizando una gigantesca lente. El diamante desapareció, pero el vapor de óxido de diamante estaba ahora atrapado en la campana y podía estudiarse. Resultó tener las mismas propiedades que el dióxido de carbono obtenido mediante la combustión de carbón de leña.

Cuando Lavoisier hubo elaborado a fondo su teoría de los óxidos, se vio obligado a concluir que tanto el diamante como el grafito liberaban dióxido de carbono y que ambos eran, por eso mismo, formas de carbono puro.

La incongruencia de situar el diamante y el grafito en el mismo cajón era tan grande como para provocar risa, o indignación. Los científicos lo veían difícil de creer. El diamante (una vez cortado de modo conveniente con otros diamantes) es bello y transparente, mientras que el grafito es negro y opaco. El diamante era la sustancia más dura entre las conocidas; el grafito era blando y resbaloso, hasta el punto de que podía utilizarse como lubricante. El diamante no conducía la corriente eléctrica, el grafito sí.

Durante una generación los químicos nadaron en la duda, pero la acumulación de experimentos acabaron haciendo indiscutible el hecho. El grafito y el diamante eran dos formas diferentes del carbono. En 1799, por ejemplo, el químico francés Louis Bernard Guyton de Morveau calentó fuertemente el diamante en ausencia de aire (para que no ardiese) y vio cómo se transformaba efectivamente en grafito.

Y claro, una vez conseguida la transformación de diamante en grafito brotó un furioso interés por la posibilidad de hacer lo inverso: transformar el grafito en diamante. A lo largo del siglo XIX hubo conatos en ese sentido, y durante cierto tiempo se creyó que el químico francés Henry Moissan lo había logrado en 1893. De hecho presentó diamantes preparados por él, y de los cuales uno tenía 1/35 de pulgada de diámetro y carecía aparentemente de defectos.

La operación, empero, no pudo repetirse, y hoy día sabemos que es imposible formar diamantes con los métodos utilizados por Moissan. La versión habitual es que Moissan fue víctima del engaño de su ayudante, quien después, cuando la broma fue tomada en serio, no se atrevió a confesar.

El carbono no es el único que goza de esta dualidad. Hay otros casos de elementos que existen en formas diferentes. El oxígeno común está formado por moléculas que contienen cada una dos átomos de oxígeno. Sin embargo, el ozono (descubierto en 1840) está formado por moléculas que contienen cada una tres átomos de oxígeno. El oxígeno y el ozono son «alótropos» (término proveniente de una palabra griega que significa «variedad») del oxígeno.

Hay también alótropos del azufre, del fósforo y del estaño, y en todos esos casos es cuestión de que los átomos del elemento se presentan en dos o más ordenaciones distintas.

El diamante y el grafito ¿no son entonces un caso más de alotropía? Sí, pero en ningún otro caso son las formas alotrópicas de un elemento tan diferentes en cuanto a propiedades, tan radicalmente diferentes, como el diamante y el grafito. ¿Es posible que tales opuestos sean simple producto de una reordenación de los átomos?

Volvamos al átomo de carbono. Tiene cuatro enlaces; esto es, puede vincularse a cuatro átomos diferentes en cuatro direcciones distintas. Los enlaces están en las direcciones de los vértices de un tetraedro.

Quizá podáis visualizarlo, sin un modelo tridimensional (pues los dibujos bidimensionales son de dudosa ayuda), si imagináis que el átomo de carbono está sentado sobre tres de sus enlaces como si se tratara de un trípode, mientras el cuarto enlace apunta hacía arriba.

Cuando una serie de átomos de carbono se unen entre sí para formar una cadena, ésta suele representarse, por razones de sencillez, en línea recta: -C-C-C-C-. De hecho, debiera escribirse en zig-zag para reflejar fielmente el ángulo natural (109,5º C) que forman los enlaces.

Respetando el ángulo natural de los enlaces, es fácil obtener un anillo de seis átomos de carbono, pero el anillo no es plano. Visto de perfil, los dos bordes se curvan, uno hacia arriba y otro hacia abajo, o los dos hacia el mismo lado. Ignorando este extremo, podemos representar del modo siguiente el «anillo del ciclo hexano»:

Obsérvese que cada átomo de carbono tiene cuatro enlaces en total. Dos se utilizan para conectarse con sus vecinos del anillo, pero los dos restantes quedan disponibles para otros fines.

Ahora bien, uno de esos enlaces sobrantes puede también agregarse a los del anillo. En tal caso, cada átomo de carbono está vinculado a uno de sus vecinos por un enlace simple y al otro por un enlace doble, formando un «anillo del benceno»:

Habitualmente, como expliqué en el capítulo previo, el enlace doble entre átomos de carbono es menos estable que el enlace sencillo. Cabría esperar que fuese fácil convertir el anillo de benceno en un anillo de ciclohexano, pero no es así. ¡Al contrario! El anillo de benceno es más estable que el anillo de ciclohexano, a pesar de los enlaces dobles.

La razón es que los átomos de carbono en el anillo de benceno se encuentran en un plano; el anillo de benceno es perfectamente plano. Además, es simétrico. La planicie y la simetría contribuyen a la estabilidad del anillo por razones que requerirían el uso de la mecánica cuántica y, si no os importa, vamos a dejar la mecánica cuántica fuera de estos capítulos.

El anillo de benceno antes dibujado no es del todo simétrico. Cada átomo de carbono tiene un enlace sencillo en un lado y un enlace doble en el otro, lo cual representa, sin duda, una asimetría. De acuerdo; pero es que esta cuestión de los enlaces sencillos y los enlaces dobles surgió antes de que los químicos se instruyesen sobre los electrones. Actualmente sabemos que los enlaces consisten en electrones compartidos, y que los electrones tienen propiedades ondulatorias.

Si los enlaces sencillos y los enlaces dobles se toman al pie de la letra, se diría que dos átomos de carbono separados por un enlace simple comparten dos electrones, y que dos átomos de carbono separados por un enlace doble comparten cuatro. Así sería si los electrones fuesen partículas, pero son ondas.

Debido a la planicie y simetría del anillo de benceno, las ondas electrónicas se esparcen por todo el anillo y se distribuyen por igual entre todos los átomos. El resultado es que cada átomo de carbono está vinculado a cada uno de sus vecinos de modo exactamente idéntico (por eso es tan estable el anillo de benceno). Pecando de simplistas, diríamos que las seis conexiones en el anillo de benceno consisten en seis enlaces de «uno y medio».

Podemos, por tanto, representar el anillo de benceno del modo siguiente, con el fin de mostrar la equivalencia de los enlaces y hacer íntegramente simétrica a la molécula:

Obsérvese que cada átomo de carbono tiene todavía un enlace de sobra, que puede unirse a algún átomo fuera del anillo. Esos enlaces pueden vincularse todos ellos a otros átomos de carbono, que acaso formen parte de otros anillos de benceno. Al final obtendríamos un mosaico de hexágonos (como los que vemos frecuentemente en los suelos de azulejos), en el que cada vértice está ocupado por un átomo de carbono:

Si imagináis un gran número de esos mosaicos planos, apilados unos sobre otros, no se mantendrán unidos por enlaces químicos ordinarios, sino por las más débiles fuerzas de Van der Waals, mencionadas en el capítulo anterior.

Cada átomo de carbono de un hexágono está a 1,4 angstroms de su vecino (un angstrom es la cienmíllonésima parte de un centímetro). Sin embargo, cada mosaico está a 3,4 angstroms del inmediatamente inferior. La mayor distancia en el segundo caso es una expresión de la menor fuerza atractiva.

Pues bien, el grafito puro está formado justamente por esas pilas de mosaicos de átomos de carbono. Cada capa plana de hexágonos mantiene firmemente su integridad, pero se deja despegar (exfoliar) fácilmente de las dos capas contiguas. Por eso sirve el grafito para escribir y lubricar.

Por otro lado, los electrones que se distribuyen a lo largo de todo el anillo de benceno tienen algunas de las propiedades de los electrones móviles que ayudan a formar enlaces metálicos (mencionados en el capítulo precedente). El resultado es que el grafito conduce la corriente eléctrica moderadamente bien (aunque no tan bien como los metales).

El calor y la electricidad pueden viajar más fácilmente sobre el plano de cada mosaico que de un plano a otro. Quiere decirse que, en una de las direcciones, el calor viaja a través de un cristal de grafito mil veces más fácilmente que en la otra. La cifra correspondiente para la electricidad es de 200.

¿Y el diamante? Volvamos al átomo de carbono, con sus cuatro enlaces apuntando en cuatro direcciones, cada una en el mismo ángulo con respecto a las otras tres: un átomo de carbono sentado sobre un trípode plano, con el cuarto enlace hacia arriba.

Imaginad que cada enlace está conectado con un átomo de carbono, que cada uno de ellos tiene tres enlaces sobrantes, que cada uno de éstos está vinculado a un átomo de carbono, cada uno de los cuales tiene tres enlaces sobrantes, y que cada uno de éstos está vinculado a un átomo de carbono…

El resultado es una disposición «diamantina», una disposición perfectamente simétrica de átomos de carbono en tres dimensiones.

Significa eso que todos los átomos de carbono están sostenidos con fuerza pareja en cuatro direcciones diferentes. No hay átomo ni grupo de átomos singularmente propenso a separarse, por lo cual el diamante no es exfoliable. No es posible escribir con él ni utilizarlo como lubricante.

Más bien al contrario. Puesto que los átomos de carbono se mantienen unidos en todas direcciones por fuertes enlaces sencillos, y puesto que éstos son los enlaces más fuertes que darse puedan en ninguna sustancia sólida a temperaturas ordinarias (como expliqué en el capítulo precedente), el diamante es insólitamente duro. Raya y no es rayado, y lejos de lubrificar, destrozaría rápidamente cualquier cosa que se frotara contra él.

Además, los electrones del diamante están firmemente asentados en su sitio. Sus ondas se limitan a los espacios entre átomos adyacentes, con lo cual el diamante es un mal conductor del calor y de la electricidad.

Quizá la única cosa no fácil de explicar es por qué el diamante es transparente y el grafito opaco. Eso volvería a llevarnos a la mecánica cuántica, por lo cual no lo intentaré.

La siguiente cuestión es ésta: si inicialmente tenemos una gran cantidad de átomos de carbono y dejamos que se combinen, ¿qué disposición adoptarán espontáneamente, la del grafito o la del diamante?

Pues bien, depende de las condiciones.

En conjunto, el anillo de benceno es tan estable que, puestos a elegir, los átomos de carbono formarán alegremente esos hexágonos plenos. (Mientras que los átomos de carbono se encuentran separados por 1,4 angstroms en el anillo de benceno, los del diamante distan 1,5 angstroms). Así pues, en la mayor parte de las situaciones cabe esperar que se forme grafito.

Sin embargo, el diamante tiene una densidad de 3,5 gramos por centímetro cúbico, aproximadamente, mientras que la del grafito -debido a la gran distancia entre mosaicos- sólo es dos gramos por cm3, aproximadamente.

En consecuencia, si los átomos de carbono son sometidos a una gran presión, la tendencia a reagruparse en una forma que emplee menos espacio acaba siendo abrumadora, y se forma diamante.

Pero si a las presiones ordinarias el grafito es la forma predilecta, ¿cómo es que existe el diamante? Aun suponiendo que se formara bajo las grandes presiones de las entrañas profundas de la Tierra, ¿por qué no se convirtió en grafito tan pronto como remitió la presión?

El quid es el siguiente: los átomos de carbono del diamante obrarían con naturalidad si adoptaran la configuración del grafito. Sin embargo, están atados tan firmemente por sus enlaces que la energía necesaria para romperlos y permitir el desplazamiento es enorme. Es como si el diamante estuviese en la cima de una colina y fuese perfectamente capaz de rodar ladera abajo, si no fuese porque se encuentra en el fondo de un pozo profundo sobre la cima de la colina y hubiera que sacarlo de allí antes de poder rodar hacía abajo.

Al elevar la temperatura de un diamante a unos 2.000º C (en ausencia de oxígeno, para evitar la combustión), lo sacamos, por así decirlo, del pozo. Los átomos quedan libres y asumen la configuración preferida del grafito.

Para hacer lo inverso -convertir el grafito en diamante- no sólo es preciso utilizar temperaturas muy elevadas para desvincular a los átomos, sino también presiones muy altas para convencerles de que deben adoptar la configuración más densa del diamante.

El instrumental del que disponía Moissan en 1893 era absolutamente incapaz de proporcionar el incremento simultáneo de temperatura y presión requerido, por lo cual sabemos que no pudo haber formado realmente diamantes sintéticos. En 1955, científicos de la General Electric consiguieron formar los primeros diamantes sintéticos trabajando con temperaturas de 2.500º C junto con presiones superiores a 700 toneladas por pulgada cuadrada.

Una última cosa antes de dejaros abandonar este capítulo. El carbono tiene un total de seis electrones, el boro cinco y el nitrógeno siete. Si dos átomos de carbono se combinan (C-C), tienen doce electrones en total. Si un átomo de boro y un átomo de nitrógeno se combinan (B-N), tienen también doce electrones en total.

No es, pues, maravilla que la combinación de boro y nitrógeno, o «nitruro de boro», tenga propiedades muy semejantes a las del grafito (aunque sea blanco en vez de negro y no conduzca la electricidad). El nitruro de boro está hecho de hexágonos en cuyas esquinas alternan los átomos de boro y nitrógeno, y partiendo de esos hexágonos se forman pilas de mosaicos.

Si el nitruro de boro es sometido a la famosa combinación de alta temperatura y alta presión, sus átomos adoptan también la disposición del diamante. El resultado es una forma más densa y más dura de nitruro de boro, llamada «borazón». (El sufijo «azon» proviene de «azote», viejo nombre del nitrógeno.)

El borazón es casi tan duro como el diamante (tampoco debe sorprendernos). Incluso tiene una importante ventaja sobre el diamante, y es que no es combustible. Puede utilizarse a temperaturas a las que el diamante se combinaría con oxígeno, desapareciendo.

El borazón puede, pues, que sustituya al diamante en usos industriales, pero me da que por algún tiempo no veremos anillos de compromiso hechos de borazón.

D) Sobre microorganismos

9. A través del microcristal

Acabo de regresar de un trabajo de dos semanas en una conferencia de escritores celebrada en Bread Loaf, Vermont, donde lo he pasado muy bien. Entre los muchos encantos del lugar figuran todas las jóvenes damiselas ansiosas por aprender a escribir, y mi actitud hacia ellas fue muy notada y no poco admirada por su afabilidad.

Hacia el final de mi estancia, una de las jóvenes damas, con quien me estaba comportando pero que muy afablemente, rió y me dijo:

–Oh, doctor Asimov, es usted tan levascio.

Me quedé de piedra. Estábamos sentados en un banco y mi brazo había reposado hasta entonces cómodamente cerca de su cintura… pero una nube cruzó ahora sobre el Sol de mi persona. Nunca me habían llamado «levascio», menos una jovencita. Me sentía anonadado. Sobre todo porque no sabía qué significaba la palabra.

–¿Levascio? – dije-. ¿Qué es eso?

Ella respondió:

–Oh, ya sabe, doctor Asimov. El modo en que va usted requebrando a las mujeres.

Por el modo en que pronunció «requebrando» comprendí su sistema de manejar las palabras. Acertaba la primera y la última letras y dejaba las intermedias a su libre albedrío.

–¿Por levascio -dije- no querrá decir lascivo?

–Esa es la palabra, – dijo alegremente, batiendo palmas.

Quedé inmediatamente sumido en mis pensamientos. Jamás me había tenido por lascivo, solamente afable. Por otra parte, ya puestos, también podría ser levascio. Sonaba bien: una mezcla de «leve» y «vivaz». Más aún, provenía claramente del latín levare, que significa «levantar», como levantar el ánimo. Y, en efecto, muchas chicas de Bread Loaf me habían dicho: «Oh, doctor Asimov, su risueña vivacidad me levanta el ánimo.»

Pero mientras elucubraba todo esto la joven que había puesto en marcha el tinglado se escabulló.

Lo cual demuestra que las palabras me importan todavía más que las mujeres, como conviene a un escritor. Y por eso no es maravilla que en la mayor parte de los segmentos del conocimiento que me interesaban tenga constantemente que vérmelas con las palabras.

Tomemos por ejemplo la microbiología (proveniente de palabras griegas que significan «el estudio de la vida pequeña»)…

En 1675 el microscopista holandés Anton van Leeuwenhoek se convirtió en el primer hombre que vio minúsculas cosas vivientes bajo sus lentes: criaturas demasiado pequeñas para ser vistas a simple vista, pero indiscutiblemente vivas.

Las llamó «animálculos», que significa «pequeños animales». Pero no todos los minúsculos organismos visibles bajo un microscopio son activos y de naturaleza animaloide; algunos son verdes y pasivos, y claramente afines a las plantas. Hoy día llamamos a todos esos organismos microscópicos «microorganismos», término perfectamente general, de significado absolutamente transparente.

Los microorganismos existen en diversos tamaños, y algunos son realmente pequeños. En 1683 Van Leeuwenhoek detectó minúsculos objetos en el límite mismo de resolución de sus lentes, objetos que a la larga resultaron ser menos avanzados que los microorganismos animales y vegetales.

La microscopía necesitó otro siglo para llegar al punto de ver con suficiente claridad esos minúsculos objetos y estudiarlos con cierto detalle. El biólogo danés Otto Friedrich Müller fue el primero en dividir esas minúsculas criaturas en grupos e intentar clasificarlas en géneros y especies. En un libro suyo publicado en 1786 (dos años después de su muerte) se refería a algunos con el término de «bacilos», palabra que proviene de otra latina que significa «pequeño bastón», pues ésa era su forma. A otros los llamó «espirilos», pues tenían la forma de diminutas espirales.

A lo largo del siglo XIX se introdujeron nuevos términos. El botánico alemán Ferdinand Cohn aplicó un nuevo nombre a microorganismos con forma de bastón, pero más gruesos y cortos que los bacilos. Los llamó «bacterias», término derivado de una palabra griega que significa «bastón pequeño». El cirujano austriaco Albert Christian Theodor Billroth llamó «cocos» a las variedades con aspecto de pequeñas esferas, utilizando una palabra griega para «baya».

Menciono ahora algunos términos generales:

Los microorganismos unicelulares de naturaleza claramente animal, que comparten propiedades con las células componentes de animales grandes como nosotros, eran «protozoos», término proveniente de palabras griegas que significan «primeros animales». Los microorganismos unicelulares cuya naturaleza era claramente afín a las plantas y muy semejantes a las células encontradas en fibras grandes de algas se denominaron «algas», de la palabra latina «algae».

Pero ¿y esos microorganismos singularmente pequeños, los bacilos y demás? ¿Qué nombre general podría cubrirlos a todos? Los científicos han acabado eligiendo el de «bacterias» para ese propósito, y el estudio de esos organismos se denomina bacteriología.

Sin embargo, la gente en general utilizaba otro nombre, que sigue siendo popular.

En latín, cualquier mota de vida que pueda desarrollarse hasta formar un organismo mayor era un germen. Las semillas minúsculas eran los mejores ejemplos de gérmenes conocidos por los antiguos, y cuando una semilla inicia su desarrollo, decimos que «germina». Es más, seguimos hablando de «germen del trigo», por ejemplo, cuando queremos indicar la parte del grano que constituye el núcleo vital.

Parecía entonces razonable llamar también «gérmenes» a esos minúsculos microorganismos. Menos común es «microbio», término proveniente de palabras griegas que significan «vida pequeña».

En realidad, ninguno de esos términos es perfecto. «Germen» y «microbio» son demasiado generales, porque existen pequeños trozos de vida distintos de las criaturas designadas usualmente con tales nombres. Por otra parte, «bacteria» es demasiado específico, pues originalmente sólo era usado para una variedad de las criaturas que llamamos habitualmente bacterias… Pero de nada sirve; nadie nos escucha a nosotros, los logoductores.[18]

A mediados del siglo XIX el químico francés Louis Pasteur era el más destacado químico-biólogo-bacteriólogo del mundo. Había explicado el misterio del ácido racémico, por ejemplo, y había aprendido cómo evitar que se avinagrara el vino mediante un calentamiento suave o «pasteurización». En un experimento público muy espectacular, realizado en 1864, demostró que las bacterias estaban vivas en el pleno sentido de la palabra. No brotaban de la materia inanimada, sino de otras bacterias. (Una historia fascinante, pero que dejamos para otro día.)

Fue así como en 1865, cuando la industria del gusano de seda en el sur de Francia amenazaba ruina por una enfermedad misteriosa que mataba a los gusanos, se recabó la ayuda del milagroso Pasteur. Ninguna otra persona serviría. Pasteur acudió.

Con su microscopio estudió los gusanos de seda y las hojas de morera de que se alimentaban. Descubrió que un minúsculo microorganismo infectaba a los gusanos enfermos y a las hojas, mientras que los gusanos sanos y las suyas estaban libres de él.

La solución de Pasteur fue simple pero drástica: había que destruir todos los gusanos de seda y hojas de morera infestados por el microorganismo. Era preciso comenzar de nuevo con gusanos sanos; y estando ausente el microorganismo todo iría bien. Cualquier reaparición de la enfermedad debería ser contrarrestada con una nueva destrucción inmediata antes de que pudiera propagarse.

La industria de la seda siguió las órdenes y quedó a salvo.

Pero esto hizo a Pasteur pensar sobre las enfermedades que podían transmitirse de un organismo a otro. Evidentemente, la infección del gusano de la seda por microorganismos no podía ser única. ¿No era razonable suponer que las enfermedades infecciosas estaban siempre asociadas con algún microorganismo, y que la infección consistía en el paso de un microorganismo de una persona enferma a otra sana?

La idea de Pasteur se conoce desde entonces como «teoría germinal de la enfermedad», y la frase es buena. Aunque los primeros organismos que se estudiaron en conexión con la enfermedad fueron bacterias, se ha descubierto que los agentes patógenos pueden ser más y menos complejos que las bacterias; el término más general de «germen» es precisamente el adecuado y por esa razón llamaré gérmenes a los microorganismos patógenos (productores de enfermedades) en el resto de este artículo.

Soñar con una teoría germinal de la enfermedad estaba bien, pero era preciso demostrar su validez.

En primer lugar, era preciso detectar un germen de algún tipo en organismos enfermos de cierta dolencia, sin que pudiese ser detectado en organismos libres de esa enfermedad.

En segundo lugar, el germen debía ser aislado, dejando que se multiplicara en condiciones que proporcionarían al experimentador un cultivo puro, sin ningún otro organismo.

En tercer lugar, una pequeña cantidad de este cultivo debía producir la enfermedad al introducirlo en un organismo sano.

En cuarto lugar había que aislar el germen en el organismo recién enfermado y demostrar que era capaz de producir la dolencia en otro organismo distinto.

El trabajo del médico alemán Robert Koch cumplió esos requisitos para varias enfermedades diferentes; lo cual prestó a la teoría germinal de la enfermedad una base firme. Ninguna persona sensata la ha puesto en duda desde entonces.

La teoría de los gérmenes condujo directamente a la conquista de las enfermedades infecciosas. Por primera vez se supo exactamente por qué convenía lavarse las manos antes de almorzar, por qué no era bueno emplazar el retrete demasiado cerca del pozo, por qué convenía hervir el agua en caso de sospecha, por qué era recomendable construir buenos sistemas de alcantarillado, etc. En resumen, ya no era posible igualar la higiene personal y pública a una afectada decadencia y suponer que la suciedad fuese marca de ruda masculinidad o incluso de santidad.

Una vez estudiadas las enfermedades desde ese nuevo ángulo, se descubrió también que los organismos creaban sustancias capaces de contrarrestar el efecto nocivo de los gérmenes. Tales sustancias podían cultivarse intencionadamente en animales invadidos por el germen. Las sustancias podían luego aislarse e inyectarse en seres humanos para ayudarles a combatir la dolencia. O bien cabía introducir gérmenes debilitados en seres humanos y, sin causar daño al cuerpo, obligarle a formar una sustancia capaz de combatir los gérmenes incluso en su plena potencia. En otras palabras, se desarrollaron técnicas de inmunización.

Una de las enfermedades resueltas por Pasteur desde la perspectiva de la teoría de los gérmenes fue la rabia. Se trata de una enfermedad que afecta al sistema nervioso, y los animales que la contraen muestran una conducta tan peculiar que parecen locos. (De ahí el adjetivo «rabioso».) El animal rabioso se torna increíblemente agresivo y muerde sin motivo alguno.

Como la rabia afecta principalmente al sistema nervioso, hay naturalmente una pérdida del control muscular. Cuando un ser humano afectado de rabia intenta tragar, los músculos de la garganta empiezan a contraerse incontrolada y dolorosamente. A veces, la mera visión del agua suscita la agonía, al traer a la mente el pensamiento de tragar. Por esa razón la rabia se denomina a veces «hidrofobia», utilizando palabras griegas que significan «miedo al agua».

Aunque la enfermedad no es común, es muy temida por ser prolongada, extremadamente dolorosa y casi con certeza fatal una vez declarada. El grito de «perro rabioso» y la visión del animal en un estado avanzado de la enfermedad, con la saliva formando espuma alrededor de las mandíbulas, hace que todo el mundo ponga pies en polvorosa. Y no sin razón, porque si el mordisco desgarra la piel y la saliva entra en el torrente sanguíneo de la víctima, ésta contraerá muy probablemente la enfermedad.

No había duda de que la rabia era una enfermedad comunicable, y Pasteur inició un programa ideado para aislar el germen y encontrar un medio de combatirlo. Lo cual requería un coraje rabioso también (visto desde un espíritu tímido como el mío). Era necesario empezar con la saliva de un perro rabioso, lo cual significaba apresarlo, reducirlo y extraer muestras de saliva. No habría sido más peligroso trabajar con cobras furiosas.

Pasteur consiguió sus muestras, y cuando inyectó la saliva de perros rabiosos en el torrente sanguíneo de conejos, éstos acabaron contrayendo la enfermedad.

Sin embargo, era un trabajo lento. Tras inyectarlo en la sangre, el germen de la rabia tardaba de semanas a meses en establecerse realmente. Tras haber sido mordido por un perro rabioso, un ser humano raramente tardaba menos de dos semanas en empezar a mostrar síntomas, y ese período de aterrorizada espera agravaba aún más el horror de la enfermedad.

Pasteur necesitaba encontrar un medio de cortar el período de espera. Puesto que los primeros síntomas de la enfermedad parecían ser los derivados de un desorden nervioso, parecía verosímil que el retardo fuese expresión del tiempo que tardaba el germen en trasladarse desde la sangre al sistema nervioso. Los síntomas aparecerían una vez que el germen se hubiera establecido allí. ¿Qué acontecería entonces si se inyectara directamente en el cerebro de un conejo la saliva de un perro rabioso? Tras establecerse bien la enfermedad, el cerebro y la médula espinal serían fuentes sin duda mucho más ricas del germen que la saliva.

Todas estas hipótesis eran correctas. Comenzando con una muestra de saliva de un perro rabioso, Pasteur empezó a multiplicar el germen inyectándolo en un cerebro de conejo y luego pasándolo de un conejo a otro por vía del sistema nervioso.

Al cabo de cierto tiempo tuvo una gran provisión de material patógeno, sin depender ya tanto de perros rabiosos y de la espuma de su saliva. Por otro lado, a medida que el germen pasaba de un conejo a otro parecía adaptarse a la nueva especie y hacerse menos y menos infeccioso para los perros.

Pasteur comenzó a preguntarse si no cabría reducir la virulencia del germen. Con anterioridad había debilitado (o «atenuado») gérmenes de otras enfermedades sometiéndolos a condiciones desfavorables. ¿Qué acontecería con éste?

Pasteur desecó médula espinal infectada, en presencia de un calor suave. En días sucesivos inyectó en conejos una preparación de la médula seca y observó si aparecía rabia y con qué virulencia. Era claro que el germen de la preparación se iba deteriorando, pues el virus resultaba cada día menos mortífero. Tras dos semanas no producía ya la enfermedad.

Había que comprobar si el germen atenuado era capaz de estimular al organismo para que formase una sustancia que pudiese combatir los gérmenes, aun los fuertes y virulentos. Por lo letal de la rabia una vez establecida, se diría que el cuerpo carecía de defensas; pero también podía ser que el germen, una vez afincado en el organismo, arrasara las defensas. Y podían existir muchos casos de infección mínima en los que la enfermedad fuese derrotada antes de poder establecerse y los síntomas no llegaran, por tanto, a aparecer, con lo cual todo el asunto pasaría inadvertido.

Pasteur estudió esa posibilidad inyectando su preparación atenuada de germen de rabia a un perro sano y esperando luego largo tiempo para ver si la enfermedad aparecía. Cuando quedaba claro que no había signo alguno de rabia, la cuestión era determinar si el perro había adquirido una defensa antirrábica. Para verificarlo se metió al perro en una jaula ocupada por otro rabioso. El perro rabioso atacó de inmediato y armó allí la de San Quintín. El perro sano fue rescatado después de haber sido vapuleado y mordido a conciencia… pero no cogió la rabia.

Ahora bien, ¿y en el hombre? ¿Cómo atreverse a realizar los experimentos necesarios en seres humanos, incluso en criminales condenados? La posibilidad de contagiar accidentalmente la rabia a un ser humano era intolerable para alguien como Pasteur.

El 4 de julio de 1885, un muchacho alsaciano de nueve años, Joseph Meister, sufre mordeduras graves por un perro rabioso. Las heridas son tratadas con ácido carbólico, pero sabiendo que ese remedio es inútil frente a la enfermedad, parece sensato llevar al niño a Louis Pasteur.

Si la enfermedad hacía mella en el sistema nervioso del muchacho sería demasiado tarde, pero había un período de gracia, y Pasteur se dispuso a trabajar rápidamente. El caso parecía recomendar un experimento, pues si Pasteur no hacía nada el muchacho moriría sin duda entre agonías.

Pasteur empezó por inyectar la preparación rábica más atenuada, luego otra menos atenuada, luego una tercera aún menos atenuada, y así sucesivamente, confiando en que el niño crearía defensas masivas antes de que los verdaderos gérmenes se apoderasen del sistema nervioso. Tras once días, Pasteur estaba inyectando al joven Joseph gérmenes prácticamente sin atenuar. El muchacho no contrajo la rabia, y Pasteur fue más que nunca el hombre milagro.

(Por cierto, el fin de Joseph Meister fue trágico. Creció y acabó trabajando de portero en el Instituto Pasteur, la institución de investigación bautizada con el nombre del gran hombre que le había salvado y en cuyos sótanos estaba enterrado Pasteur. En 1940, con 64 años y siendo todavía portero, los nazis tomaron París. Por curiosidad, un oficial nazi le ordenó que abriese la cripta de Pasteur. Antes que hacerlo Meister prefirió suicidarse.)

En todo su trabajo sobre la rabia, Pasteur no había logrado cumplir el primer requisito de la teoría de los gérmenes como origen de las enfermedades. No había detectado ningún germen en ninguna de sus preparaciones y menos ninguno relacionado con la rabia. Todos los gérmenes que fue detectando resultaron ser incapaces de producir la enfermedad. (Uno de los que detectó fue estudiado por el médico alemán Albert Fraenkel en 1886; resultó ser el causante de la pulmonía.)

Estrictamente hablando, la ausencia de cualquier germen detectable podría tomarse como prueba de que la teoría de los gérmenes era equivocada. Pero a Pasteur no se le pasó eso ni un momento por la mente. Para él estaba claro que todo su trabajo con la rabia tenía sentido si suponía que existía un germen. El hecho de no ver él ninguno no significaba que no existiese; sólo demostraba que él no lo veía.

No hay nada místico ni sorprendente en lo que acabo de decir. Dadas las circunstancias, la afirmación es perfectamente lógica. Los microorganismos poseen varios tamaños. Algunos son tan grandes que en condiciones favorables pueden verse como motas claramente visibles a simple vista. Otros son más pequeños, y otros más pequeños aún, hasta el punto que apenas pueden ser divisados con un buen microscopio del tipo de los de Pasteur.

¡Qué monumental coincidencia sería que los microorganismos más pequeños resultasen ser lo bastante grandes como para ser contemplados a través del microscopio de Pasteur, y que no hubiese microorganismos más pequeños aún! La coincidencia hubiese sido en verdad increíble, y Pasteur no creyó en ella. Estaba seguro de que existían microorganismos demasiado pequeños para que los detectara su microscopio, y de que uno de esos gérmenes demasiado pequeños era el causante de la rabia.

Pero ¿depende uno exclusivamente de los ojos? ¿No habrá algún modo de detectar un germen pequeño que no consista en verlo?

Supongamos, por ejemplo, que filtramos una preparación donde no parecen existir gérmenes en absoluto, pero que es capaz de provocar una enfermedad cuando se inyecta en un animal sano. Supongamos que utilizamos como filtro una sustancia con agujeros minúsculos. Si los agujeros fuesen demasiado minúsculos para dejar pasar a los gérmenes, pero lo bastante grandes como para permitir que pasen las moléculas de agua, el fluido emergente del filtro ya no será patógeno. Pero el material retenido en el filtro, una vez lavado, sí será capaz de transmitirla. Así es como se puede detectar un germen sin verlo realmente.

Un bacteriólogo francés, Charles Edouard Chamberland, construyó un filtro capaz de retener objetos tan minúsculos como el germen medio. Se trataba de un cilindro hueco con el fondo cerrado por porcelana no vitrificada. Debido a su aspecto se llamó «bujía Chamberland».

El Primero en usar tal filtro -con el fin de aislar un germen de una preparación líquida- fue el bacteriólogo ruso Dimitri Alexeievich Ivanovski, quien trabajaba a la sazón con plantas de tabaco afectadas por una enfermedad que producía un dibujo de mosaico jaspeado sobre las hojas: la enfermedad del mosaico del tabaco.

Macerando las hojas, podía extraerse un jugo capaz de provocar la enfermedad al extenderlo sobre plantas de tabaco sanas. Con arreglo a la teoría de los gérmenes, cabía esperar el descubrimiento de un germen en el jugo, germen que sería el transmisor de la enfermedad.

Sin embargo, Ivanovski no logró encontrar signo alguno de germen en el jugo que transmitía la enfermedad. Mas no se contentó con abandonar el tema diciendo que el germen era demasiado pequeño para ser visible. Menos imaginativo que Pasteur, supuso que el defecto radicaba de algún modo en su propia persona, y se le ocurrió utilizar un método distinto del visual para atrapar al germen.

En 1892 hizo pasar el líquido que portaba la enfermedad a través de una bujía Chamberland, y descubrió que el filtrado seguía siendo capaz de transmitir la enfermedad a plantas de tabaco sanas.

El hecho podía ser interpretado como confirmación de la intuición de Pasteur; el germen, puesto que pasaba a través de un filtro capaz de retener gérmenes comunes, tenía que ser más pequeño que éstos y demasiado diminuto para ser detectado por un microscopio.

Desgraciadamente, Ivanovski no pudo desprenderse de su resistencia a aceptar que había algo demasiado pequeño para ser visto en un microscopio. Su interpretación de los resultados fue que la bujía Chamberland utilizada era defectuosa. De manera que aunque a veces se le considera el primero en demostrar la existencia de formas de vida sub-bacterianas, su reivindicación de esa fama queda menoscabada por el hecho de no percatarse él mismo del significado de su trabajo.

El experimento se intentó de nuevo en 1898. Esta vez fue un botánico holandés, Marínus Willem Beijerinck, quien también estaba trabajando sobre la enfermedad del mosaico del tabaco, utilizando asimismo un extracto capaz de transmitir la enfermedad pero en el cual no había trazas de germen alguno. Lo hizo pasar, como Ivanovski, a través de un filtro de porcelana no vitrificada, y obtuvo un líquido capaz aún de comunicar la enfermedad.

Sin embargo, a diferencia de Ivanovski, Beijerinck no supuso defectos en el filtro. Afirmó, lisa y llanamente, que había demostrado la existencia de un germen demasiado pequeño para ser visto en un microscopio y lo bastante minúsculo como para pasar a través de los poros de la porcelana no vitrificada.

Beijerinck había llamado a este fluido portador de enfermedad «virus», término proveniente de una palabra latina para un extracto vegetal venenoso (como el jugo de la cicuta que mató a Sócrates). En definitiva, el fluido extraído de plantas de tabaco enfermas era una especie de extracto vegetal venenoso. Puesto que el virus de la enfermedad del mosaico del tabaco atravesaba un filtro pero seguía siendo un «virus» Beijerinck lo llamó «virus filtrable». Es, pues, a Beijerinck a quien le cupo el mérito de descubrir los agentes patógenos sub-bacterianos.

Habiendo optado por la pequeñez, Beijerinck se fue al extremo y afirmó que el virus filtrable era una especie de fluido viviente; esto es, una forma de vida con partículas del mismo orden de complejidad que las del agua u otros líquidos comunes.

Pero esta vez erró, y la prueba vino de la mano de filtros aún más finos. El bacteriólogo inglés William Joseph Elford abandonó la porcelana no vitrificada y utilizó membranas de colodión. Los métodos para prepararlas permitían obtener poros de cualquier tamaño. Se podían fabricar membranas con poros lo bastante pequeños como para detener objetos mucho menores que las bacterias comunes.

En 1931 Elford hizo pasar virus filtrables a través de membranas capaces de detener objetos de diámetro cien veces menor que el de una bacteria común. Filtrado a través de la membrana, el fluido resultante no era infeccioso. El germen había sido atrapado. Era mucho menor que un germen común, pero seguía siendo mucho mayor que una molécula de agua. El virus filtrable no era una forma de vida líquida [19].

El término «virus filtrables», aplicado por Beijerinck al fluido portador de la enfermedad, se desplazó ahora al propio agente infeccioso. La expresión quedó simplemente en «virus», y éste es el término que hoy se acepta universalmente para algo mucho menor que una bacteria pero lo suficientemente vivo como para transmitir una enfermedad.

Pero ¿qué son los virus? ¿Simplemente bacterias ultra pequeñas? ¿O acaso tienen propiedades peculiares que hacen de ellos una forma completamente nueva de organismo?

Pues bien, si termino un capítulo con una pregunta, podéis estar seguros de que el próximo capítulo tratará de la respuesta.

10. De la ameba para abajo

La semana pasada estuve en una fiesta. La mayoría de nosotros, yo incluido, estábamos en el piso de abajo con las bebidas y (en mi caso) con los entremeses. En el piso de arriba, prácticamente sola, estaba la joven que había tenido la amabilidad de acompañarme. Siendo una criatura callada y sensible, necesitaba retirarse de cuando en cuando.

Más tarde me diría: «Estaba medio dormida cuando súbitamente percibí la voz rápida, temblorosa y cascada de un hombre muy, muy viejo en el piso de abajo. Me desperté bruscamente, sabiendo que no había ningún anciano en la fiesta. Escuché, pero no pude distinguir las palabras. Luego la voz se detuvo y hubo un estruendo de risas. Me tranquilicé, pues sabía que eras tú contando el chiste del rabino de ochenta y ocho años» [20].

Lo cual revela dos cosas sobre mí. En primer lugar, que cuento chistes condenadamente bien. La modestia me prohíbe decirlo, pero nunca escucho a Modestia.

La segunda cosa es que tiendo a repetirme. Cuando oigo un chiste que me gusta me paso por lo menos un mes contándoselo al primero que encuentro; quiere decirse que un acompañante asiduo está condenado a oírlo 2.700 veces, con lo cual puede identificarlo de lejos sobre la base del más leve indicio.

Este recordatorio más bien duro de mi tendencia a repetirme hizo que me sintiera un poco auto-conciente. En definitiva, el capítulo que tenéis ante vosotros hace el número 173 de mis artículos mensuales para la Revista de Fantasía y Ciencia ficción (aproximadamente 700.000 palabras, por amor de Dios); forzoso es que haya alteraciones aquí y allá. Este capítulo y el anterior tratan de microorganismos, por ejemplo. ¿Había tocado ya antes el tema? Voy a mi lista de ensayos de fantasía y ciencia ficción, y resulta que hay algunos comentarios sobre microorganismos en dos ensayos escritos hace once años.

Pero la reiteración no es grande. El enfoque y el detalle son ahora muy distintos, y ha pasado mucho tiempo. Proseguiré, pues, con la conciencia en un estado de pureza químicamente limpia.

Por ejemplo, en esos primeros ensayos analicé el tamaño de los microorganismos; ahora voy a hacerlo de nuevo, pero con un propósito diferente.

Empecemos con el microorganismo del que todo el mundo ha oído hablar, si es que ha oído hablar de alguno: la ameba. Una ameba de tamaño medio tiene aproximadamente 1/125 de pulgada de diámetro, pero nadie utiliza pulgadas a la hora de hacer tales mediciones. Si pasamos al sistema métrico podemos usar milímetros, cada uno de los cuales es aproximadamente 1/25 de pulgada. En consecuencia, puede decirse que el diámetro de la ameba es un quinto de milímetro o, si preferís, 0,2 milímetros.

Sin embargo, sería mejor utilizar el mili-micrómetro como unidad de medida, y aún mejor darle su actual nombre de «nanómetro». Puesto que hay un millón de nanómetros en un milímetro, podemos decir que la ameba tiene un diámetro de 200.000 nanómetros.

La yuxtaposición de 1/125 de pulgada y 200.000 nanómetros es significativa. El diámetro es el mismo expresado de ambos modos, pero 1/125 muestra que la ameba es muy pequeña en la escala común, y 200.000 muestra que es muy grande en la escala microscópica. Puesto que vamos a permanecer en el reino de lo sub-microscópico, quedémonos con el nanómetro como unidad y evitemos el tedio de repetirlo cada vez, dando la palabra por entendida.

La ameba está compuesta por una sola célula. Sólo definiré «célula» como una burbuja de materia viviente encerrada dentro de una membrana. El desproporcionado tamaño de la ameba resulta manifiesto si os digo que cada una de las células de nuestro cuerpo -unos 50 billones- es menor que la ameba. La mayor de las células humanas (que sólo existe en la mujer) es el óvulo, con un diámetro de 140.000 nanómetros aproximadamente. La célula humana media tiene un diámetro de unos 55.000.

La diferencia de tamaño es todavía más radical si consideramos el volumen en vez del diámetro. Una ameba tiene casi cuatro veces el diámetro de la célula somática media, lo cual le proporciona un volumen aproximadamente cincuenta veces superior. Pero la ameba no está más cabalmente viva que la célula somática por ser más grande, como tampoco está más vivo un hombre que un ratón.

Con todo, cabría aventurar, no sin razón, que tiene que haber un momento en que la célula se haga tan pequeña que no pueda seguir estando completamente viva, Diríase que no hay espacio suficiente para albergar todos los ingredientes necesarios de la vida.

Consideremos, por ejemplo, los glóbulos rojos, de los cuales hay aproximadamente cinco millones por cada centímetro cúbico de sangre. Son una de las células más pequeñas del cuerpo humano, con forma de disco y un diámetro superior de 7.500 solamente. Pues bien, los glóbulos rojos no poseen todos los ingredientes que asociamos generalmente con la vida.

La célula típica tiene un núcleo, un cuerpo pequeño situado más o menos en el centro de la célula, y todo lo demás es «citoplasma». El glóbulo rojo no tiene núcleo y es esencialmente un saco de citoplasma. Puesto que la maquinaria para la división celular está contenida en el núcleo, el glóbulo rojo, al carecer de él, nunca puede dividirse. Desempeña su trabajo, llevando moléculas de oxígeno desde los pulmones a las células del cuerpo, hasta que se desgasta (al cabo de unos tres meses), siendo entonces desmantelado. Sin embargo, el cuerpo no se queda sin glóbulos rojos, porque continuamente se están formando otros a partir de precursores que sí tienen núcleo.

Cabría decir, y a menudo se hace, que el glóbulo rojo no es una célula completa aunque esté vivo (pues metaboliza). A veces se le niega el nombre de célula y se le denomina «corpúsculo».

Tampoco es el glóbulo rojo la unidad viviente más pequeña del cuerpo. La más pequeña de todas (presente sólo en el varón) es la célula espermática, cuyo diámetro es aproximadamente de 2.500, con lo cual caben dentro de una sola ameba medio millón de ellas.

La célula espermática es poco más de la mitad de un núcleo, y punto. Con esa mitad de núcleo no puede dividirse, y como sólo posee un minúsculo citoplasma (en el que existe el aparato productor de energía de la célula) no puede permanecer viva mucho tiempo. Tiene justamente la energía bastante para hacer esa loca carrera hacia el óvulo (si es que hay alguno en la vecindad) y en caso de suerte superlativa, entrar y fertilizarlo. Si no hay óvulo presente, o si algún otro candidato le gana por la mano, la célula espermática muere.

A la vista de eso ¿podemos afirmar que una célula espermática es una célula completa? Quizás no. Su único propósito, a fin de cuentas, es unirse a otra célula para formarse completa. Y no es cuestión de tamaños. El óvulo humano, que, ya lo dije, es la mayor de las células del cuerpo, tampoco contiene sino medio núcleo, y no puede dividirse hasta que un espermatozoide entra y añade la otra mitad.

Así pues, prescindiendo del tamaño, ¿debemos definir la «célula completa» como aquella que tiene un núcleo completo junto con citoplasma suficiente para una adecuada producción de energía a fin de que pueda dividirse?

En ese caso, ¿qué decir de las células nerviosas y musculares del cuerpo humano? Ambos tipos de células están tan especializados que han perdido la capacidad de dividirse, pese a tener un núcleo perfectamente bueno y un citoplasma de sobra adecuado. Cada célula nerviosa y. muscular puede vivir más de un siglo, y así sucede con muchas, pues de lo contrario no podría sobrevivir el ser humano. Sería necio no llamarlas células porque no se dividen y, de hecho, ningún fisiólogo les niega el nombre.

Pero si no insistimos en la división celular como criterio de completitud para la célula, ¿con qué derecho negamos que un glóbulo rojo sea completo? Ciertamente, no posee un núcleo, pero hace lo que debe, con eficacia, durante tres meses, y es injusto pedirle más.

Propondré, pues, un criterio diferente de completitud celular.

Las sustancias químicas características de las células son las grandes moléculas de ácidos nucleicos y proteínas. Ciertas proteínas llamadas «enzimas» catalizan reacciones específicas dentro de las células. Sin esas enzimas en pie de guerra una célula no puede realizar las reacciones químicas características de la vida y, en el mejor de los casos, sólo puede vivir en una especie de animación suspendida durante algún tiempo.

En cuanto a los ácidos nucleicos, anidan en primer lugar de que se formen las enzimas apropiadas.

Sin ácidos nucleicos, la célula tiene que arreglárselas con las enzimas ya presentes, y mientras éstas duren. Con ácidos nucleicos, en cambio, una célula puede vivir mucho tiempo, porque los ácidos pueden renovarse a sí mismos y fabricar nuevas enzimas a partir de pequeñas moléculas absorbidas del mundo exterior. Si no está demasiado especializada como para no poder dividirse, una célula con ácido nucleico, y sus descendientes, pueden vivir de modo indefinido.

Definamos, pues, una célula completa como aquella que posee todas las grandes moléculas (enzimas y ácidos nucleicos) necesarias para sus funciones normales; o, caso de no tener suficiente de una de esas cosas o de ambas, como aquella célula que puede construir lo que necesita a partir de las pequeñas moléculas de su medio.

Una célula incompleta sería aquella que carece de algunas de las grandes moléculas que necesita y no puede construirlas a partir de moléculas pequeñas. Tal célula sólo puede permanecer en animación suspendida y acabar muriendo, salvo que de algún modo logre hacer uso de las grandes moléculas de otra célula, distinta de ella misma. Dicho con otras palabras, una célula incompleta sólo puede funcionar si, al menos durante parte de su vida, es parásita de una célula completa.

Con arreglo a esta definición el glóbulo rojo es completo, mientras que el óvulo y el espermatozoide son incompletos. Cada uno de éstos es media célula condenada a un lapso vital limitado, hasta llegar el momento de unirse y hacerse célula completa; cada cual depende en parte de las grandes moléculas del otro para construir una vida más plena.

Ahora bien, el mutuo parasitismo de óvulo y espermatozoide es cosa vista y no vista. Una vez combinados, el «óvulo fertilizado» resultante es permanentemente completo. Frente a eso, ¿hay fragmentos de vida que sean permanentemente incompletos, parásitos de células completas que en modo alguno se tornen completos a lo largo del proceso?

De existir, cabe sospechar que tendrán un tamaño más pequeño que el de las células comunes de criaturas multicelulares como nosotros. La célula espermática humana, con un diámetro de 2.500, es ya tan pequeña que sólo puede contener la mitad de un núcleo y prácticamente ningún citoplasma. Cualquier cosa de ese tamaño o más pequeña (podría razonarse) habrá de ser incompleta por simple falta de espacio para el número mínimo de grandes moléculas que requiere el total funcionamiento celular.

Esto nos lleva, naturalmente, al mundo de las bacterias, todas ellas menores que el espermatozoide humano. Las bacterias mayores tienen quizá 1.900 nanómetros de diámetro; 1.000 podría considerarse la media. Y ¿no son parásitos? Quien más, quien menos, piensa que las bacterias viven despiadadamente a costa de otros seres vivos, y especialmente del hombre.

Pero eso es equivocado. La mayor parte de las bacterias son saprófitas, seres que viven de los residuos muertos de cosas vivas. Incluso las que son parásitas -en el sentido de florecer dentro de organismos vivos- viven de las pequeñas moléculas presentes en esos organismos (en los intestinos, donde habitualmente no nos molestan; y a veces en la sangre, donde habitualmente sí molestan).

No obstante su pequeño tamaño, las células bacterianas son completas. Sólo necesitan un suministro de pequeñas moléculas; a partir de ellas pueden manufacturar todas las grandes moléculas que necesitan. En algunos aspectos su versatilidad química supera a la de las células grandes que componen nuestro cuerpo.

Por este motivo, las bacterias, incluso las parásitas, pueden cultivarse en el laboratorio con medios artificiales donde se contengan las pequeñas moléculas que necesitan. Y porque pueden ser cultivadas y estudiadas en aislamiento, la medicina de finales del siglo XIX pudo dar el paso hacia la conquista de las enfermedades bacterianas.

Pero ¿cómo pueden ser completas las células bacterianas cuando son tan minúsculas y tan inferiores en tamaño a la célula espermática, donde sólo hay medio núcleo? La bacteria más pequeña conocida es el organismo de la pleuroneumonía, cuyo diámetro es de 150 nanómetros solamente. Caben unas 2.000 de esas bacterias en un espacio que tenga las dimensiones de una célula espermática humana.

Esto parece paradójico, mas no sería justo comparar el núcleo requerido para contener todos los elementos de control de un organismo del tamaño y complejidad de un ser humano y sus decenas de billones de células cooperativas, con el núcleo necesario para el funcionamiento de una minúscula burbuja de materia muy inferior en tamaño a cualquiera de esas células. Porque a tenor de eso cabría decir entonces que, siendo necesario un corazón para el funcionamiento de cualquier mamífero, no podría existir ningún mamífero de tamaño inferior al corazón humano (un ratón, por ejemplo). Después de todo, el ratón tiene también un corazón, pero mucho más pequeño que el nuestro.

Análogamente, la célula bacteriana tiene también materia nuclear, pero necesita mucha menos que nuestras células. Y digo «materia nuclear» porque la célula bacteriana no tiene núcleo nítido, pero sí los ácidos nucleicos habitualmente encontrados en el núcleo de la célula. Los ácidos nucleicos están localizados en trocitos por toda la célula bacteriana. En este sentido, las bacterias se asemejan a ciertas células vegetales muy simples llamadas algas verdiazules, que son estructuralmente como bacterias, salvo que son algo mayores y poseen clorofila.

Las bacterias y las algas verdiazules representan al parecer un estadio muy primitivo en la evolución. A medida que las células se hicieron mayores y más complicadas, la cantidad creciente de materia nuclear necesaria para la manufactura de enzimas fue reunida en un núcleo compacto, para que la división celular pudiera verificarse así de manera impecable. Pero el hecho de que las bacterias y las algas verdiazules sean más primitivas en este sentido no significa que tales células sean incompletas, igual que el hecho de ser más primitivo que nosotros no hace que el gusano terrestre sea un organismo menos completo.

Llegamos así a Howard Taylor Ricketts, un patólogo americano que hace unos setenta años estudió el tabardillo pintado de las Montañas Rocosas, una grave enfermedad que mataba al 20 por 100 o más de quienes la contraían.

Ricketts logró mostrar que era básicamente una enfermedad de las garrapatas y de los pequeños animales de cuya sangre se alimentaban. A veces la tenían las garrapatas del ganado; y era a través de éste como solían contraer la enfermedad los seres humanos. Ricketts consiguió localizar el microorganismo productor de la dolencia y mostró que era transmitido de la garrapata al mamífero y de nuevo a la garrapata.

Pasó luego a estudiar una enfermedad aún más extendida y grave, el tifus, producido por un microorganismo similar, que primero infestaba al piojo y luego pasaba de una persona a otra debido al mordisco de esa pequeña criatura.

Mientras estudiaba el tifus en la ciudad de Méjico, Ricketts contrajo la enfermedad y murió de ella el 3 de mayo de 1910, a los veintinueve años. Méjico observó tres días de luto en su recuerdo. Los organismos que causan el tabardillo pintado de las Montañas Rocosas y el tifus se denominan rickettsias en su honor, y las enfermedades consiguientes son ejemplos de «enfermedades rickettsiales».

Las rickettsias parecen pequeñas bacterias, con diámetros típicos de 475, pero no pueden ser cultivadas en medios artificiales como acontece con otras bacterias. Las rickettsias se mantienen en vida suspendida fuera de las células, y sólo pueden crecer dentro de las células de las criaturas por ellas infectadas.

Carecen al parecer de ciertas enzimas claves necesarias para el crecimiento y la reproducción, y no pueden fabricarlas a partir de moléculas pequeñas. Dentro de la célula invadida hacen uso de las enzimas allí presentes para sus propios propósitos.

Así, pues, las rickettsias son ejemplos de verdaderas células incompletas, que viven como parásitos de células completas y que a lo largo del proceso no devienen completas.

Tampoco es cuestión de tamaño. Una célula rickettsial típica tiene unas 30 veces el volumen del organismo de la pleuroneumonía y, por tanto, puede suponerse que tiene espacio para 30 veces más cantidad de cada molécula grande. Sin embargo, una molécula grande clave, por lo menos, debe faltar en la célula rickettsial, mientras que no hay ninguna que falte totalmente en el organismo de la pleuroneumonía, con lo cual la primera es una célula incompleta y la segunda una célula completa.

¿Qué decir entonces de los virus de que hablé en el capítulo anterior? William Elford, como dije, filtró una suspensión del virus y retuvo el agente infeccioso. Mostró que los virus deben ser partículas con un diámetro de 100 nanómetros (o al menos el del virus con el que trabajó). En realidad, algunos son mayores, casi la mitad del diámetro de una célula rickettsial. Otros, por el contrario, son mucho más pequeños. El virus de la necrosis del tabaco, por ejemplo, sólo tiene un diámetro de 16.

Veinticinco mil partículas del virus de la necrosis del tabaco pueden embutirse en un volumen igual al de una célula rickettsial, casi cuatro millones en el volumen de una célula espermática humana, dos billones en el volumen de una ameba. En efecto, un virus tan minúsculo sólo tiene unas 15 veces el volumen de una molécula proteínica media.

Sin duda, los virus deben ser células incompletas que sólo pueden vivir, como las rickettsias, dentro de las células que parasitan; pero al ser mucho más pequeños no pueden ser detectados ni dentro ni fuera de la célula por ningún microscopio ordinario.

De hecho, ¿están realmente vivos? ¡Porque tiene que haber un límite por debajo del cual un objeto no puede ser vivo! Las partículas víricas son tan pequeñas que no pueden contener sino muy pocas moléculas según los criterios celulares ordinarios. ¿Cómo puede haber las suficientes para dotarles de las complejas propiedades de la vida?

Como nadie ignora, los virus crecen y se multiplican con feroz velocidad una vez dentro de una célula, y es bastante lógico suponer que allí readaptan el material a los fines de su propia estructura, y no sin eficacia. ¿No basta con eso para considerarlos vivos? ¿Qué más puede hacer cualquier otro organismo viviente?

La naturaleza, sin embargo, no conoce fronteras rígidas, y, si nos paramos a pensar un poco veremos que en el curso de la evolución gradual de las moléculas grandes a partir de las pequeñas, en el océano primordial, tuvo que haber un período en el que existieran moléculas o sistemas de moléculas no lo bastante complejos como para adquirir todas las propiedades que atribuimos a la vida, pero sí lo bastante complejos como para adquirir algunas de ellas.

Si hubo esa época de subvida, ¿no podría ser que los virus sean residuos que han sobrevivido hasta hoy? En ese caso, ¿no pertenecerán a una clase especial de objetos que en realidad no son ni vivientes ni no-vivientes?

¿Dónde trazar la línea divisoria? ¿Son los virus la forma más simple de vida, la forma más compleja de no-vida, o están en la línea fronteriza?

Llegamos así a Wendell Meredith Stanley, quien, de estudiante en el Earlham College de Indiana, jugaba al fútbol americano con maestría y cuya ambición era ser entrenador de ese deporte. Sin embargo, mientras visitaba el campus de la Universidad de Illinois fue tan incauto como para enzarzarse en una discusión con un profesor de Química. Despertó así a una nueva afición, y nunca llegó a ser entrenador de fútbol. Logró su doctorado en Illinois, estudió en Europa, y en 1931 pasó al Rockefeller Institute, en Nueva York.

El Rockefeller Institute estaba trastornado en aquella época por una nueva hazaña bioquímica, la cristalización de enzimas.

En un cristal, los átomos, iones o moléculas están dispuestos con gran regularidad. Esta regularidad es lo que proporciona al cristal sus propiedades. Naturalmente, cuanto mayor y más compleja sea una posible partícula constituyente, tanto más difícil es conseguir que cierto número de ellas ocupen las posiciones regulares necesarias.

Sin embargo, trabajando con una solución bastante pura de una proteína específica es posible forzar las moléculas a que ocupen posiciones cristalinas. En 1926 una enzima llamada ureasa había sido cristalizada por James Batcheller Sumner, y esto fue la prueba final de que las enzimas eran proteínas. En 1930, John Howard Northrop, en el Rockefeller Institute, había cristalizado la famosa enzima digestiva pepsina.

En medio de la emoción suscitada por la cristalización de materiales biológicos hasta entonces no cristalizados, a veces en la mismísima institución donde Stanley estaba trabajando, se le ocurrió intentar cristalizar un virus.

El virus del mosaico del tabaco parecía bueno para ese fin. Era más fácil trabajar con un huésped vegetal que con uno animal, y las plantas de tabaco podían criarse en el invernadero del Instituto. Stanley las cultivó, las infectó con la enfermedad del mosaico del tabaco, las cosechó, exprimió las hojas, manipuló el jugo y dio todos los pasos necesarios para concentrar y purificar proteínas.

Finalmente, logró aislar en 1935 unos pocos gramos de unas minúsculas agujas blancas que representaban el virus cristalino, habiendo empezado con una tonelada de plantas de tabaco.

El descubrimiento de Stanley ocupó la primera plana del Times de Nueva York y más tarde, en 1946, Sumner, Northrop y Stanley compartieron el premio Nobel de Medicina y Fisiología.

Los cristales víricos pasaron todos los tests de las proteínas, por lo cual el virus era esencialmente proteína. Hasta ahí, todo perfecto. Los cristales se conservaban bien a bajas temperaturas, como las proteínas, e incluso tras largo tiempo de almacenamiento seguían siendo infecciosos. Es más, un peso dado del virus cristalizado era cientos de veces más infeccioso que las soluciones típicas ensayadas.

El hecho de que el virus pudiera mantenerse almacenado durante largos períodos de tiempo sin perder infectividad (sin morir, en otras palabras) no demostraba que el virus no estuviese vivo. Ciertas bacterias pueden formar esporas capaces de permanecer en animación suspendida durante más tiempo y soportar condiciones más duras que un cristal vírico y, sin embargo, nadie niega que la espora bacteriana esté viva.

No. Era más bien el que los virus pudiesen cristalizarse lo que parecía indicar que no se trataba de cosas vivientes. El propio Stanley capitaneó la lucha en favor del criterio de que los virus, siendo cristalizables, no podían ser vivientes.

Pero ¿es así? Hasta 1935 los cristales habían sido desde luego asociados sin remisión con las sustancias no vivientes. Abundaban sobre todo en el campo de las sustancias inorgánicas, donde cualquier compuesto puro podía ser cristalizado, habitualmente sin complicaciones. Incluso los cristales orgánicos estaban compuestos de moléculas simples que podían estar asociadas con la vida y encontrarse en tejidos vivientes, pero que, de suyo, no cabía llamar vivientes por mucha imaginación que se echara al asunto.

Retrocediendo a antes de 1935: las enzimas cristalizadas de Sumner y Northrop estaban hechas de conjuntos ordenados de moléculas anormalmente grandes y complejas, pero que seguían siendo no vivientes con arreglo a cualquier criterio razonable.

Una vez cristalizado un virus, cabía argüir, y se arguyó, que los virus no eran organismos vivos, sino una molécula proteínica no viviente.

La cosa parecía razonable, pues era difícil concebir un organismo cristalizado. ¿Os imagináis, por ejemplo, una humanidad cristalina?

Y, sin embargo, había una diferencia entre un virus y una molécula proteínica no viviente. Algunas moléculas proteínicas tenían sobre el organismo un efecto tan poderoso como el de un virus. Algunas mataban rápidamente en muy pequeñas cantidades.

Pero había una cosa inasequible a toda molécula proteínica no viviente y posible para un virus, y es que la molécula proteínica no viviente no puede trascenderse a sí misma. Una pequeña cantidad de proteína puede afectar a un organismo, pero un extracto de ese organismo es incapaz de afectar un segundo del mismo modo. En el caso del virus la infección podía propagarse de un organismo a otro y a otro y a otro indefinidamente.

Además, ¿qué magia tiene la cristalización que la divorcie de la vida? La característica clave de un cristal es la disposición ordenada de sus partículas constituyentes. Mas ¿por qué no pueden ser vivientes esas partículas si resultan ser lo bastante simples en estructura? Suficiente simplicidad para cristalizar y suficiente complejidad para estar vivo no son realmente posibilidades de cara a ninguna ley de la naturaleza. Se suponía que ambas propiedades se excluían mutuamente, porque hasta 1935 ninguna cosa conocida poseía ambas. Pero suponed que los virus contienen ambas.

Para mostrar que no es ridículo, seamos un poco más liberales en la definición de cristal y preguntémonos de nuevo si no cabría imaginar una humanidad cristalina. ¡Pues sí! ¡Yo mismo he visto casos!

Columnas de soldados que marchan a lo largo de una avenida en un desfile componen una especie de cristal humano. Las propiedades de una masa de diez mil hombres en orden de formación y marchando al paso son completamente diferentes de las de una masa de otros tantos moviéndose a voluntad en perfecto desorden. El éxito casi inevitable de un batallón militar entrenado frente a un número igual de civiles igualmente armados es en parte producto de que las propiedades del hombre cristalino convienen más a la guerra organizada que las del hombre tumulto.

Por eso, un escuadrón de aviones en formación cerrada tiene propiedades cristalinas. Imaginaos que esos mismos aviones rompen de pronto la formación y toman direcciones al azar. El resultado podía ser un instantáneo desastre. Son necesarias las propiedades cristalinas de la formación para hacer que vuelen seguros.

Pienso, pues, que el dato de que los virus puedan ser cristalizados no incide para nada en el problema más amplio de su naturaleza viviente o no viviente. Debemos buscar otras pruebas, y en 1937, dos años después de la cristalización, Frederick B. Bawden y Norman W. Pirie, dos bioquímicos ingleses, mostraron que los virus no son enteramente proteína.

Pero ésa es otra historia. La historia del siguiente capítulo.

11. El compuesto Cenicienta

Existe una organización que se dedica a computarizar las citas bibliográficas científicas. En un campo específico de la ciencia recorre los artículos pertinentes, estudia los escritos a que aquellos remiten, luego aquellos otros que se citan en éstos, etc. Algunos artículos son citados más a menudo que otros, y con la ayuda de la computadora es posible establecer una red donde aparecen las referencias claves: las grandes líneas divisorias que determinan una nueva dirección en la corriente de la ciencia.

Como es natural, la organización quería saber si con sólo contar y organizar las referencias estaba obteniendo un cuadro fiel del progreso de la ciencia. Así pues, proyectó comparar sus resultados con el. cuadro ofrecido por algún libro sobre el tema y que proporcionase la perspectiva histórica vista por un científico perspicaz. La computadora sería así cotejada con el juicio e intuición de un experto cualificado.

Me enteré de esto porque hace varios años la organización me escribió para informarme. Habían decidido utilizar la biología molecular como campo de experimentación (pues ésa era precisamente la rama científica más apasionante en el cuarto de siglo siguiente a la Segunda Guerra Mundial), y el libro que planeaban utilizar como pauta de comparación era El código genético, publicado en 1962 y escrito por -¡todos a una, ahora!– Isaac Asimov.

Huelga decir que un color se me iba y otro se me venía, pero antes de que muráis de intriga os diré que el final fue feliz. El diagrama extraído de mi libro y el diagrama elaborado por la computadora coincidían bastante bien.

Ellos gritaron de triunfo, porque creían probada la bondad del programa de automación. Yo suspiré de alivio, por no verme en la picota como experto menos que cualificado.

Pero lo que más me interesó fue que la computadora y yo coincidimos en un descubrimiento clave que sirvió para canalizar toda la investigación por nuevos derroteros, aunque el científico responsable de ese hallazgo sigue siendo desconocido para el gran público. Una docena de hombres de la especialidad recibieron el premio Nóbel por explorar el camino que él indicó, pero no así él. Hay nombres que hoy día son casi familiares, pero no el suyo.

Os contaré, pues, en qué coincidimos la computadora y yo, especialmente porque enlaza con los dos capítulos anteriores. Para ello, empecemos retrocediendo un siglo.

El bioquímico suizo Johann Friedrich Miescher, que a la sazón sólo contaba veinticinco años, descubrió en 1869 que los núcleos celulares parecían bastante resistentes a la acción de la pepsina, una enzima que actúa rompiendo proteínas. Del núcleo extrajo cantidades apreciables de algo que, fuese lo que fuese, no era proteína. Considerando la fuente, lo denominó «nucleína».

Miescher analizó la nucleína y descubrió que contenía tanto nitrógeno como fósforo. Ernst Felix Hoppe-Seyler, el bioquímico alemán a cuyas órdenes trabajaba Miescher, se aferró inmediatamente al trabajo y no dejó que fuese publicado hasta dos años después. Y no porque albergara alguna duda sobre la gran importancia del hallazgo, sino porque hasta entonces sólo otro compuesto aislado del tejido viviente había resultado tener a la vez átomos de nitrógeno y de fósforo en su molécula. Se trataba de la lecitina, y la había descubierto el propio Hoppe-Seyler.

Hoppe-Seyler, siendo humano además de bioquímico, no quería ver ligeramente empañado el carácter único de su descubrimiento, y no permitió que la noticia saliera del laboratorio hasta que él mismo confirmó por entero el trabajo de Miescher.

Más tarde se descubrió que la nucleína mostraba una marcada reacción ácida, por lo cual se cambió el nombre al de «ácido nucleico».

En 1879 otro de los discípulos de Hoppe-Seyler, Albrecht Kossel, empezó a romper la estructura del ácido nucleico y a identificar algunos de los fragmentos obtenidos. Descubrió una serie de compuestos que tenían moléculas formadas por anillos de átomos de carbono y nitrógeno. Estos anillos poseían los nombres químicos de «purinas» y «pirimidinas». En la mezcla de fragmentos también había moléculas de azúcares que no pudo identificar bien.

A la larga, el trabajo de Kossel condujo a la demostración de que la molécula de ácido nucleico estaba formada por una hebra de unidades menores llamadas «nucleótidos». Cada nucleótido estaba compuesto por una purina (o una pirimidina), un azúcar y una combinación de fósforo y oxígeno denominada fosfato.

En una molécula específica de ácido nucleico había nucleótidos de cuatro clases diferentes, residiendo la importante diferencia en la estructura concreta de la componente púrica o pirimidínica. El azúcar y el fosfato eran idénticos en todos los nucleótidos. No necesitamos ocuparnos de los nombres químicos exactos de los diferentes nucleótidos. Podemos llamarlos simplemente 1, 2, 3 y 4.

El hombre que identificó realmente los nucleótidos como la unidad básica en la estructura del ácido nucleico fue un químico ruso-americano llamado Phoebus Aaron Theodore Levene, que había estudiado a las órdenes de Kossel. En 1909 halló que el azúcar del ácido nucleico era la «ribosa», un átomo de azúcar de cinco carbonos que había sido estudiado en el laboratorio como producto sintético, pero que nunca se había encontrado en un tejido viviente.

Más tarde, en 1929, descubrió que algunos ácidos nucleicos contenían un azúcar no enteramente igual a la ribosa. El nuevo azúcar tenía en su molécula un átomo de oxígeno menos que aquélla, por lo cual se denominó «desoxirribosa». Antes del descubrimiento de Levene no se conocía la desoxirribosa, ni en el laboratorio ni en la naturaleza.

Cualquier muestra de ácido nucleico tenía entre sus unidades constituyentes, ribosa o desoxirribosa, nunca ambas. En consecuencia, los químicos empezaron a hablar de dos clases de ácido nucleico: «ácido ribonucleico» y «ácido desoxirribonucleico», abreviados habitualmente con las siglas RNA y DNA, respectivamente. Cada una de las dos variedades estaba compuesta de nucleótidos que contenían el azúcar característico de ella, más cualquiera de cuatro tipos de purinas o pirimidinas. Tres de esos tipos se daban en ambas variedades de ácido nucleico. El cuarto difería en ambos, pero sólo levemente. Podríamos decir que el RNA estaba compuesto de 1, 2, 3 y 4a, mientras que el DNA constaba de 1, 2, 3 y 4b.

La siguiente cuestión era: ¿qué hacían en el cuerpo los ácidos nucleicos? ¿Cuál era su función?

Fuese la que fuese, tenía que ver con las proteínas. Kossel había descubierto que los ácidos nucleicos estaban asociados con ellas, y la combinación se denominó «nucleoproteína».

A nadie le cogió por sorpresa. En el primer tercio del siglo XIX quedaron establecidas las clases generales de compuestos contenidos en el tejido viviente, y una de ellas resultó ser con mucho la más complicada y la más frágil. Parecía compuesta precisamente por el tipo de sustancias que uno esperaría qué intervengan en algo tan versátil y delicado como la vida.

En 1839 el químico holandés Gerardus Johannes Mulder usó por primera vez la palabra «proteína» para este complicado grupo de compuestos. El nombre proviene de un término griego que significa «de primera importancia». Mulder había acuñado el nombre para resaltar la importancia de una fórmula específica elaborada por él para ciertos fragmentos de proteína. La fórmula resultó completamente falta de importancia, pero década a década, durante los cien años siguientes, se vio cada vez más claro cuán certero era el nombre.

Hacia la época en que se descubrieron los ácidos nucleicos ningún bioquímico dudaba ya de que las proteínas fuesen «de primera importancia», ni de que fuesen efectivamente las moléculas claves de la vida. En el siglo XX nuevos descubrimientos vinieron a apuntalar más y más la posición de las proteínas en este sentido. Las enzimas, que controlaban de cerca las reacciones químicas en el interior del cuerpo, resultaron ser proteínas. Las hormonas, las vitaminas, los antibióticos, los oligoelementos (los venenos también, a esos efectos) parecían actuar todos, de un modo u otro, a través de su efecto sobre las enzimas.

Las proteínas eran la cosa.

Las diversas moléculas proteínicas estaban constituidas por cadenas de unidades más pequeñas llamadas «aminoácidos». Había unas veinte variedades de aminoácidos y cada una de ellas se daba en casi todas las proteínas.

Algunas moléculas proteínicas sólo estaban compuestas por una cadena de aminoácidos; recibieron el nombre de «proteínas simples» en un sistema de clasificación elaborado, en principio, por Hoppe-Seyler. Las proteínas que contenían, como partes mayores o menores de sus moléculas, agrupaciones atómicas que no eran aminoácidos, se denominaron «proteínas conjugadas».

Las proteínas conjugadas fueron clasificadas a su vez con arreglo a la naturaleza de las porciones no-aminoácidas de la molécula. Cuando eran moléculas grasas, el resultado era una «lipoproteína» o una «lecitoproteína». La presencia de hidratos de carbono daba lugar a las clases de «glucoproteínas» y «mucoproteínas». Cuando los grupos añadidos daban color a la proteína, se hablaba de «cromoproteínas». Luego había «fosfoproteínas», «metaloptoteínas», y así sucesivamente.

Si de una cosa estaban seguros los bioquímicos era de que en el caso de todas las proteínas conjugadas la parte crítica era la porción proteínica. La porción no aminoácida, denominada «grupo prostético», podía tener su función, incluso crucial, pero de algún modo nunca se veía en ella sino mero instrumento de la porción proteínica.

Por ejemplo, la célebre proteína llamada hemoglobina, que transporta oxígeno desde los pulmones a las células de los tejidos, tiene como grupo prostético un grupo llamado «heme». Es el heme el que efectivamente recoge el oxígeno y lo transporta. Sin embargo, el heme, por sí solo, no puede hacer el trabajo, y las hemoglobinas anormales que funcionan mal (como en la anemia de las células falciformes) no presentan ningún defecto en el grupo heme, sino que habitualmente tienen pequeñas desviaciones en las cadenas de aminoácidos de la porción proteica de la molécula.

Es como si os imagináis a un hombre utilizando un pincel para pintar un cuadro, o un hacha para derribar un árbol, o un fusil para cazar un pato. El instrumento utilizado puede ser esencial para la función en cuestión, pero es indudable que quien cuenta en todos los casos es el hombre; el hombre puede hacer cosas sin instrumentos (y muchas proteínas simples pueden hacer trabajos importantes), pero los instrumentos nada pueden hacer sin el hombre.

Era habitual concebir los grupos prostéticos como moléculas relativamente pequeñas y estables, aptas para realizar funciones simples; la proteína, en cambio, como una molécula grande y delicada, de muy versátil funcionamiento. Puesto que así era claramente en el caso de muchas proteínas conjugadas, se supuso, demasiado a la ligera, que lo mismo ocurría en el caso de las nucleoproteínas. El ácido nucleico fue catalogado como una molécula pequeña y estable que realizaba su tarea bajo la guía, por así decirlo, de la proteína.

Todavía en 1939, cuando yo estudiaba química orgánica en Columbia, se enseñaba que la molécula del ácido nucleico era un «tetranucleótido», esto es, una molécula compuesta por una sarta de cuatro nucleótidos, uno de cada tipo: 1-2-3-4.

Un tetranucleótido tiene un tamaño medianamente grande para una molécula orgánica, pero es quince veces menor que una molécula proteínica media. De ahí que el ácido nucleico fuese descartado displicentemente como un mero auxiliar proteínico, una especie de compuesto Cenicienta sentado a las brasas, mientras la hermana mayor, Proteína, se marchaba al baile.

Naturalmente, nadie sabía exactamente qué hacía el ácido nucleico, pero los bioquímicos estaban seguros de que, fuese lo que fuese, debía ser algo rutinario. Y siguieron en sus trece a pesar de que se descubrieron ácidos nucleicos en algunos lugares muy importantes. Se vio, por ejemplo, que los cromosomas estaban compuestos de nucleoproteínas, y los cromosomas eran sartas de «genes» que controlaban la herencia de características físicas…, tarea no desdeñable.

Pero nadie acusó el recibo. Esos pequeños tetranucleótidos tendrían sin duda su pulcro y modesto cometido genético, pero fuese cual fuese, había de ser la proteína de los cromosomas la que controlase las características físicas del cuerpo. Sólo la molécula proteínica podía ser lo bastante complicada para hacerlo.

Pero luego resultó que la molécula del ácido nucleico podía no ser tan pequeña como parecía. Al aislar el ácido nucleico de las células y separarlo de su desconocido soporte, quedaba roto en pequeños fragmentos. Se ideó luego un tratamiento más delicado, que desembocó en la obtención de fragmentos cada vez mayores. Y empezó a entreverse que las moléculas de ácido nucleico pecaban más bien de grandes.

Tampoco ahora se inmutó nadie. Que la molécula fuese grande sólo quería decir que los tetranucleótidos se repetían: 1-2-3-4-1-2-3-4-1-2…, y así para siempre, con fáciles puntos de ruptura cada cuatro nucleótidos, como si fuese una cadena perforada de sellos. Y de ser así, los ácidos nucleicos seguían sin ser lo bastante complicados para adquirir carta de importancia en el esquema viviente de las cosas.

Toda esa insistencia en cargar la mano en las proteínas e ignorar el ácido nucleico fue a costa de ignorar más o menos un hallazgo primordial y muy peculiar anunciado en 1869 por Kossel.

Kossel estaba estudiando células espermáticas, que son ricas en ácido nucleico. Y no es difícil ver por qué han de serlo. Puesto que las células espermáticas transportan sustancias que controlan la herencia de características físicas (porque si no ¿cómo es que los jóvenes se asemejan tan a menudo a sus padres en ese o aquel aspecto físico?), deben contener cuando menos la mitad del grupo de los cromosomas paternos. (Al fertilizar el óvulo, la semidotación del espermatozoide se combina con la semidotación del óvulo y el joven organismo hereda una dotación completa, la mitad de un progenitor y la mitad del otro.)

Sin embargo, una célula espermática es tan pequeña que apenas tiene espacio para esa media dotación; en consecuencia, debe ser prácticamente material cromosómico casi puro -esto es, nucleoproteína- y ser rica en ácido nucleico.

Kossel utilizó esperma de salmón (fácil de obtener en cantidad) y de otros peces, y descubrió que la proteína allí contenida era bastante atípica. Las moléculas eran relativamente pequeñas y relativamente simples. El esperma del salmón era extremoso en este sentido, pues su proteína principal, la salmina, estaba compuesta de pequeñas moléculas que contenían un solo aminoácido, llamado arginina, con exclusión virtual de los demás. Sólo del 10 al 20 por 100 de los aminoácidos en la salmina eran distintos de la arginina.

Una pequeña molécula de proteína, hecha casi de arriba abajo por un solo aminoácido, no podía tener nada de la intrincadísima complejidad de la molécula proteínica habitual, de tamaño mucho mayor, y compuesta por más de veinte variedades de aminoácidos. ¿Las moléculas proteínicas del esperma de salmón podían transportar la información necesaria para convertir el huevo en desarrollo en un salmón adulto, grande y perfecto?

Por otra parte, el ácido nucleico del esperma de salmón no parecía diferir del ácido nucleico de otras células.

Cabría razonar del modo siguiente: la célula espermática debe nadar como loca para llegar al óvulo antes que las demás. No puede permitirse el lujo de llevar ningún lastre. Debe llevar sólo lo estrictamente esencial para la herencia, además de combustible suficiente para la carrera y la cantidad justa de maquinaria molecular requerida para efectuar la entrada en el óvulo.

Incluso los cromosomas que el espermatozoide transporta deben reducirse al mínimo indispensable. Si hay algo que puede eliminarse sin graves secuelas, eliminado sea. Tiempo habrá de restaurarlo cuando el espermatozoide se encuentre a salvo dentro del óvulo, con rico suministro de materias primas a su disposición.

Por eso, si la mayor parte de las proteínas son eliminadas del bagaje del espermatozoide, mientras que el ácido nucleico permanece intocado, es de pensar que el ácido nucleico es esencial para la transmisión de información genética y que la proteína no.

Desgraciadamente, para extraer esa conclusión los bioquímicos habían de abandonar un prejuicio demasiado fuerte. Los bioquímicos sabían que la proteína era importante y que los ácidos nucleicos no lo eran; de modo que, a la vista de los hallazgos de Kossel, decidieron que las proteínas del esperma, por simples que parecieran, lograban de alguna manera (una vez seguras en la célula huevo) guiar la construcción de proteínas más complejas que, ésas sí, se bastaban para transportar la información genética.

En cuanto a los ácidos nucleicos, eran demasiado minúsculos para transportar la información, y no había más que hablar. El que las células espermáticas insistiesen en aferrarse a una dotación completa de ácidos nucleicos era sorprendente, pero no podía pasar de anecdótico.

La ruptura vino con los estudios sobre el neumococo, el pequeño germen causante de la pulmonía.

Hay dos cepas de neumococos, distintas en su aspecto por la presencia o ausencia de una cápsula de carbohidrato. La cepa que poseía cápsula presentaba una superficie lisa; la que carecía de ella tenía una superficie rugosa. Para distinguirlas se las llamó «cepa S» y «cepa R».

Las dos cepas eran la misma especie de bacteria, pero la R carecía de la pieza de información genética necesaria para manufacturar el carbohidrato que formaba la cápsula.

Un bacteriólogo inglés, Fred Griffith, había descubierto ya en 1928 que si se hervía una muestra de la cepa S hasta matarla y se la añadía luego a una colonia viva de la cepa R, al cabo de un tiempo empezaban a aparecer neumococos de la cepa S.

¿Qué sucedía? Sin duda la cepa S muerta no resucitaba. Una explicación lógica sería que cuando la cepa S era aniquilada por ebullición, el compuesto químico que porta la información genética necesaria para manufacturar el carbohidrato no era destruido, o al menos no lo era del todo. Al agregar cepa S muerta a la cepa R viva, la información química no destruida se incorporaba de algún modo a la estructura de algunos de los neumococos vivientes de la cepa R, que empezaban así a fabricar cápsulas de carbohidrato y se convertían en la cepa S.

En 1931 se descubrió que para esa conversión no eran necesarias bacterias muertas intactas. Cierta cantidad de bacterias S muertas, sumergidas en un solvente y filtradas, dejaban atrás un «extracto» que contenía parte del material de las células. El extracto (que no contenía una sola célula intacta) servía con todo para transformar la cepa R en cepa S.

La cuestión era: ¿cuál es la naturaleza de la molécula de información presente en el extracto que actúa como «principio transformador»? Indudablemente, alguna especie de proteína, pero una proteína insólita, capaz de soportar la temperatura del agua en ebullición, cosa imposible para cualquier proteína compleja.

En 1944, el bioquímico americano Oswald Theodore Avery, junto con dos colaboradores, Colin Munro MacLeod y Maclyn McCarty, purificó ese extracto de principio transformador y acabó por identificar su naturaleza química.

No era una proteína. Era ácido nucleico puro, DNA, para ser más exactos.

El panorama cambió de raíz. Ahora se vio que lo importante era el componente de DNA de los cromosomas, y que el componente proteínico era tan sólo la fuerza auxiliar, con lo cual los hallazgos de Kossel sobre la proteína espermática cobraron súbitamente pleno sentido. El ácido nucleico era ahora un compuesto Cenicienta que había llegado al baile con carruaje y caballos, cocheros y magnífico vestido. El Príncipe Bioquímico se enamoró de ella al instante.

Una vez que los bioquímicos repararon al fin en el DNA, en vez de ignorarlo, los avances se sucedieron a ritmo de vértigo. La verdadera complejidad de su estructura fue descubierta en 1953; y el método mediante el cual almacena la información que dirige la construcción de enzimas específicas, en la década de los sesenta.

¿Cómo enlaza esto con los virus, que dejamos en el capítulo previo en el momento de ser cristalizados por Stanley?

En 1937, dos años después de la demostración de Stanley, dos bioquímicos ingleses, Frederik Charles Bawden y Norman W. Pirie, habían descubierto que el virus del mosaico del tabaco (el mismo que había sido cristalizado por primera vez) no era proteína pura. Un 6 por 100 era ácido nucleico de la variedad RNA.

En aquel momento nadie se hizo lenguas, pues era antes del hallazgo de Avery. Andando el tiempo se descubrió que otros virus poseían también componentes de ácido nucleico, tanto RNA como DNA, y, en algunos casos, ambos. De hecho, todo virus indiscutible contiene ácido nucleico.

Tras publicar Avery su trabajo, el ácido nucleico vital fue mirado también con nuevos ojos; y, por fortuna, la bioquímica de los años de post-guerra disponía ya de toda una batería de nuevas técnicas instrumentales. El microscopio electrónico puso los virus al alcance de la vista, y bombardeándolos con rayos X cupo aprender algunas cosas sobre la naturaleza de su estructura molecular.

Empezó a entreverse que la molécula del virus estaba compuesta por un continente y un contenido. El continente estaba compuesto por proteínas, y dentro estaba el contenido: un ovillo de ácido nucleico. La proteína empezó a emerger como una mera cápsula, provista quizá aquí y allá de una molécula enzimática capaz de ayudar a disolver la pared o membrana celular para que el virus pudiese penetrar.

En 1952 dos bioquímicos americanos, Alfred D. Hershey y M. Chase, intentaron un experimento crucial con el bacteriófago, un virus más bien grande y complicado que elegía como presa a las células bacterianas.

En primer lugar cultivaron bacterias en medios que contenían átomos de azufre radiactivo y átomos de fósforo radiactivo. Las células bacterianas incorporaron ambos tipos de átomos a su estructura; su presencia era fácilmente detectada por las radiaciones que emitían.

Se permitió entonces que los bacteriófagos infestaran estas bacterias «marcadas», y aquellos incorporaron también a su estructura átomos radiactivos. Tanto el azufre como el fósforo fueron a parar a la proteína del virus. Puesto que el ácido nucleico contiene fósforo pero no azufre, sólo se incorporó fósforo radiactivo. al ácido nucleico del virus.

Por último, se dejó que los bacteriófagos marcados infestasen bacterias normales sin marcar. Tras dar tiempo suficiente para que el virus penetrara en las células bacterianas, se lavaron éstas cuidadosamente para eliminar cualquier adherencia. Resultó que en el interior de la célula sólo había fósforo radiactivo. No había azufre radiactivo detectable en el interior.

Quería decirse que la cápsula proteínica del virus, que incluía átomos de azufre radiactivo en su estructura, no podía estar en el interior de la célula. Quizá ayudaba al virus a penetrar mediante acción enzimática, pero hecho eso sólo entraba en la célula la parte de ácido nucleico del virus.

Dentro de la célula, el ácido nucleico del virus provocaba la producción de nuevas moléculas de ácido nucleico idénticas a la primera, imponiendo sus propias directrices a la célula y haciendo uso de la maquinaria enzimática de ésta para sus propios propósitos. Y no sólo construía nuevas moléculas de ácido nucleico a su imagen y semejanza, sino que también supervisaba la producción de sus propias moléculas proteínicas específicas para hacerse nuevas cápsulas, a expensas de las necesidades de la célula. Al final, la célula bacteriana era destruida, y allí donde había entrado un bacteriófago existían ahora unos 200, dispuesto cada uno a invadir una nueva célula.

Ha de ser, pues, el ácido nucleico la parte verdaderamente viviente del virus, y por tanto, de todas las criaturas, incluidos nosotros.

Además, mientras que los microorganismos comunes eran células que vivían libremente y que podían, en algunos casos, invadir y parasitar organismos grandes compuestos de numerosas células, los virus eran algo todavía más básico, Cabría compararlos a cromosomas en existencia libre, capaces de invadir y parasitar células que contienen numerosos cromosomas.

Avery tenía sesenta y siete años cuando se publicó su trabajo revolucionario, y cerca ya del fin de su distinguida carrera de investigación médica… pero no tanto como para no haber tiempo de reconocérselo. Murió en 1955, once años después; por entonces el triunfo del ácido nucleico era claro e indiscutible, y no había duda de que el hallazgo de Avery constituía el comienzo de ese triunfo.

Sin embargo, Avery nunca obtuvo el premio Nobel, y según la clara opinión de la computadora y la mía propia, aquello fue un desatino de la justicia científica.

E) Sobre la glándula tiroidea

12. Cirujano, cirujano, la garganta

córtame

Hace dos meses me convencieron de que fuera al médico para un reconocimiento rutinario. Me resistí, porque en general gozo de perfecta salud y no quiero que ningún médico me lo desmienta. Finalmente, sin embargo, de morros y enfurruñado, me dejé examinar.

El doctor me dijo:

–Tu salud es perfecta, Isaac.

–Ya te lo dije -repuse con calor- antes de que empezaras.

–Excepto un tumor de tiroides, – agregó.

La verdad es que había un bulto bien claro en las suaves y juveniles líneas de mi garganta cuando inclinaba hacia atrás la cabeza. Al tacto se notaba sin dificultad. Pero como hasta entonces jamás lo había visto, ni sentido, le acusé, naturalmente, a él de habérmelo puesto ahí. Sonrió con indulgencia y replicó que cómo esperaba si no que se ganara la vida.

No entremos en lo que aconteció a lo largo del mes siguiente. Desestimando por completo mis protestas y mi súbito interés en las curaciones por fe, mi médico trazó obstinadamente sus insidiosos planes quirúrgicos, y el 12 de febrero de 1972 me encontré metido en una habitación de hospital. Con aprensión creciente observé los preparativos para operarme de la garganta la mañana del 15.

Mi cirujano (un simpático bribón de ojos brillantes y fácil sonrisa) me describió detenidamente la incisión que se proponía hacer, de oreja a oreja, así como la lenta inspección de cuatro horas a que pretendía someter a todas las piezas de mi garganta.

Como podéis imaginar, no paré de darle vueltas al asunto.

La noche anterior me obligaron a tomar un somnífero (hasta entonces jamás los había probado) y a la mañana siguiente entraron y me pincharon tres veces con lo que supongo eran tres tranquilizantes y/o sedantes distintos. Según me explicaron, era para impedir que me subiera por las paredes mientras trataban de bajarme en la camilla al cuarto de trinchar.

Pero, ¡ay!, no tuvieron en cuenta mí peculiar constitución emocional. En mí no hay más que dos emociones: ansiedad e hilaridad. Cuando surge algo que me quita la primera, ya sea una buena noticia, una compañía agradable, o medio dedo de vino ligero… me lleno de hilaridad.

Así que cuando el día 15, muy de mañana, me inyectaron los primeros tranquilizantes de mi vida, volaron mis preocupaciones y empecé a ponerme alegre.

Me colocaron en el carro de la carne y mientras me empujaban por los pasillos empecé a agitar los brazos y a cantar al tope de mi estentórea voz. Seguí así durante todo el calvario hacia la cámara de tortura. Y oí con claridad que una enfermera le decía a otra:

–¿Has visto alguna vez una reacción así a la medicación?

Finalmente me transportaron al tajo, inclinaron el carro y me depositaron bajo el potente foco. Y allí apareció mi cirujano, con su máscara verde y los ojos brillando jovialmente.

En cuanto le vi me incorporé, le agarré y entoné:

Cirujano, cirujano,

la garganta córtame.

Y cortado que la hayas,

¿la coserás otra vez?

A esas alturas ya se las habían arreglado para pincharme con la anestesia, y perdí contacto con todo. Pero, según me dijo después mi cirujano, se quedó allí partido de risa temiendo no poder mantener la mano suficientemente firme para hacer la primera incisión [21].

Bien, la operación pasó; la mitad de mi tiroides ha desaparecido, y me recupero. Saquemos, pues, algo en limpio y hablemos de las hormonas.

A la humanidad le costó bastante tiempo apercibirse de su sistema nervioso. Hay aproximadamente ciento cincuenta mil kilómetros de fibras nerviosas en el cuerpo humano adulto, enfocadas hacia el cerebro y la médula espinal, que consisten en tres libras de la más compleja organización de materia que el hombre conoce, Sin embargo, Aristóteles no supo asignar al cerebro otra función que la de servir como órgano de enfriamiento para la sangre que lo atravesaba.

En 1766, el fisiólogo suizo Albrecht von Haller publicó sus investigaciones. Mostraban que la estimulación de un nervio que conduce a un músculo provoca más fácilmente la contracción muscular que la estimulación directa del músculo. Von Haller probó asimismo que todo nervio conduce en definitiva al cerebro o a la médula espinal. Fue el fundador de la neurología, y a lo largo del siglo XIX los fisiólogos se interesaron más y más por desentrañar los recursos del sistema nervioso.

Por ejemplo, cuando coméis, los jugos gástricos del estómago empiezan a fluir mientras la comida está todavía en la boca. Las glándulas de la pared estomacal saben que la comida está en camino antes de que cosa alguna llegue a ellas.

Es de presumir que este «conocimiento» anticipado por parte de las glándulas estomacales les llegue a través de la actividad nerviosa. La comida en la boca estimula determinados nervios, que conducen el mensaje al cerebro, el cual, a su vez, envía un nuevo mensaje a lo largo de nervios que conducen a las paredes estomacales, diciendo «¡segregad!»

En ciencia, sin embargo, las soluciones «presumibles» ni pinchan ni cortan mientras el fenómeno pueda ser comprobado por experimento. En 1889, el fisiólogo ruso Ivan Petrovich Pavlov se puso a comprobar lo presumible.

Cortó el esófago de un perro y conectó la parte superior con el exterior a través de una fístula en el cuello. El perro podía comer, pero la comida caía por el esófago abierto y no llegaba al estómago [22]. Sin embargo, la secreción gástrica fluía en el momento oportuno. Pavlov cortó luego ciertos nervios que iban al estómago, o que venían de la boca y la garganta, y aunque el perro comía con igual apetito que antes, los jugos gástricos no fluían.

Pavlov recibió en 1904 el premio Nobel de Medicina y Fisiología por estas y otras investigaciones acerca de la fisiología de la digestión, y por establecer la importancia del sistema nervioso autonómico.

La naturaleza de la conexión nerviosa entre la boca y el estómago suscitó la pregunta por la naturaleza de la conexión nerviosa entre el estómago y el intestino delgado, paso siguiente en el camino del canal alimentario.

Cuando la comida abandona el estómago y penetra en el intestino delgado, se activa súbitamente una gran glándula digestiva, llamada páncreas, que derrama su secreción digestiva en el duodeno, primera sección del intestino delgado. El resultado es que el contenido estomacal, a medida que es embutido en el duodeno, se ve rápidamente bañado por una secreción digestiva bien preparada para continuar el proceso de digestión a partir del punto en que cesó la labor del estómago.

He aquí un ejemplo de excelente organización. Si el páncreas segregase continuamente sus jugos, sería un gran dispendio, porque la mayor parte del tiempo se gastarían. Por otra parte, si el páncreas segregara sus jugos intermitentemente (como lo hace), pero a intervalos regulares o al azar, lo probable es que las secreciones no estuviesen sincronizadas con la entrada de comida en el duodeno, y entonces no sólo se gastarían en balde las secreciones, sino que la comida quedaría imperfectamente digerida.

El hecho de que la entrada de comida y la secreción del páncreas estén perfectamente sincronizadas parece indicar la presencia de actividad nerviosa. Por si hubiera alguna duda, los experimentos de Pavlov sobre la boca y el estómago seguramente lo probarían por analogía.

Pero las pruebas por analogía son poco firmes. Preferible, y con mucho, es la comprobación directa. En 1902, dos fisiólogos ingleses, William Maddock Bayliss y Ernest Henry Starling, decidieron dedicar algún tiempo a la ingrata labor de llevar los descubrimientos de Pavlov un paso más adelante. (Uno consigue el premio Nobel por el primer paso, tan sólo una nota a pie de página en los libros de historia por el segundo.)

Bayliss y Starling seccionaron los nervios dirigidos hacia el páncreas de un animal de laboratorio, y supongo que se cayeron de la silla cuando comprobaron que el páncreas seguía funcionando perfectamente sincronizado a pesar de que le faltaban los nervios que habrían de llevarle los mensajes.

¿Cómo podía ser?

El contenido estomacal es único en el cuerpo por ser fuertemente ácido. El jugo gástrico no sólo contiene la enzima pepsina, que digiere proteínas, sino también una cantidad sorprendente de ácido clorhídrico, que mantiene los jugos gástricos al fuerte nivel de acidez necesario para que trabaje la pepsina con eficiencia y que digiere también algunas proteínas por su cuenta [23]. El descubrimiento de esa producción de ácido clorhídrico (un fuerte ácido mineral que por sus características parecía incompatible con la vida) llegó en 1824 y supuso un gran impacto para los biólogos.

La rápida descarga de jugo pancreático no sólo contribuye a la descomposición digestiva del alimento, sino que ayuda a neutralizar la acidez, pues el jugo pancreático es levemente alcalino. (Un fallo en el buen control de la acidez contribuye con seguridad a la formación de una úlcera de duodeno.)

Con todo esto en la mente, Bayliss y Starling trataron de encontrar el factor que originaba la sincronización pancreática. Si no se trataba de actividad nerviosa, ¿era algo que estuviera en el contenido estomacal mismo? De ser así, ¿qué podría ser sino aquella característica distintiva, la acidez de tal contenido? Para empezar, ¿por qué no separar la acidez de todo lo demás, e investigarla a solas?

Así pues, introdujeron una pequeña cantidad de ácido clorhídrico en el intestino delgado en un momento en que el animal estaba en ayunas y tenía el estómago vacío. Inmediatamente, el páncreas, sin conexiones nerviosas, se puso a trabajar vigorosamente, y el duodeno vacío se llenó de jugo pancreático.

Siendo, por tanto, la acidificación de la pared duodenal lo que activaba el páncreas, Bayliss y Starling decidieron dar un paso más. Se procuraron una sección del duodeno de un animal recientemente muerto y la empaparon de ácido clorhídrico. Algo de ese duodeno se había convertido ahora (quizá) en el factor activante (cualquiera que éste fuese).

Si el mensaje no era conducido por vía nerviosa, podía serlo por la sangre, que era el único tejido móvíl del cuerpo que conectaba cualquier órgano del cuerpo con todos los demás, en este caso, el duodeno con el páncreas.

Supongamos entonces que una pequeña cantidad del ácido en el que se había empapado la pared duodenal es inyectada en el torrente sanguíneo de un animal vivo. Si el ácido contiene el factor activante, ¿qué sucederá?

Se escogió un animal en ayunas, sin nada en el duodeno: ni contenido gástrico, ni ácido clorhídrico insertado artificialmente. Sin embargo, a causa de la inyección de «fuese lo que fuese» en el torrente sanguíneo, el páncreas entró en funcionamiento.

La conclusión parecía inevitable. La pared intestinal reaccionaba a la acidez produciendo un compuesto químico que se segregaba en la corriente sanguínea. El torrente sanguíneo transportaba el compuesto químico por todo el cuerpo y a todos los órganos, incluido el páncreas. Cuando el compuesto químico llegaba a este último, estimulaba de alguna manera al órgano para que segregara su jugo.

Bayliss y Starling llamaron a la sustancia producida por la pared intestinal «secretina», por razones obvias. Suponiendo que podría haber otros ejemplos de tales sustancias en el cuerpo, Bayliss sugirió en 1905, en el curso de una conferencia, un nombre general. Llamó a estos mensajeros químicos «hormonas», de una palabra griega que significa «yo despierto», dado que las hormonas provocan actividad en órganos hasta entonces dormidos.

Bayliss y Starling nunca obtuvieron el premio Nobel por su descubrimiento de las hormonas, aunque, en mi opinión, su trabajo fue de importancia más fundamental que el de Pavlov. Quizá Pavlov pensó lo mismo, pues tras el descubrimiento de las hormonas abandonó el campo de la fisiología digestiva ortodoxa y comenzó a estudiar las diversas formas de estimular la producción de saliva en perros. En tal empeño, estableció en los años veinte los detalles de la respuesta condicionada, hallazgo que merece mucho más el premio Nobel que las investigaciones por las que lo recibió.

Aunque las hormonas fueron descubiertas más tarde que la actividad nerviosa, son los mensajeros más antiguos y básicos. Los animales muy simples, y todas las plantas, carecen de sistema nervioso y no obstante, se las arreglan con la sola ayuda de los mensajes químicos.

Cabe suponer, de hecho, que los nervios aparecieron en los animales más complejos porque la necesidad de un movimiento muscular rápido (las plantas y los animales muy simples tampoco tienen músculos) privilegió las sensaciones y reacciones veloces.

El paso de hormonas a nervios es de alguna manera análogo (según me parece) al paso de la interacción mecánica a la interacción electrónica de la tecnología humana. El control por flujo de electrones es mucho más rápido y más delicado que el control por engranajes conectados. En esta analogía, el cerebro sería la sala central de control, donde los objetos distantes son delicadamente ajustados mediante la observación de agujas que pivotan y luces que destellan y el establecimiento de los contactos adecuados.

Otra pregunta sería por qué las hormonas siguen funcionando en organismos en que la red nerviosa y el cerebro están altamente desarrollados. ¿Para qué utilizar el sistema de «carreta» para transportar compuestos químicos por la corriente sanguínea a todas las partes del cuerpo, esperando que alguna de estas partes los utilice, cuando tenemos el sistema de «propulsión a chorro» de los nervios que llevan sus mensajes rápida y específicamente a los lugares necesitados?

Una respuesta es que la evolución es un proceso conservador, que tiende a retener todo lo posible, que modifica y ajusta en vez de abandonar.

Además, las hormonas tienen también sus ventajas. Por una parte, pueden controlar porciones de la fisiología sin molestar al sistema nervioso, que está ya sobrecargado y agradece cualquier respiro. Por otra, las hormonas se las arreglan para mantener un ajuste permanente de algunos factores en forma simple y automática, que requiere poca inversión de esfuerzo por parte del cuerpo en general.

La secretina, por ejemplo, se produce por acción de la acidez sobre la pared duodenal. Una vez producida, la secretina induce al páncreas a descargar jugo pancreático en el duodeno. El jugo pancreático, levemente alcalino, disminuye rápidamente la acidez del contenido estomacal que ha penetrado en el duodeno. Y la reducción de la acidez corta la producción de secretina, lo cual, a su vez, corta la actividad pancreática.

En resumen, la formación de la secretina estimula una acción que determina el cese en la formación de secretina. Es un proceso autolimitativo, un proceso de «realimentación». El resultado no es sólo que la actividad hormonal inicie el flujo de jugo pancreático, sino también que la tasa de flujo sea ajustada cuidadosamente, paso a paso, por la actividad hormonal y la realimentición que produce.

En el transcurso del siglo XX fueron descubriéndose otras hormonas, algunas de ellas producidas por pequeños órganos que tenían como única función esa producción. Uno de ellos -el que en este momento despierta en mí morboso interés- es una masa amarilla-rojiza de tejido glandular, de unas dos pulgadas de altura, poco más de dos pulgadas de anchura, y que pesa una onza o poco menos. Está compuesta por dos lóbulos, a ambos lados de la tráquea, con un estrecho istmo de conexión que pasa por delante de la tráquea, exactamente en el límite inferior de la nuez.

La nuez se denomina con más propiedad cartílago tiroides, de una palabra griega que significa «en forma de escudo» (refiriéndose a los grandes escudos oblongos que llevaban los guerreros homéricos y pre-homéricos). Dichos escudos presentaban en la parte superior un rebaje por encima del cual podía asomarse con cuidado la cabeza para estudiar la situación. En la parte superior de la nuez hay un rebaje parecido, y de ahí el nombre.

El tejido glandular vecino a la nuez toma a préstamo este nombre, y se llama glándula tiroidea o tiroides.

La función de la glándula tiroidea no se conocía a finales del siglo XIX. Era algo más prominente en las mujeres que en los hombres, y había quien opinaba que el tiroides no era más que un relleno del cuello (sobre todo en las mujeres) que lo hacía regordete y atractivo. En algunas regiones de Europa el tiroides (y particularmente entre las mujeres) tenía un tamaño superior al normal; esta hinchazón del cuello se aceptaba como realce de la belleza, y no al revés.

Dicha tumefacción, llamada bocio, se asociaba a veces con uno de dos conjuntos opuestos de síntomas. Algunos individuos con bocio eran apagados, indiferentes y apáticos, mientras que otros eran nerviosos, tensos e inestables. (Hoy día sabemos que el tiroides controla el metabolismo del cuerpo, la velocidad general del motor del cuerpo, por así decirlo. Un tiroides hipertrofiado en el que todas sus piezas funcionen acelera el motor; mientras que un tiroides hipotrofiado en el que pocas piezas funcionen, lo ralentiza hasta convertirlo en un murmullo.)

En 1896, el químico alemán Eugen Baumann localizó yodo en la glándula tiroidea. Lo cual era sorprendente, pues hasta entonces no se sabía que el yodo pudiera ser componente de un tejido vivo. Además, no se ha encontrado nunca, ni antes ni después, un elemento que esté presente en el organismo en forma tan desequilibrada. La concentración de yodo en el tiroides es 60.000 veces más grande que en el resto del cuerpo.

En 1905, el físico americano David Marine, recién salido de la Facultad de Medicina, estudió este hecho. El yodo no era un elemento común, y se obtenía principalmente de organismos marinos, que lo concentraban a partir de su muy diluida presencia en el agua de mar. La sal rociada por el océano podía distribuir pequeñas cantidades de yodo sobre la tierra, pero había lugares donde el contenido de yodo de la tierra era muy bajo, y era precisamente allí donde el bocio era especialmente común.

La ausencia de yodo quizá originara un mal funcionamiento del tiroides, que intentaba (en vano) corregir la situación aumentando de tamaño. Marine experimentó con animales: al privarles de yodo, aparecía el bocio y la apagada languidez que caracteriza (según sabemos hoy) a un tiroides que funciona mal. El mal quedaba subsanado añadiendo pequeñas cantidades de yodo a la comida.

En 1916 Marine pisaba ya lo bastante seguro como para experimentar con sujetos jóvenes, y logró mostrar que la presencia de yodo en la comida cortaba la incidencia de bocio en los humanos. Lanzó entonces una campaña para añadir pequeñas cantidades de compuestos de yodo al suministro de agua de Cleveland, procedimiento que eliminaría virtualmente el bocio. La campaña, que tropezó con la habitual resistencia de quienes preferían el bocio al cambio, le llevó diez años.

En general, la hormona tiroidea se produce en proporción a su necesidad. Si la tasa metabólica necesita ser alta, la hormona tiroidea se consume rápidamente y su nivel en la sangre desciende. Esta bajada y el consiguiente nivel, inferior al normal, de la hormona en la sangre provoca una actividad más fuerte del tiroides y mantiene el nivel normal a pesar del mayor uso. Si la tasa de metabolismo necesita ser más baja, la hormona tiroidea se consume lentamente y su nivel en sangre se eleva. Esto inhibiría la actividad del tiroides y lo desaceleraría.

Cabría suponer que el nivel alto o bajo de la hormona tiroidea en la sangre afecta directamente a la glándula tiroidea, pero no es así. Dado que es la glándula tiroidea la que produce la hormona, la concentración en su vecindad es siempre más alta que en el resto del cuerpo, por lo cual respondería menos rápidamente a los cambios en el metabolismo. Sí la glándula tiroidea se fiara de sí misma y de aquello que inmediatamente la rodea, no recibiría más que una imagen vaga y distorsionada de lo que estaba ocurriendo. (Sería algo así como un ejecutivo que juzgase el valor de sus ideas por las opiniones de los hombres que siempre le dicen sí.)

Una solución mejor es hacer que intervenga una glándula distinta, localizada en un lugar diferente del cuerpo. En este caso, la pituitaria o hipófisis, situada en la base del cerebro.

La hipófisis produce una serie de hormonas, entre ellas la así llamada hormona estimulante del tiroides, o TSH (del inglés, thyroid-stimulating hormone).

La TSH, aunque vertida en la sangre como toda hormona, sólo afecta al tiroides. La TSH lo estimula y hace que incremente su producción de hormona tiroidea. Cuando el nivel en sangre de la hormona tiroidea es demasiado bajo, aumenta la producción de TSH en la hipófisis, que está lo suficientemente lejos del tiroides como para que la sangre que pasa a su través refleje con exactitud el nivel general de hormona tiroidea en el cuerpo.

El incremento de TSH estimula la actividad del tiroides. El nivel de la hormona tiroidea en la sangre se incrementa entonces, y esto reduce la actividad de la hipófisis. Cuando la TSH baja, también baja la actividad tiroidea, y cuando la hormona tiroidea baja, sube la TSH y con ella la actividad tiroidea.

El resultado de la labor conjunta del tiroides y la hipófisis es que la hormona tiroidea se mantiene en un nivel bastante constante en el riego sanguíneo, a pesar del alza y disminución de la necesidad del cuerpo en momentos diferentes y bajo condiciones diferentes de actividad.

Veamos en qué me afecta todo esto.

El hecho de que haya desaparecido la mitad de mi tiroides no es de suyo muy serio. La otra mitad que me queda, obligada a trabajar el doble de lo habitual por las incesantes demandas de mi hipófisis, se hipertrofiaría (esto es, crecería) y produciría fácilmente toda la hormona tiroidea que yo necesitase.

Pero eso es algo que mis médicos ven sin entusiasmo. Una mitad de mi tiroides ha mostrado ya un crecimiento indisciplinado y ha tenido que ser extirpada. En vista de lo cual cabe confiar en que el resto de la tiroides sepa cómo hipertrofiarse con discreción. Ha de ser tratada con espíritu de aguda suspicacia.

El resultado es que voy a tener que tomar píldoras tiroideas el resto de mi vida. La hormona tiroidea es un aminoácido modificado que no es digerido sino absorbido directamente. Lo cual significa que no tengo que inyectarme el producto como tendría que hacer si necesitase insulina. Me limito a tragarlo. Además, dado que las píldoras tiroideas se preparan de tiroides de ganado muerto, y que no existe otro uso para dichas glándulas, las píldoras son relativamente baratas y fáciles de obtener.

Al penetrar en mi cuerpo, desde afuera, un suministro constante de hormona tiroidea, mi hipófisis (incapaz de diferenciar la hormona tiroidea de una píldora de la de mi propio tiroides) reduce su producción de TSH y la mantiene en un nivel bajo.

Reducida crónicamente la TSH, lo que queda de mi glándula tiroidea permanece infra-estimulado y, en vez de crecer, encoge. De resultas de ello, la probabilidad de que me aparezca un tumor en el lado izquierdo, parecido al que otrora tuve en el derecho, disminuye significativamente.

Así que esas tenemos, y a mí no me gusta, pero al universo no le importa si me gusta o no, y lo único que puedo hacer es dar gracias de que no fuera peor. Y ahora, excluyendo posteriores incidentes de infortunada naturaleza, puede ser que continúe escribiendo ensayos durante algún tiempo.

Ojalá.

F) Sobre la sociedad

13. Perdido en la no traducción

En la Noreascon (la vigésimo novena Convención Mundial de Ciencia ficción), celebrada en Boston durante el fin de semana del Día del Trabajo [24] de 1971, me senté en el estrado, naturalmente, ya que mi posición de Bob Hope de la ciencia ficción conlleva la obligación de entregar los premios Hugo. A mi izquierda estaba mi hija Robyn, de dieciséis años, rubia, de ojos azules, bien proporcionada y hermosa.

(No, este último adjetivo no se debe a la típica parcialidad del padre orgulloso. Pregúntenle a cualquiera.)

El invitado de honor era mi viejo amigo Clifford D. Simak, quien comenzó su discurso presentando, con un orgullo plenamente justificado, a sus dos hijos, que estaban entre el público. Inmediatamente Robyn me miró alarmada.

–Papá -me dijo en un susurro apremiante, plenamente consciente de mi capacidad para provocar situaciones embarazosas-, ¿no irás a presentarme a mí?

-¿Te molestaría, Robyn? – pregunté

–Sí.

–Entonces no lo haré -dije, y le di una palmadita en la mano para tranquilizarla.

Se quedó un rato pensando. Luego dijo:

–Claro que si te apetece mencionar de manera casual a tu hermosa hija, no me importará.

Así que ya se pueden imaginar que eso fue lo que hice, mientras ella bajaba los ojos con encantadora modestia.

Pero no pude por menos que ponerme a pensar en el estereotipo de belleza nórdica, rubia y de ojos azules, que ha predominado en la literatura occidental desde que las tribus germánicas, rubias y de ojos azules, ocuparon la parte occidental del Imperio romano, hace quince siglos, y se establecieron como la aristocracia gobernante.

… Y en la forma en que se ha utilizado este estereotipo para subvertir una de las lecciones más claras e importantes de la Biblia; una subversión que también aporta su granito de arena a la grave crisis a la que se enfrenta hoy el mundo, y especialmente los Estados Unidos.

Siguiendo mi inclinación de empezar por el principio, retrocedan conmigo al siglo VI a. C. Un grupo de judíos ha regresado del exilio en Babilonia para reconstruir el templo de Jerusalén, destruido por Nabucodonosor setenta años antes.

Durante el exilio, los judíos, guiados por el profeta Ezequiel, han preservado firmemente su identidad nacional, modificando, complicando e idealizando su culto a Yahvé hasta darle una forma que es el antecedente directo del judaísmo actual. (De hecho, Ezequiel es llamado a veces «el padre del judaísmo».)

Esto planteó un problema religioso a los exiliados a su regreso a Jerusalén. Durante el exilio se había establecido un pueblo en la antigua región de Judea; este pueblo adoraba a Yahvé según un ritual que ellos consideraban el correcto y el consagrado por la costumbre. Como su ciudad más importante (al estar Jerusalén destruida) era Samaria, los judíos que volvían del exilio los llamaron samaritanos.

Los samaritanos rechazaron las modernas modificaciones traídas por los judíos, y éstos aborrecían las anticuadas creencias de los samaritanos. Entre ellos surgió una incansable hostilidad, el tipo de hostilidad que se encona cada vez más porque las diferencias en sus creencias son comparativamente pequeñas.

Además, por supuesto, también vivían en aquellas tierras pueblos que adoraban a otros dioses: los amonitas, los edomitas, los filisteos, etcétera.

Los judíos recién llegados no sufrían una presión militar, ya que toda la zona estaba bajo la férula más o menos benéfica del Imperio persa, sino social, que quizá por eso mismo era más agobiante. Resulta difícil mantener un ritual estricto delante de las narices de un número abrumador de incrédulos, y la tendencia a que se relajase el ritual era casi irresistible. Además, los jóvenes recién llegados se sentían atraídos por las mujeres disponibles, y había matrimonios mixtos. Como es natural, descuidaban aún más el ritual para complacer a sus esposas.

Pero más tarde, posiblemente en el 400 a.C., un siglo después de la construcción del segundo templo, Esdras llegó a Jerusalén.

Era un erudito de la ley mosaica, que había sido redactada en su versión definitiva y publicada durante el exilio en Babilonia. Horrorizado por esta recaída, utilizó toda su demagogia para provocar un renacimiento del ritual. Reunía a la gente, les hacía recitar la ley y comentarla, alentaba su fervor religioso y les instaba a confesar sus pecados y renovar su fe.

Una de las cosas que exigía con el máximo rigor era que se abandonara a todas las esposas no judías y a sus hijos. Según él, sólo así podría mantenerse el carácter sagrado del judaísmo estricto. Según la Biblia (cito de la reciente traducción de la Nueva Biblia Inglesa): «El sacerdote Esdras se puso en pie y les dijo: "Habéis pecado al casaros con mujeres extranjeras, agravando la culpa de Israel. Ahora, confesadlo al Señor, Dios de vuestros padres, cumplid su voluntad y separaos de los pueblos paganos y de las mujeres extranjeras." Toda la comunidad respondió en alta voz: "Haremos lo que nos dices…"» (Esdras, 10, 10-12).

A partir de ese momento la comunidad judía empezó a poner en práctica el exclusivismo, a separarse voluntariamente de los demás pueblos, a multiplicar las costumbres extrañas que acentuaban aún más su separación: todo ello les ayudó a mantener su identidad mientras soportaban todas las miserias y catástrofes por venir, en todas las crisis, exilios y persecuciones que los dispersaron por la faz de la Tierra.

Este exclusivismo, naturalmente, también tuvo el efecto de hacerlos socialmente indigeribles y extremadamente notorios, lo cual contribuyó a crear las condiciones que los convertían en objetos probables de exilio y persecución.

No todos los judíos observaron esta política exclusivista. Algunos creían que todos los hombres eran iguales a los ojos de Dios y que no había que excluir a nadie de la comunidad basándose únicamente en la identidad del grupo.

Y uno de los que creían en esto (pero que permanecerá eternamente en el anonimato) intentó defender su causa escribiendo una pequeña obra de ficción histórica. La heroína de este cuento del siglo IV a. C. era Ruth, una mujer moabita. (La historia está ambientada en la época de los Jueces, así que, según la tradición, fue escrita por el profeta Samuel en el siglo XI a. C. En la actualidad, ningún estudioso de la Biblia cree en esta versión.)

Por cierto, ¿por qué una mujer moabita?

Parece ser que los judíos, al volver del exilio, conservaban ciertas tradiciones relativas al momento en que llegaron por primera vez a las fronteras de Canaán, primero conducidos por Moisés y luego por Josué, casi mil años antes. En aquella época la pequeña nación de Moab, situada al este de la desembocadura del Jordán y del mar Muerto, sintiéndose comprensiblemente alarmada por la incursión de estos endurecidos invasores del desierto, se aprestó a resistir sus ataques. No sólo impidieron a los israelitas atravesar su territorio, sino que, según cuenta la tradición, llamaron a un vidente, Balaam, y le pidieron que utilizara sus poderes mágicos para provocar la desgracia y la destrucción de los invasores.

Los intentos de Balaam fracasaron, y se supone que antes de partir éste, aconsejó al rey de Moab que permitiera a las jóvenes moabitas seducir con sus encantos a los invasores del desierto, que de esta manera quizá dejaran de acometer sus tareas con un empeño tan implacable. La Biblia nos cuenta: «Estando Israel en Acacias, el pueblo empezó a prostituirse con las muchachas de Moab, que los invitaban a comer de los sacrificios a sus dioses y a prosternarse ante ellos. Israel se emparejó con Baal Fegor, y la ira del Señor se encendió contra Israel» (Números 25, 1-3).

En consecuencia, «las muchachas de Moab» se convirtieron en la quintaesencia del tipo de influencia exterior que intentaba trastornar a los devotos judíos mediante el anzuelo del sexo. De hecho, tanto Moab como el reino de su frontera norte, Ammon, fueron singularizados en el código mosaico:

«No se admiten en la asamblea del Señor amonitas ni moabitas; no se admiten en la asamblea del Señor ni aun en la décima generación. Porque no te salieron al encuentro con pan y agua cuando ibas de camino al salir de Egipto, y porque alquilaron para que te maldijera a Balaam… No busques su paz ni su amistad mientras vivas» (Deuteronomio, 23, 3-4, 6).

Y, sin embargo, hubo una época anterior en la historia en la que hubo amistad entre Moab y al menos algunos hombres de Israel, posiblemente porque se unieron contra algún enemigo común.

Por ejemplo, un poco antes del 1.000 a. C., Israel estaba gobernado por Saúl, que había detenido el avance de los filisteos, conquistado a los amalequitas y había dado a Israel más poder que en ningún otro momento de su historia anterior. Como es natural, Moab desconfiaba de su política expansionista, y, por tanto, se aliaba con cualquiera que se rebelara contra Saúl. Eso es lo que hizo el guerrero judío David, nacido en Belén. Cuando David estaba siendo acosado por Saúl, se retiró a un refugio fortificado y su familia se refugió en Moab.

«David… dijo al rey de Moab: "Permite a mis padres vivir entre vosotros, hasta que vea qué quiere Dios de mi."

Se los presentó al rey de Moab, y se quedaron allí todo el tiempo que David estuvo en el refugio» (I Samuel, 22, 3-4).

David acabó por vencer a Saúl, se convirtió en el primer rey de Judea y más tarde de todo Israel, y construyó un imperio que abarcaba toda la costa este del Mediterráneo, desde Egipto al Eufrates; las ciudades fenicias conservaron su independencia a cambio de una alianza con él.

Posteriormente, los judíos siempre han considerado la época de David y de su hijo Salomón como una edad de oro, y la posición de David en la leyenda y el pensamiento judaicos era inatacable. David fundó una dinastía que gobernó Judea durante cuatro siglos, y los judíos nunca dejaron de creer que todavía estaba por volver algún descendiente de David que volvería a reinar sobre ellos en alguna idealizada época futura.

Pero es posible que, basándose en estos versos que describen cómo David refugió a su familia en Moab, se difundiera la historia de que algunos de los antepasados de David fueron moabitas. Parece ser que el autor del Libro de Ruth decidió servirse de esta historia para apoyar su doctrina de no exclusivismo, utilizando a la tan odiada mujer moabita como heroína de su historia.

El Libro de Ruth habla de una familia de Belén de Judea: un hombre, su mujer y sus dos hijos, que acuden a Moab acuciados por el hambre. Allí los dos hijos se casan con muchachas moabitas, pero después de algún tiempo los tres hombres mueren, dejando solas a las tres mujeres: Noemí, la suegra, y Ruth y Orfá, sus nueras.

En aquellos tiempos las mujeres eran consideradas como bienes del hombre, y las mujeres que no estaban casadas, que no pertenecían a ningún hombre que cuidara de ellas, sólo podían vivir de la caridad. (De ahí el reiterado mandato bíblico de cuidar de las viudas y huérfanos.)

Noemí decidió volver a Belén, donde quizá sus parientes pudieran ocuparse de ella, pero instó a Ruth y Orfá a que se quedaran en Moab. No lo dice, pero podemos suponer que pensaba que las muchachas moabitas no serían muy bien recibidas en Judea, donde se odiaba a los moabitas.

Orfá se queda en Moab, pero Ruth se niega a abandonar a Noemí, diciendo: «No insistas en que te deje y me vuelva. A donde tú vayas, iré yo; donde tú vivas, viviré yo: tu pueblo es el mío, tu Dios es mi Dios; donde tú mueras, allí moriré y allí me enterrarán. Sólo la muerte podrá separarnos, y si no, que el señor me castigue» (Ruth, 1, 16-17).

En Belén tuvieron que enfrentarse a la más absoluta miseria, y Ruth se ofreció a mantenerlas a las dos trabajando como espigadora en los campos. Era la época de la cosecha, y. según la costumbre, todas las espigas de grano que cayeran al suelo durante la recolección y que quedaran allí podían ser recogidas por los pobres. Era una especie de programa de beneficencia para los pobres. Pero era un trabajo durísimo, y cualquier mujer joven que se dedicara a hacerlo, sobre todo si era moabita, corría el riesgo evidente de ser asaltada por los jóvenes y lascivos segadores. Ruth se había ofrecido a hacer algo heroico.

Ruth se puso a trabajar de segadora en las tierras de un rico granjero judío llamado Boaz, que al acercarse a vigilar las labores observó que trabajaba sin descanso. Preguntó quién era, y sus segadores le respondieron: «Es una muchacha moabita, la que vino con Noemí de la campiña de Moab» (Ruth, 2, 6).

Boaz la trata con bondad, y Ruth dice: «Yo soy una forastera, ¿por qué te he caído en gracia y te has interesado por mi?» (Ruth, 2, 10). Boaz explica que se ha enterado de cómo ha abandonado su tierra por amor a Noemí y de cuánto tiene que trabajar para cuidar de ella.

Daba la casualidad de que Boaz era pariente del difunto marido de Noemí, lo que debe haber contribuido a que le conmovieran el amor y la fidelidad de Ruth. Al oír la historia, Noemí tuvo una idea. En aquella época, si una mujer se quedaba viuda y no tenía hijos, tenía derecho a esperar que el hermano de su difunto marido se casara con ella y le ofreciera su protección. Si éste no tenía hermanos, algún otro pariente había de tomarla a su cargo.

Noemí era demasiado vieja para tener hijos, así que no era apta para el matrimonio, que en aquellos días giraba alrededor de la futura descendencia; pero ¿y Ruth?

Claro que Ruth era una moabita y era muy posible que ningún judío quisiera casarse con ella, pero Boaz se había portado con benevolencia. Por tanto, Noemí instruyó a Ruth sobre la manera de acercarse a Boaz una noche para suplicarle su protección, sin intentar seducirle abiertamente.

Boaz, conmovido por la modestia y el desamparo de Ruth, prometió cumplir con su deber, pero señaló que había un pariente más cercano que él y que éste tenía prioridad sobre él.

Al día siguiente Boaz fue a ver a su pariente y le propuso que comprara unas tierras que correspondían por derecho a Noemí y que aceptara otra responsabilidad junto con las tierras. Boaz dijo: «Al comprarle esa tierra a Noemí adquieres también a Ruth, la moabita, esposa del difunto…» (Ruth, 4, 5).

Es posible que Boaz pusiera especial énfasis en recalcar el adjetivo «la moabita», porque el otro pariente se volvió atrás inmediatamente. así que Boaz se casó con Ruth, que a su debido tiempo le dio un hijo. La orgullosa y feliz Noemí puso al niño en su regazo, y sus amigas le dijeron: «…Y el niño te será un descanso y una ayuda en tu vejez; pues te lo ha dado a luz tu nuera, la que tanto te quiere, que te vale más que siete hijos» (Ruth, 4, 15).

Al juzgar así las mujeres de Judea a Ruth, una mujer del odiado país de Moab, al dictaminar que ella «te vale más que siete hijos» en una sociedad que valoraba a los hijos infinitamente más que a las hijas, el autor nos está presentando la moraleja de su historia: que en todos los pueblos hay personas nobles y virtuosas, y que no hay que desdeñar a nadie por adelantado basándose únicamente en que pertenece a tal o cual grupo.

Y para remachar su argumentación, en caso de que los sentimientos nacionalistas de algunos judíos les hicieran insensibles al idealismo, la historia concluye: «Las vecinas le buscaban un nombre, diciendo: "¡Noemí ha tenido un niño!" Y le pusieron por nombre Obed. Fue el padre de Jesé, padre de David» (Ruth, 4, 17).

¿Qué habría sido de Israel entonces, si hubiera habido un Esdras que hubiera prohibido el matrimonio de Boaz con una «esposa extranjera»?

¿A dónde nos lleva esto? Nadie puede negar que el Libro de Ruth es una historia agradable. Normalmente es calificada de «encantador idilio» y cosas por el estilo. Es indiscutible que Ruth representa muy bien el prototipo de mujer dulce y virtuosa.

En realidad, todo el mundo queda tan encantado con la historia y con Ruth que se olvida de su intención principal.

Es, por derecho propio, una historia sobre la tolerancia con los oprimidos, sobre el amor por los despreciados, sobre las recompensas de la fraternidad entre los seres humanos. Al mezclar los genes y las razas se engendran grandes hombres.

Los judíos incluyeron el Libro de Ruth en el canon, en parte porque es una historia maravillosamente narrada, pero sospecho que sobre todo porque incluye algunos datos sobre el linaje del gran David, un linaje que no era conocido más allá del padre de David, Jesé, en los severos libros históricos de la Biblia anteriores a aquél. Pero, por lo general, los judíos siguieron siendo bastante exclusivistas y no se aplicaron la lección de universalismo que predica el Libro de Ruth.

Y tampoco se han tomado esa historia muy en serio desde entonces. ¿Por qué habrían de hacerlo, cuando no se ahorran esfuerzos para desterrarla al olvido? La historia de Ruth ha vuelto a ser narrada en muchos lugares, desde cuentos para niños hasta novelas serias; hasta se han hecho películas con este argumento. La misma Ruth debe de haber sido representada en cientos de ilustraciones. Y en todas las ilustraciones que yo he podido ver, siempre se la representa como una hermosa rubia bien proporcionada y de ojos azules: el perfecto estereotipo nórdico al que me refería al principio.

Por el amor de Dios, ¿cómo no iba a enamorarse Boaz de ella? ¿Qué mérito tenia casarse con ella? Si una chica como ésa se hubiera postrado a sus pies y le hubiera pedido humildemente que cumpliera con su deber y fuera tan amable de casarse con ella, lo más probable es que no lo hubiera dudado un instante.

Claro que se trataba de una moabita, pero ¿y qué? ¿Qué quiere decir «moabita» para usted? ¿Le provoca alguna reacción violenta? ¿Conoce usted a muchos moabitas? ¿Se han visto sus hijos últimamente acosados por alguna banda de asquerosos moabitas? ¿Se han dedicado los moabitas a devaluar el valor de la propiedad en su vecindario? Dígame cuándo ha sido la última vez que le ha oído decir a alguien: «Tenemos que echar de aquí a esos malditos moabitas. No hacen más que engrosar las listas de la beneficencia.»

La verdad es que, a juzgar por las ilustraciones de Ruth, los moabitas son aristócratas ingleses y su presencia incrementaría el valor de las propiedades.

El problema es que la única palabra que no está traducida del Libro de Ruth es la palabra clave, «moabita», y mientras no esté traducida, se perderá el sentido de la historia; estará perdido en la no traducción.

La palabra «moabita» quiere decir, en realidad, «individuo perteneciente a un grupo que no recibe de nosotros más que lo que se merece: odio y desprecio». ¿Cómo podría traducirse esta palabra en un solo vocablo que significara eso mismo en la actualidad para, por ejemplo, un gran número de ciudadanos griegos?…Pues por «turco». ¿Y para muchos ciudadanos turcos?…Pues por «griego». ¿Y para muchos estadounidenses blancos?…Pues por «negro».

Para poder apreciar en su justa medida el Libro de Ruth, vamos a pensar que Ruth no es una moabita, sino una negra.

Relean la historia de Ruth y traduzcan «moabita» por «negra» cada vez que aparezca. Noemí (imagínenselo) regresa a los Estados Unidos con sus dos nueras negras.

No es extraño que intente convencerlas de que no la acompañen. Es asombroso que Ruth quiera tanto a su suegra que esté dispuesta a enfrentarse a una sociedad que la odia sin ningún motivo y que se arriesgue a recolectar el trigo delante de las narices de impúdicos segadores que no tienen ningún motivo para suponer que hayan de tratarla con alguna consideración especial.

Y cuando Boaz preguntó quién era, en lugar de leer «Es una muchacha moabita», pongan «Es una muchacha negra». En realidad, es más probable que los segadores le dijeran algo equivalente a (y perdonen mi lenguaje): «Es una asquerosa negra.»

Si lo consideran de esta manera, se darán cuenta de que toda la intención de la historia está única y exclusivamente en la traducción. El hecho de que Boaz esté dispuesto a casarse con ella, porque es una mujer virtuosa (y no porque fuera una belleza nórdica) adquiere una cierta nobleza. El veredicto de las vecinas, según el cual Ruth era mejor para Noemí que siete hijos, se transforma en algo que sólo habrían dicho de tener muy buenas razones para ello. Y el toque final de que de este cruce de razas naciera nada menos que el gran David es algo que corta el aliento.

En el Nuevo Testamento tenemos un ejemplo parecido.

En una ocasión, un estudiante de la Ley le preguntó a Jesús qué había que hacer para merecer la vida eterna, y respondió a su propia pregunta diciendo: «Amarás al Señor tu Dios con todo tu corazón, con toda tu alma, con todas tus fuerzas y con toda tu mente. Y a tu prójimo como a ti mismo» (Lucas, 10, 27).

Estas admoniciones están tomadas del Antiguo Testamento, por supuesto. La última frase sobre el prójimo está tomada de un versículo que dice: «No serás vengativo ni guardarás rencor a tus conciudadanos. Amarás a tu prójimo como a un hombre igual a ti mismo» (Levítico. 19, 18).

(En este caso me gustan más las traducciones de la Nueva Biblia Inglesa que la del rey Jaime: «Amarás a tu prójimo como a ti mismo.» ¿Quién es el santo capaz de sentir verdaderamente el dolor o el éxtasis de otro de la misma forma que siente los suyos? No hay que pedir demasiado. Pero si nos limitamos a admitir que otra persona es «un hombre igual a ti mismo», entonces al menos podemos tratarlo decentemente. Cuando nos negamos a admitir incluso esto y consideramos a los demás inferiores a nosotros, es cuando el desprecio y la crueldad llegan a parecer naturales y hasta laudables.)

Jesús se muestra de acuerdo con la sentencia del hombre de leyes y éste se apresura a preguntar: «Y, ¿quién es mi prójimo?» (Lucas, 10, 29). Después de todo, el versículo del Levítico habla en primer lugar de guardarse de ser vengativo y rencoroso con los conciudadanos; ¿no podría ser entonces que el concepto de «prójimo» se limitara a los conciudadanos, a los de nuestra propia clase?

Jesús le responde con la que quizá sea su mejor parábola: la del viajero que fue asaltado por los ladrones, que le apalearon y robaron, dejándolo medio muerto en el camino. Jesús continúa: «Coincidió que bajaba un sacerdote por aquel camino; al verlo, dio un rodeo y pasó de largo.

Lo mismo hizo un levita que llegó a aquel sitio; al verlo dio un rodeo y pasó de largo. Pero un samaritano, que iba de viaje, llegó a donde estaba el hombre, y, al verlo, le dio lástima, se acercó a él y le vendó las heridas, echándoles aceite y vino; luego le montó en su propia cabalgadura, le llevó a una posada y le cuidó» (Lucas, 10, 31-34).

Luego Jesús preguntó quién era el prójimo del viajero, y el abogado no tuvo más remedio que responder: «El que tuvo compasión de él» (Lucas, 10, 37).

Esta es la parábola del buen samaritano, aunque en la parábola Jesús no se refiere a él como buen samaritano, sino simplemente como a un samaritano.

La fuerza de la parábola queda completamente destruida al utilizar la extendida frase «buen» samaritano, porque de esta manera se da una falsa impresión de quiénes eran los samaritanos. Si se utilizara la palabra «samaritano» en un test de libre asociación, todo el mundo respondería «bueno». Tenemos tan grabado en la memoria que los samaritanos son buenos, que damos por supuesto que un samaritano siempre actuaría así y nos asombramos de que Jesús insista de esa manera en la historia.

¡Nos olvidamos de quiénes eran los samaritanos en la época de Jesús!

Los judíos no los consideraban buenos. Eran herejes odiados, despreciados y viles con los que ningún buen judío hubiera querido mezclarse. De nuevo, el punto culminante es la no traducción.

Supongamos, en cambio, que es un viajero blanco en Mississippi el que ha sido atacado y yace medio muerto. Y supongamos que los que hubieran pasado de largo, negándose a «tener nada que ver», fueran un sacerdote y un pastor actuales. Y supongamos que el que se paró y cuidó del hombre fuera un aparcero negro.

Ahora pregúntense: ¿quién era el prójimo al que hay que amar como si fuera un hombre igual a uno mismo para salvarse?

La parábola del buen samaritano nos demuestra claramente que el concepto de «prójimo» no está restringido en absoluto a ningún grupo, que no se puede ser bueno sólo con los del propio grupo o la propia clase. Todo el género humano, hasta aquellos que son más despreciados, es nuestro prójimo.

Bien, así que en la Biblia tenemos dos ejemplos, en el Libro de Ruth y en la parábola del buen samaritano, de enseñanzas que se pierden en la no traducción y que, sin embargo, son terriblemente pertinentes para nosotros en la actualidad.

A todo lo largo y ancho del mundo se producen enfrentamientos entre diferentes grupos del género humano definidos por su raza, su nacionalidad, su filosofía económica, su religión o su idioma, de manera que un grupo no es el «prójimo» de ningún otro.

Estas diferencias más o menos arbitrarias entre los pueblos que son miembros de una única especie biológica son tremendamente peligrosas, y en ningún lugar lo son tanto como en los Estados Unidos, donde el enfrentamiento más peligroso (no es necesario que se lo diga) es el que se produce entre blancos y negros.

Hablando en general, después del problema de la explosión demográfica, el mayor peligro al que se enfrenta el género humano es el de estos enfrentamientos, sobre todo en los Estados Unidos.

Tengo la impresión de que cada año aumentan el odio y la ira que hacen que los blancos y los negros se enfrenten violentamente. Esta continua escalada de violencia no parece tener otra salida que la guerra civil.

Con toda probabilidad, esta guerra sería «ganada» por los blancos, que están en ventaja numérica y en mayor ventaja aún en cuanto a fuerzas organizadas. Pero esta victoria supondría un enorme coste material, y sospecho que el coste espiritual resultaría fatal.

¿Y por qué? ¿Tan difícil es reconocer que, después de todo, el prójimo somos todos? ¿No podríamos las dos partes -las dos partes- aceptar la enseñanza de la Biblia?

O, si les parece que citar la Biblia es demasiado poco comprometido y que repetir las palabras de Jesús es demasiada beatería, digámoslo de otra manera, de una manera práctica.

¿Acaso el privilegio de sentir odio es una sensación tan agradable que por ella merezca la pena pasar por el infierno material y espiritual de una guerra civil entre blancos y negros?

Si verdaderamente la respuesta es «sí», entonces sólo me queda dejarlo por imposible.

14. Lo antiguo y lo último

Hace unas tres semanas (en el momento de escribir esto) asistí a un seminario en un lugar al norte del Estado de Nueva York, un seminario sobre las comunicaciones y la sociedad. Yo no tenía mucho que hacer, pero estuve allí cuatro días, así que tuve la oportunidad de enterarme de las actividades que se estaban desarrollando [25].

La primera noche asistí a una conferencia excepcionalmente buena dictada por un caballero extraordinariamente inteligente y encantador, que trabaja en el campo de las cintas de vídeo. Con argumentos atractivos, y en mi opinión irrefutables, afirmó que las cintas de video representaban la tendencia del futuro en el campo de las comunicaciones, o al menos una de las tendencias.

Señaló que los programas comerciales destinados a cubrir los tremendos gastos de las cadenas de televisión y de los terriblemente ávidos anunciantes no tenían más remedio que atraer a audiencias de decenas de millones de espectadores.

Como todos sabemos, los únicos programas que tienen alguna posibilidad de agradar a entre veinticinco y cincuenta millones de personas son los que evitan cuidadosamente la posibilidad de ofender a nadie. Cualquier cosa que pudiera darles un poco de sabor o de variedad ofendería a alguien y se habría perdido la partida.

Así que sólo sobreviven las papillas insípidas, no porque sean especialmente agradables, sino porque tienen buen cuidado de no resultar desagradables para nadie.

(Bueno, a algunas personas, como a usted y a mí, por ejemplo nos desagradan, pero cuando los magnates de la Unidad contabilizan el número de ustedes y yoes, y de gente como nosotros, el resultado final les provoca desdeñosas carcajadas.)

Pero las cintas de video, capaces de complacer a los paladares más peculiares, solo venden contenido, y no tienen por que enmascararlo con un barniz falso y costoso o con la presencia de alguna renombrada estrella del espectáculo. Si se lanza una cinta sobre estrategias de ajedrez con símbolos de las piezas de ajedrez moviéndose sobre un tablero, no es necesario añadir nada más para vender un número x de copias a un número X de fanáticos del ajedrez. Si cada cinta se vende a un precio que cubra los gastos de su edición (más un honrado margen de beneficios) y si el número de ventas está de acuerdo con lo fijado, entonces todo va bien. Es posible que alguna cinta venda menos de lo previsto, pero también es posible que otra venda mucho más de lo que se esperaba.

Para abreviar, el negocio de las cintas de vídeo sería bastante parecido al de las editoriales.

El orador expuso este punto con toda claridad, y lo dijo:

–El manuscrito del futuro no será un fajo de papeles torpemente mecanografiados, sino una secuencia de imágenes hábilmente fotografiada, – no pude evitar removerme inquieto en mi silla.

Es posible que al moverme llamara la atención sobre mi persona ya que estaba sentado en la primera fila, porque el orador añadió acto seguido:

–Y los hombres como Isaac Asimov se quedarán anticuados y serán sustituidos por otros.

Como es natural, di un brinco, y todo el mundo se rió alegremente ante la ocurrencia de que yo pudiera quedarme anticuado y fuera reemplazado por otro.

Dos días más tarde el orador que iba a hablar aquella tarde llamó desde Londres para comunicar que le era imposible salir de la ciudad, así que la encantadora dama que dirigía el seminario vino a verme y me pidió dulcemente que lo sustituyera.

Como es natural, dije que no tenía nada preparado, y como es natural ella dijo que todo el mundo sabía que no necesitaba prepararme para dar una conferencia maravillosa, y como es natural, me ablandé ante los cumplidos, y como es natural aquella tarde me levanté y como es natural di una conferencia maravillosa [26]. Todo fue muy natural.

Me resulta imposible contarles qué es lo que dije exactamente, porque, como todas mis charlas, fue improvisada; pero, por lo que recuerdo, en esencia era algo así:

Como hacía dos días que un orador nos había hablado de las cintas de vídeo, presentándonos la fascinante y deslumbrante imagen de un futuro en el que las cintas de video y los satélites dominarían el panorama de las comunicaciones, yo me disponía a servirme de mis conocimientos de ciencia ficción para explorar un futuro aún más lejano y hablaría de cómo podrían fabricarse cintas de video con métodos mejores y más refinados, haciéndolas aún más sofisticadas.

En primer lugar, el orador nos había mostrado que las cintas tenían que ser decodificadas por un aparato bastante caro y voluminoso, que transmitía las imágenes a una pantalla de televisión y el sonido a un altavoz.

Evidentemente, todo el mundo esperaría que este equipo auxiliar fuera haciéndose más pequeño, más ligero y transportable. En el fondo, lo que se esperaría es que acabara por desaparecer y que se integrara a la misma cinta.

En segundo lugar, para que la información contenida en la cinta se transforme en imágenes y sonido es necesario un gasto de energía que redunda en perjuicio del medio ambiente. (Como cualquier gasto de energía; aunque su uso es inevitable, hay que evitar utilizarla más de lo estrictamente necesario.)

Por consiguiente, es razonable esperar que disminuya la cantidad de energía necesaria para decodificar las cintas.

En último término, esperaríamos que disminuyera tanto como para llegar a desaparecer por completo.

Por tanto, podemos imaginarnos una cinta que fuera completamente transportable y autónoma. Seria necesario emplear energía en su fabricación, pero no en su utilización, y tampoco sería necesario un equipo especial para su uso posterior. No sería necesario enchufarla en la pared ni cambiarle las pilas, y podría ser transportada para ser vista en el lugar en que cada uno encontrara más cómodo: en la cama, en el cuarto de baño, en un árbol o en el ático.

Una cinta de video de estas características produce sonidos, como es natural, y también desprende luz. Evidentemente su usuario debe recibir con claridad las imágenes y el sonido, pero sería un inconveniente que molestara a otras personas que posiblemente no estarían interesadas en su contenido. Idealmente, esta cinta autónoma y transportable sólo tendría que ser vista y oída por el usuario.

Por muy sofisticadas que sean las cintas existentes en la actualidad en el mercado o previstas para un futuro próximo, siempre tienen necesidad de controles. Tiene que haber una palanca o un interruptor para encenderlas y apagarlas, y otros para controlar el color, el volumen, el brillo, el contraste y todas esas cosas. Mi idea es que esos controles pudieran ser manejados, en la medida de lo posible, por la voluntad.

Me imagino una cinta que deje de correr en el momento en que se aparte la mirada. Permanece parada hasta que se le vuelve a prestar atención, momento en el cual vuelve a ponerse en marcha inmediatamente. Me imagino una cinta que corre más deprisa o más despacio, hacia adelante o hacia atrás, a saltos o con repeticiones, dependiendo únicamente de la voluntad del usuario.

Admitirán ustedes que una cinta de estas características constituye un perfecto sueño futurista: autónoma, transportable, sin consumo de energía, absolutamente privada y controlada en gran medida por la voluntad.

Ah, pero soñar no cuesta nada, así que seamos prácticos. ¿Es posible la existencia de una cinta así? Mi respuesta es: sí, naturalmente.

La siguiente pregunta es: ¿cuántos años habrá que esperar antes de conseguir una cinta tan increíblemente perfecta?

También tengo respuesta para eso, y una respuesta bastante concreta. La conseguiremos dentro de menos de cinco mil años, porque lo que acabo de describir (como es posible que hayan adivinado), ¡es el libro!

¿Estoy haciendo trampas? ¿Acaso usted opina, amable lector, que el libro no es la cinta más refinada posible, ya que sólo ofrece palabras y no imágenes, que las palabras sin imágenes son un tanto unidimensionales y están divorciadas de la realidad, que es imposible que las palabras por sí solas nos transmitan información relativa a un universo que se manifiesta en imágenes?

Bien, vamos a considerar la cuestión. ¿La imagen es más importante que la palabra?

No cabe duda de que si sólo tenemos en cuenta las actividades puramente físicas del hombre, el sentido de la vista es con diferencia la manera más importante que tenemos de reunir información sobre el Universo. Si me dieran a elegir entre correr por un terreno escabroso con los ojos vendados y un sentido del oído muy agudo o con los ojos abiertos y sin poder oír nada, sin ninguna duda preferiría utilizar los ojos. De hecho, si tuviera los ojos cerrados, pondría la máxima atención en cualquier movimiento que realizara.

Pero el hombre inventó la palabra durante las primeras fases de su desarrollo. Aprendió a modular el aliento al espirar, y a utilizar distintas modulaciones del sonido como símbolos establecidos de objetos materiales y de diferentes acciones y -lo que es mucho más importante- de conceptos abstractos.

Por último, aprendió a codificar los sonidos modulados en señales visibles que podían ser traducidas mentalmente a sus sonidos correspondientes.

Un libro, no es necesario que lo diga, es un dispositivo que contiene lo que podríamos llamar un «discurso almacenado».

El lenguaje constituye la diferencia fundamental entre el hombre y los demás animales (excepto quizás el delfín, que posiblemente haya desarrollado un lenguaje, pero no un sistema para almacenarlo).

El lenguaje y la capacidad potencial de almacenarlo no sólo distinguen al hombre del resto de las especies vivas ahora o en el pasado; además es algo que todos los hombres tienen en común. Todos los grupos conocidos de seres humanos, por muy «primitivos» que sean, saben hablar y utilizar un lenguaje. He oído decir que algunos pueblos «primitivos» utilizan lenguajes muy complejos y sofisticados.

Lo que es más, todos los seres humanos con una mentalidad incluso inferior a la normal aprenden a hablar a una edad temprana.

Como el lenguaje es el atributo universal de todo el género humano, ocurre que nos llega más información, en nuestra calidad de animales sociales, a través del lenguaje que a través de las imágenes.

Y no estoy hablando de cantidades ni siquiera similares. El lenguaje y las formas de almacenarlo (la palabra escrita o impresa) constituyen la fuente abrumadoramente mayoritaria de la información que obtenemos, hasta tal punto que sin ella estaríamos indefensos.

Para poner un ejemplo, pensemos en un programa de televisión, normalmente compuesto de imágenes y lenguaje, y vamos a preguntarnos qué ocurre cuando prescindimos de aquéllas o de éste.

Supongamos que oscurecemos la imagen y dejamos puesto el sonido. ¿No seguiremos teniendo una idea bastante aproximada de lo que está ocurriendo? Es posible que en algunos momentos haya mucha acción y poco sonido, dejándonos frustrados ante la pantalla oscura y en silencio, pero si se supiera por anticipado que no se iba a ver la imagen, sería posible añadir algunos comentarios, y nos enteraríamos de todo.

De hecho, la radio está basada únicamente en el sonido; se servia del lenguaje y de «efectos sonoros». Es decir, en algunos momentos el diálogo se servia de artificios para compensar la falta de imágenes: «Ahí viene Harry. Oh, no ha visto el plátano. Oh, ha pisado el plátano. Ahí va.» Pero, por lo general, no era difícil enterarse. No creo que ningún oyente de la radio echara realmente de menos la falta de imágenes.

Pero volvamos a la televisión. Quitemos ahora el sonido y dejemos la imagen intacta: perfectamente enfocada y a todo color. ¿Qué es lo que sacamos en limpio? Muy poco. Ni todas las expresiones de emoción de los rostros, ni todos los gestos apasionados, ni todos los trucos de la cámara, dirigiéndose aquí y allá, son capaces de transmitirnos más que una vaga idea de lo que está ocurriendo.

Además de la radio, que utilizaba únicamente el lenguaje y sonidos diversos, estaban las películas mudas, que eran sólo imágenes. Los actores de estas películas, que no disponían del sonido ni del lenguaje, tenían que «emocionar». Oh, los ojos relampagueantes; oh, las manos que se llevaban a la garganta, que se agitaban en el aire, que se alzaban al cielo; oh, los dedos que apuntaban confiadamente hacia el cielo, o firmemente hacia el suelo, o airadamente hacia la puerta; oh, la cámara que se acercaba para enseñarnos la piel de plátano en el suelo, el as en la manga, la mosca en la nariz. Y, con todos los recursos de la inventiva visual en sus manifestaciones más exageradas, ¿qué es lo que ocurría cada quince segundos? La acción se detenía por completo y aparecían unas palabras en la pantalla.

Esto no quiere decir que no sea posible comunicarse, en cierto modo, sirviéndose únicamente de los recursos visuales: utilizando imágenes pictóricas. Un mimo hábil como Marcel Marceau o Charlie Chaplin o Red Skelton es capaz de hacer maravillas; pero la razón de que les observemos y aplaudamos es precisamente que sean capaces de comunicar tanto sirviéndose únicamente de imágenes.

De hecho, nos divertimos jugando a las charadas, intentando que otras personas adivinen una frase sencilla que nosotros «representamos». No sería un juego tan popular si no exigiera mucho ingenio, y aun así, los jugadores idean series de señales y estratagemas que (lo sepan o no) se sirven de los mecanismos del lenguaje.

Dividen las palabras en sílabas, indican si una palabra es larga o corta, utilizan sinónimos y sonidos similares. Al hacerlo, están sirviéndose de imágenes visuales para hablar.

Sin valerse de ningún truco relacionado con alguna propiedad del lenguaje, sirviéndose únicamente de los gestos y las acciones, ¿serían ustedes capaces de comunicar una frase tan sencilla como «Ayer hubo un atardecer muy bonito, rosa y verde»?

Claro que ustedes podrían objetar que una cámara de cine puede fotografiar una hermosa puesta de sol. Pero para ello es necesario invertir una gran cantidad de tecnología, y no estoy seguro de que eso les informara de que la puesta de sol fue así ayer (a menos que la película truque el calendario, que también es una forma de lenguaje).

O piensen en esto: las obras de Shakespeare fueron escritas para ser representadas. La imagen era parte esencial de ellas. Para apreciar todo su sabor, hay que ver a los actores y observar sus acciones. ¿Cuánto dejarían de entender si asisten a una representación de Hamlet y cierran los ojos, concentrándose únicamente en escuchar?

¿Cuánto dejarían de entender si se tapan los oídos y se concentran únicamente en mirar?

Una vez que he expuesto claramente mi creencia de que un libro, formado por palabras y no por imágenes, no pierde demasiado por esta falta de imágenes y, por tanto, es más que razonable considerarlo como una variante tremendamente sofisticada de una cinta de video, voy a cambiar de terreno y a servirme de un argumento aún mejor.

Un libro no carece de imágenes en absoluto: tiene imágenes. Lo que es más, imágenes mucho mejores -al ser personales- que cualquiera de las que la televisión podría ofrecernos jamás.

¿Acaso no acuden imágenes a su mente cuando está leyendo un libro interesante? ¿Acaso no ven mentalmente todo lo que está ocurriendo?

Esas imágenes son suyas. Le pertenecen a usted y sólo a usted, y son infinitamente mejores para usted que aquellas que otros le presentan sin que se lo pida.

Una vez vi a Gene Kelly en Los tres mosqueteros (la única versión que he visto que se mantiene razonablemente fiel al libro). La pelea de espadachines entre D'Artagnan, Athos, Porthos y Aramis, por un lado, y los cinco hombres de la guardia del cardenal, por el otro, que ocurre casi al principio de la película, era verdaderamente maravillosa.

Por supuesto, se trataba de un baile, y disfruté muchísimo con él… Pero Gene Kelly, por mucho talento de bailarín que tenga, no encaja en la imagen de D'Artagnan que yo tengo en la cabeza, y durante toda la película me sentí a disgusto porque violentaba «mi» visión de Los tres mosqueteros.

Esto no quiere decir que, en ocasiones, no resulte que un actor encaja exactamente con nuestra propia visión.

Resulta que para mí Sherlock Holmes es precisamente Basil Rathbone. Pero es posible que para usted Sherlock Holmes no sea Basil Rathbone; podría ser Dustin Hoffman. ¿Por qué tendrían todos nuestros millones de Sherlock Holmes que encajar en un único Basil Rathbone?

Ya ven, por tanto, por qué un programa de televisión, por maravilloso que sea, nunca podrá proporcionar tanto placer, ser tan absorbente y ocupar un lugar tan importante en la vida de la imaginación como un libro. Para ver el programa de televisión sólo tenemos que poner la mente en blanco y sentarnos apáticamente mientras nos dejamos invadir por el despliegue de imágenes y sonidos, sin que nuestra imaginación intervenga para nada. Si hay otras personas viéndolo, también se dejan llenar hasta arriba exactamente de la misma manera, todas ellas, y con exactamente las mismas imágenes sonoras.

En cambio, el libro exige la colaboración del lector.

Insiste en que tome parte en el proceso.

Al hacerlo, nos ofrece una interrelación de la que el lector dispone a su gusto según sus necesidades, que se justa exactamente a sus características y a su idiosincrasia.

Cuando leemos un libro, creamos nuestras propias imágenes, los sonidos de las diferentes voces, los gestos, las expresiones y emociones. Creamos todo excepto las mismas palabras. Y si la creación nos produce algún placer, el libro nos ha dado algo que el programa de televisión es incapaz de darnos.

Además, si diez mil personas leen el mismo libro al mismo tiempo, no obstante cada una de ellas crea sus propias imágenes, sus propias voces, sus propios gestos, expresiones y emociones. No será un solo libro, sino diez mil libros. No será obra exclusivamente de su autor, sino el producto de la interacción del autor con cada uno de los lectores por separado.

Por tanto, ¿qué es lo que podría sustituir al libro?

Admito que el libro puede sufrir alteraciones en algunos aspectos secundarios. Hubo una época en que se escribía a mano; ahora se imprime. La tecnología de la publicación de libros impresos ha progresado de mil maneras, y es posible que en el futuro los libros puedan visualizarse electrónicamente en la pantalla de televisión de nuestras casas.

Pero en último término, nos encontraremos a solas con la palabra impresa, y ¿qué podría sustituirla?

¿No estaré tomando mis deseos por realidades? ¿No será que como me gano la vida con los libros no quiero aceptar el hecho de que los libros puedan ser reemplazados por otra cosa? ¿Me estaré limitando a inventar argumentos ingeniosos para consolarme?

Nada de eso. Estoy seguro de que los libros no serán sustituidos en el futuro, porque no lo han sido en el pasado.

Desde luego, hay muchos más espectadores de televisión que lectores de libros, pero esto no es ninguna novedad. Los libros siempre han sido una actividad minoritaria. Había muy poca gente que leyera antes de la televisión y antes de la radio y antes de cualquier cosa que se les pueda ocurrir.

Como he dicho, los libros son absorbentes y exigen una cierta actividad creativa por parte del lector. No todo el mundo, en realidad muy pocas personas, están dispuestas a dar lo que éstos requieren, así que no leen ni leerán. No renuncian a ello porque el libro les decepcione de algún modo, sino por naturaleza.

La verdad es que me gustaría insistir en que leer es difícil, excesivamente difícil. No es como hablar, algo que hasta los niños que no tienen una inteligencia normal aprenden sin necesidad de un programa de enseñanza consciente. Basta con el impulso de imitación que se manifiesta a partir del primer año.

Por el contrario, leer requiere un cuidadoso aprendizaje que pocas veces tiene éxito.

El problema es que nos engañamos a nosotros mismos con nuestro concepto de lo que es saber leer y escribir. Casi todo el mundo puede aprender (si lo intenta con bastante interés y durante el tiempo suficiente) a leer las señales de tráfico y comprender las instrucciones y los avisos y carteles, y a descifrar los titulares de los periódicos. Siempre que el mensaje impreso sea corto y razonablemente sencillo y que la motivación para leerlo sea grande, casi todo el mundo sabe leer.

Y si esto es saber leer, entonces casi todos los norteamericanos saben leer. Pero si luego nos preguntamos por la razón por la que tan pocos norteamericanos leen libros (parece ser que el norteamericano medio que ha completado los estudios primarios no lee ni siquiera un libro al año), nos estamos engañando con nuestra interpretación de lo que es saber leer.

Pocas personas de las que saben leer, en el sentido de ser capaces de leer un cartel de PROHIBIDO FUMAR, llegan a familiarizarse con la palabra impresa y a realizar con facilidad el proceso de decodificar rápidamente las pequeñas y complicadas formas que representan sonidos modulados hasta el punto de estar dispuestos a emprender una lectura prolongada, como, por ejemplo, la de abrirse camino por un marasmo de mil palabras consecutivas.

No creo que esto se deba únicamente a un fallo de nuestro sistema educativo (aunque Dios sabe que es un fallo). No es de esperar que si, por ejemplo, se enseña a todos los niños a jugar al béisbol, todos ellos lleguen a ser jugadores de béisbol de primera clase, o que todos los niños que aprenden a tocar el piano se conviertan en pianistas de talento. En casi todos los campos del esfuerzo humano aceptamos la idea de que es necesaria la existencia de un cierto talento que puede ser alentado y desarrollado, pero que no es posible crear de la nada.

Bueno, en mi opinión la lectura también es un talento.

Se trata de una actividad muy difícil. Permítanme que les cuente cómo la descubrí.

De adolescente leía de vez en cuando revistas de historietas, y mi personaje preferido, si les interesa saberlo, era Scrooge McDuck. En aquella época las revistas de historietas costaban diez centavos, pero por supuesto yo las leía gratis porque las cogía del quiosco de mi padre.

Aunque siempre me asombraba de que alguien pudiera ser tan tonto como para pagar diez centavos cuando bastaba con hojear la revista en el quiosco durante un par de minutos para leérsela entera.

Después ocurrió que un día iba a la Universidad de Columbia en el metro; estaba agarrado a mi correa en un vagón atestado de gente y no tenía nada a mano para leer.

Afortunadamente, la chica que iba sentada frente a mí estaba leyendo una revista de historietas. Era mejor que nada, así que me coloqué de manera que pudiera ver las páginas y leerlas al mismo tiempo que ella. (Afortunadamente, puedo leer al revés con tanta facilidad como al derecho.)

Pasaron algunos segundos y pensé: ¿por qué no le da la vuelta a la página?

Por fin, lo hizo. Tardaba varios minutos en acabar cada doble página, y mientras estaba observando sus ojos que iban de una viñeta a la siguiente y sus labios que murmuraban cuidadosamente cada palabra, tuve una súbita revelación.

Estaba haciendo lo que yo haría si estuviera descifrando palabras inglesas escritas en caracteres hebreos, griegos o cirílicos. Como no conozco estos alfabetos más que por encima, primero tendría que reconocer cada letra, recordar su sonido, luego unirlas y después reconocer la palabra.

Luego tendría que pasar a la siguiente palabra y hacer lo mismo. Después de haber descifrado varias palabras de este modo, tendría que volver atrás e intentar combinarlas.

Pueden apostar a que en esas circunstancias yo leería bien poco. La única razón de que lea es que cuando miro una línea impresa inmediatamente veo las palabras ya formadas.

Y la diferencia entre el lector y el no-lector se va haciendo cada vez mayor con el paso de los años. Cuanto más lee un lector, más información va acumulando, más amplía su vocabulario y más se va familiarizando con las diversas alusiones literarias. Cada vez le resulta más fácil y más divertido leer, mientras que al no-lector cada vez le resulta más difícil y menos gratificante.

El resultado es que hay, y que siempre ha habido (sea cual sea el supuesto nivel cultural de una sociedad determinada) lectores y no-lectores; aquellos constituyen una pequeña minoría de, supongo, menos del uno por ciento.

He calculado que unos cuatrocientos mil norteamericanos han leído alguno de mis libros (de una población de doscientos millones), y yo soy considerado, y yo mismo me considero, un autor de éxito. Si se vendieran dos millones de ejemplares de un libro determinado en todas las ediciones estadounidenses, seria un notable éxito de ventas, y esto sólo significaría que un uno por ciento de la población de los Estados Unidos se habría animado a comprarlo.

Además, estoy seguro de que al menos la mitad de los compradores no conseguirían hacer otra cosa que recorrerlo a trompicones para encontrar los pasajes subidos de tono.

Estas personas, estos no-lectores, estos receptores pasivos de entretenimiento, son terriblemente volubles. Pasan de una cosa a otra, buscando continuamente algún dispositivo que les dé el máximo posible y les exija el mínimo esfuerzo.

De los juglares a los actores de teatro, del teatro a las películas, de las películas mudas a las sonoras, del blanco y negro al color, del tocadiscos a la radio y de nuevo al tocadiscos, de las películas a la televisión y luego a la televisión en color y luego a las cintas de vídeo.

¿Qué importa?

Pero mientras tanto esa minoría de menos del uno por ciento se mantiene fiel a los libros. Sólo la palabra impresa puede exigirles tanto, sólo la palabra impresa puede obligarles a mostrarse creativos, sólo la palabra impresa puede adaptarse a sus deseos y necesidades, sólo la palabra impresa puede darles lo que no podría darles ninguna otra cosa.

Puede que el libro sea un invento antiguo, pero también es definitivo y nada convencerá a los lectores de que lo abandonen. Se mantendrán como minoría, pero se mantendrán.

Así que, a pesar de lo que dijo mi amigo en su conferencia sobre las cintas de video, los autores de libros no se quedarán nunca pasados de moda ni serán sustituidos. Puede que escribir no sea una buena manera de hacerse rico (¡oh, bueno, y qué importa el dinero!), pero siempre existirá como profesión.

15. Por los números

La hipocresía es un fenómeno universal. Termina con la muerte, pero no antes. Cuando es conciente, repugna, pero pocos de nosotros somos hipócritas concientes. ¡Es tan fácil inventar argumentos que hagan el caldo gordo a nuestros propios intereses y prejuicios, y encontrarlos sinceramente nobles!

Yo también lo hago, no me cabe duda, pero por la misma naturaleza de las cosas es difícil ver con claridad la viga en el ojo propio. Permitidme que dé en cambio un ejemplo que afecta a un buen amigo mío.

Hablaba de los profesores. Pudo haber sido profesor, decía, de haber seguido el camino apropiado después de graduarse. Ahora se alegraba de no haberlo hecho, pues no querría ser portador de un título que ostentan quienes ceden tan débil y supinamente a las ruines demandas de estudiantes bellacos.

Sus ojos brillaron enfebrecidos en este punto, y levantó los brazos como sujetando entre ellos una imaginaria metralleta. Rechinando los dientes, dijo: «Lo que les hubiese dado yo a esos bastardos es rat-tat-tamat», y roció todo el cuarto con balas imaginarias, matando (en su fantasía) a todos los presentes.

Aquello me chocó bastante. En circunstancias ordinarias, mi amigo era una de las personas más amables y razonables que conozco y recurrí a excusas -haciendo hipócritamente por un amigo lo que no hubiera hecho por un enemigo-. Había bebido unas copas, y yo sabía que su juventud había sido solitaria y triste. Sin duda, al otro lado de aquella metralleta danzaban las sombras de aquellos jóvenes que muchos años atrás le habían hostigado para divertirse.

No hice, en consecuencia, comentario alguno, y cambié de tema, mencionando una campaña política a la sazón en curso. Se vio en seguida que, para nueva desazón mía, mi amigo, que habitualmente tenía los mismos puntos de vista que yo, había desertado y pensaba votar al candidato opuesto. No pude por menos de expresar mi desencanto, y mi amigo comenzó inmediatamente a exponer en detalle sus razones para desertar.

Disentí, deseando pararle los pies. «No hay nada que hacer -dije-. No me vas a convencer… Odio demasiado a esa persona para votarle alguna vez.»

Mi amigo se reclinó sobre la silla, esbozó una sonrisa de virtud auto-consciente [27] y dijo: «Me temo que no sé odiar muy bien.»

La visión de la imaginaria metralleta con la que tres minutos antes había simulado matar a cientos de estudiantes surgió ante mis ojos. Suspiré y volví a cambiar de tema. ¿Para qué protestar? Estaba claro que pensaba sinceramente que no sabía odiar.

Pero mi amigo me trajo a la mente los hombres en general. ¿Qué decir de la hipocresía, nada distinta, de todos aquellos que hoy están en contra de la tecnología?

Sabe el cielo cuánta gente se ocupa hoy de denunciar nuestra sociedad tecnológica Y todos los males que nos ha traído. Y lo hacen con una virtud auto-conciente que enmascara el hecho de que todos ellos anhelan los beneficios de esa sociedad tanto como cualquier otro. Por así decirlo, son capaces de denunciar la maquinilla eléctrica de afeitar del vecino mientras rasguean una guitarra eléctrica.

No faltan los idealistas que «vuelven a la madre tierra» y perseveran el mes o dos necesarios para que les salgan callos. Imagino que usarán palos y piedras como herramientas, despreciando los fantasiosos instrumentos metálicos manufacturados por modernos hornos y fábricas. Pero incluso así sólo son libres de hacerlo porque se aprovechan de que nuestra sociedad tecnológica puede alimentar (aunque sea imperfectamente) a miles de millones de seres humanos, y dejar todavía tierra para que los amantes de la vida llana caven en ella.

La sociedad tecnológica no le fue impuesta a la humanidad. Nació de la demanda humana de alimento abundante, calor en el invierno, fresco en el verano, menos trabajo y más juego y diversión. Por desgracia, la gente quiere esto, y además todos los hijos que les parece bien tener, y el resultado es que la tecnología [28], en sus mejores logros, nos ha llevado a una situación de considerable peligro.

Muy bien; hay que salir del aprieto y salvar el pellejo, ¿pero cómo? Para mí, la única respuesta posible es: a través de un uso continuado y más sabio de la tecnología. No digo que esto garantice el éxito, pero sí que ninguna otra solución funcionará.

Para empezar, me parece que debemos continuar, extender e intensificar la aplicación de computadores a la sociedad.

¿Una idea ofensiva? ¿Por qué?

¿Que las computadoras no tienen alma? ¿Que no tratan a los seres humanos como seres humanos, sino como tarjetas perforadas (o como su equivalente electrónico)?

Pongamos las cosas en su sitio. Las computadoras no tratan a nadie como nada. Son instrumentos matemáticos proyectados para acumular y manipular datos. Los responsables son los seres humanos que programan y controlan las computadoras, y si a veces se esconden tras ellas para enmascarar su propia incapacidad, es realmente un error humano y no un fallo de la computadora. ¿No es así?

Podría, desde luego, argumentarse que si la computadora no estuviera allí para escudarse uno detrás, las personas encargadas se verían colocadas en la picota, y obligados a tratarnos con más decencia.

¿No lo creéis así? La historia de la ineptitud administrativa, del salvajismo burocrático, de todas las injusticias y tiranía del pequeño funcionariado precede con mucho a la computadora. Y con eso es con lo que estaríais tratando si abolieras la computadora.

Claro que tratando con un ser humano cabría razonar y persuadir -lo que quiere decir que una persona inteligente y con facilidad de palabra tendría ventaja sobre otra cuyo caso fuera igual de legítimo, pero que fuese simple, de escasa labia y temerosa-. O quizá cupiera saltarse una decisión oficial dando subrepticiamente a alguien unos billetes, haciendo un favor o recurriendo a un amigo influyente. En cuyo caso, los que poseen dinero o son importantes tienen ventaja sobre los menos favorecidos.

Pero eso está mal, ¿no? Lo que todos veneramos es la imparcialidad a ultranza. Proclamamos que las leyes deben cumplirse sin favoritismos. Mantenemos que la ley no respeta a las personas. Si realmente lo creemos, debiéramos dar la bienvenida a las computadoras, que aplicarían las reglas de la sociedad sin ser capaces de plegarse a zalamerías ni a sobornos. Los casos difieren, desde luego, de una persona a otra, pero cuanto más elaborado sea el programa de una computadora, más pueden tomarse en cuenta esas diferencias.

¿O es que no queremos, en realidad, que se nos trate imparcialmente? Es muy probable; y por ello sospecho que la hipocresía tiene mucho que ver con el clamor contra las computadoras.

¿Perdemos nuestra individualidad en una sociedad organizada por computadoras? ¿Nos convertimos en números?

Lo que ocurre es que no podemos ser personas sin alguna especie de agarraderas. Todos estamos codificados, y tenemos que estarlo. Si os tocara tratar con alguien que se niega en redondo a datos su nombre, os referiréis a él por medio de alguna descripción, como «el tipo de pelo rojo y mal aliento». Y al final lo abreviaréis a «el viejo mal-aliento».

Con el tiempo y las generaciones, se convertiría en «Vimal», o algo así, e incluso podría llegar a considerarse un nombre aristocrático.

En resumen, estamos codificados. No podemos ser «personas» más que para el pequeño puñado de gente que trata con nosotros cada día. Todos los demás nos conocen sólo por la clave. El problema no es el de si codificarnos o no; el problema es el de codificarnos eficientemente.

Todo se reduce a la diferencia entre un número y un nombre. Mucha gente parece creer que el número es más vil que el nombre. Los nombres son de alguna manera personales y cariñosos, mientras que los números son impersonales y malvados.

Reconozco el sentimiento. A mí, sin ir más lejos, me encanta mi nombre, y organizo un escándalo cada vez que lo escriben o pronuncian mal (cosa nada difícil). Pero me busco excusas. En primer lugar, mí nombre es intensamente personal. Soy, que yo sepa, el único Isaac Asimov en el mundo; desde luego, el único que hay en los Estados Unidos. Por lo demás, si alguien conoce mi nombre sin conocerme a mí, se debe por completo a lo que yo mismo, personalmente, he hecho de mi vida.

Y, sin embargo, tiene inconvenientes. Mi nombre es difícil de escribir y difícil de pronunciar, y dedico varias horas al año a negociar con las telefonistas para persuadirlas, en vano, a que pronuncien mi nombre en forma siquiera aproximadamente correcta.

¿Que me busque un nombre más fácil y más pronunciable? ¡Pero es que entonces me perdería en un océano nominal! Habrá mucha gente que prefiera los nombres a los números y se llame Fred Smith, Bob Jones o Path McCarthy. Cada uno de ellos lo comparten millones de personas y ¿qué valor real tiene una combinación de sonidos duplicada sin fin? Imagínense la historia de los entuertos a que ha llevado tal multiplicación, desde la presentación de una factura a alguien por un artículo que no compró hasta la ejecución de un sujeto por un crimen que no cometió.

Los números son también nombres, pero nombres eficientes. Distribuidos apropiadamente, nunca se necesitarán duplicaciones. Cada número-nombre singular puede ser único en todo el espacio y tiempo terrestres. Y todos serían igualmente dóciles a la escritura y a la pronunciación.

Naturalmente, habría que distinguir entre la designación cifrada oficial de un hombre y su designación personal. Incluso hoy día, un hombre puede llamarse Obdulio Garagorrigoicoechea y ningún documento que se refiera a él será legal sin que cada letra de su nombre aparezca cuidadosamente escrita…, sin embargo, puede que sus amigos le llamen «Orejas». Tener un número oficial no significa que vayan a llamarnos por ese número.

Lo único que hace falta es tener ese número archivado, que sea único, conveniente y fácilmente almacenable y manipulable por computadora. Seréis así infinitamente más personas al haber algo siempre asequible que es exclusiva e inerradicablemente vuestro, que no con un nombre sin sentido, apenas conocido por unas cuantas personas.

En realidad vivimos ya en la época del número, aunque en forma muy primitiva. Y está ahí porque insistimos en ello. Cada año nos empeñamos en sobrecargar la Oficina de Correos más y más, por lo que necesitamos códigos territoriales para imprimir rapidez a los repartos. Como verdaderos hipócritas, nos quejamos amargamente de esos códigos, pero más nos quejaríamos si los abandonáramos, retrasando inevitablemente el reparto.

De la misma forma, el número ingente de conferencias telefónicas y la resistencia de la gente a ser operadores de teléfonos en vez de usuarios telefónicos (o a pagar la plantilla de operadores) hace que los códigos de área sean necesarios.

En cuanto a los números de Seguridad Social, intentad que el sistema fiscal funcione sin ellos.

Ya os oigo decir: ¿pero quién necesita el sistema fiscal? Y en eso, amigos míos, os aseguro que estoy con vosotros. Mis pagos por impuestos son mayores cada año, y rondan un orden de magnitud que nunca hubiese soñado (cuando me doctoré) llegaría a constituir el total de mis ingresos y desde luego no los pago con gusto.

Sin embargo, esos impuestos existen -a pesar de las objeciones de cada uno de nosotros- y existen por exigencia absoluta… de cada uno de nosotros. Insistimos en que el gobierno mantenga diversos servicios de alto costo, y ello significa impuestos enormes y complicados. Pedir el servicio y quejarse del pago es hipocresía, si se entiende la contradicción, e idiocia si no se entiende.

La mayor y más cara de nuestras exigencias es que el gobierno mantenga un ingente tinglado militar del tipo más avanzado y costoso con el fin de protegernos en nuestra posición de nación más rica y más poderosa frente a las envidiosas hordas exteriores.

¿Qué? ¿Que tú no lo exiges? ¿Ni tú tampoco? Supongo que es porque vosotros y yo somos antimilitaristas, y creemos en la paz y el amor. El hecho es, sin embargo, que el pueblo americano, por gran mayoría, prefiere pagar por armas que por cualquier otra cosa. Si lo dudáis, estudiad el registro de votos del Congreso y recordad que hay pocos senadores y diputados que se atreverían a ofender a sus electores, arriesgando la pérdida de su preciada posición.

Sí, estáis a favor de reducir los gastos gubernamentales. Y yo también. La única dificultad es que vosotros, y yo, y todos los demás, estamos en favor de reducirlos sólo en aquellas áreas que no nos perjudiquen ni emocional ni económicamente… lo cual es natural entre hipócritas.

Y si todos clamamos por una reducción sin dar nuestro brazo a torcer, no habrá reducción mientras nuestra civilización tecnológica permanezca estable.

Así pues, si insistimos en que el gobierno emprenda inmensas y costosas actividades y si esperamos, en consecuencia, que el gobierno recaude cerca de un cuarto de billón de dólares al año de los generalmente reacios contribuyentes que, en definitiva, no encuentran antipatriótico evadirlos, ponemos al gobierno en difícil posición.

Por esa difícil posición, al Servicio de Recaudación de Impuestos le toca bailar con la más fea (os digo francamente que yo mismo les odio de la cabeza a los pies -y sé, al revés que mi amigo, odiar bastante bien-). No obstante, esa odiosa labor es esencial, y no habría forma de llevarla a cabo sin números de Seguridad Social y computadoras.

Dado que la labor ha de realizarse, hagámosla menos odiosa. Tengo para mí que la salida está en crear un banco nacional de computadoras, a cargo del gobierno (inevitablemente), que registre en sus entrañas cuanta información sea posible acerca de todo individuo que resida en los Estados Unidos (o en el mundo, si alguna vez somos lo suficientemente inteligentes como para organizar un gobierno mundial).

Y no lo espero con triste resignación o con temerosa aprensión, sino con anhelo.

Me gustaría que cada persona recibiese una clave de identificación, larga y complicada, con símbolos que representen su edad, ingresos, educación, vivienda, ocupación, número de miembros de la familia, gustos particulares, posición política, preferencias sexuales, todo lo que sea concebible codificar. Me gustaría que todos estos símbolos fuesen periódicamente puestos al día, para que todo nacimiento, toda muerte, todo cambio de domicilio, todo nuevo trabajo, toda nueva calificación académica, toda detención, toda enfermedad sea constantemente registrada. Naturalmente, cualquier intento de evadir o falsificar tales símbolos sería claramente una acción antisocial, y como tal habría de ser tratada y castigada.

¿No sería una codificación así una invasión de la intimidad? Sí, desde luego, pero ¿por qué mencionarlo? Esa batalla la perdimos hace mucho tiempo. En cuanto aceptamos un impuesto sobre la renta, concedimos al gobierno el derecho a conocer ese extremo. Al insistir en que el impuesto sobre la renta fuera igualitario, admitiendo deducciones por gastos y pérdidas comerciales, por contribuciones, depreciación, y quién sabe cuántas otras cosas, hicimos necesario que el gobierno se ocupara de todo ello, que investigase cada cheque que firmamos, que observase cada comida en cada restaurante, que hojease todos nuestros registros.

No me gusta. Odio, y me sienta mal, que me traten como culpable hasta que no pruebe mí inocencia. Odio participar en una pelea desigual con una agencia que es al mismo tiempo fiscal y juez.

Y, sin embargo, es necesario. A mí, personalmente nunca me han cogido, hasta el momento, más que en exceso de pagos y, en consecuencia, no he recibido más que reembolsos, pero tengo entendido que no es lo habitual. El Servicio de Recaudación de Impuestos, al volver a todo el mundo patas arriba y sacudirlo, recoge millones de dólares que pertenecen legítimamente al gobierno.

Bien, ¿qué ocurriría si todos estuviéramos perfectamente codificados, y si esta codificación fuera manipulada y manejada por computadoras? Nuestra intimidad no se vería más destruida de lo que lo está, pero los efectos de esa destrucción podrían ser menos sensibles e irritantes. El Servicio de Recaudación no necesitaría estudiar nuestros registros. Tendría nuestros registros.

A mí, por mi parte, me encantaría estar en una situación en la que no pudiera de ninguna manera hacer trampas, siempre y cuando ningún otro pudiera hacerlas tampoco. Para la mayoría supondría un ahorro en impuestos.

Incluso me gustaría ver una sociedad sin dinero efectivo. Me gustaría que todo el mundo funcionara con tarjetas de crédito organizadas por computadora. Me gustaría que toda transacción, de cualesquiera naturaleza y monto, desde la compra de General Motors a la compra de un periódico, llevase aparejado el uso de esa tarjeta de crédito, con lo que el dinero sería transferido electrónicamente de una cuenta a otra.

Todo el mundo sabría en todo momento cuál era su activo. Por lo demás, el gobierno podría recibir su parte por cada transacción, y ajustar las cuentas, en más o en menos, a fin de cada año. No podríais evadir impuestos, ni os tendríais que preocupar para nada.

Todo este entrometimiento personal, ¿no permitiría al gobierno controlarnos y reprimirnos más despiadadamente? ¿Es compatible con la democracia?

La verdad es que al gobierno no le faltan nunca métodos para controlar a la población. No se necesita computadora alguna, ni código, ni expedientes. La historia de la humanidad es una historia de la tiranía y del gobierno por represión, y algunos de los gobiernos más represivos y eficientemente despóticos han contado con muy poca tecnología a su servicio.

¿Usó la Inquisición española computadoras para perseguir a los herejes? ¿Lo hicieron los puritanos de Nueva Inglaterra? ¿Los calvinistas de Ginebra?

Lo difícil, claro, es encontrar un gobierno que no sea represivo. Hasta el más liberal y tolerante de los gobiernos, que respete de ordinario las libertades civiles, se torna rápidamente represivo tan pronto como surge una emergencia y se siente amenazado. Y lo hace sin dificultad alguna, saltándose cualquier barrera legal como si no estuviera allí.

En la Segunda Guerra Mundial, por ejemplo, el gobierno de los Estados Unidos -a quien quiero y respeto- llevó a miles de americanos de ascendencia japonesa a campos de concentración, sin rastro alguno de derecho legal. No podía ni siquiera considerarse como una medida necesaria en tiempo de guerra, dado que no se hizo lo mismo (ni en sueños) con los americanos de ascendencia alemana o italiana, a pesar de que tan en guerra estábamos con Alemania e Italia como con Japón. Sin embargo, la acción encontró en general poca resistencia entre la población, y fue, de hecho, popular, y sólo por nuestra prevención hacia la gente de ojos extraños y por el miedo a Japón en el tiempo inmediatamente posterior a Pearl Harbor.

Esa es la palabra clave: miedo. Toda represión surge del miedo. Si no es del miedo general, es del miedo de un tirano a perder su propia seguridad.

De no conocer en detalle a su población, un gobierno sólo puede sentirse seguro si reprime a todos. A falta de conocimiento, un gobierno tiene que ser cauto, tiene que reaccionar ante rumores y suposiciones, y tiene que atacar a todos duramente para no ser atacado. Las peores tiranías son las tiranías de los hombres temerosos.

Si un gobierno conoce a fondo a su población, no necesita temer inútilmente; sabrá a quién temer. Habrá, desde luego, represión, dado que jamás ha existido un gobierno que no haya reprimido a quienes considerase peligrosos; pero la represión no tendría que ser tan general, tan duradera, ni tan encarnizada. En resumen, habría menos temor en las alturas y, por tanto, más libertad abajo.

¿No reprimiría un gobierno por el mero gusto de hacerlo, si tuviese el tipo de oportunidad que la computadora le ofrece? No, salvo que esté loco. La represión crea enemigos y conspiradores, y por muy eficiente ayuda que pueda proporcionar una computadora para luchar contra ellos, ¿para qué crearlos si no es necesario?

Por otra parte, un conocimiento profundo de las características de la población puede hacer que los servicios gubernamentales que ahora exigimos sean más eficientes. No podemos esperar que el gobierno actúe inteligentemente si no sabe, en todo momento, lo que está haciendo; o, en detalle, lo que se le está exigiendo. Para empezar, hay que comprar los servicios con dinero, como todo contribuyente sabe; mas para que esos servicios sean útiles y eficientes hay que entregar luego, a cambio, información sobre nosotros mismos.

Tampoco es esto novedad. El censo decenal se ha ido haciendo más complejo con el paso de los años, para beneficio del hombre de negocios y del administrador, que encuentran en él la información que puede ayudarles a dirigir sus respuestas. Pues bien, lo único que sugiero es que esto se lleve a sus últimas consecuencias.

Ese sometimiento definitivo a las computadoras, esa absoluta conversión en una sociedad organizada numéricamente, ¿no borrará la iniciativa, la creatividad, el individualismo?

Pero ¿en qué sociedad los ha habido?

Mostradme una sociedad, en cualquier momento de la historia mundial, en la que no hubiera guerra, ni hambre, ni pestes, ni injusticia. Hemos conocido sociedades en las que hubo iniciativa, y creatividad, e individualismo, sí, pero sólo en un pequeño estrato superior de aristócratas y privilegiados.

Los filósofos de Atenas tuvieron tiempo para pensar y especular porque la sociedad ateniense era rica en esclavos que no tenían ocio alguno. Los senadores romanos vivieron vidas lujosas a base de saquear todo el mundo mediterráneo. Las cortes reales de todas las naciones, nuestras propias gentes del Sur, nuestros propios industriales del Norte, vivieron fácilmente a costa de campesinos y esclavos y trabajadores.

¿Queréis esas sociedades? Si es así, ¿dónde os situaríais? ¿Os meteríais en el pellejo de los esclavos atenienses o en el de los filósofos? ¿En el de los campesinos italianos o en el de los senadores romanos? ¿En el de los aparceros sureños o el de los propietarios de plantaciones? ¿Os gustaría veros transportados a una de esas sociedades y correr el riesgo de que os tocara la posición que os tocara, recordando que por cada persona que vivía cómodamente había cien o mil que se debatían en la oscuridad?

¡Hipócritas! No queréis para nada la sociedad simple. Lo que queréis es estar cómodos, y al infierno con todos los demás.

En cualquier caso, y por fortuna, no podemos tener hoy sociedades simples. A lo único que legítimamente podemos aspirar es justo a la sociedad compleja que ahora tenemos -pero que funcione-. La única alternativa, la única, es la completa destrucción.

Y eso supone la automación completa, porque la sociedad se ha hecho demasiado compleja para ser capaz de funcionar de cualquier otra forma.

Si programamos adecuadamente las computadoras, podremos aplicar impuestos mínimos, podremos reducir la corrupción al mínimo, podremos minimizar la injusticia social. A la postre, cualquier sociedad en la que la gente es saqueada, en la que unos pocos se enriquecen, en la que amplios sectores de la población son pobres, están hambrientos, alienados e irascibles, contribuye a su propia inestabilidad.

Los individuos pueden ser lo suficientemente miopes como para preferir el beneficio inmediato y mandar al infierno a todos los demás, incluidos sus hijos; pero las computadoras no son tan desalmadas. Serían programadas para el funcionamiento de una sociedad, y no para la comodidad de los individuos, y no venderían el derecho de primogenitura de nuestra sociedad por el plato de lentejas de un individuo, como hace el ser humano incontrolado.

Por otro lado, las personas son a veces lo bastante emocionales como para desear la guerra e imponer sus puntos de vista, a pesar de que una guerra termina casi invariablemente con la derrota de ambos lados (aunque algunos individuos particulares se beneficien), y no es concebible que ninguna guerra sea tan útil como un compromiso sensato. Pero es imposible que una computadora adecuadamente programada sea tan desalmada como para recomendar la guerra como solución óptima.

Y si las diversas naciones se sometieran a computadoras bien programadas, sospecho que todas las computadoras nacionales llegarían, por así decirlo, a un acuerdo. Todas recomendarían programas compatibles, dado que está claro que hoy en día, y más aún en el futuro, ninguna parte de la tierra puede beneficiarse del mal de otra. El mundo es pequeño. O nos salvamos todos juntos, o nos hundimos a una [29].

Eso es, pues, lo que quiero, un mundo sin guerra y sin injusticia, posible gracias a la computadora.

Y como trato de no ser hipócrita, admitiré francamente que quiero ese mundo simplemente por razones egoístas. Me hará sentirme bien.

G) Y (acertAsteis) sobre mí

16. El crucero y yo

En la introducción al capítulo 2 mencioné de pasada mi presencia en la cubierta de un buque, frente a la costa de Florida. Se me ocurre que no debiera dejarlo así. Especialmente porque es notorio que no viajo, y mis fieles y Amables Lectores podrían querer saber cómo es que me embarqué y cómo sobreviví.

Lo cierto es que con anterioridad al crucero en el buen vapor Statendam no había cruzado el océano más que dos veces en mi vida, y ninguna de ellas voluntariamente.

A los tres años de edad me llevaron de Europa a América. Tuve que ir; mis padres insistieron. Supongo que viajamos en cubierta. Afortunadamente, no me acuerdo de nada.

Cuando estaba haciendo el servido militar, ostentando orgullosamente el exaltado grado de soldado raso, hice mi segundo viaje por mar, esta vez desde San Francisco a Hawai. Una vez más tuve que ir; daba la impresión de que el sargento lo esperaba de mí. Viajé en una especie de draga transformada, en la que la primera clase era entrepuente. De este viaje, desafortunadamente, sí me acuerdo.

Con tales precedentes, reaccioné con obstinado silencio cuando, a finales de la primavera de 1972, Richard C. Hoagland me abordó, entusiasmado de embarcar a un grupo de idealistas hacia el Sur para ver el lanzamiento del «Apolo 17».

Era, explicó, la última expedición tripulada de la serie Apolo, probablemente la última de cualquier tipo hasta dentro de algunas décadas. Era, prosiguió, el único lanzamiento nocturno de la serie, y sería un gran espectáculo, especialmente porque estaríamos observándolo desde el mar, con un cielo claro de horizonte a horizonte.

Apunté una objeción insuperable:

–Pero está casi a mil millas; y me da angustia de separación en cuanto pierdo de vista mi estudio.

–Bien -dijo-, te pondré en la lista. La gente ya no podrá mofarse de que Isaac Asimov, el mejor escritor de ciencia ficción vivo, jamás ha visto un lanzamiento de cohete.

–¿Eso hacen?, – pregunté.

–¿El qué? ¿Mofarse?

–No, decir que soy el mejor escritor de ciencia ficción vivo.

–Lo tengo por escrito y protocolizado.

Así que fui. Después de todo, tengo una posición en que pensar.

Subía a bordo del S. S. Statendam poco después de las dos de la tarde del lunes 4 de diciembre de 1972. Estaba bien preparado para pronunciar conferencias, participar en coloquios, encabezar seminarios y arrebujarme en mi camastro, no necesariamente por ese orden.

Me encontré a bordo con otros cuatro escritores de ciencia ficción: estaba Robert A. Heinlein, con quien había compartido cuatro años de precaria disciplina oficinesca durante los arduos días de la Segunda Guerra Mundial. Estaba Theodore Sturgeon, que parecía un Don Quijote vestido de gamuza. Estaba Frederik Pohl, que ha sido en varias ocasiones, a lo largo de los treinta y cuatro años que han pasado desde que nos conocimos, mi agente, mi editor, mi colaborador y siempre mi amigo. Y estaba Ben Bova, que el año pasado se calzó los difíciles zapatos de John W. Campbell como director de Analog.

Por rara coincidencia, Hoagland tenía testimonios escritos de que cada uno de ellos era el mejor escritor de ciencia ficción vivo.

Bob Heinlein, que estuvo en Annapolis en sus buenos tiempos me introdujo en los misterios de la criptografía marina. La parte de delante del barco era la proa. Se iba hacia adelante para ir hacia ella y a popa en sentido contrario. Mirando a proa, la izquierda era babor y la derecha estribor. Pregunté a Bob por qué se llamaban así, y me dijo que era parte del código mosaico tal como fue transmitido desde el Sinaí.

–Los pisos -dijo- son cubiertas, y las ventanas ojos de buey.

Estábamos en el lado de babor cuando lo dijo, y asentí con viveza e inteligencia.

–Ya veo -dije-. Las ventanas del otro lado son agujeros de estribor, ¿no? [30]

Me golpeó con un burel.

A las cuatro menos cinco me abrí camino hasta un lugar en el lado del barco donde, acodado en una pasarela, podía observar lo que iba a ocurrir a las cuatro en punto, hora prevista para zarpar. Una llovizna helada saturaba el aire, pues hacía el típico buen día de diciembre en Nueva Vork. Poco a poco me fui quedando como un témpano, ya que el barco no zarpó hasta las seis. Luego nos despedimos de los rascacielos de Nueva York, turbios a través de la bruma.

Mientras esperaba me encontré con Norman Mailer. Estaba a bordo en representación de la respuesta de las letras, ciencia ficción excluida al empeño espacial (suponiendo que algo que no sea ciencia ficción pueda considerarse literario).

La primera y única vez que me había hablado con él fue en el ascensor de un edificio del centro de la ciudad en el que (sin saberlo yo) tenía una oficina. Estábamos solos en el ascensor. Estudié su mata de pelo gris acero y le dije:

–¿Le han dicho alguna vez que se parece a Norman Mailer?

–Unas cuantas, – dijo, y se bajó.

Esta vez me presenté, y me dijo que leía la Guía de la Ciencia de Asimov todas las mañanas mientras meditaba. Le felicité por su buen gusto en materia de lectura.

Había también a bordo una frágil dama de cabello blanco llamada Katherine Anne Porter. En cuanto me la señalaron me vino a la cabeza una ocurrencia extraordinariamente graciosa. Estaba claro que su mera presencia nos convertía en una especie de «barco de tontos» [31].

Busqué a Fred Pohl.

–¿Sabes que Katheríne Anne Porter está a bordo? – preparándome limpiamente para entrar a matar.

–Sí -dijo-. Y eso nos convierte en una especie de barco de tontos, ¿no?

Me pareció una observación estúpida.

Mi primera comida a bordo me enseñó los rigores de la vida marinera. Había descubierto ya los ascensores, la boutique, la biblioteca, las quince bares y salones, y ahora me ofrecían un menú elaborado según el modelo de las fiestas ofrecidas por los más decadentes emperadores romanos. Habiéndome percatado de que las comidas estaban incluidas en el precio del crucero, pedí de todo.

Los camareros eran todos indonesios, más o menos recién venidos de su viejo país, por lo cual estaban todavía lo suficientemente subdesarrollados como para ser industriosos, eficientes y agradables. Fue desconcertante, pero todos nos forzamos a ser tolerantes para con sus extrañas maneras foráneas.

En un determinado momento de la comida sentí un súbito espasmo de mareo. Fue como si toda la habitación se hubiera bamboleado. Me auto-diagnostiqué un pequeño ataque de corazón, y agradecí la presencia del médico del barco (un hombre serio y apuesto en uniforme de almirante) en mi misma mesa.

–Señor -dije angustiado-, me ha parecido que la habitación se bamboleaba, y sospecho que me ha dado…

–Sí, el mar está un poco movido -dijo.

Decidí no mencionar mi ataque de corazón. Era un hombre ocupado.

Marvin Minsky, que trabaja en robots en el M. I. T. me llamó desde la mesa de al lado para preguntarme cuánto creía que se inclinaba el barco. Hice un cálculo rápido agudo del ángulo y contesté que no sabía.

Señaló entonces un lápiz que había atado a un tenedor, de forma que se mecía sobre la mesa, y dijo:

–Casi nada. Quizá dos grados. Así que ya es podéis sentir mejor.

No creo que lo consiguiera. (En un momento posterior del crucero, Marvin, que tiene una cabeza magníficamente calva, se puso una peluca Carlos II y, con ademanes de admirador, se me acercó con meloso acento y me pidió humildemente un autógrafo. Dijo que su ambición era llegar a ser como yo. Le di mi autógrafo en la más condescendiente y amable de las formas y le acaricié la cabeza.)

Hasta el segundo día no decidí que no me iba a marear. Una vez tomada esa decisión, me dispuse a oficiar de ángel misericordioso ante aquellos de mis colegas que no eran tan dotados como yo.

Para mi indignación, comprobé que muy pocos se mareaban. En un momento posterior del crucero descubrí que Carl Sagan (el famoso astrónomo de Cornell) no veía con buenos ojos el bamboleo del barco. Inmediatamente le expuse, con pleno y vivo detalle, la forma exacta en la que los diversos movimientos del buque no conseguían afectarme, atribuyendo mi inmunidad a la náusea a unos genes superiores y a una inteligencia despierta.

Carl no dio muestra alguna de agradecimiento.

Bastante menos adaptable me dediqué al principal deporte a puertas cerradas de la tropa marinera, que consistía en la consumición continuada y constante de licores varios. La compañía marítima cooperaba plenamente en el empeño; todo el mundo disponía de un suministro inagotable de bebidas fuertes.

Lo cual me complicó la vida, porque la consumición continuada y constante incluso de pequeños vasitos de vino, me reduce a un estado de repulsiva intoxicación. Tuve, pues, que recurrir a subterfugios como el de pedir un vaso de agua con hielo y meter subrepticiamente una aceituna.

A las diez y media de la segunda mañana tuvimos instrucción de salvamento. Nos pusimos ropa de abrigo y una especie de salvavidas. Después salimos a la cubierta superior (si es que se llamaba así) y nos agrupamos alrededor de los botes de salvamento que nos correspondían.

No me gustó el simbolismo de todo aquello, y alguien que se apercibió de la preocupación en los rasgos finamente cincelados de mi rostro dijo:

–Mujeres y niños primero, Asimov.

–Mujeres, niños y genios -repliqué altivamente.

–Genios jóvenes -dijo detrás de mí un mequetrefe de veintidós años.

La verdad es que el barco se convirtió muy pronto en mi hogar y perdí todo terror al mar. De hecho, los peores peligros se hallaban en tierra firme.

El sábado, día 9, llegamos a St. Thomas, en las Islas Vírgenes, y nos pasearon en un autobús abierto bajo una especie de bochorno estival muy poco propio de diciembre. Mencioné el asunto al conductor, pero sólo mostró perplejidad. «¿Qué ola de calor?», preguntó. Y como insistía en conducir por la izquierda de la carretera, evidentemente era inútil esperar de él una conversación inteligente. (Todos los demás conducían también por la izquierda. ¡Ridículo!)

Nos paramos en lo que antaño fuera la mansión del gobernador, y me puse a conversar con un caballero que explicaba que la fuente de agua de la isla era la lluvia. Una maravilla, excepto en época de sequía. El verano pasado, dijo, había sido extraordinariamente seco. Desde su casa sobre la colina podía ver innumerables chubascos por encima del Atlántico. Ninguno de ellos, dijo, había acertado con la isla, a pesar de sus mejores esfuerzos para atraerlos en la buena dirección mediante el uso de toda suerte de fintas.

–Ahora -concluyó- es la época seca. – Miré hacia arriba a las nubes que se iban juntando y dije:

–¿Está usted seguro?

–Oh, puede que haya una leve lluvia tropical -admitió de pasada-, pero no durará más de cinco minutos.

Durante la vuelta al barco cayó una leve lluvia tropical. Duró cinco horas, y se recogieron unas tres pulgadas de agua.

Al día siguiente llegamos a Puerto Rico, y el plan era visitar Arecibo (a dos horas y media de camino en precario autobús), donde veríamos el radiotelescopio más grande del mundo.

Como me había pasado toda la noche escurriéndome, miré al cielo y dije:

–Creo que no iré. Parece que va a llover.

–Está usted juzgando por los cielos de Nueva York -dijo alguien-. Aquí, en el soleado Puerto Rico, el sol brilla trescientos sesenta días al año. – Me enseñó una hoja de propaganda emitida por la Cámara de Comercio y, en efecto, eso era lo que decía.

Para mayor seguridad, y mientras aún estaba leyendo el prospecto, salió el sol alegremente por detrás de las nubes; así que me monté en el autobús. Al punto se metió el sol alegremente entre las nubes, y se puso a llover copiosamente durante todo el camino hasta Arecibo. Me di cuenta demasiado tarde de que el prospecto no decía por cuánto tiempo brillaba el sol cada uno de los trescientos sesenta días.

El paseo en autobús comenzaba en lo que parecía ser un área de barrios bajos de la isla. No habíamos salido del todo de ese área de barrios bajos cuando, dos horas y media más tarde, llegamos a nuestro destino. Las últimas cinco o seis millas transcurrían por una cornisa bordeada de precipicios a lo largo de una carretera con curvas en ángulo recto cada cinco pies. El conductor tocaba melodiosamente la bocina en cada curva, retirando cada vez las manos del volante.

Estaba completamente seguro de que jamás volvería a experimentar un paseo tan horrendo… hasta hora y media más tarde, cuando volvimos a bajar por la misma carretera. Hubo más mareo en el autobús que en el barco, y todo el mundo se precipitó sobre las pastillas de Dramamine. Yo usé mis propios métodos y me agarré bien fuerte a la chica más cercana.

El inmenso radiotelescopio constituía, no obstante, un espectáculo magnífico e impresionante, y casi valió la pena el viaje. Tenían una especie de telesilla que podía llevar a cualquier maníaco hasta los inmensos dispositivos que se encontraban muy por encima del gran cuenco. Había también una pasarela de cientos de pies que pendía en lo alto sobre un vacío absoluto. Se nos dijo que tenía una rudimentaria barandilla que serviría para detener nuestra caída uno o dos instantes, y un pavimento de tablillas con vanos lo suficientemente anchos como para dejar pasar medio cuerpo.

Algunos miembros del grupo decidieron violar las reglas y utilizar estos artefactos. Yo no me precipité, sin embargo, porque no me gusta atropellar, y al final no pude ir. Me lo tomé con filosofía.

La segunda mañana del crucero, inmediatamente después de la instrucción de salvamento, nos pusimos a tratar los asuntos serios del crucero, Ken Franklin, del Museo Americano de Historia Natural, nos puso en movimiento con un discurso edificante, y yo veía ante mí una semana o más de puro goce, puro descanso, pura somnolencia… pero me empecé a preocupar.

Parece ser que había periodistas a bordo; hombres de estrechas miras, cínicos y sofisticados, que encontraban defectos en la comida, en la acomodación, en los arreglos, en el personal. Lo único en lo que no encontraban defecto era, por lo que pude ver, el alcohol. Y quizá se lo hubiesen encontrado, entre copa y copa, de haber habido respiro entre vaso y vaso.

¡Ay de mí!, pensé. Escribirán artículos de estrechas miras, cínicos y sofisticados, riéndose del crucero [32], y me tocará a mí hacer todo lo que pueda para enderezar las cosas.

Así que, de entrada, convencí a los encargados de que permitiesen a Hugh Downs actuar como moderador en las discusiones. Había venido a bordo para hacer algunas observaciones sobre los últimos estadios de la cuenta atrás del lanzamiento, y pensé que no era cosa de desperdiciar su experiencia profesional. Fue una inspiración. Hizo que las sesiones transcurrieran en forma perfecta. Fue una pena que nos dejase en St. Thomas.

El miércoles 6, Ben Bova abrió la jornada con una agradable charla sobre exploración espacial. Y lo hizo sin servirse del sistema de altavoces para conferencias. Los esfuerzos de doce científicos de alto copete para meter en vereda a un micrófono recalcitrante no dieron resultado. Yo no intervine, naturalmente, dado que mi nivel de competencia ingenieril es limitado. Sé accionar con notoria habilidad un interruptor hacia abajo si resulta que está hacia arriba, o hacia arriba si resulta que está hacia abajo; pero fuera de eso no piso firme.

Ben había terminado su charla cuando localizaron al ingeniero del barco en algún oscuro rincón de la nave y lo trajeron. Miró el interruptor del micrófono, se apercibió de que estaba hacia abajo, y lo empujó hacia arriba. Instantáneamente sobrevino el milagro de la amplificación electrónica, y yo deploré no haberme brindado a ayudar; empujar interruptores es mí especialidad en ingeniería.

De hecho, el sistema eléctrico de la sala de conferencias nos dio guerra todo el viaje. Y también los proyectores de diapositivas. Y la iluminación. Y el dispositivo para bajar la pantalla. La tecnología nos derrotó continuamente, y todos agradecimos no estar a cargo de la cuenta atrás que a la sazón se desgranaba en las costas de Florida.

Una noche, la que precedió a la última del crucero, Ken Franklin preparó ocho proyectores de diapositivas, así como un comentario grabado, en la parte plana posterior del barco (la bovedilla, creo). Manipulando hábilmente las diversos proyectores pretendía ofrecemos lo más parecido a un planetarium real.

Desafortunadamente, no parecía haber manera de montar los cables de los proyectores para que funcionasen sin fundir también un plomo. Ken tuvo que improvisar una charla, y la llevó magníficamente, sin más ayuda visual que las estrellas del cielo. Lástima que el cielo estuviese en parte nublado y que el dispositivo quita-nubes tampoco funcionara.

Mi primera charla, el viernes, trataba de la posibilidad de colonizar los asteroides, y mantuve la atención del público bastante bien. Norman Mailer, que me seguía, se refirió a mí como «distinguido escritor» y mencionó mi «brillante charla». Intenté parecer modesto, y casi lo consigo.

Mailer procedió entonces a pronunciar una conferencia muy poco habitual, intentando hacer de «abogado del diablo». Deploró el hecho de que nos quedaran sólo dos enfermedades, el resfriado común y el ubicuo «virus», y se lamentó de la pérdida de las enfermedades de antaño: difteria, escarlatina, tifus y todas las demás del alegre montón. Especuló también acerca de la existencia de espíritus fantasmales en una «tanatoesfera» situada alrededor de la tierra (idea que había visto yo mencionada en la Canción de Navidad, de Dickens), e insistió vigorosamente en la necesidad de investigar la Luna, los campos de levitación, la percepción extrasensorial y la magia en general.

Los demás nos las arreglarnos para que no nos convenciera.

Mailer nos dejó en St. Thomas, y Carl Sagan se nos unió allí. El lunes y el martes siguientes, el 11 y el 12, Carl pronunció tres charlas que fueron absolutamente magníficas, sobre todo una presentación de dos horas de las nuevas vistas de Marte, resultado de las últimas fotografías tomadas por un cohete puesto en órbita alrededor del planeta. En un determinado momento levanté la mano.

–Carl -dije-, ¿no predijiste todo esto, sobre la base de consideraciones puramente teóricas, unos cuantos años antes de que se enviase la sonda a Marte, y no probaron las fotografías que tenías toda la razón?

–Sí, Isaac -dijo-, pero había pensado no mencionarlo, por modestia. Y sonrió abiertamente al público. [33]

Pero, naturalmente, todo, todo -la charla de Sagan sobre Marte, el papel de Mailer como abogado del diablo, la encantadora charla de Fred Pohl, en la que definió el progreso como aquello que presenta más opciones a la humanidad sirvió sólo como fondo al verdadero fin del crucero, la observación del lanzamiento del Apolo 17.

Una excitación creciente se apoderó del barco durante todo ese primer miércoles, 6 de diciembre. El buque había anclado a la altura de Florida durante el día, y el gigantesco cohete se perfilaba contra la llana costa de Florida como un monumento a Washington mal emplazado.

El día murió; vino la noche; las nubes se acumularon en el horizonte oriental; y hubo una continua exhibición de mudos y lejanos relámpagos que entraban y salían de los distantes cúmulos. La cuenta atrás se acercaba al minuto cero, las 9,53, y mi preocupación crecía. Nunca había habido ninguna dificultad, ningún retraso en un lanzamiento de la serie Apolo, pero, por otra parte, era un hecho innegable que yo tampoco había presenciado ninguno.

En consecuencia, no las tenía todas conmigo cuando Hugh Downs me entrevistó para los pasajeros del barco en esos últimos minutos que precedían al lanzamiento. Cuando quedé libre, casi todos los lugares de las barandillas estaban ocupados. Encontré finalmente un sitio, en la cubierta superior, desocupado porque las brillantes luces que iluminaban la mesa de ping-pong reducían todo lo demás a formas confusas. Tampoco había silencio, pues a diez minutos del lanzamiento, varios miembros de la tripulación se entretenían con una partida de ping-pong enervante. Richard Hoagland pasó a mi lado.

–Dick -grité-, consígueme un buen sitio, por favor, viejo, y no me pongas en la penosa necesidad de arrancarte el corazón.

Me arrastró a través de innumerables pasillos hasta el puente, a un lugar recóndito que había reservado.

–Qué pasa si algo falla -pregunté.

–¿Cómo va a fallar nada? – preguntó Dick-. Falta menos de un minuto para el lanzamiento.

–T menos treinta segundos y deteniendo la cuenta atrás -dijo la radio.

¡Lo sabía! ¡Lo sabía!

Y también sabía lo peor de lo que había de venir: la radio se dejaría ahora llevar por su propio cáncer, la incapacidad de tolerar un relajado silencio.

Durante dos horas y media la cultivada y agradable voz del locutor hiló un comentario continuo acerca de nada. Frase tras frase, párrafo tras párrafo, con un contenido nulo suavemente rectilíneo e invariable; una suave e irritante repetición de nada, vaciedades, nulo, cero; una y otra vez variaciones infinitas sobre un no-tema.

Mailer había dicho sardónicamente que la NASA había conseguido hacer de la mayor aventura de la humanidad algo aburrido. ¿Difícil? De ninguna manera. En un mundo que ha olvidado las virtudes del silencio, todo puede hacerse aburrido a la fuerza.

No es que la cultivada voz goteara sin respiro. A intervalos periódicos las fuerzas de la radio rendían homenaje a sus dioses económicos, emitiendo unos pocos anuncios cantados y entusiastas mensajes de venta a nivel sonoro redoblado.

Hasta las 12,20 de la noche no subió Dick Hoagland al puente para decirle al capitán que tendría que mantener el barco en el cabo un día más, porque tenía prueba escrita y protocolizada de que el capitán era el mejor marino del mundo, de que todos los aplazamientos se habían terminado y de que la cuenta atrás comenzaba otra vez hacia cero.

Para entonces era ya más de media noche, y de todo el barco sólo yo parecía apercibirme de que habíamos entrado en el día de Pearl Harbor. Pero se llegó al cero, y una nube de vapor envolvió al cohete. Contuve la respiración y esperé a que se elevase, lleno de incertidumbre.

Finalmente, se elevó y se abrió la amplia flor roja de su cola. Lo que seguramente es la luz artificial más concentrada que el mundo haya visto, iluminó las nocturnas costas de Florida.

Como dije brevemente en mi introducción al capítulo 2, la noche desapareció de horizonte a horizonte. Nosotros, y el barco, y todo el mundo visible, nos encontramos súbitamente cubiertos por la mortecina bóveda de cobre de un cielo del que se habían borrado las estrellas, mientras que a nuestros pies el negro mar se tornaba grisáceo.

En el más profundo silencio, el sol artificial que había cambiado tanto nuestro mundo inmediato se elevó y elevó, y después -cuarenta segundos después de la ignición- la violenta sacudida del aire que rodeaba los motores del cohete se abrió camino a través de las siete millas de mar que nos separaban de la costa y llegó hasta nosotros. Muy alto ya el cohete, nos vimos sacudidos por un poderoso trueno, con lo que nuestro privado y transitorio día se vio acompañado por un terremoto privado y transitorio.

El sonido y la luz fluyeron majestuosamente mientras el cohete siguió elevándose, hasta convertirse en un rubicundo manchón en lo alto del cielo. La noche volvía a caer; salieron las estrellas, y el mar se oscureció. Hubo un relámpago en el cielo al encenderse la segunda fase, y el cohete fue ya una estrella entre estrellas; moviéndose, y moviéndose, y moviéndose, y haciéndose más imperceptible…

Y en el ínterin era inútil tratar de hablar, porque no había nada que decir. No se habían inventado las palabras y frases que pudieran servir de acompañamiento a ese magnífico salto a la luna, y no traté de inventar ninguna.

Si hubiese tenido el tiempo y la audacia, y no me hubiese encontrado absolutamente anonadado por visiones y sonidos tan superiores a cualquier cosa hasta entonces experimentada, podría haber tratado de apostrofar al mundo que me rodeaba y decir: ¡Oh maravilla de maravillas! ¡Oh, elevado espíritu del hombre, que conquista el espacio y se acerca indomablemente a las estrellas!…

Pero no pude, y no lo hice, y fue algún joven quien tras de mí contribuyó con acompañamiento hablado a la ascensión de la nave espacial.

Con todos los magníficos recursos del idioma inglés a su disposición, escogió la frase que quizás expresaba más íntimamente la procesión que le recorría.

–Oh, mierda -dijo mientras su cabeza se levantaba lentamente. Y después, alzando su voz de tenor sobre todas las silenciosas cabezas de a bordo, añadió-: ¡Oh, m i i i i erda!

Bien, a cada uno lo suyo. Yo no dije nada.

17. La Universidad y yo

¿Me creeríais si os dijera que he llegado a un punto en el que soy tema de tesinas?

Pues lo soy. Hay gente que obtiene el grado de licenciado preparando bibliografías sobre mis cuentos, libros y artículos. Y a fe que se lo merecen, porque tratar de preparar una bibliografía completa de Asimov es casi imposible. Ni yo mismo me atrevería.

Un caballero, Lloyd Neil Goble, ha obtenido su grado de «Master of Science» analizando muy cuidadosamente las técnicas que utilizo para escribir sobre ciencia; como en estos capítulos, por ejemplo. Su tesis ha sido publicada por Mirage Press y se titula Asimov analizado.

He leído el libro con una mezcla de satisfacción y de temor.

La satisfacción es fácil de explicar. Cierto que hay quienes, por mis escritos, opinan que me decanto un poco por el lado de la inmodestia, pero ni siquiera en mis más desaforados arrebatos de amor por mí mismo me atrevería a ser tan pro-Asimov como el señor Goble.

El temor proviene del hecho de que el señor Goble me confunde: determina cuidadosamente la longitud media de las oraciones, y mi sistema de usar los paréntesis, y parece pensar que todo ello es parte de un plan cuidadosamente construido para crear un estilo particularmente idóneo para escribir sobre ciencia.

¡Nada de eso! El hecho cierto es, creedme, que no he planificado nada de antemano y que no tengo la menor idea de lo que estoy haciendo. Me limito a aporrear mi máquina de escribir, y nada más. Por consiguiente, paso las páginas de la tesis del señor Goble con sumo cuidado e intento no leerla en detalle, porque si descubro demasiado acerca de mis trucos, me tornaría demasiado auto-conciente y perdería ese estilo fácil y fluido que sólo surge de mi inocente ingenuidad.

Pero, por si fuera poco, he aquí otra cosa:

Ocurre que la gente universitaria ha descubierto la ciencia ficción… No me refiero a los estudiantes; quiero decir los claustros de profesores. Las Facultades están dando cursos sobre ciencia ficción. Y en la Universidad de Dayton se imparte uno titulado «La ciencia ficción de Isaac Asimov».

Cuando me enteré, fui y me acosté un rato. Después de todo, soy una persona racional, y hay cosas que se me antojan alucinaciones.

Mi posición con respecto al mundo académico, incluso antes de la súbita y contagiosa popularidad de la ciencia ficción en las aulas universitarias, era desde luego muy peculiar. Desde hace mucho tiempo tengo un pie en cada mundo.

No digo que sea el único profesor universitario que escribe ciencia ficción, ni que sea el único escritor de ciencia ficción con empleo de profesor. Sospecho, sin embargo, que ningún profesor escritor escribe tanta ciencia ficción como yo, ni (¿me atreveré a decirlo?) tan buena. Y no creo que ningún escritor de ciencia ficción haya llegado a una posición académica en un departamento científico, tan notable como la mía.

Lo cual tiene sus ventajas. A veces me entrevistan caballeros o damas de los medios de comunicación, y esta combinación de carreras parece fascinarles. La yuxtaposición se les antoja ora excéntrica, ora inadmisible, y me hacen preguntas sobre ella; las mismas preguntas, una y otra vez.

Permitidme, pues, aprovechar esta oportunidad para contestar algunas de las preguntas que con demasiada frecuencia me formulan. Quizás así facilitaremos la invención de otras nuevas.

1. Doctor Asimov, ¿no es extraño que un bioquímico escriba ciencia ficción? ¿Qué le hizo abandonar sus conferencias y sus probetas y ponerse a escribir relatos sensacionales?

Lo creáis o no, es una pregunta que me hacen a menudo, y el mero hecho de plantearla revela que el interlocutor no sabe mucho acerca de lo que escribo, pues de lo contrario sabría que nunca me pasé de la bioquímica a la ciencia ficción. La ciencia ficción llegó antes. ¡Años antes!

Porque he sido escritor desde bien antes de mi adolescencia, y vendí mi primer cuento de ciencia ficción en 1938, cuando tenía dieciocho años y era estudiante de cuarto año en la Universidad de Columbia.

Es más, a mediados de 1942 era ya un notable escritor de ciencia ficción y a esas alturas había escrito 42 cuentos y publicado 31 [34], incluido Night Fall, los tres primeros cuentos de robots positrónicos, y las dos primeras novelitas de Fundación. Y por entonces no era más que un estudiante graduado con un título de licenciado recién salido del horno.

Siete años después, y ya incorporado al claustro de profesores de la Facultad de Medicina, tenía escritas todas las novelas de Fundación y todos, menos uno, de los cuentos que habrían de aparecer en Yo, Robot.

Por tanto, no, no, NO soy un bioquímico que se pasó a la ciencia ficción. Soy un escritor de ciencia ficción que en un momento dado se hizo profesor, lo cual es muy distinto.

2. Ya veo. Bien, en ese caso, profesor Asimov, ¿por qué decidió ser profesor de bioquímica? Si se había establecido como escritor de ciencia ficción, ¿por qué buscó otra cosa?

Porque nunca tuve la intención de ser escritor de ciencia ficción para ganarme la vida. Es como si se me hubiera ocurrido ser trapero para ganarme la vida. Me explico:

Mi ambición, de niño, era ser médico, Mis padres me dijeron que esa era mi ambición, y yo lo creí. Era corriente que los padres judíos del ghetto tuvieran esa ambición para sus hijos. Era la forma más segura de que los hijos salieran del ghetto.

Por tanto, cuando en 1935 ingresé en la Universidad de Columbia, fue con la intención de solicitar el ingreso en la escuela de medicina al terminar los cuatro primeros años de Universidad. La perspectiva no me llenaba de gozo, porque no me atraía mezclarme con el dolor, la enfermedad y la muerte. Por otra parte, no conocía más alternativa que heredar la confitería de mi padre, con su jornada de trabajo de dieciséis horas y su semana de siete días.

Afortunadamente, no ingresé en la escuela de medicina. Falto de entusiasmo, sólo solicité el ingreso en cinco escuelas en total, y ninguna de ellas me admitió. Para entonces, no obstante, había descubierto otra alternativa. Mi licenciatura iba a ser en Química, algo que había empezado con nociones médicas rutinarias, y descubrí que me gustaba. Por consiguiente, al no conseguir ingresar en las escuelas de medicina, solicité, en 1939, permiso para continuar en Columbia para poder hacer trabajo de graduado en química y obtener el título de doctor.

Mi idea era que, una vez obtenido el doctorado, lo podría utilizar para conseguir un puesto en alguna buena Facultad universitaria, Allí enseñaría química e investigaría.

La Segunda Guerra Mundial retrasó las cosas, pero finalmente obtuve el doctorado en 1948 y me convertí en profesor en la Escuela de Medicina de la Universidad de Boston en 1949… Mi plan había dado resultado.

Así pues, a lo largo de toda mi vida fue un doctorado u otro -el de Medicina para mis padres, el de académico para mí-, lo que constituyó mi objetivo y el anhelado medio de ganarme la vida.

El escribir ciencia ficción no tuvo nada que ver con eso, nada en absoluto. Cuando empecé a escribir fue por un impulso incontrolable. No veía el dinero, ni tampoco a los lectores; era sencillamente el deseo de inventar historias para mi propio contento.

Cuando finalmente vendí mi primer cuento, en 1938, era, como ya he dicho, un joven de dieciocho años en cuarto curso universitario. Estaba todavía en mi estadio pre-médico, aguardaba aún con inquietud la posibilidad de ingresar en la Escuela de Medicina ese mismo año, y me preguntaba de dónde iba a sacar el dinero necesario. Bastante difícil era ya conseguirlo para pagar la matrícula, y eso que en aquellos días Columbia sólo cobraba 400 dólares al año.

Así que cuando recibí los primeros cheques por mis obras de ciencia ficción, no vi en ellos más que una sola cosa: una contribución para sufragar los gastos de matrícula. Eso es lo que fueron, y eso es todo lo que podían ser.

¿Fui miope al no ver que algún día podrían ser algo más? Veamos.

Cuando comencé a escribir ciencia ficción, la tarifa máxima por palabra era un centavo. Lo corriente es que me dieran medio centavo por palabra. El número de revistas de ciencia ficción era exactamente tres, y sólo una de ellas era boyante. Ciencia ficción era lo único que escribía y lo único (así me parecía) que podía escribir. Ni siquiera quería escribir más que ciencia ficción.

Con un mercado tan limitado y tan pobre, ¿podía una persona en sus cabales esperar ganarse la vida como escritor? Con el paso de los años, surgieron algunas revistas más y subieron un poco las tarifas, pero aun así las perspectivas siguieron siendo poco claras.

Para ser más preciso: durante mis primeros once años de escritor de ciencia ficción, mis ingresos totales, totales, fijaos bien, por mi trabajo ante la máquina de escribir, fueron de menos de 8.000 dólares. Y las cosas me iban bien. Vendía todo lo que escribía, después de los cuatro primeros años.

Con esa experiencia, ¿es maravilla que al escribir ciencia ficción no me arrancase ni por un momento de la seria labor de prepararme para lo que tenía por mi verdadera carrera? Y claro, cuando en junio de 1949 surgió la oportunidad de incorporarme a una Facultad por la principesca retribución de 5.000 dólares al año, me abalancé sobre ella.

3. Comprendo, profesor. Pero, dígame, ¿le supuso a usted alguna vez un conflicto su doble carrera? ¿No le despreciaron nunca sus colegas académicos por su desacreditada ocupación accesoria?

Supongo que tema de diversión sí fue un poco en Columbia. Buena parte de los estudiantes habían leído ciencia ficción en uno u otro momento de su vida. Pero allá por los años 40 se tenía la ciencia ficción esencialmente por literatura para niños. La norma, en general, era leer ciencia ficción en la escuela y abandonarla en la Universidad. Si se reían de mí no era tanto por leer ciencia ficción como por seguir leyéndola.

El hecho de que escribiera ciencia ficción era más fácil de aceptar y comprender que el hecho de que la leyera; después de todo, me pagaban por ese trabajo, y el dinero lo usaba para ayudarme en mi educación. No había nada malo en ello.

A lo largo de toda mi época universitaria, sólo perdí los nervios una vez en relación con mi ciencia ficción.

En 1947 tenía la cabeza ocupada en mi inminente tesis doctoral, fue uno de los pocos períodos en que escribía poco. La presión para escribir cualquier cosa iba acumulándose.

Me hallaba a la sazón haciendo unos experimentos en los que intervenía una sustancia llamada catecol. Se presentaba en cristales esponjosos, blancos y extremadamente solubles. Tan pronto como tocaban la superficie del agua, desaparecían disueltos. Y se me ocurrió que quizás se disolvían una fracción de milímetro antes de llegar a la superficie del agua; decidí, pues, escribir una historia acerca de una sustancia que se disolvía antes de añadir agua.

Obsesionado como estaba con mi tesis, no pude resistir la tentación de escribirla en forma de pseudotesis, con todas sus frases ampulosas, tablas, gráficos y referencias inventadas. La llamé «Las propiedades endocrónicas de la tiotimolina resublimada» y se la vendí a John Campbell, editor de Astounding Science Fiction.

Entonces me puse nervioso. Mi posición en Columbia era, en cualquier caso, inestable, porque, aun dejando de lado el asunto de la ciencia ficción, se me tenia por excéntrico. Mi expediente no estaba mal, pero era ruidoso, vocinglero e irreverente (comportándome en los sagrados salones de Columbia, hace un cuarto de siglo, más o menos como me comporto ahora en los sagrados salones de la editorial Doubleday). Sabía que algunos miembros del claustro de profesores pensaban que me faltaba la seriedad necesaria para ser un buen científico, y pensé que el artículo de la tiotimolina, que tomaba claramente a broma la ciencia y los científicos, podía ser la última gota… Y el artículo se publicaría más o menos hacia la época en que me estaba preparando para el examen oral de doctorado.

Llamé al señor Campbell y le dije que quería que el artículo se publicase bajo pseudónimo. Se mostró de acuerdo.

Pero se olvidó. Salió con mi nombre unos tres meses antes de los exámenes orales. Sí, sí, toda la facultad lo leyó. Ante el tribunal soporté el infierno de rigor, y después, cuando habían conseguido convertirme brutalmente en una temblorosa masa de pánico, uno de ellos dijo: «Y ahora, señor Asimov, ¿podría usted decirnos algo acerca de las propiedades termodinámicas de la tiotimolina?», y hubo que sacarme de la sala en pleno ataque de histeria.

Aprobé, como es obvio, que si no, no sería ahora el Buen Doctor.

4. En realidad no le preguntaba si tuvo problemas como estudiante, Buen Doctor; lo que quería decir es si tuvo dificultades con sus compañeros del claustro de profesores cuando ya formaba parte de éste.

No, ni esperaba tenerlas. Algunos de los profesores eran aficionados a la ciencia ficción, sobre todo el que me recomendó para el puesto, y conocían bien mis escritos.

Solo hubo un momento malo. Mi primer libro lo había contratado un par de semanas antes de que aceptara el empleo de profesor y me fuera a Boston. El libro, Pebble in the Sky, tenía que publicarse en Doubleday el 19 de enero de 1950, y yo sabía que iban a mencionar mi relación con la Escuela. Me enteré cuando leí las pruebas de imprenta de la cubierta que Doubleday me envió. En la contraportada (junto con un muy buen retrato mío que me rompe el corazón cuando lo miro ahora) se hablaba del asunto de la tiotimolina en el examen oral, y una frase final que decía:

«El Dr. Asimov vive en Boston, donde se dedica a la investigación sobre el cáncer en la Escuela de Medicina de la Universidad de Boston.»

Me lo pensé un buen rato, y después decidí coger el toro por los cuernos. Solicité ver al decano y le planteé la cuestión con franqueza. Yo era un escritor de ciencia ficción, dije, y lo había sido durante años. Mi primer libro iba a aparecer con mi nombre, y mi relación con la Escuela de Medicina iba a mencionarse, ¿Quería que dimitiese?

El decano lo meditó y dijo:

–¿Es bueno el libro?

Cautelosamente dije:

–Los editores creen que sí.

Y él:

–En ese caso, a la Escuela de Medicina le complacerá identificarse con él.

Y así se solucionó el asunto.

5. Pero si era usted un escritor de ciencia ficción, profesor, ¿no suscitaba ello dudas sobre la validez de su trabajo científico? Quiero decir que si publicaba un artículo científico, ¿no sería desestimado por alguno como «más ciencia ficción»?

No habría tenido ninguna gracia, pero, que yo sepa, nunca ha sucedido.

Mi carrera de investigador en activo fue desde luego corta, y el número de artículos que publiqué no fue grande, pero todos ellos fueron perfectamente buenos y sobrios, y no sé de nadie que los desechara a causa de mi otra profesión.

Naturalmente, ignoro lo que ocurrió a mis espaldas, pero las historias me hubiesen llegado indirectamente…

Un compañero del departamento, que consiguió el empleo sólo un mes después que yo, y que no era lector de ciencia ficción, me dijo años más tarde que en cuanto descubrió que yo era autor de ciencia ficción, pensó que aquello arruinaría mi carrera científica. Me dijo que tuvo la suficiente curiosidad como para hacer un sondeo acerca del sentir de los demás, y que nadie le daba importancia.

Bueno, casi nadie. A veces me asaltaban dudas sobre el individuo, socialmente conservador, con quien realicé mis primeras investigaciones. No creo que tuviese tantas objeciones a mi ciencia ficción en particular como a mi personalidad en general.

Me sugería, por ejemplo, que en plena canícula bostoniana llevase, de acuerdo con mi status social como miembro del claustro, chaqueta y corbata. Yo sonreía amablemente y, claro, me hacía el sordo. También hice caso omiso de todas las sugerencias de que mis relaciones con los estudiantes eran demasiado informales. (De haber observado con más cuidado, se hubiera dado cuenta de que mis relaciones con todo el mundo eran demasiado informales).

En cualquier caso, llegó a mis oídos una historia sobre la que no puedo certificar personalmente pero que, según juramento de mi informador, era cierta. Mi colega de investigación fue una vez a Washington para presionar en favor de un aumento en las subvenciones, y uno de los funcionarios a quien consultó, mirando el informe, señaló mi nombre en la lista de los que participaban en el proyecto, y dijo: «¿No es ése el escritor de ciencia ficción?»

Mí colega, sudoroso al punto ante la posibilidad de perder la subvención, aseguró que yo nunca permitía que la ciencia ficción se mezclara con la ciencia.

Pero el funcionario no hizo el menor caso y se puso a preguntar muchas más cosas sobre mí. Resultó que era un aficionado a la ciencia ficción, y que estaba mucho más interesado en mí que en el proyecto. Mi colega consiguió esa vez todo el dinero que pedía, pero creo que el asunto, en el fondo, le molestó.

Pero no importó nada. Sólo trabajé con él algunos años, y no tuve más problemas.

6. Cambiando de tema, profesor Asimov: usted escribe mucho, ¿verdad?

Publico siete u ocho libros al año por término medio; digamos que medio millón de palabras al año.

7. Pero ¿cómo puede hacer eso y sobrellevar una dedicación absoluta a la enseñanza?

Ni puedo, ni lo hago.

Cuando me hice cargo de mi empleo en la Escuela de Medicina me ocurrió algo gracioso. En cuanto conseguí finalmente terminar la carrera científica tantos años anhelada, mis actividades literarias, que hasta entonces no habían sido más que una útil ayuda, cobraron súbitamente vida propia.

A mi primer libro siguió otro, y después otro. Los derechos de autor comenzaron a llegar con regularidad. Las antologías empezaron a multiplicarse, y los clubs de libros, y las ediciones en rústica, y el interés en el extranjero. Mis ingresos de escritor empezaron a subir vertiginosamente.

Entonces ocurrió otra cosa. Trabajando con otros dos miembros del departamento, ayudé a escribir un libro de texto sobre bioquímica para estudiantes de medicina y descubrí que me gustaba escribir no-ficción. Entonces me dí cuenta de que había un mercado más amplio para la literatura científica que para la ficción, y que las tarifas por palabra eran notablemente mejores. Y descubrí que podía escribir ensayos sobre toda suerte de temas.

Así que empecé a escribir más y más, tanto ciencia como ficción, y me divertía lo indecible. Después de dedicarme varios años a esa labor, descubrí dos cosas más: una, que ganaba más dinero escribiendo que enseñando, y que la disparidad crecía cada año; dos, que me gustaba más escribir que enseñar, y que esa disparidad aumentaba también cada año.

Constantemente me asediaba el impulso a dejar mi empleo y dedicarme exclusivamente a escribir, pero ¿cómo hacerlo? Había dedicado demasiado de mi vida a formarme para este empleo como para tirarlo. Así que vacilaba.

La vacilación tocó a su fin en 1957, cuando yo ya tenía un nuevo jefe de departamento, y la Escuela un nuevo decano. Los antiguos se habían mostrado tolerantes con mis excentricidades, puede que hasta las apreciaran, pero los nuevos, no. Incluso veían mis actividades con muy malos ojos.

Lo que más les preocupaba era el estado en que se encontraba mi investigación. Si sólo hubiese escrito ciencia ficción, mi investigación no se hubiese visto afectada. La ciencia ficción la escribía en mi tiempo libre. Por muy candente que fuese la historia, por muy apremiante que fuese el plazo de entrega, se escribía sólo por las tardes y los fines de semana.

La divulgación científica era otra cosa. Yo consideraba que mis libros sobre ciencia para el público constituían una actividad académica, y trabajaba en horas de trabajo. Mantuve, naturalmente, mi dedicación plena a la enseñanza, pero abandoné la investigación.

La nueva administración me llamó por ello la atención, pero me mantuve testaruda e incluso un poco fieramente en mis trece. Dije que se me pagaba fundamentalmente por enseñar, que cumplía con todos mis deberes de enseñanza, y que en general se reconocía que yo era uno de los mejores profesores de la Escuela.

Por lo que toca a mi investigación, dije que no pensaba que llegara a ser nunca más que un investigador del montón, y que a pesar de que mi trabajo científico sería lo suficientemente respetable, nunca daría lustre a la Escuela. Mis escritos, por otro lado (dije) eran de primera, y podían dar bastante fama a la Escuela. Sobre esa base (continué), mi intención era no abandonar mis escritos por la investigación, no sólo por cuestión de preferencia personal, sino también preocupado por el bienestar de la Escuela.

No conseguí hacer mella alguna. Se me dijo, bastante fríamente, que la Escuela no podía permitirse el lujo de pagar a alguien 6.500 dólares al año (ése era entonces mi sueldo) para tenerle escribiendo libros de ciencia.

Así que les dije con desprecio:

–Quédense entonces con el condenado dinero, y no enseñaré más para ustedes.

–Bien -me dijeron-, su empleo terminará en junio de 1958.

–No, señor -dije-. Sólo el sueldo. El empleo lo conservo, porque tengo derechos adquiridos.

Lo que siguió fue una lucha homérica que duró dos años. Los detalles no importan, pero todavía tengo el título. Desde junio de 1958, sin embargo, ni enseño ni cobro sueldo. Doy una conferencia al año y cumplo con algunos deberes honoríficos (como formar parte de comités), pero ahora soy un escritor de tiempo completo, y soy todavía profesor adjunto de Bioquímica.

La Escuela está ahora muy contenta con la situación. Como predije, mis escritos les han proporcionado publicidad favorable. Y yo estoy también contento con la situación, porque valoro mi conexión académica. Es agradable poder entrar en una gran Universidad y sentir que se pertenece a ella, y que se está allí por derecho.

El administrador con quien tuve a la sazón problemas se ha retirado hace mucho, y desde entonces los sucesivos presidentes, directores y decanos han sido todos extremadamente amables conmigo. Quiero hacer hincapié en que, salvo aquella discusión de 1957 y 1958, siempre he sido tratado con enorme generosidad por todo el mundo en la Escuela, del primero al último.

Quiero también hacer hincapié una vez más en que incluso en aquella discusión no fueron mis escritos de ciencia ficción los que se pusieron en cuestión. La pelea se refirió enteramente a mi abandono de la investigación, y yo la había abandonado en aras de mi literatura científica.

8. Teniendo en cuenta que ya no enseña, doctor Asimov, ¿sigue usted teniéndose por un científico?

Desde luego. ¿Por qué no? Tengo formación profesional en química. He dado durante años conferencias de bioquímica a nivel profesional. He escrito libros de texto sobre estos temas. Nada de esto se ha borrado.

Considero que uno de los más importantes deberes de todo científico es la enseñanza de la ciencia a estudiantes y al público en general. Aunque pocas veces doy conferencias ante clases propiamente dichas, mis libros sobre ciencia llegan y enseñan a más gente de la que podría alcanzar de viva voz.

Es cierto que ya no enseño en las aulas, pero esto no quiere de ninguna manera decir que ya no enseño. Ahora enseño más ciencia de la que jamás haya enseñado en la Escuela y, por ello, no sólo me considero científico, sino también científico en activo.

Naturalmente, también me considero escritor.

9. A la vista de la amplia variedad de escritos que produce, ¿qué tipo de escritor cree ser?

A veces me lo pregunto. En los dos últimos años he publicado unas notas sobre Byron, un trabajo en dos volúmenes sobre Shakespeare, una sátira sobre libros de sexo, y un libro de chistes [35], además de mis libros sobre ciencia y sobre historia.

Dejo, por tanto, que otros decidan. Los otros parecen identificarme siempre como escritor de ciencia ficción. Así fue como empecé, y como causé mi primer y quizás mayor impacto.

Tampoco me he retirado realmente como escritor de ciencia ficción. No es ya mi mayor campo de actividad, pero nunca he dejado de escribirla. Mi novela más reciente es The Gods Themselves (Doubleday, 1972).

Ya veis…

Soy un escritor de ciencia ficción.

[1] La rotación terrestre no logró demostrarse directamente hasta 1851. Hasta entonces hubo que aceptarla por razonamiento indirecto.

[2] A la primitiva estructura lítica de Stonehenge se le ha atribuido el propósito de seguir los movimientos del Sol y de la Luna de un modo complejo y bastante sofisticado, lo que quizás remita a milenios de elaboración y desarrollo previos.

[3] Y, desde luego, no es ningún misterio que la Luna desbarate la visión heliocéntrica del universo, porque realmente gira alrededor de la Tierra.

* Me pregunto sí, cuando exploremos la galaxia, descubriremos que la vida está universalmente presente en todos los planetas semejantes a la Tierra, pero siempre vida marina. Acaso hallemos que la vida terrestre requiere ese acontecimiento máximamente improbable que es la captura de una gran luna y, por tanto, que estamos, después de todo, solos en la galaxia.

[4] Porque vamos a ver, ¿a quién le importa de veras las fases de la Luna? ¿Os importa a vosotros? ¿Sabéis siquiera en qué fase está la Luna esta noche?

[5] Si no lo veis claro, consultad un calendario y comprobaréis que en cualquier año de trescientos sesenta y cinco días, el 1 de enero y el 31 de diciembre, primer y último días del año, caen en el mismo día de la semana.

[6] No hay misterio en el 28. La semana tiene siete días, y cada cuatro años uno es bisiesto. Como siete y cuatro son primos entre sí, la pauta sólo se repite al cabo de 7 x 4 = 28 años.

[7] El título original, «The Week Excuse», encierra una ambigüedad fonética intraducible. Week = semana, suena casi igual que weak = débil; el título sería entonces «La débil excusa». (N. del Traductor)

[8] ¿Por qué ese día? Pues bien, Scaliger contó hacia atrás y descubrió que ese día comenzaban todos juntos varios importantes cielos astronómicos como el año solar, el mes lunar, el período sarónico de eclipses, etc.

[9] No, no me avergüenzo lo más mínimo.

[10]Mientras pensaba si hacer o no un artículo sobre Ceres, se me ocurrió el título de este capítulo, y no hubo forma ya de contenerme.

[11] Recuérdese que a menor magnitud, mayor brillo.

[12] ¡Y la gente todavía me pregunta por qué prefiero escribir divulgación científica! ¿Cómo iba yo a meter en una novela estos ridículos vuelos de la imaginación?

[13] Galileo.

[14] Digo bien. No me olvido de los compuestos de gases nobles. Los átomos de kriptón y xenón se unen a otras clases de átomos -flúor y oxígeno, por ejemplo. Pero dos átomos de kriptón o dos de xenón no se unen jamás en condiciones de laboratorio, ni tampoco uno de xenón con otro de kriptón.

[15] ¿Por qué? En cierto modo, no importa por qué. Se trata de un hecho medido y debe ser aceptado sepamos o no por qué. Sin embargo, existe un tratamiento matemático llamado mecánica cuántica que explica el porqué de muchos hechos atómicos de la vida Pero, si me queréis, no me pidáis, por favor, que entre en la mecánica cuántica.

[16] La única energía de enlace que no pude encontrar en mi biblioteca fue la del boro, por lo cual me vi obligado a hacer un cálculo aproximado en base a otros datos que logré reunir. Se me pregunta a menudo por qué no busco los datos para mis artículos fuera de mi biblioteca cuando ésta resulta insuficiente, pensamiento que quizá os esté cruzando por la mente ahora mismo. La respuesta es elemental: me parece que eso es hacer trampas.

[17] Existe también «adamante» como sinónimo antiguo de «diamante». [N. del T.]

[18] Esta la podéis mirar vosotros mismos.

[19] Pero las teorías superadas perviven a veces en la ciencia ficción. Recuerdo haber leído con agrado un relato de Ralph Milne Farly que trataba los virus al modo de Beijerinck. El relato, llamado «Vida líquida», apareció en el número de octubre de 1936 de Thrilling Wonder Stories, cinco años después de la demostración de Elford.

[20] No, no os voy a contar el chiste del rabino de ochenta y ocho años. Es demasiado largo y roza la inconveniencia.

[21] A menudo he dicho que haría lo que fuese por una carcajada; pero tener al cirujano con el escalpelo en mi gaznate y hacerle doblarse de risa supera, creo, todos los límites de la razón.

[22] La necesidad de los experimentos con animales la reconozco racionalmente, mas no con el corazón. En mis tiempos de investigador en una Escuela de Medicina nunca hice experimentos con animales, y siempre me salía del laboratorio cuando otro compañero se disponía a hacerlos… Pero hay muchas veces en que el organismo intacto no tiene sustituto.

[23] Un enigma perenne es por qué las enzimas digestivas no digieren el recubrimiento del canal alimentario. O lo que es lo mismo, por qué el ácido clorhídrico no hace estragos en las paredes del estómago. Sea cual sea el sistema de producción, no es perfecto, y cuando falla sobreviene una úlcera gástrica.

[24] El primer lunes de septiembre. (N. de la T.)

[25] Por si han pensado que violé mis principios y me tomé unas vacaciones, más vale que les diga que me llevé mi máquina de escribir portátil, y que además hice uso de ella.

[26] Bueno, eso fue lo que dijo todo el mundo.

[27] Si la virtud auto-conciente pudiese venderse a dólar la libra, seríamos todos ricos. También yo, porque estoy cargado de tantas toneladas de virtud auto-conciente como cualquiera. De todas formas, los hechos posteriores a aquellas elecciones me han dado de sobra la razón.

[28] Observad que digo «tecnología» y no «ciencia». La ciencia es un método sistemático Para estudiar y determinar aquellas generalizaciones que parecen describir el comportamiento del universo. Podría existir como mero juego intelectual que no afectase nunca a la vida práctica de los seres humanos, ni para bien ni para mal, y eso fue lo que ocurrió en la antigua Grecia, por ejemplo. La tecnología es la aplicación de los descubrimientos científicos a los instrumentos de la vida cotidiana, y esa aplicación puede ser sabia o necia, útil o dañina. Quienes gobiernan las decisiones tecnológicas no son, a menudo, científicos, y saben poco acerca de la ciencia, pero están perfectamente dispuestos a hacer de la voracidad humana alcahuete del beneficio fácil y del dólar inmediato.

[29] Apunté esto por primera vez en un relato titulado «El conflicto evitable», publicado en 1950 e incluido en I, Robot (Doubleday, 1950).

[30] Juego de palabras basado en: port = babor; hole = agujero; porthole = ojo de buey (N. del T.)

[31] Ship of Fools (= Barco de tontos) es una de las mejores obras de K. A. Porter. (N. del T.)

[32] De hecho, lo hicieron. Dejaron bien claro que eran en todos los aspectos demasiado superiores para divertirse, y ninguno renunció a conquistar las máximas cotas de ingenio mencionando la presencia de Miss Porter y sugiriendo que éramos un barco de tontos. Demos gracias a Dios por la gracia de los reporteros.

[33] Los periodistas se fueron con Mailer, por lo que la charla de Mailer fue después muy aireada, mientras que la de Sagan ni se mencionó. Después del ingenio periodístico, supongo que no hay nada mejor que el juicio periodístico.

[34] Once de mis primeros cuentos nunca se vendieron, nunca se publicaron y ya no existen. Lo lamento, pero así son las cosas. Y no, no los puedo reconstruir. Si quieren conocer la historia completa de mis primeros tiempos de escritor, la encontrarán, junto con 27 de mis primeros cuentos, hasta ahora no recogidos en ninguno de mis libros, en The Early Asimov (Doubleday, 1972).

[35] Para quien tenga curiosidad, son: Asimov’s Annotated Don Juan (Doubleday, 1972); Asimov’s Guide to Shakespeare (Doubleday, 1970); The Sensuous Dirty Old Man (Walker, 1971, bajo el transparente seudónimo de «Dr. A.»); y Treasury ol Humor (Houghton Mifflin, 1971).

13/06/2008
