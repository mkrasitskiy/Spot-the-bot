LOS ÚLTIMOS TRES MINUTOS

Los últimos tres minutos, obra del físico y escritor Paul Davies, es un libro maravilloso y divertido que recoge las más recientes ideas científicas sobre el destino último del universo, transportando al lector a vivir las sensaciones que experimentará cuando llegue el final.

El lector asiste al último día de luz solar y a la llegada de la noche perpetua. Experimenta el inicio del cataclismo estelar, una vez que se haya agotado definitivamente la energía de las estrellas activas, y viaja por los eones de tiempo en los que los agujeros negros son la última fuente de energía importante, devorando los restos dispersos de las galaxias apagadas. Y luego, quizá, podrá vivir el gran crujido, esos últimos tres minutos en los que la temperatura del cosmos se hace tan grande que incluso deben desintegrarse los núcleos atómicos, en que regiones cada vez mayores de espacio se comprimen en volúmenes cada vez menores, cuando «la obra del gran pum y de generaciones de estrellas se deshace en menos tiempo del que se tarda en leer esta frase».

¿Será éste el escenario en el que la vida cósmica represente su escena final? ¿O está destinado el universo a acabar de forma muy distinta y en un futuro mucho menos lejano, avasallado por una catástrofe cósmica súbita e inesperada? ¿Se acabará de verdad el universo? Y si dura eternamente, ¿hallará la humanidad, o sus descendientes, sean robots o seres de carne y hueso, el modo de sobrevivir a esa eterna noche?

Los últimos tres minutos es uno de los libros de ciencia más originales que han aparecido en los últimos años, lectura fascinante de un científico plenamente acreditado.

Título Original: The last three minutes

©1994, Davies, Paul

Corregido: Silicon, 07/09/2010

PREFACIO

En mi época de estudiante, a principios de la década de los 60, había mucho interés por el problema del origen del universo. La teoría del «big bang» que databa de los años 20 y que sólo se había tenido en cuenta seriamente a partir de los años 50, era bien conocida pero estaba lejos de ser convincente. Su rival, la teoría del estado estacionario, que suprimía por completo el origen cósmico, seguía siendo el panorama más de moda en determinados reductos. Entonces, en 1965, Robert Penzias y Arno Wilson descubrieron la radiación cósmica térmica de fondo y el asunto cambió. Esa radiación era, con seguridad, la prueba clara de un origen caliente, violento y brusco del universo.

Los cosmólogos ponderaron febrilmente las consecuencias del descubrimiento. ¿Cómo era de caliente el universo un millón de años después del big bang? ¿O al cabo de un año? ¿O de un segundo? ¿Qué tipo de procesos físicos se habrían producido en aquel infierno primordial? ¿Habrían retenido los residuos de ese alborear de la creación alguna huella de aquellas condiciones extremas que debieron haber imperado?

Recuerdo haber asistido en el año 1968 a una conferencia sobre cosmología. El profesor terminó haciendo un repaso de la teoría del big bang a la luz del descubrimiento de la radiación de calor de fondo. «Algunos teóricos han proporcionado una buena idea de la composición química del universo basada en los procesos nucleares que se dieron en los tres primeros minutos posteriores al big bang», comentó con una sonrisa. Todo el público prorrumpió en una sonora carcajada. Parecía absurdamente ambicioso intentar describir el estado del universo a los pocos momentos de haber empezado a existir. Ni siquiera el arzobispo del siglo XVII James Ussher, cuyo estudio de las minucias de la cronología bíblica le había llevado a afirmar que el mundo había sido creado el 23 de octubre del año 4004 a.C., había cometido la temeridad de catalogar la exacta secuencia de los acontecimientos ocurridos durante los tres primeros minutos.

El ritmo del progreso científico es tal que apenas una década después del descubrimiento de la radiación de calor de fondo cósmico, los primeros tres minutos se habían convertido ya en tema normal para los estudiantes. Ya se escribían libros sobre la materia. Fue entonces, en 1977, cuando el físico y cosmólogo norteamericano Steven Weinberg publicó un número uno en ventas llamado muy apropiadamente Los tres primeros minutos del universo. Resultó ser un hito en las publicaciones de divulgación científica. Hete ahí a uno de los expertos mundiales proporcionando al público en general una descripción detallada y absolutamente convincente de los procesos que se dieron momentos después del big bang.

Mientras el público iba poniéndose al día en estos vertiginosos descubrimientos los propios científicos seguían avanzando. La atención fue desplazándose desde lo que se había denominado universo temprano (con lo cual se hacía referencia a los primeros minutos después del big bang) al llamado universo muy temprano (a una fracción casi infinitesimal de segundo después del comienzo). Más o menos una decena de años después, el físico matemático británico Stephen Hawking pisaba ya lo suficientemente firme como para describir en su Historia del tiempo, las últimas ideas acerca de la primera sextillonésima de segundo. La risa que cerró aquella conferencia de 1968 parece en estos momentos un tanto estúpida.

Una vez bien implantada la teoría del big bang, tanto popular como científicamente, cada vez se va dedicando más reflexión al futuro del universo. Tenemos una idea bastante aproximada de cómo empezó el universo pero ¿cómo terminará? ¿Qué podemos decir de su destino definitivo? ¿Acabará el universo con un estallido o con un quejido, si es que se acaba alguna vez? ¿Y qué será de nosotros? ¿Puede la humanidad, podrán nuestros descendientes, sean robots o de carne y hueso, sobrevivir durante toda la eternidad?

Es imposible no tener curiosidad sobre estos asuntos incluso aunque el Armagedón no esté a la vuelta de la esquina. Nuestra lucha por sobrevivir en el planeta Tierra, que se ve acosado actualmente por distintas crisis provocadas por los seres humanos, queda situada en un nuevo contexto, bienvenido, cuando nos vemos obligados a reflexionar sobre la dimensión cosmológica de nuestra existencia. Los últimos tres minutos es el relato del futuro del universo, en nuestra mejor predicción, basado en las últimas ideas de algunos físicos y cosmólogos reconocidos. No todo es apocalíptico. Lo cierto es que el futuro ofrece la promesa de un potencial de desarrollo y de riqueza de experiencias sin precedentes. Pero no podemos pasar por alto el hecho de que lo que puede existir puede también dejar de existir.

Este libro está pensado para el lector común. No hacen falta conocimientos previos de ciencias o de matemáticas. Sin embargo, de tanto en tanto hará falta tratar con números muy grandes o muy pequeños y viene bien utilizar la notación matemática compacta conocida como potencias de diez para representarlos. Por ejemplo, el número cien mil millones escrito completamente desarrollado es 100.000.000.000 lo cual es bastante engorroso. En ese número hay once ceros después del 1 así que podemos representarlo escribiendo 1011: que en palabras se expresa «diez elevado a la undécima potencia, o diez elevado a la once». De manera similar, un millón es 106 y un billón es 1012. Y así sucesivamente. Recuérdese sin embargo que esta notación propende a camuflar la tasa a la que crecen estos números: 1012 es cien veces mayor que 1010; es un número mucho mayor aunque parezca casi lo mismo. Utilizadas en negativo, las potencias de diez pueden también representar números muy pequeños: así la fracción una milmillonésima, o 1 / 1.000.000.000, se convierte en 10-9 («diez a la menos nueve»), porque hay nueve ceros después del 1 del denominador de la fracción.

Por último, me gustaría advertir al lector de que este libro es, por necesidad, sumamente especulativo. Aunque la mayoría de las ideas que se presentan se basan en nuestra comprensión actual de la ciencia, la futurología no puede disfrutar del mismo estatuto que otros empeños científicos. Sin embargo, es irresistible la tentación de especular acerca del destino último del cosmos. Con este espíritu de investigación abierta es con el que he escrito este libro. Científicamente, está bastante bien establecido el panorama de un universo que se origina en un big bang, para luego expandirse y enfriarse avanzando hacia un estado final de degeneración física, o acaso desplomándose catastróficamente. Sin embargo, son mucho menos seguros los procesos físicos predominantes que puedan darse a esas inmensas escalas de tiempo. Los astrónomos tienen una idea clara del destino general de las estrellas corrientes y van ganando confianza en su comprensión de las propiedades básicas de las estrellas de neutrones y de los agujeros negros; pero si el universo dura muchos billones de años o más, puede haber sutiles efectos físicos que ahora sólo seamos capaces de atisbar y que puedan terminar teniendo mucha importancia.

Cuando nos enfrentamos con el problema de nuestra comprensión incompleta de la naturaleza, lo único que podemos hacer para intentar deducir el destino definitivo del universo es utilizar nuestras mejores teorías actuales y extrapolarlas para sacar las conclusiones lógicas que de ellas se deriven. El problema es que muchas de las teorías que tienen una relación importante con el destino del universo siguen sin haberse comprobado experimentalmente. Los teóricos creen entusiásticamente en algunos de los procesos que examino (por ejemplo, la emisión de ondas gravitatorias, la desintegración de los protones y la radiación de los agujeros negros) pero no se han observado todavía. Igualmente, habrá sin duda otros procesos físicos de los que no sabemos nada y que podrían alterar drásticamente las ideas que aquí se presentan.

Estas incertidumbres se hacen aún mayores cuando consideramos los posibles efectos de la vida inteligente en el universo. Aquí entramos en el reino de la ciencia ficción; sin embargo, no podemos pasar por alto el hecho de que los seres vivos puedan, a lo largo de los eones, modificar significativamente el comportamiento de los sistemas físicos a escala cada vez mayor. He decidido incluir el tema de la vida en el cosmos porque para muchos lectores la fascinación por el destino del universo va ligada íntimamente a su preocupación por el destino de los seres humanos, o de los remotos descendientes de los seres humanos. Con todo, deberíamos recordar que los científicos no tienen una comprensión auténtica de la naturaleza de la conciencia humana, ni de los requerimientos físicos que puedan permitir que la actividad consciente continúe en el futuro lejano del universo.

Me gustaría dar las gracias a John Barrow, Frank Tipler, Jason Twamley, Roger Penrose y Duncan Steel por las discusiones tan útiles que han mantenido conmigo sobre el tema de este libro; al editor de la serie, Jerry Lions, por su lectura crítica del manuscrito y a Sara Lippincott por su excelente trabajo con el manuscrito definitivo.

CAPÍTULO 1: EL JUICIO FINAL

Fecha: 21 de agosto de 2126. Día del juicio final.

Lugar: La Tierra. Por todo el planeta, la población desesperada intenta guarecerse. Hay miles de millones de personas que no tienen dónde ir. Unos huyen bajo la tierra, buscando desesperadamente cuevas y minas abandonadas, o se hacen a la mar en submarinos. Otros lo destrozan todo a su paso, mortíferos y despreciativos. La gran mayoría espera sentada, cariacontecida y perpleja, esperando el final.

En lo alto del cielo, hay grabado un rayo de luz en el azul del cielo. Lo que empezó siendo un estrecho trazo de blanda nebulosidad radiante ha crecido día a día hasta formar un vórtice de gas que hierve en el vacío del espacio. En el vértice de ese rastro de vapor yace un pegote oscuro, informe y amenazante. La diminuta cabeza del cometa contrasta con su enorme poder destructivo. Se acerca al planeta Tierra a la asombrosa velocidad de 65.000 kilómetros por hora, 18 kilómetros por segundo: un billón de toneladas de hielo y piedra destinados a estrellarse a setenta veces la velocidad del sonido.

La humanidad sólo puede mirar y esperar. Los científicos, que han abandonado hace tiempo sus telescopios a la vista de lo inevitable, apagan silenciosamente los ordenadores. Las inacabables simulaciones del desastre siguen siendo demasiado inciertas y las conclusiones que obtienen son, en cualquier caso, demasiado alarmantes como para darlas a conocer públicamente. Algunos científicos han elaborado complejas estrategias de supervivencia utilizando sus conocimientos técnicos para sacar ventaja a sus conciudadanos. Otros tienen pensado observar el cataclismo lo más cuidadosamente posible, cumpliendo su papel de verdaderos científicos hasta el mismísimo fin, transmitiendo datos a las cápsulas profundamente enterradas. Para la posteridad...

Se acerca el momento del impacto. En todo el mundo, millones de personas comprueban nerviosamente sus relojes. Los últimos tres minutos.

Justo por encima del nivel de la tierra, se abren los cielos. Mil kilómetros cúbicos de aire se abren. Un brazo de llamas abrasadoras más ancho que una ciudad se arquea hacia abajo y quince segundos después alancea a la Tierra. El planeta se estremece con la fuerza de diez mil terremotos. Una onda de choque de aire desplazado barre la superficie del globo, aplastando cualquier estructura, pulverizándolo todo a su paso. El terreno plano en torno al punto del impacto se yergue formando una corona de montañas líquidas de varios kilómetros de alto, exponiendo las entrañas de la Tierra en un cráter de cientos de kilómetros de diámetro. La pared de roca triturada se extiende hacia el exterior, sacudiendo el paisaje de alrededor como cuando se mueve una manta a cámara lenta.

Dentro del propio cráter, billones de toneladas de rocas se vaporizan. Buena parte de ellas salen despedidas, algunas proyectadas al espacio. Pero más aún saltan atravesando medio continente para llover a cientos o incluso miles de kilómetros de distancia, sembrando la destrucción generalizada a todo lo que hay por debajo. Alguno de los materiales fundidos y despedidos caen sobre el océano, originando gigantescos tsunamis que contribuyen al caos creciente. A la atmósfera llega una gran columna de restos pulverulentos, impidiendo el paso de la luz solar sobre todo el planeta. La luz del sol se ve sustituida por un relumbre siniestro y parpadeante de miles de millones de meteoritos, que queman la tierra con su calor abrasador, mientras el material desplazado va cayendo hacia la atmósfera desde el espacio.

Este panorama se basa en la predicción de que el cometa Swift-Tuttle chocará con la Tierra el 21 de agosto de 2126. De ser así, seguirá una devastación global sin duda alguna que destruirá la civilización humana. Cuando este cometa nos visitó en 1993, los primeros cálculos parecían indicar que la colisión de 2126 era posibilidad clara. Desde entonces, los cálculos revisados indican que el cometa no golpeará la Tierra por un lapso de dos semanas: estará cerca, pero podemos respirar tranquilos. Con todo, el peligro no desaparecerá por completo. Antes o después, el Swift-Tuttle u otro objeto similar chocará con la Tierra. Las estimaciones indican que existen unos 10.000 objetos de medio kilómetro de diámetro o más que se mueven en órbitas que intersectan la de la Tierra. Estos intrusos astronómicos se originan en las frías regiones exteriores del sistema solar. Algunos son restos de cometas que han quedado atrapados por los campos gravitatorios de los planetas, otros provienen del cinturón de asteroides situado entre Marte y Júpiter. La inestabilidad orbital origina un tránsito continuo de estos cuerpos pequeños pero letales, que continuamente entran en el sistema solar interior y vuelven a salir de él, constituyendo una amenaza siempre presente para la Tierra y nuestros planetas hermanos.

Muchos de estos objetos son capaces de causar más daños que todas las armas nucleares del mundo juntas. Es una mera cuestión de tiempo que alguno nos golpee. Mala noticia para nosotros si se produce tal cosa. La historia de nuestra especie se interrumpirá abruptamente, cosa que no ha ocurrido nunca. Pero para la Tierra se tratará de un suceso más o menos habitual. Los impactos cometarios o de asteroides de esta magnitud se dan, como media, cada pocos millones de años. Generalmente se cree que uno o más de tales sucesos fueron los causantes de la extinción de los dinosaurios hace sesenta y cinco millones de años. La próxima vez podría tocarnos a nosotros.

La creencia en el Armagedón está arraigada profundamente en la mayoría de las religiones y culturas. El Apocalipsis proporciona un vivido relato de la muerte y de la destrucción que nos esperan:

Y se produjeron relámpagos, y voces, y truenos, y sobrevino un gran temblor de tierra cual no lo hubo desde que el hombre existe sobre la Tierra, tan grande fue... Y las ciudades de los pueblos se desplomaron... y las islas huyeron y no se pudo encontrar a las montañas. Del cielo cayó sobre los hombres un enorme pedrisco con piedras como de a quintal. Y los hombres maldijeron a Dios por causa de la plaga del pedrisco, porque era horrible.

Desde luego que hay montones de cosas desagradables que podrían pasarle a la Tierra, escuchimizado objeto en un universo recorrido por violentas fuerzas, aunque nuestro planeta ha seguido siendo hospitalario para la vida por lo menos durante tres mil quinientos millones de años. El secreto de nuestro éxito sobre el planeta Tierra es el propio espacio. Hay mucho. Nuestro sistema solar es una isla diminuta en un océano de vacío. La estrella más cercana, aparte del Sol, queda a más de cuatro años luz. Para hacernos una idea de lo lejos que es eso, pensemos que la luz recorre los más de 149 millones de kilómetros que nos separan del Sol en sólo ocho minutos y medio. En cuatro años recorre más de 32 billones de kilómetros.

El Sol es una estrella enana normal que se encuentra en una región normal de nuestra galaxia, la Vía Láctea. La galaxia alberga aproximadamente cien mil millones de estrellas, que varían en masa desde un pequeño porcentaje de la masa solar hasta cien veces la masa del Sol. Estos objetos, así como una enorme cantidad de nubes de gas y polvo y un número indeterminado de cometas, asteroides, planetas y agujeros negros orbitan lentamente en torno al centro galáctico. Esa inmensa colección de objetos puede producir la impresión de que nuestra galaxia es un sistema sumamente poblado, hasta que se cae en la cuenta de que la parte visible de la Vía Láctea mide aproximadamente cien mil años luz de diámetro. Tiene la forma de un plato con un bulto central; en los bordes se proyectan unos pocos brazos espirales compuestos de estrellas y gas. Nuestro Sol está situado en uno de esos brazos espirales y está aproximadamente a unos treinta mil años luz del centro.

Por lo que sabemos, la Vía Láctea no tiene nada de excepcional. A unos dos millones de años luz se encuentra otra galaxia parecida, llamada Andrómeda, en dirección a la constelación del mismo nombre. Puede verse a simple vista como un borrón de luz. El universo observable se ve adornado por muchos miles de millones de galaxias, espirales algunas de ellas, otras elípticas o irregulares. La escala de distancias es amplísima. Los telescopios potentes pueden resolver galaxias individuales que se encuentren a varios miles de millones de años luz. En algunos casos, su luz ha tardado en llegarnos más que la edad que tiene la Tierra (cuatro mil quinientos millones de años).

Todo este espacio significa que las colisiones cósmicas son raras. La mayor amenaza para la Tierra seguramente procede de nuestro propio entorno. Los asteroides normalmente no orbitan cerca de la Tierra; están generalmente confinados al cinturón que queda entre Marte y Júpiter. Pero la enorme masa de Júpiter puede perturbar las órbitas de los asteroides, impulsando a alguno de ellos hacia el Sol de tanto en tanto y amenazando así la Tierra.

Los cometas plantean otra amenaza. Se cree que estos cuerpos espectaculares se originan en una nube invisible situada a un año luz del Sol. En este caso la amenaza no proviene de Júpiter, sino de las estrellas que pasan cerca. La galaxia no es estática, sino que rota lentamente, al igual que sus estrellas orbitan en torno al núcleo galáctico. El Sol y su pequeño cortejo de planetas tardan unos doscientos millones de años en completar una vuelta completa a la galaxia y en ese tiempo corren múltiples aventuras. Las estrellas cercanas pueden rozar la nube de cometas, desplazando a unos pocos hacia el Sol. Cuando los cometas se meten en el sistema solar interior el Sol evapora parte de sus materiales volátiles y el viento solar los dispersa formando un largo rastro, la famosa cola de los cometas. Muy de vez en cuando, un cometa colisiona con la Tierra a su paso por el interior del sistema solar. Es el cometa el que produce el daño, pero la estrella es la responsable última. Afortunadamente, las inmensas distancias entre las estrellas impiden que se produzca un número excesivo de tales encuentros.

También pueden cruzarse con nosotros otros objetos que viajen en torno a la galaxia. Las nubes gigantes de gas derivan lentamente y aunque son más tenues que cualquier vacío creado en laboratorio pueden alterar drásticamente el viento solar y afectar el flujo de calor que nos llega del Sol. Otros objetos más siniestros pueden acechar en las tenebrosas profundidades del espacio: planetas solitarios, estrellas de neutrones, enanas marrones, agujeros negros: todos estos y muchos más podrían aparecer sin anunciarse, sin ser vistos y sembrar estragos en el sistema solar.

O podría ser más insidiosa la amenaza. Algunos astrónomos creen que el Sol puede formar parte de una estrella doble, lo mismo que tantísimas otras estrellas de la galaxia. Si existe, su compañera (apodada Némesis o Estrella de la Muerte) es demasiado tenue y está demasiado lejos como para haberla detectado. Pero en su lenta órbita en torno al Sol, podría seguir haciendo sentir su presencia gravitatoria, perturbando periódicamente cometas distantes y arrojando algunos hacia la Tierra, cosa que produciría una serie de impactos devastadores. Los geólogos han descubierto que la destrucción ecológica generalizada se produce desde luego periódicamente: aproximadamente cada treinta millones de años.

A escala mayor, los astrónomos han observado galaxias enteras en aparente colisión. ¿Qué posibilidades hay de que la Vía Láctea sufra un choque con otra galaxia? Hay algunas pruebas, debido al rapidísimo movimiento de algunas estrellas, de que la Vía Láctea puede haberse visto perturbada ya por colisiones con algunas pequeñas galaxias cercanas. Sin embargo, la colisión de dos galaxias no significa necesariamente el desastre para las estrellas que la constituyen. Las galaxias están tan escasamente pobladas que pueden fundirse unas con otras sin que haya colisiones estelares individuales.

A la mayor parte de la gente le fascina la perspectiva del Día del Juicio Final: una destrucción súbita y espectacular del mundo. Pero la muerte violenta es una amenaza menor que la lenta decadencia. Hay muchas maneras de que la Tierra se vaya volviendo inhóspita poco a poco. La degradación ecológica paulatina, el cambio climático, cualquier pequeña variación en la emisión calorífica del Sol: todas estas cosas pueden amenazar nuestra comodidad, cuando no nuestra supervivencia, sobre nuestro frágil planeta. Sin embargo, algunos cambios se producirán a lo largo de miles de años, o incluso de millones, y la humanidad puede ser capaz de afrontarlos por medio de una tecnología avanzada. Por ejemplo, el inicio gradual de una edad de hielo no supondría el desastre total para nuestra especie, teniendo el tiempo suficiente para reorganizar nuestras actividades. Podemos conjeturar que la tecnología seguirá avanzando espectacularmente a lo largo de los próximos milenios; de ser así, es tentador creer que los seres humanos, o sus descendientes, dispondrán del control de sistemas físicos cada vez mayores y que pueden llegar a un momento en que sepan eludir desastres incluso a escala astronómica.

En principio ¿puede la humanidad sobrevivir para siempre? Puede ser. Pero ya veremos que la inmortalidad no resulta fácil y que podría resultar que fuera imposible. El propio universo está sujeto a leyes físicas que le imponen un ciclo vital propio: nacimiento, evolución y, quizá, muerte. Nuestro propio destino está inextricablemente unido al destino de las estrellas.

CAPÍTULO 2: EL UNIVERSO MORIBUNDO

En el año 1856, el físico alemán Hermann von Helmholtz hizo la que con seguridad es la predicción más deprimente de toda la historia de la ciencia. El universo se muere, declaró Helmholtz. La base para tan apocalíptica afirmación era la llamada segunda ley de la termodinámica. Formulada originariamente a principios del siglo XIX como una declaración más bien técnica sobre la eficiencia de las máquinas térmicas, la segunda ley de la termodinámica (generalmente reconocida ahora sin más como «la segunda ley») se vio enseguida que tenía un significado universal y consecuencias verdaderamente cósmicas.

En su versión más simple, la segunda ley afirma que el calor fluye de lo caliente a lo frío. Naturalmente, se trata de una propiedad familiar y evidente de los sistemas físicos. La vernos en funcionamiento siempre que cocinamos algo o dejamos que se enfríe una taza de café: el calor fluye de la región del espacio que está a mayor temperatura hacia aquella que está a temperatura inferior. No hay misterio en ello. El calor se manifiesta en la materia bajo la forma de agitación molecular. En un gas, como por ejemplo el aire, las moléculas se agitan caóticamente y chocan unas con otras.

Hasta en un cuerpo sólido los átomos vibran enérgicamente. Cuanto más caliente esté un cuerpo, más enérgica será la agitación molecular. Si dos cuerpos a diferentes temperaturas se ponen en contacto la agitación molecular más vigorosa del cuerpo caliente se transmite enseguida a las moléculas del cuerpo más frío.

Como el flujo de calor es unidireccional, el proceso es asimétrico en el tiempo. Una película que mostrara el calor fluyendo espontáneamente de lo frío a lo caliente tendría un aspecto tan tonto como la de un río que subiera colina arriba o la de las gotas de lluvia que subieran hasta las nubes. De modo que podemos identificar una direccionalidad fundamental en el flujo de calor y que suele representarse mediante una flecha que va del pasado al futuro. Esta «flecha del tiempo» indica la naturaleza irreversible de los procesos termodinámicos y lleva fascinando a los físicos ciento cincuenta años. (Véase figura 2.1.)

La flecha del tiempo. El cubito de hielo que se derrite define la dirección del tiempo: el calor fluye del agua caliente al hielo frío. Una película que fuera en sentido (III), (II), (I) se reconocería inmediatamentecomo falsa. Esta asimetría está caracterizada por una magnitud llamada entropia, que aumenta conforme va fundiéndose el hielo.

Los trabajos de Helmholtz, Rudolf Clausius y lord Kelvin condujeron al reconocimiento del significado de una magnitud llamada entropía que caracterizara el cambio irreversible en termodinámica. En el caso sencillo de un cuerpo caliente puesto en contacto con otro frío, la entropía puede definirse como energía calorífica dividida por temperatura. Pensemos en una pequeña cantidad de calor que fluya del cuerpo caliente al frío. El cuerpo caliente perderá parte de entropía y el frío ganará parte de ella. Como hay cierta energía calorífica en juego pero las temperaturas son distintas, la entropía ganada por el cuerpo frío será mayor que la perdida por el cuerpo caliente. De este modo crece la entropía total de todo el sistema (cuerpo caliente más cuerpo frío). Una afirmación de la segunda ley de la termodinámica es, por ello, que la entropía de un sistema de esas características nunca decrecerá porque para que decreciera habría que suponer que parte del calor ha pasado espontáneamente de lo frío a lo caliente.

Un análisis más minucioso permite que esta ley se generalice para todos los sistemas cerrados: la entropía nunca decrece. Si el sistema comprende un refrigerador, el cual puede transferir calor del frío a lo caliente, el total de la entropía de todo el sistema debe tener en cuenta la energía empleada en hacer funcionar el refrigerador. Este proceso de gasto incrementará por sí solo la entropía. Es así que siempre se da que la entropía creada por el funcionamiento del refrigerador supera siempre a la reducción de la entropía que resulta de transferir calor de lo frío a lo caliente. Asimismo, en los sistemas naturales, como los que suponen organismos naturales o formación de cristales, la entropía de una parte del sistema suele decrecer, pero este decrecimiento siempre se ve compensado por un aumento de entropía en otra parte del sistema. En conjunto la entropía nunca disminuye.

Si el universo como conjunto puede considerarse como sistema cerrado basándonos en que no existe nada «fuera» de él, entonces la segunda ley de la termodinámica predice algo importante: que el total de la entropía del universo nunca disminuye. Por el contrario, sigue aumentando implacablemente. Un buen ejemplo lo tenemos a la vuelta de la esquina en términos cósmicos: el Sol, que continuamente vierte calor en las frías profundidades del espacio. Ese calor se dispersa en el universo sin regresar jamás; se trata de un proceso espectacularmente irreversible.

Una cuestión evidente es la siguiente: ¿puede seguir aumentando para siempre la entropía del universo? Imaginemos un cuerpo caliente y un cuerpo frío que se pusieran en contacto dentro de una cámara térmicamente sellada. La energía fluiría de lo caliente a lo frío y la entropía aumentaría, pero el cuerpo frío terminaría por calentarse y el cuerpo caliente se enfriaría de modo que alcanzarían la misma temperatura. Cuando se llegue a ese estado, no habrá más transferencia de energía. El sistema en el interior de la cámara habrá alcanzado una temperatura uniforme: un estado estable de máxima entropía al que se denomina equilibrio termodinámico. Mientras el sistema permanezca aislado, no se puede esperar cambio posterior; pero si los cuerpos se vieran perturbados de algún modo (por ejemplo, introduciendo más calor desde el exterior de la cámara), entonces habría algo más de actividad térmica aumentando la entropía hasta un máximo mayor.

¿Qué nos dicen estas ideas básicas de termodinámica sobre el cambio astronómico y cosmológico? En el caso del Sol y de la mayoría de las demás estrellas, la emisión de calor puede continuar durante muchos miles de millones de años, pero no es inagotable. El calor de una estrella normal lo generan los procesos nucleares de su interior. Como veremos, el Sol terminará por quedarse sin combustible y a menos que ocurran otras cosas, se irá enfriando hasta alcanzar la misma temperatura que el espacio circundante.

Aunque Hermann von Helmholtz no sabía nada de reacciones nucleares (en su época la fuente de la inmensa energía del Sol era un misterio) sí comprendía el principio general de que toda actividad física en el universo tiende hacia un estado final de equilibrio termodinámico, o de máxima entropía, a partir del cual no ocurrirá nada para el resto de la eternidad. Este sesgo hacia el equilibrio se conoció entre los primeros termodinámicos como «muerte térmica» del universo. Se aceptaba que los sistemas individuales podían verse revitalizados por perturbaciones externas, aunque como el universo no tenía nada «fuera» de él por definición nada podría impedir una muerte térmica que lo abarcara por completo. Parecía ineludible.

El descubrimiento de que el universo se moría como consecuencia inexorable de las leyes de la termodinámica tuvo un profundo efecto depresor sobre varias generaciones de científicos y filósofos. Bertrand Russell, por ejemplo, se vio movido a escribir el siguiente párrafo pesimista en su libro Por qué no soy cristiano:

Todo el esfuerzo de las eras, toda la devoción, toda la inspiración, toda la brillantez del mediodía del genio humano, están destinados a la extinción en la vasta muerte del sistema solar y... todo el templo del logro humano se verá inevitablemente enterrado bajo los restos de un universo en ruinas; todas estas cosas, aun no siendo absolutamente incontestables, son casi tan seguramente ciertas que no puede permanecer ninguna filosofía que las rechace. Sólo dentro del entramado de estas verdades, sólo sobre la firme base de la desesperación inquebrantable, puede erigirse a salvo la morada del alma a partir de ese momento.

Muchos otros escritores han llegado a la conclusión, a partir de la segunda ley de la termodinámica y de su consecuencia del universo que se muere, de que el universo no tiene sentido y que la existencia humana es, en último término, fútil. Volveré a esta desoladora valoración en capítulos posteriores y examinaré si está o no mal planteada.

La predicción de una muerte cósmica definitiva del universo no sólo habla del futuro del universo, sino que también implica una cosa importante del pasado. Está claro que si el universo avanza irreversiblemente hacia su agotamiento a una velocidad finita, entonces no puede haber existido desde siempre. La razón es sencilla: si el universo fuera infinitamente antiguo, ya habría muerto. Es evidente que una cosa que avance hasta detenerse a una tasa finita no puede haber existido desde toda la eternidad. Dicho de otro modo, el universo debe haber surgido a la existencia hace un cierto tiempo, un tiempo finito.

Es notable que esta profunda conclusión no la captaran adecuadamente los científicos del siglo XIX. La idea de un universo originado bruscamente en un big bang tuvo que esperar a las observaciones astronómicas de los años 20, pero ya se sugería con fuerza, sobre bases puramente termodinámicas, una génesis definida en cierto momento del pasado.

Sin embargo, como no se llegó a esta conclusión, los astrónomos del siglo XIX se vieron desconcertados por una curiosa paradoja cósmica. Conocida como paradoja de Olbers, por el astrónomo alemán a quien se reconoce su formulación, plantea una pregunta sencilla pero profundamente significativa: ¿por qué el cielo es oscuro por la noche?

El problema, en un principio, parece una tontería. El cielo nocturno es oscuro porque las estrellas están situadas a inmensas distancias de nosotros y por ello parecen tan tenues. (Véase figura 2.2.) Pero imaginemos que el espacio no tiene límites. En tal caso, bien podría haber infinidad de estrellas. Un número infinito de estrellas supondría un montón de luz. Resulta fácil calcular la luz estelar acumulada proveniente de una infinidad de estrellas que no cambian y distribuidas más o menos uniformemente por todo el espacio. El brillo de una estrella disminuye con la distancia, según la ley del inverso del cuadrado. Lo cual significa que a una distancia dos veces mayor, la estrella es la cuarta parte de brillante, a una distancia tres veces mayor es la novena parte de brillante y así sucesivamente. Por una parte, el número de estrellas se incrementa cuanto más lejos miramos. De hecho, la mera geometría nos indica que el número de estrellas a, por ejemplo, doscientos años luz es cuatro veces mayor que el número de estrellas a cien años luz, mientras que el número de estrellas a trescientos años luz es nueve veces mayor que ese último. De modo que el número de estrellas crece con el cuadrado de la distancia mientras que el brillo disminuye con el cuadrado de la distancia. Los dos efectos se anulan y el resultado es que la luz total que nos llega de todas las estrellas que se encuentran a una distancia dada no depende de la distancia. La luz total que llega desde las estrellas que están a doscientos años luz es la misma que la luz total que nos llega desde estrellas a la distancia de cien años luz.

La paradoja de Olbers. Imaginemos un universo sin cambios poblado por estrellas distribuidas al azar con una densidad media uniforme. Aquí se muestra una selección de las estrellas que ocupan una delgada corona esférica de espacio con centro en la Tierra. (En el dibujo, se han eliminado las estrellas fuera de la corona.) La luz de las estrellas de esta corona contribuye al flujo total de luz estelar que llega a la tierra. La intensidad de luz procedentede una estrella dada disminuirá con el cuadrado del radio de la corona. Sin embargo, el número total de estrellas en la corona crecerá en proporción al cuadrado del radio de la corona. Por lo tanto, estos dos factores de anularán uno al otro y la luminosidad total de la corona será independiente de su radio. En un universo infinito, abrá una infinidad de coronas y, aparentemente, un flujo infinito de luz que llege a la tierra.

El problema surge cuando sumamos la luz proveniente de todas las estrellas a todas las posibles distancias. Si el universo no tiene límites, no parece haber límite a la cantidad total de luz recibida por la Tierra. En lugar de estar oscuro ¡el cielo nocturno debería ser infinitamente brillante!

El problema se alivia un poco cuando se tiene en cuenta el tamaño finito de las estrellas. Cuanto más lejos se encuentra una estrella de la Tierra menor es su tamaño aparente. Una estrella cercana oscurecerá a una estrella más lejana si queda en la misma línea de visión. En un universo infinito eso ocurriría con una frecuencia infinita y al tenerlo en cuenta cambiaría la conclusión de los cálculos anteriores. En lugar de llegar a la Tierra un flujo de luz infinito, el flujo no es más que muy grande (aproximadamente equivalente al disco del Sol que llenara el cielo, lo cual ocurriría si la Tierra estuviera situada en torno a un millón y medio de kilómetros de la superficie solar). Una situación muy incómoda, sin duda: la verdad es que la Tierra se vaporizaría rápidamente debido al intenso calor.

La conclusión de que un universo infinito debería ser un horno cósmico es, ciertamente, una repetición del problema termodinámico que he examinado antes. Las estrellas vierten calor y luz al espacio y esta radiación se acumula lentamente en el vacío. Si las estrellas han estado ardiendo desde siempre, a primera vista parece que la radiación debe tener una intensidad infinita. Pero una parte de la radiación, al viajar por el espacio, choca con otras estrellas y se reabsorbe. (Esto equivale a darse cuenta de que las estrellas cercanas oscurecen la luz de las más lejanas.) Por lo tanto, la intensidad de la radiación aumentará hasta que se establezca un equilibrio en el que la tasa de emisión se equilibre con la tasa de absorción. Este estado de equilibrio termodinámico se dará cuando la radiación del espacio alcance la misma temperatura que la superficie de las estrellas: unos pocos miles de grados. De este modo, el universo estaría lleno de radiación térmica a una temperatura de varios miles de grados y el cielo nocturno, en lugar de ser oscuro, debería deslumbrar a esa temperatura.

Heinrich Olbers propuso una solución a su propia paradoja. Al darse cuenta de la existencia de grandes cantidades de polvo en el universo, formuló la sugerencia de que ese material absorbiera la mayor parte de la luz estelar, oscureciendo así el cielo. Esta idea, por desgracia, aun siendo imaginativa estaba radicalmente equivocada: el polvo habría terminado por calentarse terminando por iluminar con la misma intensidad que la radiación que absorbiera.

Otra resolución posible es la de abandonar la suposición de que el universo es infinito en extensión. Supongamos que las estrellas son muchas pero en número finito, de tal modo que el universo consista en un inmenso conjunto de estrellas rodeado por un vacío oscuro e infinito; entonces, la mayor parte de la luz estelar se dispersará en el espacio y se perderá. Pero también esta sencilla solución tiene una pega esencial, pega que, por cierto, ya le fue familiar a Isaac Newton en el siglo XVII. La pega se refiere a la naturaleza de la gravitación: toda estrella atrae a cualquier otra estrella con una determinada fuerza gravitatoria, y por lo tanto, todas las estrellas del conjunto tenderían a reunirse unas con otras, concentrándose en el centro de gravedad. Si el universo tiene un borde y un centro definidos, da la impresión de que debería colapsarse sobre sí mismo. Un universo sin soporte, finito y estático es inestable y propenso al derrumbe gravitatorio.

Este problema gravitatorio volverá a surgir en mi relato más adelante. Lo único que necesitamos por el momento es tomar nota de la ingeniosa manera en que Newton intentó sortearlo. El universo puede derrumbarse sobre su centro de gravedad, razonó Newton, sólo si tiene centro de gravedad. Si el universo es a la vez infinito en extensión y (por término medio) poblado uniformemente por estrellas, no habrá entonces ni borde ni centro. Una estrella se verá atraída por todas partes por sus muchas vecinas, como en una especie de tirasoga gigantesco en que la cuerda estuviera en todas direcciones. Por término medio, todos esos tirones se anularían unos a otros y la estrella no se movería.

De modo que si aceptamos la solución de Newton para la paradoja del cosmos que se derrumba, volvemos nuevamente al universo infinito y al problema que plantea la paradoja de Olbers. Tal parece que tenemos que afrontar una u otra. Pero gracias a la introspección podemos encontrar una vía entre los cuernos del dilema. Lo que es erróneo no es asumir que el universo es infinito en el espacio, sino suponer que es infinito en el tiempo. La paradoja del cielo llameante surgió porque los astrónomos supusieron que el universo no cambiaba, que las estrellas eran estáticas y llevaban brillando con la misma intensidad durante toda la eternidad. Pero hoy sabemos que ambas suposiciones eran erróneas. En primer lugar, como explicaré brevemente, el universo no es estático, sino que se está expandiendo. En segundo lugar, las estrellas no pueden haber estado brillando desde siempre porque ya haría mucho tiempo que se habrían quedado sin combustible. Que brillen en la actualidad supone que el universo debe haber empezado a existir hace una cantidad de tiempo finita.

Si el universo tiene una edad finita, la paradoja de Olbers desaparece instantáneamente. Para ver por qué, consideremos el caso de una estrella muy distante. Como la luz viaja a una velocidad finita (300.000 kilómetros por segundo en el vacío), no vemos la estrella como es en la actualidad, sino como cuando salió de la estrella. Por ejemplo, la brillante estrella Betelgeuse está a unos 650 años luz de nosotros, de manera que se nos aparece como era hace 650 años. Si el universo empezó a existir hace, por ejemplo, diez mil millones de años, entonces no veremos las estrellas que estén a más de diez mil millones de años luz de la Tierra. El universo puede ser infinito en extensión espacial, pero si tiene una edad finita no podemos en ningún caso ver más allá de una determinada distancia finita. Así la luz estelar acumulada procedente de un número infinito de estrellas de edad finita será finita y seguramente insignificantemente pequeña.

La misma conclusión se obtiene de las consideraciones termodinámicas. El tiempo necesario para que las estrellas llenen el espacio con la radiación térmica y para que alcancen una temperatura común es inmenso debido a la gran cantidad de espacio vacío que hay en el universo. Sencillamente, no ha habido tiempo suficiente desde el inicio del universo para haber alcanzado ya el equilibrio termodinámico.

Por ello todas las pruebas llevan a un universo que tenga un lapso de vida limitado. Comenzó a existir en cierto momento, hierve de actividad en la actualidad pero va indefectiblemente degenerando hacia una muerte térmica en cierto momento del futuro. Inmediatamente surgen montones de preguntas: ¿Cuándo llegará el final? ¿Bajo qué forma se dará? ¿Será lenta o rápidamente? Y ¿es concebible que la conclusión sobre la muerte térmica, tal y como la entienden hoy los científicos, pueda ser errónea?

CAPÍTULO 3: LOS PRIMEROS TRES MINUTOS

Los cosmólogos, como los historiadores, saben que la clave del futuro radica en el pasado. En el último capítulo, expliqué cómo las leyes de la termodinámica parecen indicar un universo de longevidad limitada. Los científicos tienen la opinión casi unánime de que todo el cosmos se originó hace diez mil millones o veinte mil millones de años en una gran explosión y que este acontecimiento puso al universo en el camino hacia su destino definitivo. Teniendo en cuenta cómo comenzó el universo, e investigando los procesos que se dieron en la fase primitiva, pueden extraerse pistas cruciales acerca del futuro lejano.

La idea de que el universo no ha existido siempre está profundamente arraigada en la cultura occidental. Aunque los filósofos griegos consideraron la posibilidad de un universo eterno, todas las religiones occidentales principales han sostenido que el universo fue creado por Dios en un determinado momento.

La argumentación científica a favor de un origen brusco en una gran explosión es irresistible. La evidencia más directa proviene del estudio de las cualidades de la luz de las galaxias lejanas. En los años 20, el astrónomo norteamericano Edwin Hubble (trabajando sobre las pacientes observaciones de Vesto Slipher, un experto en nebulosas que trabajaba en el observatorio Flagstaff de Arizona) cayó en la cuenta de que las galaxias lejanas parecían ser un poco más rojas que las más cercanas. Hubble utilizó el telescopio de 2,5 metros de Mount Wilson para medir con cuidado ese enrojecimiento, hasta obtener una gráfica. Descubrió que se trataba de una cuestión sistemática: cuanto más lejos está una galaxia, más roja parece.

El color de la luz está relacionado con su longitud de onda. Dentro del espectro de la luz blanca, el azul se encuentra en el extremo de las ondas más cortas y el rojo en el extremo de las ondas más largas. El enrojecimiento de las galaxias distantes indica que la longitud de onda de su luz se ha estirado. Determinando cuidadosamente las posiciones de las líneas características del espectro de muchas galaxias, Hubble pudo confirmar que el alargamiento de las ondas de luz se debe a que el universo se está expandiendo. Con esta declaración trascendental, Hubble puso los cimientos de la moderna cosmología.

La naturaleza del universo en expansión produce confusión en muchas personas. Desde el punto de vista de la Tierra, parece que las galaxias distantes se alejaran rápidamente de nosotros. Sin embargo, eso no significa que la Tierra esté en el centro del universo; la tasa de expansión es (por término medio) la misma en todo el universo. Todas las galaxias (o para ser más precisos, todos los cúmulos de galaxias) se están alejando unas de otras. Lo cual se visualiza mejor como el estiramiento o la hinchazón del espacio entre los cúmulos galácticos y no tanto como el movimiento de cúmulos galácticos por el espacio.

El hecho de que el espacio pueda estirarse puede parecer sorprendente, pero se trata de un concepto que lleva siendo familiar a los científicos desde 1915, año en que Einstein hizo pública su teoría general de la relatividad. Esta teoría indica que la gravedad es en realidad una manifestación de la curvatura o distorsión del espacio (o, estrictamente hablando, del espacio-tiempo). En cierto sentido, el espacio es elástico y puede doblarse o estirarse de un modo que depende de las propiedades gravitatorias del material que lo integra. Esta idea se ha visto ampliamente confirmada por las observaciones.

El concepto básico de espacio en expansión puede comprenderse con la ayuda de una analogía sencilla. Imaginemos una hilera de botones, que representan cúmulos galácticos, cosidos a una tira de goma (véase figura 3.1). Imaginemos ahora que estiramos la goma tirando de los extremos. Todos los botones se alejan unos de otros. Sea cual sea el botón que miremos, parecerá que los botones vecinos se alejan de él. Sin embargo, la expansión es la misma en todas partes: no hay un centro que sea un punto especial. Por supuesto que tal y como lo he dibujado hay un botón que está en el centro, pero eso no tiene nada que ver con el modo en que se expande el sistema. Podríamos eliminar tal detalle si la goma con botones fuera infinitamente larga o se cerrara en un círculo.

Desde cualquier botón concreto, los más cercanos a él parecerían alejarse a la mitad de velocidad que el siguiente más alejado, y así sucesivamente. Cuanto más lejos estuviera un botón de nuestro punto de vista, más rápidamente se alejaría. En este tipo de expansión la tasa de alejamiento es proporcional a la distancia: una relación enormemente significativa. Con esta imagen en mente podemos ahora imaginar las ondas de luz que viajan entre los botones, o cúmulos galácticos, en el espacio en expansión. Conforme el espacio se estira, lo mismo ocurre con las ondas. Ello explica el desplazamiento cosmológico hacia el rojo. Hubble descubrió que la cantidad de ese desplazamiento es proporcional a la distancia, como queda ilustrado en esta sencilla analogía gráfica.

Modelo unidimensional de un universo en expansión. Los botones representan cúmulos dalácticos y la goma elástica representa el espacio. Conforme se estira la goma, los botones se separan unos de otros.El estiramiento sirve para incrementar la longitud de onda que se propaga a lo largo de la goma. Lo cual corresponde con el desplazamiento al rojo de la luz descubierto por Hubble.

Si el universo se está expandiendo es que debe haber estado más comprimido. Las observaciones de Hubble, y las que se han hecho desde entonces, muy mejoradas, proporcionan una medida de la tasa de expansión. Si pudiéramos invertir la película cósmica y ponerla al revés, veríamos que todas las galaxias se funden en una en un pasado remoto. Del conocimiento de la tasa actual de expansión, podemos deducir que ese estado de fusión debió darse hace muchos miles de millones de años. Sin embargo, es difícil ser precisos, y por dos razones. La primera es que resulta difícil hacer mediciones con precisión ya que éstas están sujetas a una cierta variedad de errores. Aunque los modernos telescopios han incrementado grandemente el número de galaxias investigadas, la tasa de expansión sigue siendo incierta dentro de un factor de 2, y está sujeta a una viva polémica.

La segunda es que la tasa a la cual se expande el universo no permanece constante en el tiempo. Lo cual se debe a la fuerza de la gravedad, que actúa entre las galaxias y, por supuesto, entre todas las formas de materia y energía del universo. La gravedad actúa como un freno, sujetando a las galaxias en su alejamiento hacia afuera. En consecuencia, la tasa de expansión va disminuyendo gradualmente con el paso del tiempo. De ahí se sigue que el universo debe haberse expandido más rápidamente antes que ahora. Si dibujamos una gráfica del tamaño de una región característica del universo en función del tiempo, obtenemos una curva de la forma general que se indica en la figura 3.2. Por esa gráfica vemos que el universo se inició muy comprimido y que se expandió muy rápidamente, y que la densidad de materia ha ido descendiendo con el tiempo al crecer el volumen del universo. Si se traza la curva hasta el origen (que aparece marcado como O en la figura) se viene a indicar que el universo comenzó con un tamaño O y una tasa infinita de expansión. En otras palabras, ¡el material que compone todas las galaxias que hoy podemos ver surgió de un único punto explosivamente veloz! Ésta es una descripción idealizada del llamado big bang.

La tasa de expansión del universo se decelera progresivamente con el paso del tiempo aproximadamente como muestra la figura. En este sencillo modelo, la tasa de expansión es infinita en el punto marcado como 0 en el eje del tiempo. Es el punto que se corresponde con el big bang.

Pero ¿tenemos justificación para extrapolar la curva hasta llegar al origen? Hay muchos cosmólogos que creen que sí. Dado que esperamos que el universo haya tenido un principio (por las razones examinadas en el capítulo anterior) da desde luego la impresión de que el big bang sea ese principio. De serlo, entonces el inicio de la curva señala algo más que una explosión. Recordemos que la expansión representada gráficamente aquí es la del propio espacio, de modo que el volumen cero no significa tan sólo que la materia se viera comprimida a una densidad infinita. Significa que el espacio se vio comprimido a la nada. En otras palabras, el big bang es el origen del espacio así como de la materia y la energía. Es importantísimo darse cuenta de que según este panorama no hubo un vacío preexistente en el cual se produjera el big bang.

La misma idea básica es aplicable al tiempo. La frontera del tiempo la marcan también la densidad infinita de materia y la compresión infinita del espacio. La razón es que tanto el tiempo como el espacio los estira la gravedad. Este efecto es, a su vez, consecuencia de la teoría general de la relatividad de Einstein y se ha comprobado experimentalmente de forma directa. Las condiciones en el big bang suponen una distorsión infinita del tiempo de tal modo que el mismísimo concepto de tiempo (y de espacio) no puede prolongarse más atrás del big bang. La conclusión que parece imponérsenos es que el big bang fue el principio definitivo de todas las cosas físicas: espacio, tiempo, materia y energía. Evidentemente no tiene sentido preguntar (como hacen muchas personas) qué ocurrió antes del big bang o cuál fue la causa de la explosión. No hubo un antes. Y sin haber tiempo no puede haber causación en su sentido corriente.

Si la teoría del big bang, con sus extrañas implicaciones para el origen cósmico, se apoyara solamente en las pruebas de la expansión del universo, seguramente la hubieran rechazado muchos cosmólogos. Sin embargo, en 1965 se produjeron pruebas adicionales importantes en apoyo de esa teoría, al descubrirse que el universo está bañado por una radiación térmica. Esta radiación nos llega del espacio con la misma intensidad desde todas las direcciones y lleva viajando más o menos imperturbablemente desde muy poco después del big bang. Proporciona por eso una instantánea del estado del universo primigenio. El espectro de la radiación térmica se ajusta exactamente al resplandor que existe en el interior de un horno que ha llegado al estado de equilibrio termodinámico: una forma de radiación conocida por los físicos como radiación del cuerpo negro. Nos vemos obligados a deducir que el universo primitivo estuvo en ese estado de equilibrio, con todas sus regiones a una misma temperatura.

Las mediciones de la radiación térmica de fondo revelan que está a unos 3 grados por encima del cero absoluto (el cero absoluto es -273 °C) pero la temperatura cambia lentamente con el paso del tiempo. Conforme se expande el universo, se enfría de acuerdo con una fórmula sencilla: a doble radio, la temperatura baja a la mitad. Este enfriamiento es el mismo efecto que el corrimiento hacia el rojo de la luz: tanto la radiación térmica como la luz consisten en radiaciones electromagnéticas y también la longitud de onda de la radiación térmica se estira conforme se expande el universo. La radiación de baja temperatura consiste en ondas más largas (por término medio) que la radiación de alta temperatura. Viendo la película al revés, como antes, vemos que el universo tuvo que haber estado mucho más caliente. La propia radiación data de unos trescientos mil años después del big bang cuando el universo ya se había enfriado hasta una temperatura de unos 4.000 °C. En un primer momento, el gas primordial, fundamentalmente hidrógeno, fue un plasma ionizado y por ello opaco a la radiación electromagnética. Con el descenso de la temperatura, el plasma se convirtió en gas de hidrógeno normal (desionizado), que es transparente, permitiendo así que la radiación lo atravesara sin obstáculos.

La radiación de fondo es característica no sólo por la forma de cuerpo negro de su espectro, sino también por su extremada uniformidad en todo el cielo. La temperatura de la radiación sólo varía en una cienmilésima en las distintas direcciones del espacio. Esta homogeneidad indica que el universo debe ser notablemente homogéneo a gran escala, ya que un amontonamiento cualquiera de materia en determinada región del espacio, o en alguna dirección concreta, se revelaría como variación de la temperatura. Por otro lado, sabemos que el universo no es completamente uniforme. La materia se congrega en galaxias y las galaxias suelen formar cúmulos. A su vez, estos cúmulos se organizan en supercúmulos. A la escala de muchos millones de años luz el universo presenta una especie de textura espumosa, con inmensos vacíos rodeados de láminas y filamentos de galaxias.

Ese abultamiento del universo a gran escala debe haber surgido no se sabe cómo a partir de un estado originario mucho más homogéneo. Aunque los responsables pueden haber sido diversos mecanismos físicos, la explicación más plausible parece haber sido la atracción gravitatoria lenta. Si es correcta la teoría del big bang, Podemos esperar ver alguna prueba de esos primeros estados del proceso de agregación impresos en la radiación térmica de fondo cósmica. En 1992, un satélite de la NASA llamado COBE (siglas de «Cosmic Background Explorer»1) reveló que la radiación no es precisamente homogénea, sino que alberga ondulaciones inconfundibles, o variaciones de intensidad, de un lugar a otro del cielo. Estas irregularidades diminutas parecen ser los suaves inicios del proceso de formación de supercúmulos. La radiación ha preservado fielmente a lo largo de los eones esa insinuación de las aglomeraciones primordiales y demuestra gráficamente que el universo no siempre ha estado organizado de la manera característica en que hoy lo vemos. La acumulación de materia en galaxias y estrellas es un proceso evolutivo amplio que comenzó con el universo en un estado casi absolutamente uniforme.

Hay una última traza de evidencia que confirma la teoría de un origen cósmico en un punto caliente. Sabiendo la temperatura de la radiación térmica actual, podemos fácilmente calcular que más o menos un segundo después del inicio, el universo tuvo que tener una temperatura de más o menos diez mil millones de grados. Lo cual era todavía demasiado caliente para que existieran núcleos atómicos. En ese momento, la materia debió haber estado troceada en sus componentes más elementales, formando un puré de partículas fundamentales como protones, neutrones y electrones. Sin embargo, al enfriarse el puré, pasaron a ser posibles las reacciones nucleares. Concretamente, los neutrones y los protones pudieron agruparse en parejas, combinándose a su vez estas parejas para formar núcleos del elemento helio. Los cálculos indican que esta actividad nuclear duró unos tres minutos (y de ahí el título del libro de Steven Weinberg) durante los cuales se sintetizó como helio más o menos una cuarta parte de la materia. Con lo cual se agotaron prácticamente todos los neutrones disponibles. Los protones restantes no combinados estaban destinados a convertirse en núcleos de hidrógeno. Por eso predice la teoría que el universo debería consistir en aproximadamente un 75% de hidrógeno y un 25% de helio. Proporciones que están muy de acuerdo con las mediciones que tenemos en la actualidad sobre la abundancia cósmica de estos elementos.

Las reacciones nucleares primordiales produjeron probablemente también cantidades muy pequeñas de deuterio, helio-3 y litio. Los elementos más pesados, sin embargo, que en total constituyen menos del 1 % de la materia cósmica, no se produjeron en el big bang. Por el contrario, se formaron mucho después, en el interior de las estrellas tal y como lo veremos en el capítulo 4.

Tomadas conjuntamente, la expansión del universo, la radiación térmica de fondo cósmica y las proporciones relativas de los elementos químicos son pruebas poderosas a favor de la teoría del big bang. Quedan sin embargo muchas preguntas por contestar. ¿Por qué, por ejemplo, se está expandiendo el universo a la tasa actual? O, dicho con otras palabras, ¿por qué el big bang fue así de grande? ¿Por qué fue tan uniforme el universo primitivo y con una tasa de expansión tan parecida en todas direcciones y por todas las regiones del espacio? ¿Cuál es el origen de las pequeñas fluctuaciones de densidad descubiertas por el COBE, fluctuaciones que son cruciales para la formación de galaxias y de cúmulos galácticos?

En los últimos años se han hecho heroicos esfuerzos para abordar estos rompecabezas más profundos combinando la teoría del big bang con las últimas ideas de la física de partículas de alta energía. Esta «nueva cosmología», insisto, se basa en unos cimientos científicos mucho menos seguros que los aspectos que he examinado hasta ahora. En concreto, los procesos que nos interesan suponen energías de partícula muchísimo mayores que las que hayan podido observarse directamente y el tiempo cósmico al que tales procesos se remontan es a una fracción minúscula de segundo después del parto cósmico. En ese momento, las condiciones debieron ser tan extremadas que la única guía disponible por el momento es la modelización matemática y basada sólo en ideas casi puramente teóricas.

Una conjetura esencial para la nueva cosmología es la posibilidad de un proceso llamado inflación. La idea básica es que en cierto momento de la primera fracción de segundo, el universo aumentó de tamaño de golpe (se infló) en un factor enorme. Para ver qué supone esto, volvamos a mirar la figura 3.2. La curva siempre se dobla hacia abajo indicando que así como el tamaño de cualquier región dada del espacio se incrementa, eso se produce con una tasa decreciente. Por contra, lo que ocurre durante la inflación es que la expansión se acelera. La situación queda representada (aunque no a escala) en la figura 3.3. En un primer momento la expansión se desacelera, pero con el inicio de la inflación remonta con mucha rapidez y la curva se dirige directamente hacia arriba durante un corto trecho. Por último, la curva recupera su curso normal pero en ese lapso el tamaño de la región espacial representada en el gráfico se ha incrementado enormemente (mucho más de lo que aquí se muestra) comparada con la posición equivalente de la gráfica que aparece en la figura 3.2.

La situación inflacionaria. En tal situación, el universo da un salto súbito y grande en su tamaño al poquísimo tiempo de originarseen una explosión. La escala vertical está tremendamente comprimida. Después de la fase inflacionaria, la expansíón prosige a un ritmo cada vez más lento, de manera parecida a la mostrada en la figura 3.2.

¿Y por qué iba a comportarse el universo de manera tan curiosa? Recuérdese que la curvatura hacia abajo de la curva se debe a la fuerza atractiva de la gravedad como freno de la expansión. Por ello puede pensarse en la curva hacia arriba como si fuera una especie de antigravedad, o de fuerza repulsiva, que hace que el universo crezca cada vez más deprisa. Aunque la antigravedad parezca una posibilidad chocante, algunas teorías especulativas recientes parecen indicar que tal efecto podría haberse dado en las condiciones extremadas de temperatura y densidad que prevalecían en el universo muy primitivo.

Antes de examinar el cómo, permítaseme explicar por qué una fase inflacionaria ayuda a resolver algunos de los enigmas cósmicos que acabamos de enumerar. En primer lugar, la expansión cada vez mayor puede proporcionar una explicación convincente de por qué el big bang fue así de grande. El efecto de la antigravedad es un proceso inestable e incontrolado, lo que equivale a decir que el tamaño del universo crece exponencialmente. Matemáticamente, esto significa que una región del espacio dada dobla su tamaño en un periodo determinado de tiempo. Llamemos tic a este periodo. Al cabo de dos tics, el tamaño se ha cuadruplicado; al cabo de tres tics, se ha incrementado ocho veces; al cabo de diez tics, la región se ha expandido más de mil veces. Un cálculo muestra que la tasa de expansión al final de la era inflacionaria es coherente con la tasa de expansión que se observa hoy. (En el capítulo 6, explicaré con más precisión lo que quiero decir con esto.)

El enorme salto en tamaño ocasionado por la inflación proporciona además una explicación adecuada para la uniformidad cósmica. Todas las regularidades iniciales se suavizaron al estirarse el espacio, de manera muy parecida a como desaparecen las arrugas de un globo al inflarlo. Del mismo modo, cualquier variación primitiva de la tasa de expansión en distintas direcciones se verían enseguida superadas por la inflación, la cual funciona con la misma energía en todas direcciones. Por último, las ligeras irregularidades reveladas por el COBE podrían atribuirse al hecho de que la inflación no terminara en todas partes en el mismo instante (por motivos que se examinarán en breve) de tal modo que ciertas regiones se habrían inflado algo más que otras, produciendo ligeras variaciones de densidad.

Pongamos algunas cifras. En la versión más sencilla de la teoría inflacionaria, la fuerza inflacionaria (antigravedad) resulta ser fantásticamente poderosa, haciendo que el universo doble su tamaño aproximadamente cada diez mil millonésima de billonésima de billonésima de segundo (10-34). Este tiempo casi infinitesimal es lo que he llamado un tic. Al cabo de sólo un centenar de tics, una región del tamaño de un núcleo atómico se habría inflado a un tamaño de cerca de un año luz de diámetro. Es lo suficientemente sencillo como para resolver los antedichos enigmas cosmológicos.

Acudiendo a la física de las partículas subatómicas se han descubierto diversos mecanismos posibles que podrían producir un comportamiento inflacionario. Todos estos mecanismos se basan en un concepto conocido como vacío cuántico. Para comprender qué supone esto, hace falta primero saber algo de física cuántica. La teoría cuántica empezó con un descubrimiento sobre la naturaleza de las radiaciones electromagnéticas, como el calor y la luz. Aunque esta radiación se propaga por el espacio en forma de ondas, puede comportarse no obstante como si consistiera en partículas. En concreto, la emisión y absorción de la luz se da en forma de pequeños paquetes (o cuantos) de energía, llamados fotones. Esta extraña amalgama de aspectos ondulatorios y corpusculares, que a veces se llama dualidad onda-corpúsculo, resultó ser aplicable a todas las entidades físicas a escala atómica y subatómica. Así, las entidades que normalmente consideramos partículas (tales como electrones, protones y neutrones) e incluso átomos enteros presentan aspectos ondulatorios en determinadas circunstancias.

Un principio esencial de la teoría cuántica es el principio de incertidumbre de Werner Heisenberg, según el cual los objetos cuánticos no poseen valores netamente definidos para todos sus atributos. Por ejemplo, un electrón no puede tener al mismo tiempo una posición definida y un momento definido. Ni tampoco puede tener un valor definido de energía en un momento definido. La que nos interesa aquí es la incertidumbre del valor de la energía. Mientras que en el mundo macroscópico de los ingenieros la energía siempre se conserva (no puede crearse ni destruirse) esta ley puede quedar en suspenso en el reino cuántico subatómico. La energía puede cambiar, espontánea e impredeciblemente, de un momento al siguiente. Cuanto más corto sea el intervalo considerado, más grandes serán estas fluctuaciones cuánticas aleatorias. En efecto, la partícula puede tomar prestada energía de la nada, siempre que devuelva el préstamo enseguida. La forma matemática concreta del principio de incertidumbre de Heisenberg exige que un préstamo grande de energía deba devolverse enseguida, mientras que los préstamos pequeños admiten una mayor demora.

La incertidumbre energética lleva a algunos efectos curiosos. Entre ellos, la posibilidad de que una partícula, por ejemplo un fotón, puede aparecer repentinamente de la nada, para disolverse al poco tiempo. Estas partículas viven de energía prestada y por ello mismo de tiempo prestado. No las vemos porque su aparición es fugaz, pero lo que creemos normalmente espacio vacío es en realidad un hormiguero de montones de tales partículas de existencia temporal: no sólo fotones, sino electrones, protones y demás. Para diferenciar estas partículas temporales de las permanentes, las que nos son más familiares, a las primeras se las llama «virtuales» y a las segundas «reales».

Prescindiendo de su naturaleza temporal, las partículas virtuales son idénticas a las reales. De hecho, si se aporta energía suficiente por el medio que sea desde fuera del sistema para liquidar el préstamo de energía de Heisenberg, entonces una partícula virtual puede convertirse en real, indistinguible como tal de cualquier otra partícula real de la misma especie. Por ejemplo, un electrón virtual sobrevive por término medio sólo unos 10-21 segundos. Durante su breve vida no se está quieto, sino que puede viajar una distancia de unos 10-11 centímetros (como comparación, un átomo tiene un tamaño de unos 10-8 centímetros) antes de desvanecerse. Si el electrón virtual recibe energía durante este breve tiempo (por ejemplo, procedente de un campo electromagnético) no le hará falta desvanecerse después de todo, sino que podrá continuar existiendo como un electrón perfectamente normal.

Aunque no podamos verlos, sabemos que estas partículas virtuales «sí están ahí» en el espacio vacío porque dejan un rastro detectable de sus actividades. Por ejemplo, uno de los efectos de los fotones virtuales es el de producir un cambio diminuto en los niveles de energía de los átomos. También originan un cambio igualmente diminuto en el momento magnético de los electrones. Estas alteraciones minúsculas pero significativas se han medido con mucha precisión utilizando técnicas espectroscópicas.

La imagen sencilla del vacío cuántico dado anteriormente se modifica cuando se tiene en cuenta el hecho de que las partículas subatómicas por lo general no se mueven libremente, sino que están sujetas a una diversidad de fuerzas: el tipo de fuerza depende del tipo de la partícula de que se trate. Estas fuerzas actúan asimismo entre las partículas virtuales. Puede darse entonces el caso de que exista más de un tipo de estado de vacío. La existencia de muchos «estados cuánticos» posibles es un rasgo familiar de la física cuántica: los más conocidos son los diversos niveles de energía de los átomos. Un electrón que orbita alrededor de un núcleo atómico puede existir en determinados estados bien definidos con energías definidas. El nivel inferior se llama estado base y es estable; los niveles superiores son estados excitados y son inestables. Si se hace subir a un electrón a un estado superior, bajará hasta el estado base en una o varias etapas. El estado excitado «decae» con una vida media bien definida.

Al vacío, que puede tener uno o más estados excitados, se le aplican principios similares. Estos estados tendrían energías muy diferentes, aunque lo cierto es que parecerían idénticos: parecerían el vacío. El estado de menor energía, o base, suele llamarse a veces vacío auténtico, por reflejar el hecho de que es el estado estable y el que supuestamente se corresponde con las regiones vacías del universo tal y como lo observamos hoy. Al vacío excitado se le suele llamar falso vacío.

Debería insistirse en que los falsos vacíos siguen siendo una idea puramente teórica y en que sus propiedades dependen en buena medida de la teoría concreta que se invoque. Sin embargo, surgen de forma natural en las teorías más recientes que pretenden unificar las cuatro fuerzas fundamentales de la naturaleza: gravitación y electromagnetismo, familiares en nuestra vida diaria, y dos fuerzas nucleares de corto alcance llamadas fuerza débil y fuerza fuerte. La lista ha sido más larga: electricidad y magnetismo estuvieron consideradas en tiempos como cosas distintas. El proceso de unificación comenzó a principios del siglo XIX y ha seguido avanzando en las últimas décadas. Hoy se sabe que las fuerzas electromagnética y la nuclear débil están vinculadas y forman una única «fuerza electrodébil». Muchos físicos están convencidos de que la fuerza nuclear fuerte resultará estar vinculada a la fuerza electrodébil, asociación que de un modo u otro describen las llamadas teorías de gran unificación. Bien puede ser que las cuatro fuerzas se fundan en una única super-fuerza a determinado grado de profundidad.

El candidato mejor colocado como mecanismo inflacionario lo predicen las diversas teorías de gran unificación. Un rasgo clave de estas teorías es que la energía del falso vacío es fabulosa: por término medio un centímetro cúbico de espacio albergaría ¡1087 julios! Incluso un volumen atómico contendría en tal estado 1062 julios. Compárese con los míseros 10-18 julios, más o menos, que posee un átomo excitado. De tal modo que haría falta una enorme cantidad de energía para excitar el falso vacío y no debemos esperar encontrar en el universo actual un falso vacío. Por otro parte, dadas las condiciones extremadas del big bang, esas cifras son plausibles.

La inmensa energía asociada a los estados de falso vacío tiene un potente efecto gravitatorio. Cosa que ocurre porque, tal y como Einstein nos ha enseñado, la energía tiene masa y por ello ejerce una atracción gravitatoria, al igual que le ocurre a la materia normal. La enorme energía del vacío cuántico es extremadamente atractiva: la energía de un centímetro cúbico de falso vacío Pesaría 1067 toneladas, que es más de lo que pesa el universo observable hoy al completo (¡unas 1050 toneladas!). Esta colosal gravedad no contribuye a producir inflación, proceso que requiere alguna forma de antigravedad. Sin embargo, la inmensa energía de falso vacío va asociada a una igualmente inmensa presión de falso vacío y es esta presión la que hace el trabajo. Normalmente no solemos pensar en la presión como fuente de gravedad, pero lo es. Aunque la presión ejerce una fuerza mecánica hacia el exterior, da origen a un tirón gravitatorio hacia el interior. En el caso de los cuerpos que nos son familiares, el efecto gravitatorio de la presión es despreciable en comparación con el efecto de la masa de esos cuerpos. Por ejemplo, menos de una mil millonésima parte del peso de nuestro cuerpo en la Tierra se debe a la presión interna de la Tierra. Sin embargo, el efecto de la presión es real, y en un sistema en el que la presión llega a valores altísimos, el efecto gravitatorio de la presión puede competir con el de la masa.

En el caso del falso vacío, existen una energía colosal y una presión igual de colosal, de modo que compiten por la dominancia gravitatoria. Sin embargo, la propiedad crucial es la de que la presión es negativa. El falso vacío no empuja: chupa. Una presión negativa produce un efecto gravitatorio negativo: lo que equivale a decir que antigravita. De modo que la acción gravitatoria del falso vacío supone una competencia entre el inmenso efecto atractivo de su energía y el inmenso efecto repulsivo de su presión negativa. El resultado es que gana la presión y que el efecto neto es el de crear una fuerza repulsiva tan grande que puede reventar el universo y separarlo en una fracción de segundo. Es este empujón inflacionario gargantuesco el que hace que el universo doble su tamaño rapidísimamente, cada 10-34 segundos.

El falso vacío es en sí mismo inestable. Como todos los estados cuánticos excitados, aspira a volver al estado base, al auténtico vacío. Probablemente eso ocurre al cabo de unas pocas docenas de tics. Al ser un proceso cuántico, está sujeto al inevitable determinismo y a las fluctuaciones aleatorias que se han examinado anteriormente en relación con el principio de incertidumbre de Heisenberg. Lo cual significa que la vuelta al estado base no se dará uniformemente en todo el espacio: habrá fluctuaciones. Y algunos teóricos sugieren que esas fluctuaciones pueden ser la fuente de las ondulaciones captadas por el COBE.

Una vez que el falso vacío desaparece, el universo vuelve a su expansión normal cada vez más lenta. Se libera la energía que ha estado encerrada en el falso vacío, apareciendo en forma de calor. La enorme distensión producida por la inflación ha enfriado al universo hasta llegar a una temperatura muy próxima al cero absoluto; repentinamente, el final de la inflación lo recalienta hasta la prodigiosa de 1028 grados. Este vasto reservorio de calor sobrevive hoy, en una forma abrumadoramente disminuida, como radiación cósmica de calor de fondo. Subproducto de la liberación de la energía del vacío es que muchas partículas virtuales del vacío cuántico absorben parte de ella y pasan a ser partículas reales. Después de otros procesos y cambios posteriores, un remanente de estas partículas primordiales pasa a proporcionar las 1050 toneladas de materia que nos componen a nosotros mismos, a la galaxia y al resto del universo observable.

Si esta escena inflacionaria está en lo cierto (y no pocos cosmólogos lo creen así), entonces la estructura básica y el contenido físico del universo quedaron determinados por los procesos que se terminaron en cuanto transcurrió el brevísimo lapso de 10-32 segundos. El universo postinflacionario pasó por otros muchos cambios de tipo subatómico conforme la materia primigenia fue transformándose en las partículas y átomos que constituyen la materia cósmica de nuestra época, aunque la mayor parte del procesado adicional de materia quedó completo al cabo de tan sólo tres minutos, más o menos.

¿Cómo se relacionan los tres primeros minutos con los tres últimos? Así como el destino de la bala disparada hacia el blanco depende esencialmente de la puntería del arma, así depende sensiblemente el destino del universo de sus condiciones iniciales. Veremos cómo la manera en que se expandió el universo a partir de sus orígenes primigenios y cómo la naturaleza de la materia que surgió del big bang son las que determinan su futuro definitivo. El Principio y el final del universo están profundamente entrelazados.

CAPÍTULO 4: DESTINO ESTELAR

Un astrónomo canadiense llamado Ian Shelton trabajaba en el observatorio de Las Campanas, en lo alto de los Andes chilenos. Era la noche del 23 al 24 de febrero de 1987. Un ayudante nocturno salió brevemente al exterior y echó un vistazo al oscuro cielo nocturno. Al estar familiarizado con el cielo enseguida se dio cuenta de algo no habitual. En el borde del borrón nebuloso de luz conocido como Gran Nube de Magallanes había una estrella. No era especialmente brillante, más o menos de la misma magnitud que las del cinturón de Orión. Lo significativo es que no estaba allí el día anterior.

El ayudante llamó la atención de Shelton sobre aquel objeto y al cabo de unas pocas horas la noticia ya se propagaba por todo el mundo. Shelton y su ayudante chileno habían descubierto una supernova. Fue el primer objeto de tal especie visible a simple vista desde que Johannes Kepler registrara una en 1604. Inmediatamente, los astrónomos de diversos países empezaron a apuntar sus instrumentos hacia la Gran Nube de Magallanes. En los meses siguientes, el comportamiento de la Supernova 1987A se escrutó hasta los más mínimos detalles.

Algunas horas antes de que Shelton hiciera su sensacional descubrimiento, se registró otro acontecimiento infrecuente en un lugar muy distinto: la mina de zinc de Kamioka, en las profundidades subterráneas de Japón. Era el lugar en el que unos físicos desarrollaban un experimento a largo plazo y con un objetivo ambicioso. Su objetivo era comprobar la estabilidad última de uno de los principales constituyentes de la materia: los protones. Las grandes teorías de unificación desarrolladas en la década de 1970 predecían que los protones podían ser ligeramente inestables, descomponiéndose en su caso en una variante rara de la radiactividad. De ser así, aquello tendría profundas consecuencias para el destino del universo, como veremos en un capítulo próximo.

Para comprobar la descomposición de los protones, los experimentadores japoneses habían llenado un depósito con 2.000 toneladas de agua ultrapura, colocando detectores muy sensibles de fotones a su alrededor. La tarea de los detectores era la de registrar los chispazos reveladores de luz que pudieran ser atribuibles a productos de alta velocidad originados en descomposiciones individuales. Se eligió un lugar subterráneo para el experimento con el fin de reducir los efectos de la radiación cósmica que, de no ser así, inundaría los detectores de otros chispazos indeseables.

El 22 de febrero los detectores de Kamioka se dispararon súbitamente no menos de once veces durante otros tantos segundos. Mientras tanto, al otro lado del planeta, un detector parecido colocado en una mina de sal de Ohio registraba ocho. Como resultaba impensable el suicidio simultáneo de diecinueve protones, aquellos sucesos debían tener otra explicación. Pronto la encontraron los físicos. Sus equipos debían haber registrado la destrucción de protones en otro proceso más convencional: mediante el bombardeo de neutrinos.

Los neutrinos son partículas subatómicas que tienen un papel clave en mi historia, de modo que merece la pena detenerse a examinarlos con mayor detalle. Su existencia fue postulada en primer lugar por el físico teórico de origen austríaco Wolfgang Pauli en 1931, para poder explicar un aspecto problemático del proceso radiactivo conocido como descomposición beta. En un suceso de descomposición beta característico, un neutrón se descompone en un protón y un electrón. El electrón, partícula relativamente ligera, sale disparado con considerable energía. El problema es que en cada descomposición el electrón parece tener una energía distinta, un poco menor que el total disponible en la descomposición del neutrón. Como la energía total es la misma en todos los casos, parece como si la energía final fuera diferente a la energía inicial. Cosa que no puede ser, ya que es una ley esencial de la física que la energía se conserve, de manera que Pauli sugirió que la energía que faltaba se la llevaba una partícula invisible. Los primeros intentos de detectarla fracasaron y quedó claro que si existía debía tener un increíble poder de penetración. Como cualquier partícula cargada eléctricamente sería atrapada de inmediato por la materia, la partícula de Pauli debía ser eléctricamente neutra: de ahí el nombre de «neutrino».

Aunque sin haber sido capaces de haber detectado un solo neutrino, los teóricos sí pudieron deducir algunas propiedades más. Una de ellas se refiere a su masa.

El concepto de masa es muy sutil en lo tocante a las partículas de alta velocidad. Ello se debe a que la masa de un cuerpo no es una cantidad fija, sino que depende de la velocidad del cuerpo. Por ejemplo, una bala de plomo de 1 kilogramo pesaría 2 kilogramos si se moviera a 260.000 kilómetros por segundo. Aquí el factor clave es la velocidad de la luz. Cuanto más se acerque la velocidad de un objeto a la velocidad de la luz, más masivo se vuelve y ese aumento de la masa no tiene límite. Como la masa varía de este modo, cuando los físicos hablan de la masa de una partícula subatómica se refieren a su masa en reposo para evitar confusiones. Si la partícula se mueve a una velocidad cercana a la de la luz, su masa en ese momento puede ser de muchas veces su masa en reposo: en el interior de los grandes aceleradores de partículas, los electrones y protones que giran en ellos pueden tener una masa muchos millares de veces superiores a sus masas en reposo.

Una pista del valor de la masa en reposo del neutrino procede del hecho de que un suceso de descomposición beta a veces desprende un electrón con casi toda la energía disponible, dejando casi ninguna para el neutrino. Lo cual significa que los neutrinos pueden existir con prácticamente energía cero. Ahora bien, según la famosa fórmula de Einstein E = mc², la energía E y la masa m son equivalentes, de tal modo que una energía cero implica una masa cero. Eso quiere decir que lo más probable es que el neutrino tenga una masa en reposo muy pequeña, posiblemente nula. Si la masa en reposo es verdaderamente cero, el neutrino se desplazará a la velocidad de la luz. En cualquier caso, es probable que se descubra que se desplaza a una velocidad muy próxima a la de la luz.

Otra propiedad se refiere al giro de las partículas subatómicas. Se ha descubierto que neutrones, protones y electrones siempre están girando. La magnitud de este giro es una determinada cantidad fija, que resulta ser la misma para las tres. El giro o espín (spin) es una forma de momento angular y existe una ley de conservación del momento angular, ley tan básica como la ley de la conservación de la energía. Cuando un neutrón se descompone, su espín debe conservarse en los productos de su descomposición. Si el electrón y el protón giraban en la misma dirección, sus espines se sumarán para dar el doble que el del neutrón. Por otro lado, si rotaran en sentidos opuestos, sus espines se anularían para dar cero. En todo caso, el espín total de un electrón y un protón solos no podrá ser nunca igual al del neutrón. Sin embargo, cuando se tiene en cuenta la existencia del neutrino, la contabilidad puede equilibrarse limpiamente suponiendo que el neutrino posee el mismo espín que las demás partículas. En ese caso, dos de los tres productos de la descomposición pueden girar en la misma dirección mientras que el tercero lo hace en sentido contrario.

De modo que sin haber detectado el neutrino, los físicos fueron capaces de deducir que debía ser una partícula de carga eléctrica cero, espín igual al del electrón, poca o nula masa en reposo Y de tan minúscula interacción con la materia corriente que no dejara huellas de su paso. En resumidas cuentas, se trata de una especie de fantasma giratorio. No es sorprendente que los físicos tardaran veinte años en identificarlo definitivamente en el laboratorio desde que Pauli conjeturara su existencia. Se crean en cantidades tan copiosas en los reactores nucleares que a pesar de ser tan extraordinariamente escurridizos es posible detectar de vez en cuando a uno de sus representantes.

La llegada de una ráfaga de neutrinos a la mina de Kamioka al mismo tiempo que aparecía la supernova 1987A no se debía sin duda a una coincidencia y la concurrencia de los dos sucesos fue tomada por los científicos como confirmación esencial de la teoría de las supernovas: lo que los astrónomos habían esperado siempre de una supernova era precisamente una ráfaga de neutrinos.

Aunque la palabra «nova» significa «nueva» en latín, la supernova 1987A no supuso el nacimiento de una nueva estrella. Lo cierto es que se trataba de la muerte de una vieja en una explosión espectacular. La Gran Nube de Magallanes en la que apareció la supernova es una minigalaxia situada a unos ciento setenta mil años luz de nosotros. Lo cual es una cercanía suficiente a la Vía Láctea como para convertirla en una especie de satélite de nuestra galaxia. Se la ve a simple vista como una especie de manchón borroso de luz en el hemisferio sur, pero hacen falta telescopios potentes para resolver sus estrellas individuales. No habían pasado muchas horas desde el descubrimiento de Shelton cuando los astrónomos australianos ya fueron capaces de identificar qué estrella de entre los pocos miles de millones contenidas en la Gran Nube de Magallanes era la que había estallado; consiguieron tal hazaña inspeccionando placas fotográficas anteriores de esa región del cielo. La estrella reventada era una del tipo llamado azul supergigante B3 y su diámetro era unas cuarenta veces el del Sol. Hasta tenía nombre: Sanduleak-69º 202.

La teoría de que las estrellas pueden explotar la investigaron en primer lugar los astrofísicos Fred Hoyle, William Fowler y Geoffrey y Margaret Burbidge a mediados de los años 50. Para comprender cómo llega una estrella a semejante cataclismo es necesario saber algo de su funcionamiento interno. La estrella que nos es más familiar es el Sol. A semejanza de la mayoría de las estrellas, el Sol aparece inmutable; sin embargo, esta inmutabilidad oculta el hecho de que se ve atrapado en una lucha incesante con las fuerzas de la destrucción. Todas las estrellas son bolas de gas retenido por la gravedad. Si la gravedad fuera la única fuerza, impresionarían instantáneamente debido a su inmenso peso y se desvanecerían en cuestión de horas. El motivo de que eso no ocurra es que la fuerza de la gravedad, hacia adentro, se ve contrarrestada por la fuerza de la presión del gas comprimido en el interior estelar, hacia afuera.

Hay una relación sencilla entre la presión de un gas y su temperatura. Cuando se calienta un volumen fijo de gas, en condiciones normales sube la presión en proporción a la temperatura. A la inversa, cuando baja la temperatura también baja la presión. El interior de una estrella tiene una enorme presión por estar tan caliente: muchos millones de grados. El calor lo producen las reacciones nucleares. Durante la mayor parte de su vida, la principal reacción que alimenta a una estrella es la conversión del hidrógeno en helio mediante fusión. Esta reacción requiere una temperatura altísima para superar la repulsión eléctrica que se manifiesta entre los núcleos. La energía de fusión puede sustentar a una estrella durante miles de millones de años, pero antes o después se va agotando el combustible y el reactor empieza a fallar. Cuando eso ocurre, se ve amenazada la presión de sustentación y la estrella empieza a perder su larga batalla contra la gravedad. Una estrella vive fundamentalmente de tiempo prestado, eludiendo el colapso gravitatorio disponiendo de sus reservas de combustible. Pero cada kilovatio que dispersa la superficie estelar a las profundidades del espacio sirve para acelerar su final.

Se calcula que el Sol puede lucir alrededor de unos diez mil millones de años con el hidrógeno con el que comenzó. Hoy, aproximadamente con unos cinco mil millones de años de edad, nuestra estrella ha quemado aproximadamente la mitad de sus reservas (no hace falta aún que caigamos presa del pánico). La tasa a la que una estrella consume el combustible nuclear depende sensiblemente de su masa. Las estrellas más pesadas queman combustible mucho más deprisa: les hace falta porque son mayores y más brillantes y por ello irradian más energía. El peso extra comprime el gas a una densidad y a una temperatura mayores, incrementando la tasa de la reacción de fusión. Por ejemplo, una estrella de diez masas solares quemará la mayor parte de su hidrógeno en el corto periodo de unos diez millones de años.

Rastreemos el destino de esa estrella masiva. La mayoría de las estrellas comienzan su vida estando compuestas mayoritariamente por hidrógeno. La «quema» de hidrógeno consiste en la fusión de los núcleos del hidrógeno (el núcleo de hidrógeno es un único protón) para formar los núcleos del elemento helio, que consisten en dos protones y dos neutrones. (Los detalles son complicados y no hace falta que nos preocupemos de ellos aquí.) «Quemar» hidrógeno es la fuente de energía nuclear más eficiente pero no es la única. Si la temperatura del núcleo estelar es lo suficientemente alta, los núcleos de helio pueden fundirse para formar carbono y otras reacciones de fusión ulteriores producen oxígeno, neón y otros elementos. Una estrella masiva puede originar las temperaturas internas necesarias (que llegan a más de mil millones de grados) para que funcione esta cadena de reacciones nucleares sucesivas, pero el rendimiento disminuye constantemente. A cada nuevo elemento que se obtiene, decrece la energía liberada. El combustible se quema cada vez más deprisa hasta que la composición de la estrella cambia de mes a mes, luego diariamente, luego cada hora. Su interior parece el de una cebolla, en la que las capas son los diferentes elementos sintetizados a un ritmo cada vez más frenético. Externamente, la estrella aumenta hasta un enorme tamaño, mayor que el de nuestro sistema solar entero, convirtiéndose en lo que los astrónomos llaman una supergigante roja.

El fin de la cadena de combustión nuclear lo marca el elemento hierro, que presenta una estructura nuclear particularmente estable. La síntesis de elementos más pesados que el hierro mediante fusión nuclear requiere energía en lugar de desprenderla, de manera que cuando la estrella ha sintetizado un núcleo de hierro está sentenciada. Una vez que las regiones centrales de la estrella no pueden ya producir energía calorífica, la balanza se inclina indefectiblemente a favor de la fuerza de la gravedad. La estrella se balancea en el borde de la inestabilidad catastrófica, terminando por caer en su propio pozo gravitatorio.

Lo que ocurre, y a toda velocidad, es lo siguiente. El núcleo de hierro de la estrella, incapaz ya de producir calor por combustión nuclear, no puede soportar su propio peso y se contrae bajo la gravedad con tal fuerza que los propios átomos resultan aplastados. El núcleo termina por alcanzar tal densidad de núcleos atómicos que un dedal lleno de materia pesaría cerca de un billón de toneladas. En esta etapa, el núcleo de la estrella afectada tendrá por término medio unos 200 kilómetros de diámetro y la solidez del material nuclear le hará dar un bote. El tirón gravitatorio es tan fuerte que este bote titánico no dura más que unos pocos milisegundos. Mientras se desarrolla esta tragedia en el centro de la estrella, las capas de material estelar que lo rodean se derrumban en una convulsión súbita y catastrófica. Al viajar hacia el interior a decenas de miles de kilómetros por segundo, los cuatrillones de toneladas de material que implosiona chocan con el núcleo enormemente compacto que rebota, más duro que un muro de diamante. Lo que se produce a continuación es una colisión de violencia aterradora que produce una enorme onda de choque hacia el exterior y por toda la estrella.

Juntamente con esta onda de choque hay una emisión tremenda de neutrinos, liberados súbitamente desde las regiones internas de la estrella durante su transmutación nuclear definitiva: una transmutación en la que los electrones y los protones de los átomos de la estrella se funden unos con otros para formar neutrones. Efectivamente, el núcleo de la estrella se convierte en una bola gigante de neutrones. La onda de choque y los neutrinos transportan conjuntamente una inmensa cantidad de energía hacia el exterior atravesando las capas de la estrella. Al absorber mucha energía, las capas externas de la estrella explotan en un holocausto nuclear de furia inimaginable. Durante unos pocos días, la estrella brilla con la intensidad de diez mil millones de soles para desvanecerse pocas semanas después.

Por término medio, las supernovas se producen dos o tres veces por siglo en una galaxia media como es la Vía Láctea y los atónitos astrónomos las han registrado a lo largo de la historia. Una de las más famosas la registraron observadores chinos y árabes en el año 1054 en la constelación de Cáncer, el Cangrejo. Hoy, esa estrella destrozada aparece como una nube deshilachada de gas en expansión conocida como Nebulosa del Cangrejo.

La explosión de la supernova 1987A iluminó el universo con un relámpago invisible de neutrinos. Fue una emisión de una intensidad asombrosa. A pesar de estar a ciento setenta mil años luz de la explosión, cada centímetro cuadrado de la superficie de la Tierra se vio atravesado por cien mil millones de neutrinos, venturosamente inconscientes sus habitantes de que los habían atravesado muchísimos billones de partículas procedentes de otra galaxia. Pero los detectores para la descomposición de protones de Kamioka y de Ohio atraparon diecinueve. Sin ese equipo, los neutrinos habrían pasado sin ser detectados, lo mismo que ocurrió en 1054.

Aunque una supernova representa la muerte para la estrella afectada, la explosión tiene un aspecto creativo. La enorme liberación de energía calienta las capas externas de la estrella de forma tan efectiva que durante un breve tiempo son posibles algunas reacciones más de fusión nuclear: reacciones que absorben energía en lugar de liberarla. En ese horno estelar definitivo e intensísimo se forjan los elementos más pesados que el hierro, como oro, plomo y uranio. Estos elementos, junto con los más ligeros, como el carbono y el oxígeno que se crearon en los primeros estadios de la nucleosíntesis, salen despedidos al espacio para mezclarse en él con los detritos de incontables supernovas. A lo largo de los eones subsiguientes, esos elementos pesados se reunirán en nuevas generaciones de estrellas y planetas. Sin la manufactura y la diseminación de estos elementos, no podría haber planetas como la Tierra. El carbono y el oxígeno que nos da vida, el oro de nuestros bancos, el plomo que sirve para nuestras techumbres, las varillas de combustible de uranio de nuestros reactores nucleares, todos ellos deben su presencia terrestre a los estertores de muerte de estrellas que se desvanecieron mucho antes de que existiera nuestro sol. Es una idea llamativa que la mismísima materia que compone nuestros cuerpos esté formada de cenizas nucleares de estrellas muertas hace mucho tiempo.

Una explosión de supernova no destruye por completo la estrella. Aunque la mayor parte del material se dispersa en el cataclismo, el núcleo implotado que puso en marcha todo el suceso sigue en su sitio. Sin embargo, su destino es también cosa incierta. Si la masa del núcleo es bastante baja (digamos de una masa solar) formará entonces una bola de neutrones del tamaño de una ciudad pequeña. Lo más probable es que esta «estrella de neutrones» gire frenéticamente, con seguridad a más de 1.000 revoluciones por segundo o a un 10% de la velocidad de la luz en su superficie. La estrella adquiere ese giro vertiginoso debido a que la implosión amplía mucho la rotación relativamente lenta de la estrella primitiva: se trata del mismo principio que hace que los patinadores giren más deprisa cuando encogen los brazos. Los astrónomos han detectado muchas estrellas de neutrones que giran con esta rapidez. Pero la tasa de rotación decrece poco a poco conforme el objeto va perdiendo energía. La estrella de neutrones que está en medio de la Nebulosa del Cangrejo, por ejemplo, ha ido disminuyendo hasta las actuales 33 revoluciones por segundo.

Si la masa del núcleo es algo mayor (digamos que de varias masas solares) no puede formar una estrella de neutrones. La fuerza de la gravedad es tan grande que incluso la materia neutrónica (la sustancia más consistente que se conoce) no puede resistir una mayor compresión. Está preparado entonces el panorama para un suceso todavía más terrible y catastrófico que el de la supernova. El núcleo de la estrella sigue contrayéndose y en menos de un milisegundo crea un agujero negro y desaparece en él.

Por lo tanto, el destino de una estrella masiva es el de saltar en pedazos dejando como remanente una estrella de neutrones o un agujero negro rodeado de difusos gases expulsados. Nadie sabe cuántas estrellas han sucumbido ya de esta manera, pero sólo la Vía Láctea podría contener miles de millones de estos cuerpos estelares.

De niño, yo tenía un miedo morboso a que el Sol estallara. Sin embargo, no hay peligro de que se convierta en una supernova. Es demasiado pequeño. El destino de las estrellas livianas es generalmente mucho menos violento que el de sus hermanas masivas. En primer lugar, los procesos nucleares que devoran combustible avanzan a un paso más calmado; lo cierto es que una estrella enana situada al final de la clasificación de masas estelares puede brillar firmemente durante un billón de años. En segundo lugar, una estrella liviana no puede originar temperaturas internas lo suficientemente elevadas como para sintetizar hierro y desencadenar en consecuencia una implosión catastrófica.

El Sol es una estrella media de masa bastante baja, que quema constantemente su combustible de hidrógeno convirtiendo su interior en helio. El helio se encuentra en su mayor parte en el núcleo central que es inerte en lo que se refiere a reacciones nucleares; la fusión se produce en la superficie del núcleo. Por lo tanto, el núcleo en sí es incapaz de contribuir a la generación necesaria de calor que hace falta para que el Sol se mantenga contra las fuerzas gravitatorias que lo aplastan. Para prevenir la contracción, el Sol debe expandir hacia el exterior su actividad nuclear, buscando hidrógeno de refresco. Mientras tanto, el núcleo de helio va encogiéndose poco a poco. Conforme van transcurriendo los eones, la apariencia del Sol irá alterándose imperceptiblemente como resultado de tales cambios internos. Aumentará de tamaño pero su superficie se enfriará un tanto, dándole un tono rojizo. Esta tendencia seguirá hasta que el Sol pase a convertirse en una estrella gigante roja, seguramente unas quinientas veces mayor de lo que es ahora. Las gigantes rojas son familiares para los astrónomos y en esta categoría entran algunas estrellas brillantes bien conocidas como Aldebarán, Betelgeuse y Arturo. La fase de gigante roja señala el principio del fin de una estrella de baja masa.

Aunque una gigante roja es relativamente fría, su gran tamaño le da una enorme superficie radiante, lo cual significa una mayor luminosidad en conjunto. Los planetas del Sol pasarán por una época difícil durante unos cuatro mil millones de años al llegarles tal flujo de calor. La Tierra ya se habrá convertido en inhabitable mucho antes, evaporados los océanos y desprovista de atmósfera. Conforme vaya creciendo el Sol engullirá a Mercurio, Venus y finalmente a la Tierra en su envoltura llameante. Nuestro planeta quedará reducido a un trozo de escoria obstinadamente aferrado a su órbita incluso después de la incineración; la densidad de los gases del Sol al rojo vivo será tan baja que las condiciones serán prácticamente las del vacío, ejerciendo por ello muy poca influencia sobre el movimiento de la Tierra.

Nuestra existencia en el universo es consecuencia de la extraordinaria estabilidad de las estrellas como el Sol, que pueden arder continuadamente y con pocos cambios durante miles de millones de años, el tiempo suficiente como para que la vida surja y evolucione. Pero en la fase de gigante roja, esta estabilidad llega a su término. Las etapas sucesivas en la vida de una estrella como el Sol son complicadas, erráticas y violentas, con cambios relativamente repentinos en su comportamiento y en su aspecto. Las estrellas que envejecen pueden pasar millones de años emitiendo pulsaciones o desprendiendo corazas de gas. El helio del núcleo estelar puede incendiarse formando carbono, nitrógeno y oxígeno, proporcionando así una energía vital que mantendrá a la estrella todavía un poco más. Desprendiendo al espacio su envoltura externa, la estrella puede terminar dejando al aire su núcleo de carbono y oxígeno.

Después de este periodo de compleja actividad, las estrellas de masa baja y media sucumben inevitablemente a la gravedad y se encogen. Este encogimiento es implacable y prosigue hasta que la estrella queda comprimida al tamaño de un planeta pequeño, convirtiéndose en un objeto denominado por los astrónomos como enana blanca. Como las enanas blancas son tan pequeñas, son extremadamente poco luminosas pese a que su superficie puede alcanzar temperaturas mucho mayores que la del Sol. Sin la ayuda del telescopio, desde la Tierra no puede verse ninguna.

El destino de nuestro Sol es el de convertirse en enana blanca en un futuro lejano. Cuando el Sol llegue a esta fase seguirá estando caliente durante muchos miles de millones de años; su enorme volumen se verá tan comprimido que retendrá su calor interno con mucha mayor eficiencia que el mejor termo que imaginemos. Sin embargo, como el horno nuclear interno se habrá apagado para siempre no habrá reservas de combustible que repongan la lenta pérdida de radiación calorífica en las frías profundidades del espacio. Lenta, lentísimamente, la enana que en tiempos fue nuestro poderoso sol se enfriará y se apagará hasta que aborde su metamorfosis definitiva, solidificándose poco a poco en un cristal de rigidez extraordinaria. Y terminará por apagarse por completo, desapareciendo silenciosamente en la negrura del espacio.

CAPÍTULO 5: ANOCHECER

La Vía Láctea resplandece con la luz de cien mil millones de estrellas y todas ellas están condenadas. Dentro de diez mil millones de años, la mayor parte de las estrellas que ahora vemos habrán desaparecido, apagándose por falta de combustible, víctimas de la segunda ley de la termodinámica.

Pero la Vía Láctea seguirá luciendo con la luz de sus estrellas porque incluso cuando las estrellas mueren nacen otras nuevas que ocupan su lugar. En los brazos espirales de la galaxia, como aquel en el que está situado nuestro Sol, se comprimen las nubes de gas, se contraen por la gravedad, se fragmentan y producen una cascada de nacimientos estelares. Un vistazo a la constelación de Orión revela la actividad de este tipo de vivero nuclear. El borroso punto de luz del centro de la espada de Orión no es una estrella, sino una nebulosa: una inmensa nube de gas tachonada de jóvenes y brillantes estrellas. Observando la radiación infrarroja en lugar de observar la luz visible, los astrónomos que han estudiado la nebulosa han atisbado recientemente estrellas en sus primerísimos estadios de formación, todavía rodeadas del gas y el polvo que las oscurecen.

La formación de estrellas seguirá en los brazos espirales de nuestra galaxia siempre que haya suficiente gas. El contenido de gas en la galaxia es en parte primordial (materia que todavía no se ha agregado en estrellas) y en parte gas expulsado de estrellas en forma de supernovas, vientos estelares, pequeños estallidos explosivos y otros procesos. Evidentemente, el reciclado de la materia no puede continuar de modo indefinido. Conforme mueran y se contraigan las estrellas viejas para convertirse en enanas blancas, estrellas de neutrones o agujeros negros, dejarán de ser capaces de proporcionar más gases interestelares. La materia primordial irá poco a poco incorporándose a las estrellas hasta que también se agote por completo. Cuando estas estrellas tardías vayan cumpliendo sus ciclos vitales y vayan muriendo, la galaxia se irá apagando inexorablemente. Este apagón será muy lento. Pasarán muchos miles de millones de años hasta que las estrellas más jóvenes y de menor tamaño terminen su combustión nuclear y se encojan formando enanas blancas. Pero la noche perpetua terminará por caer con lenta y esforzada determinación.

Un destino similar aguarda a las demás galaxias esparcidas por los abismos espaciales cada vez mayores. El universo que hoy reluce con la prolífica energía nuclear terminará por quedarse sin tan valioso recurso. Se habrá acabado para siempre la era de la luz.

Sin embargo, el final del universo no llegará cuando se apaguen las luces cósmicas, porque todavía hay otra fuente de energía incluso más potente que las reacciones nucleares. La gravedad, la fuerza más débil de la naturaleza a escala atómica, es la dominante a escala astronómica. Puede que sea relativamente suave en sus efectos pero es absolutamente persistente. Durante miles de millones de años las estrellas se han apuntalado contra su propio peso por medio de la combustión nuclear. Pero la gravedad no ha dejado de solicitarlas en ningún momento.

La fuerza gravitatoria entre dos protones de un núcleo atómico no es más que de una diez billonésima de billonésima de billonésima (10-37) de la fuerza nuclear fuerte. Pero la gravedad es acumulativa. Cada protón que tiene una estrella contribuye al peso total. La fuerza gravitatoria termina por ser avasalladora. Y esta fuerza avasalladora es la clave que proporciona un poder inmenso.

No hay objeto que ilustre más gráficamente el poder de la gravitación que un agujero negro. En él la gravedad ha triunfado por completo, reduciendo la estrella a la nada y dejando una huella en el espacio-tiempo circundante en forma de un alabeado infinito del tiempo. Con los agujeros negros puede hacerse un experimento mental fascinante. Imaginemos que dejamos caer un pequeño objeto, por ejemplo un peso de 100 gramos, dentro de un agujero negro desde una gran distancia. El peso se zambullirá en el agujero desapareciendo de nuestra vista y perdiéndose irremisiblemente. Sin embargo, deja un vestigio de su existencia anterior en la estructura del agujero que se hace ligeramente mayor como resultado de haberse tragado el peso. Un cálculo muestra que si se deja caer una pelota en el agujero desde una gran distancia, el agujero ganará una cantidad de masa igual a la masa original del peso. No se escapa ni masa ni energía.

Consideremos ahora un experimento diferente, en el que el peso se baja poco a poco hacia el agujero. Tal cosa podría conseguirse atándole una cuerda, pasando la cuerda por una polea, fijándola a un tambor y dejando que la cuerda se desenrollara lentamente. (Véase la figura 5.1. Doy por supuesto que la cuerda no se estira ni tiene peso, lo cual es irreal, pero se trata de evitar complicar la idea.) Conforme se va bajando el peso, puede transmitir energía, por ejemplo, haciendo girar un generador eléctrico unido al tambor. Cuanto más se acerque el peso a la superficie del agujero negro, mayor será el tirón gravitatorio del agujero sobre el peso. Conforme aumente la fuerza hacia abajo, el peso cede cada vez más trabajo en el generador. Un simple cálculo revela la cantidad de energía que el peso habrá transmitido al generador cuando llegue a la superficie del agujero negro. En un caso ideal, resulta ser toda la masa en reposo del peso.

Recuérdese la famosa fórmula de Einstein E = mc² que nos dice que la masa m posee una cantidad de energía mc². Utilizando un agujero negro podría en principio recuperarse esa cantidad completa. En el caso de un peso de 100 gramos, la cantidad significa unos tres mil millones de kilovatios por hora de electricidad. Comparativamente, cuando el Sol quema 100 gramos de combustible en la fusión nuclear, proporciona menos de un 1% de esa cantidad. De manera que, en principio, la liberación de energía gravitatoria podría ser bastante más de cien veces que la fusión termonuclear que alimenta a las estrellas.

En este experimento mental idealizado, se deja caer lentamente un peso sujeto a una cuerda hacia la superficie de un agujero negro, utilizando un sistema de polea fija (la fijación no se muestra aquí). Como resultado, el peso que desciende realiza un trabajo y transmite energía a la caja. La energía total transmitida se aproxima a la energia del total de la masa en reposo del peso, conforme el peso se va acercando a la superficie del agujero nego.

Por supuesto que las dos situaciones aquí inventadas son absolutamente ficticias. No hay duda de que en los agujeros negros caen objetos continuamente pero nunca sujetos a poleas de lo más eficiente para extraer su energía. En la práctica, se emite un cierto valor entre el 0% y el 100% de la energía de la masa en reposo. La fracción que se emita depende de las circunstancias físicas. En los últimos veinte años, los astrofísicos han estudiado un amplio espectro de simulaciones por ordenador y de modelos matemáticos en su intento por comprender el comportamiento del gas al entrar en torbellino en el agujero negro y de calcular la cantidad y el tipo de energía liberada. Los procesos físicos que se dan son muy complejos; sin embargo, está clara la enorme cantidad de energía gravitatoria que puede salir de estos sistemas.

Una simple observación vale más que mil cálculos y los astrónomos han realizado enormes rastreos de objetos que podrían ser agujeros negros en pleno proceso de engullir materia. Aunque no se ha encontrado todavía un candidato a agujero negro completamente convincente, un sistema muy prometedor está localizado en la constelación del Cisne y se conoce como Cygnus X-1. El telescopio óptico revela una estrella grande y caliente del tipo llamado gigante azul, debido a su color. Los estudios espectroscópicos indican que la estrella azul no está sola: ejecuta un contoneo rítmico, señal de que se ve atraída periódicamente por la gravedad de otro objeto cercano. Evidentemente la estrella y el otro cuerpo están en órbitas próximas uno en relación con otro. Sin embargo, los telescopios ópticos no revelan señal alguna de su compañera: o es un agujero negro o es una estrella compacta muy tenue. La cosa parece sugerir un agujero negro pero no es, ni mucho menos, una prueba.

Una pista más procede de la estimación de la masa del cuerpo oscuro. Puede deducirse de las leyes de Newton una vez conocida la masa de la estrecha gigante azul, y que podemos estimar debido a la estrecha correspondencia entre masa de una estrella y color: las estrellas azules están calientes y por lo tanto tienen una gran masa. Los cálculos indican que la compañera no vista tiene la masa de varios soles. No se trata evidentemente de una estrella normal, pequeña y apagada, de modo que tiene que tratarse de una estrella masiva contraída: bien una enana blanca, bien una estrella de neutrones, bien un agujero negro. Pero hay razones físicas elementales por las cuales este objeto compacto no puede ser una enana blanca o una estrella de neutrones. El problema tiene relación con el intenso campo gravitatorio que intenta aplastar al objeto. La contracción total hasta ser un agujero negro sólo puede evitarse si existe alguna presión interna, lo suficientemente fuerte como para contrarrestar la aplastante fuerza de la gravedad. Pero si el objeto contraído tiene varias masas solares no hay fuerza conocida que pueda resistir el peso aplastante de su materia. Porque si el núcleo de la estrella fuera lo suficientemente rígido como para eludir el aplastamiento, entonces la velocidad del sonido en esa materia sería mayor que la velocidad de la luz. Como eso se opone a la teoría de la relatividad especial, la mayoría de los astrónomos y de los físicos cree que en esas circunstancias es inevitable la formación de un agujero negro.

La prueba clave de que Cygnus X-1 alberga un agujero negro procede totalmente de otra observación. La designación X-1 se le dio porque el sistema es una enorme fuente de rayos X, que pueden detectarse mediante sensores colocados en satélites artificiales. Los modelos teóricos proporcionan una explicación convincente de estos rayos X basándose en la suposición de que la compañera oscura en Cygnus X-l sea un agujero negro. El campo gravitatorio del agujero obtenido por ordenador es lo suficientemente fuerte como para chupar materia de la estrella gigante azul. Así como los gases abducidos se dirigen hacia el agujero (y hacia su desaparición total) la rotación orbital del sistema haría que la materia que cae en el agujero negro girara a su alrededor formando un disco. Un disco de este tipo no puede ser completamente estable porque la materia cercana al centro órbita en torno al agujero negro con mucha mayor velocidad que la materia que se encuentra en torno al borde y la viscosidad intentará suavizar este gradiente rotacional. Como resultado el gas se calienta hasta una temperatura lo suficientemente alta como para emitir no sólo luz, sino también rayos X. La pérdida de energía orbital que esto representa hace que el gas forme una espiral que gira lentamente hasta introducirse en el agujero.

La prueba de un agujero negro en Cygnus X-l descansa por lo tanto en una cadena de razonamientos bastante larga que abarca tanto detalles de observación como modelos teóricos. Lo cual es típico de la naturaleza de una amplísima parte de la investigación astronómica de nuestros días; no hay prueba irresistible en sí, pero los diversos estudios de Cygnus X-1 y de otros sistemas similares, tomados en su conjunto, parecen indicar con fuerza la presencia de una agujero negro. Desde luego, el agujero negro es la explicación más limpia y la menos forzada.

De la actividad de agujeros negros más grandes pueden esperarse acontecimientos todavía más espectaculares. Hoy parece probable que muchas galaxias contengan agujeros negros supermasivos en su centro. La prueba de ello es el rápido movimiento que muestran las estrellas en esos núcleos galácticos; aparentemente las estrellas se ven atraídas hacia un objeto atractor enormemente compacto. Las estimaciones de la masa de esos posibles objetos varían desde los diez millones de masas solares a los mil millones de masas solares, lo cual les dará un apetito voraz ante cualquier masa aislada que se encuentre en sus proximidades. Estrellas, planetas, gas y polvo seguramente son presa de tales monstruos. La violencia del proceso de caída sería en algunos casos de tal magnitud que perturbaría la estructura entera de la galaxia. Los astrónomos están familiarizados con las muchas variedades de los núcleos galácticos activos. Algunas galaxias tiene el aspecto literal de estar explotando; muchas otras son fuentes potentísimas de ondas de radio, de rayos X y de otras formas de energía. Las más características son del tipo de las galaxias activas que expulsan enormes chorros de gas: chorros de miles e incluso de millones de años luz de longitud. La emisión de energía de alguno de estos objetos es absolutamente asombrosa. Por ejemplo, los cuásares muy distantes (el nombre es una abreviatura de «objetos cuasiestelares») pueden emitir la misma energía que millares de galaxias pero desde una región que no pasa de un año luz de diámetro, lo cual les otorga el aspecto superficial de una estrella.

Muchos astrónomos creen que la maquinaria central de esos objetos francamente perturbados son inmensos agujeros negros en rotación que se encuentran en pleno proceso de ingerir materia de sus proximidades. Cualquier estrella que se acerque a un agujero negro probablemente se partirá bajo la gravedad del agujero o chocará con otras estrellas y se romperá. Como en el caso de Cygnus X-l, pero a una escala mucho mayor, la materia dispersada seguramente formará un disco de gas caliente que orbite en torno al agujero y que lentamente vaya desapareciendo por él. En mayo de 1994 se informó que el telescopio espacial Hubble había descubierto un disco de gas de rápida rotación en el centro de la galaxia M87. Las observaciones parecen indicar con fuerza la presencia de un agujero negro supermasivo.

Puede ocurrir que la copiosa energía liberada por un disco de gas que fluye hacia un agujero negro se canalice a lo largo del eje de giro del agujero, produciendo un par de chorros opuestos, tal y como se observa a menudo. El mecanismo de esta liberación de energía, y la formación de chorros, debe de ser muy complicado, poniendo en juego fuerzas electromagnéticas, de viscosidad y otras, además de la propia gravedad. Este tema sigue siendo objeto de un intenso trabajo teórico y de observación.

¿Y qué pasa con la Vía Láctea? ¿Es posible que nuestra propia galaxia se vea perturbada de este modo? El centro de la Vía Láctea queda a treinta mil años luz de nosotros, en la constelación de Sagitario. Las regiones interiores están oscurecidas por grandes nubes de gas y polvo, pero los instrumentos de radio, de rayos X, de rayos gamma y de infrarrojos han permitido discernir a los astrónomos la existencia de un objeto extremadamente compacto, muy energético, llamado Sagitario A*. Aun no teniendo más que unos pocos miles de millones de kilómetros de diámetro (un tamaño pequeño para los estándares astronómicos), Sagitario A* es sin embargo la fuente de radio más potente de la galaxia. Su posición coincide con la de una fuente muy intensa de infrarrojos y también está próxima a un objeto infrecuente emisor de rayos X. Aunque la situación es complicada, cada vez parece más probable que por allí habite por lo menos un agujero negro masivo y que sea el responsable de algunos de los fenómenos observados. Sin embargo, la masa del agujero es, seguramente, como mucho de diez millones de masas solares, lo cual lo sitúa en la parte inferior de la escala de supermasas. No hay pruebas del tipo de emisiones violentas de energía y materia que se dan en otros núcleos galácticos, pero esto puede deberse a que el agujero negro esté pasando por una fase de tranquilidad. Podría flamear en un futuro (por ejemplo, si recibiera un suministro mayor de gas), aunque probablemente no sería tan perturbador como muchos de los demás conocidos. No está claro qué efecto tendría esa deflagración sobre las estrellas y los planetas de los brazos espirales de la galaxia.

Un agujero negro seguirá liberando la energía de la masa en reposo de la materia sacrificada siempre que haya materia en sus proximidades para alimentarlo. Con el tiempo, los agujeros negros irán tragando cada vez más materia y como resultado irán aumentando de tamaño y cada vez estarán más hambrientos. Hasta las estrellas en órbitas muy lejanas en torno a un agujero negro masivo terminarán por sucumbir. El motivo es un fenómeno extremadamente débil pero decisivo en último extremo conocido como radiación gravitatoria.

Poco después de haber formulado su teoría general de la relatividad en 1915, Einstein descubrió una notable propiedad del campo gravitatorio. A partir de un estudio de las ecuaciones de campo de su teoría, descubrió que predecían la existencia de oscilaciones gravitatorias parecidas a ondas que se propagan a la velocidad de la luz por el espacio vacío. Esta radiación gravitatoria recuerda a las radiaciones electromagnéticas, tales como la luz o las ondas de radio. Sin embargo, aunque pueda transportar mucha energía, la radiación gravitatoria difiere de la radiación electromagnética en la fuerza con la cual perturba a la materia. Mientras que la onda de radio la absorbe enseguida una estructura tan delicada como puede ser una tela metálica, la onda gravitatoria actúa tan débilmente que puede pasar atravesando la Tierra sin apenas resentirse. Si pudiéramos fabricar un láser gravitatorio necesitaríamos un rayo de un billón de kilovatios para hervir un cazo con agua con la misma eficiencia que si utilizáramos una resistencia eléctrica de un kilovatio. La debilidad relativa de la radiación gravitatoria puede deberse al hecho de que la gravitación es, con mucho, la más débil de las fuerzas conocidas de la naturaleza. La proporción de la fuerza gravitatoria y de las fuerzas eléctricas en un átomo, por ejemplo, es aproximadamente de 10-40. La única razón por la cual notamos la gravedad es que, como sus efectos son acumulativos, es la que predomina en objetos grandes como los planetas.

No sólo son extremadamente débiles las ondas gravitatorias en cuanto a sus efectos, sino que también su producción es un asunto silencioso. En principio, se produce radiación gravitatoria siempre que se perturba alguna masa. Por ejemplo, el movimiento de la Tierra en torno al Sol emite un tren de ondas gravitatorias continuo, pero la potencia total emitida ¡no es más que un milivatio! Esta pérdida de energía hace que la órbita de la Tierra vaya a menos, aunque a una tasa ridículamente lenta: más o menos a un mil billonésima de centímetro por década.

Con todo, la situación es drásticamente distinta para los masivos cuerpos astronómicos que se mueven a una velocidad cercana a la de la luz. Hay dos tipos de fenómeno que seguramente producen efectos importantes de radiación gravitatoria. Uno es el acontecimiento súbito y violento, por ejemplo una supernova o la contracción de una estrella para formar un agujero negro. Este tipo de suceso determina la emisión de un pulso breve de radiación gravitatoria, que apenas dura unos pocos microsegundos y que dispersa por término medio unos 1044 julios de energía. (Compárese esta cantidad con la emisión de calor por parte del Sol, que viene a ser de unos 3 x 1026 julios por segundo.) El otro fenómeno es el movimiento rapidísimo de objetos masivos en órbita unos de otros. Por ejemplo, un sistema estelar binario de poca separación originará un gran flujo continuo de radiación gravitatoria. Este proceso es especialmente eficiente si las estrellas que orbitan son objetos contraídos, como estrellas de neutrones o agujeros negros. En la constelación del Águila hay dos estrellas de neutrones que orbitan una en torno a la otra a unos pocos millones de kilómetros. Sus campos gravitatorios son tan fuertes que completan una órbita en menos de ocho horas, de tal modo que las estrellas han de moverse a una fracción apreciable de la velocidad de la luz. Este movimiento inusualmente rápido amplifica muchísimo la tasa de la emisión de ondas gravitatorias y hace que la órbita vaya decayendo de año en año una cantidad que puede medirse (unos 75 microsegundos de alteración del periodo). La tasa de emisión seguirá en ascenso conforme las estrellas vayan acercándose en su giro. Están destinadas a encastrarse la una en la otra dentro de unos trescientos millones de años.

Los astrónomos calculan que aproximadamente cada cien mil años, y en cada galaxia, se funde un sistema binario de este tipo. Los objetos son tan compactos, y son tan intensos sus campos gravitatorios, que durante los últimos instantes antes del impacto de las estrellas éstas orbitarán la una en torno a la otra miles de veces por segundo y que la frecuencia de la onda gravitatoria se mostrará como un chirrido característico. Las fórmulas de Einstein predicen que la emisión de potencia gravitatoria será prodigiosa en esa fase final y que la órbita se cerrará rapidísimamente. La forma de las estrellas se verá muy distorsionada por su tirón gravitatorio mutuo, de modo que cuando se toquen parecerán puros gigantes girando sobre sus ejes. La fusión subsiguiente será una situación confusa, fundiéndose las dos estrellas para formar una masa compleja que bullirá enloquecida y emitirá asimismo abundante radiación gravitatoria hasta que se organice en forma más o menos esférica bamboleándose y anillándose como una campana monstruosa que repicará visiblemente. Estas oscilaciones también producirán cierta cantidad de radiación gravitatoria, quitándole aún más energía a tal objeto, hasta que se tranquilice y termine por quedar inerte.

Aunque la tasa de pérdida de energía sea relativamente baja, la emisión de radiación gravitatoria habrá de tener efectos profundos a largo plazo en la estructura del universo. Por lo mismo, es importante que los científicos intenten confirmar mediante las observaciones sus ideas sobre la radiación gravitatoria. Los estudios del sistema binario de estrellas de neutrones en el Águila muestran que la órbita va decayendo precisamente a la tasa predicha por la teoría de Einstein. Por lo tanto, este sistema proporciona una prueba directa de la emisión de radiación gravitatoria. Sin embargo, la prueba definitiva exige detectar esa radiación en un laboratorio de la Tierra. Hay muchos equipos de investigación que han montado equipos para registrar el paso fugaz de cualquier estallido de ondas gravitatorias, pero hasta el día de hoy ninguno de esos dispositivos ha sido lo suficientemente sensible para detectarlo y es probable que debamos esperar a una nueva generación de detectores antes de que pueda confirmarse por completo la existencia de la radiación gravitatoria.

La fusión de las dos estrellas de neutrones puede producir o una estrella de neutrones aún mayor o un agujero negro. La fusión de una estrella de neutrones y de un agujero negro, o de dos agujeros negros, debe producir un único agujero negro. Este proceso se vería acompañado por la pérdida de una energía de onda gravitatoria parecida a la del caso de las estrellas de neutrones binarias, seguido de complejos movimientos de anillado y bamboleo que lentamente irían amortiguándose debido a la pérdida de potencia por ondas gravitatorias.

Es interesante explorar los límites teóricos de la energía gravitatoria que podría extraerse de la fusión de dos agujeros negros. La teoría de estos procesos la obtuvieron Roger Penrose, Stephen Hawking, Brandon Cárter, Remo Ruffini, Larry Smarr y otros a principios de los años 70. Si los agujeros no rotan y son de masa idéntica, puede liberarse aproximadamente el 29% de su masa total en reposo. No hace falta que esta liberación sea en forma de radiación gravitatoria si los agujeros negros se pudieran manipular no se sabe cómo (por ejemplo, mediante una tecnología avanzada), pero en una fusión natural la mayor parte de la energía desprendida lo sería de esta forma inconspicua. Si los agujeros rotaran a la máxima tasa permitida por las leyes de la física (aproximadamente a la velocidad de la luz) y se fundieran a contrarrotación y a lo largo de sus ejes de giro, entonces podría emitirse el 50% de la energía de la masa.

Ni siquiera esta fracción considerable es el máximo teórico. Un agujero negro puede llevar carga eléctrica. Un agujero negro cargado eléctricamente tiene un campo eléctrico además de campo gravitatorio y ambos pueden almacenar energía. Si un agujero negro con carga positiva se topa con otro de carga negativa, se produce una «descarga» liberándose en el proceso energía electromagnética además de gravitatoria.

Esa descarga tiene un límite, ya que un agujero negro de masa dada puede llevar carga eléctrica sólo hasta un determinado máximo. Para un agujero que no rotara, ese valor viene dado por la siguiente consideración. Imaginemos dos agujeros idénticos que tuvieran la misma carga. Los campos gravitatorios de los agujeros crearían una fuerza de atracción entre ellos mientras que las cargas eléctricas originarían una fuerza de repulsión (cargas del mismo signo se repelen). Cuando la proporción carga-masa llegue a un valor crítico, estas dos fuerzas opuestas estarán exactamente en equilibrio y no habrá fuerza neta entre ambos agujeros. Ésta es la situación que marca el límite de cantidad de carga eléctrica que puede contener un agujero negro. Podríamos preguntarnos qué pasaría si intentáramos aumentar la carga de un agujero negro por encima de su valor máximo. Un modo de intentarlo sería meter más carga en el agujero negro. Este procedimiento serviría para incrementar la carga eléctrica pero el trabajo realizado para vencer la repulsión eléctrica consume energía, energía que pasa al agujero. Como la energía tiene masa (recuérdese que E = mc²) el agujero se hace más masivo y, por ende, mayor. Un sencillo cálculo muestra que la masa aumenta a una tasa mayor que la carga en este proceso, de modo que la proporción carga-masa en realidad disminuye, con lo cual se va al traste el intento de sobrepasar ese límite.

El campo eléctrico de un agujero negro cargado contribuye a la masa total del agujero. En el caso de un agujero que tuviera la máxima carga permitida, el campo eléctrico representa la mitad de la masa. Si dos agujeros que no rotaran llevasen la máxima carga Pero de signo opuesto se atraerían gravitatoria y electromagnéticamente. Al fundirse, las dos cargas se neutralizarán y podrá extraerse la energía eléctrica. En teoría, puede llegar hasta el 50% de la energía de la masa total del sistema.

El límite superior absoluto de la extracción de energía se obtendrá cuando ambos agujeros roten y lleven cargas eléctricas opuestas, cada una del máximo valor. Entonces podrá liberarse hasta dos tercios de la energía de la masa total. Por supuesto, estos valores tienen sólo un interés teórico, porque en la práctica un agujero negro seguramente no lleva una gran carga eléctrica, como tampoco es probable que dos agujeros negros se fundan de manera óptima, a menos que les obligue a ello una sociedad tecnológicamente avanzada. Sin embargo, incluso la fusión ineficiente de dos agujeros negros casi con seguridad producirá una liberación instantánea de energía que suponga una fracción significativa de la energía de la masa total de los objetos en cuestión. Cosa que puede compararse con el escuálido 1% de la energía de masa que las estrellas emiten por fusión nuclear a lo largo sus vidas de miles de millones de años.

La importancia de estos procesos gravitatorios es que, lejos de morir, una estrella exhausta tiene la capacidad de liberar mucha más energía como escoria contraída que con los procesos termonucleares como bola incandescente de gas. Cuando se aceptó este hecho hace unos veinte años, el físico John Wheeler, el hombre que acuñó inicialmente el término «agujero negro», concibió una hipotética civilización cuyas siempre crecientes necesidades de energía la llevaran a abandonar su estrella y a residir en torno a un agujero negro. Todos los días se cargan los productos de desecho de esa sociedad en contenedores que se disparan hacia el agujero a lo largo de una trayectoria cuidadosamente calculada. Cerca del agujero se suelta el contenido de los contenedores, arrojando la basura al agujero, con lo cual se deshace de ella para siempre. La materia que cae, al viajar a lo largo de un camino de rotación a contragiro del agujero, tiene el efecto de frenar levemente el giro de éste. Por ello mismo se libera la energía rotativa del agujero que esa civilización aprovecha para sus industrias. Por lo tanto el proceso presenta la doble virtud de ¡eliminar por completo todos los productos residuales convirtiéndolos en pura energía! De este modo, esa civilización puede liberar de la estrella muerta, según sus necesidades, una cantidad de energía mucho mayor que la energía que emitió esa misma estrella durante su fase luminosa.

Aunque el aprovechamiento de la potencia de un agujero negro es una escena de ciencia ficción, de forma natural habrá montones de materia que acaben en los agujeros negros, bien como parte de la estrella que se contrae para formar el agujero, bien como residuos engullidos durante un encuentro casual. Siempre que doy conferencias sobre agujeros negros, mis oyentes quieren saber lo que pasa cuando se entra en uno de ellos. La respuesta más concisa es «No lo sabemos». Nuestro conocimiento de los agujeros negros se basa casi por completo en consideraciones teóricas y en modelos matemáticos. Lo cierto es que por definición no podemos observar el interior de un agujero negro desde el exterior, de modo que incluso si tuviéramos acceso directo a la observación de un agujero negro (cosa que no puede ser) nunca sabríamos qué pasa en su interior. Sin embargo, la teoría de la relatividad, que en primer lugar predice la existencia de agujeros negros, puede usarse también para predecir qué le ocurriría a un astronauta que cayera en uno de ellos. Lo que sigue es un resumen de tales deducciones teóricas.

La superficie del agujero no pasa de ser un constructor matemático: no es que exista una membrana, sólo espacio vacío. El astronauta que cayera no notaría nada especialmente diferente al entrar en el agujero. Sin embargo, la superficie sí que tiene un significado físico seguro, y en cierto modo dramático. Dentro del agujero la gravedad es tan fuerte que atrapa la luz, reabsorbiendo los fotones que salen. Eso significa que la luz no puede escapar del agujero negro una vez que ha atravesado su frontera. Los sucesos que se dan dentro del agujero quedan ocultos para siempre a los observadores externos. Por este motivo, la superficie del agujero se denomina «horizonte de sucesos», ya que separa los sucesos del exterior, que pueden verse desde lejos, de los sucesos del interior, Que no se pueden ver. Sin embargo, el efecto es unilateral. El astronauta que esté dentro del horizonte de sucesos puede seguir viendo el universo exterior, incluso aunque nadie pueda ver al astronauta.

Conforme el astronauta se adentre en el agujero, aumentará el campo gravitatorio. Uno de sus efectos será la distorsión del cuerpo. Si el astronauta cae de pie, tendrá los pies más próximos al centro del agujero, donde la gravedad es más fuerte, que la cabeza. Como resultado, el agujero tirará de los pies del astronauta con mayor fuerza, estirando el cuerpo en sentido longitudinal. Al mismo tiempo, los hombros se verán arrastrados hacia el centro del agujero en trayectorias convergentes, con lo que el astronauta se verá aplastado lateralmente. A este proceso de estiramiento y de aplastamiento conjunto se le suele llamar a veces «espaguetificación».

La teoría parece indicar que en el centro del agujero negro la gravedad crece ilimitadamente. Como el campo gravitatorio se manifiesta como curvatura o alabeado del espacio-tiempo, la creciente gravedad va acompañada de un alabeado del espacio-tiempo que también sigue creciendo sin límites. Los matemáticos denominan a este rasgo singularidad espacio-temporal. Representa una frontera, un borde del espacio y del tiempo a través del cual no se puede prolongar el concepto normal de espacio-tiempo. Muchos físicos creen que la singularidad dentro de un agujero negro representa genuinamente el fin del espacio y del tiempo y que cualquier materia que llegue hasta él quedará completamente destruida. Si es así, entonces incluso los átomos del cuerpo del astronauta se desvanecerán en esa singularidad en un nanosegundo de espaguetificación.

Si el agujero negro tiene la masa de diez millones de soles (parecida a la del agujero que puede hallarse en el centro de la Vía Láctea) y no rota, entonces el paso del tiempo experimentado por el astronauta desde caer por el horizonte de sucesos hasta la singularidad aniquiladora será de unos tres minutos. Esos últimos tres minutos serán extremadamente incómodos; en la práctica, la espaguetificación matará al desventurado individuo mucho antes de llegar a la singularidad. En todo caso, durante esta fase final el astronauta será incapaz de ver esa singularidad fatal porque la luz no puede escapar de ella. Si el agujero en cuestión tiene una masa solar, su radio será de unos 3 kilómetros y el viaje desde el horizonte de sucesos hasta la singularidad tardará unos pocos microsegundos.

Aunque el tiempo transcurrido hasta la destrucción es muy rápido tal y como lo experimentaría el astronauta en su marco de referencia, el alabeado del tiempo producido por el agujero es de tal envergadura que, visto desde lejos, el último viaje del astronauta parecería desarrollarse a cámara lenta. Conforme se acercara el astronauta al horizonte de sucesos, el ritmo de los acontecimientos para el observador lejano parecería ir cada vez más despacio. De hecho, parece que debería llevar un tiempo infinito hasta que el astronauta llegara al horizonte. De manera que lo que en las regiones lejanas del universo se experimenta como eternidad, para el astronauta sería visto y no visto. En este sentido, un agujero negro es una especie de puerta que da al final del universo, una especie de callejón sin salida cósmico que representa una salida a ninguna parte. Un agujero negro es una región del espacio que alberga el fin del tiempo. Los que tengan curiosidad sobre el final del universo pueden experimentarlo por sí mismos saltando a uno de ellos.

Aunque la gravedad es, con mucho, la fuerza más débil de la naturaleza, su acción insidiosa y acumulativa sirve para determinar el destino definitivo no sólo de los objetos astronómicos individuales, sino del cosmos al completo. Esa misma atracción irresistible que aplasta una estrella funciona a escala muchísimo mayor sobre el universo en su conjunto. El resultado de esta atracción universal depende sutilmente de la cantidad total de materia que existe para ejercer el tirón gravitatorio. Y para descubrirlo, tenemos que pesar el universo.

CAPÍTULO 6: PESAR EL UNIVERSO

Suele decirse que todo lo que sube tiene que bajar. El tirón de la gravedad sobre un cuerpo que se impulsa hacia el cielo actúa como freno a su vuelo y lo devuelve a la Tierra. Pero no siempre. Si el cuerpo se mueve con suficiente velocidad, puede escapar completamente a la gravedad de la Tierra y salir al espacio para no regresar jamás. Los cohetes que lanzan naves espaciales pueden conseguir tal velocidad.

La «velocidad de escape» es de unos 11 kilómetros por segundo (39.600 kilómetros por hora), más de veinte veces la velocidad del Concorde. Esta cifra crítica se obtiene de la masa de la Tierra (es decir, de la cantidad de materia que contiene) y de su radio. Cuanto más pequeño sea un cuerpo de masa dada, mayor será su gravedad superficial. Salir del sistema solar supone superar la gravedad; la velocidad de escape que se requiere es de 618 kilómetros por segundo. Salir de la Vía Láctea también exige una velocidad de unos pocos cientos de kilómetros por segundo. En el extremo opuesto, la velocidad que se requiere para escapar de un objeto compacto como una estrella de neutrones es de varias decenas de miles de kilómetros por segundo, mientras que para escapar de un agujero negro es la velocidad de la luz (300.000 kilómetros por segundo).

¿Y para salir del universo? Como ya señalé en el capítulo 2, el universo no parece tener borde del cual salirse, pero si hacemos como si lo tuviera y el borde está situado en el límite de nuestra observación actual (a unos quince mil millones de años de nosotros), entonces la velocidad de escape sería aproximadamente la velocidad de la luz. Es un resultado muy significativo porque las galaxias más alejadas parecen alejarse de nosotros a velocidades cercanas a la de la luz. Tomándolo tal cual, las galaxias parecen apartarse unas de otras a tanta velocidad que es como si verdaderamente estuvieran «escapándose» del universo, o por lo menos escapándose unas de otras para «no volver jamás».

Lo cierto es que el universo en expansión se comporta de modo muy parecido al de un cuerpo impulsado desde la Tierra, incluso no teniendo borde bien definido. Si la tasa de expansión es lo suficientemente rápida, las galaxias que se aparten escaparán de la gravedad acumulativa del resto de la materia del universo y la expansión continuará para siempre. Por otro lado, si la tasa es excesivamente baja, la expansión terminará por detenerse y el universo empezará a contraerse. Entonces «volverán a caer» las galaxias y de ello se seguirá la definitiva catástrofe cósmica al contraerse el universo.

¿Cuál de las dos opciones será la que ocurra? La respuesta depende de la comparación de dos números. Por una parte, la tasa de expansión; por otra, el tirón gravitatorio total del universo, es decir, el peso del universo. A mayor tirón, más rápidamente debe expandirse el universo para superarlo. Los astrónomos pueden medir la tasa de expansión directamente observando el efecto de corrimiento hacia el rojo; aun así, todavía hay controversia sobre la respuesta. La segunda cantidad, el peso del universo, es aún más Problemática.

¿Cómo se pesa el universo? Parece una tarea desalentadora; esta claro que no lo podemos hacer directamente. Sin embargo, Podríamos ser capaces de deducir su peso usando la teoría de la gravitación. El límite inferior se obtiene muy directamente. Es posible medir el Sol midiendo su tirón gravitatorio sobre los planetas. Sabemos que la Vía Láctea alberga cerca de cien mil millones de estrellas de aproximadamente una masa solar por término medio, de modo que así obtenemos un límite inferior grosero a la masa de la galaxia. A continuación podemos ver cuántas galaxias hay en el universo. No podemos sumarlas una a una, hay demasiadas, pero una buena estimación es un número de cien mil millones. Eso nos da 1021 masas solares, unas 1048 toneladas en total. Tomando como radio de este conjunto de galaxias quince mil millones de años luz, podemos calcular un valor mínimo para la velocidad de escape del universo: la respuesta resulta ser aproximadamente un 1% de la velocidad de la luz. Podemos sacar la conclusión de que si el peso del universo se debiera sólo a las estrellas del universo, el universo escaparía a su propio tirón gravitatorio y seguiría expandiéndose indefinidamente.

Cosa que ciertamente muchos científicos creen que ocurrirá. Pero no todos los astrónomos y cosmólogos están convencidos de que se hayan hecho correctamente las sumas. La materia que vemos es menos de la que existe de verdad porque no todos los objetos del universo brillan. Los cuerpos oscuros, como las estrellas apagadas, los planetas y los agujeros negros suelen escaparse a nuestras observaciones. También hay montones de polvo y de gas, generalmente inconspicuos. Por si fuera poco, los espacios entre galaxias no estarán sin duda carentes de materia: entre ellas puede haber grandes cantidades de gas tenue.

Con todo, una posibilidad todavía más intrigante lleva varios años teniendo en vilo a los astrónomos. El big bang, en el que se originó el universo, fue la fuente de toda la materia que vemos pero también fuente de mucha materia que no vemos. Si el universo comenzó como un puré inmensamente caliente de partículas subatómicas entonces, además de los familiares electrones, protones y neutrones que conforman la materia ordinaria, debe haberse creado en cantidades abundantísimas toda suerte de partículas, recientemente identificadas en el laboratorio por los físicos de partículas.

La mayoría de estos otros tipos de partículas son altamente inestables y habrán desaparecido enseguida, pero algunas pueden seguir existiendo hasta el día de hoy como reliquias del origen cósmico.

Entre estas reliquias de interés, las principales son los neutrinos, esas partículas fantasmales cuya actividad se revela en las supernovas (véase capítulo 4). Por lo que sabemos, los neutrinos no pueden descomponerse en nada más. (La verdad es que hay tres tipos de neutrinos y puede que sean capaces de pasar de unos a otros, pero aquí pasaré por alto esta complicación.) De modo que esperamos que el universo esté bañado en un mar de neutrinos cósmicos residuo del big bang. Suponiendo que la energía del universo primigenio fuera compartida democráticamente por todas las especies subatómicas, resulta posible calcular cuántos neutrinos cósmicos debería haber. La respuesta viene a ser de más o menos un millón de neutrinos por centímetro cúbico de espacio, o unos mil millones de neutrinos por cada partícula de materia corriente.

Siempre me ha fascinado esta llamativa conclusión. En cualquier momento dado, tenemos en el cuerpo unos cien mil millones de neutrinos, casi todos ellos reliquias del big bang, prácticamente sin cambiar desde su primer milisegundo de existencia. Como los neutrinos se mueven a la velocidad de la luz o casi, nos atraviesan con tanta rapidez que cada segundo nos penetran ¡cien trillones de neutrinos! Esta incesante violación nos pasa absolutamente desapercibida porque los neutrinos reaccionan tan poco con la materia corriente que la probabilidad de que alguno de ellos, durante nuestra vida, se detenga al chocar con nosotros es en la práctica despreciable. En cambio, la existencia de tantísimos neutrinos dispersos por los espacios aparentemente vacíos del universo podría tener profundas consecuencias para su destino definitivo.

Aunque los neutrinos reaccionan tan poco, sí ejercen la fuerza gravitatoria común a todas las partículas. Puede que no tiren de la materia ni la empujen de manera significativa, pero sus efectos gravitatorios indirectos podrían resultar cruciales al sumarse al peso total del universo. Y para determinar en qué medida contribuyen los neutrinos es necesario conocer su masa.

Cuando se trata de la gravedad, lo que cuenta es más bien la masa real y no la masa en reposo. Como los neutrinos se mueven a una velocidad cercana a la de la luz, pueden tener una masa significativa a pesar de que su masa en reposo sea diminuta. Por supuesto que podrían tener incluso masa cero en reposo y moverse exactamente a la velocidad de la luz. De ser así, entonces su masa actual puede determinarse en relación con su energía que, en el caso de neutrinos cósmicos residuales, puede deducirse de la supuesta energía que adquirieron en el big bang. Esta energía original debe corregirse en un factor que tenga en cuenta el efecto debilitante de la expansión del universo. Una vez hecho todo esto, resulta que los neutrinos de masa cero en reposo no contribuirían significativamente al peso total del universo.

Por otra parte, tampoco podemos estar seguros de que el neutrino tenga masa cero en reposo ni tampoco que las tres especies de neutrino tengan la misma masa en reposo. Nuestra comprensión teórica actual de los neutrinos no elimina la posibilidad de una masa finita en reposo, de manera que saber cuál es el caso se convierte en una cuestión de experimentación. Como ya dije en el capítulo 4, sabemos que si el neutrino tiene masa en reposo desde luego tiene que ser muy pequeña: mucho más pequeña que la masa en reposo de cualquier otra partícula conocida. Sin embargo, al haber tantísimos neutrinos en el universo, hasta una masa diminuta en reposo significaría una gran diferencia en el peso total del universo. Se trata de un equilibrio muy ajustado. Una masa tan pequeña como la diezmilésima parte de la masa del electrón (que es la partícula más ligera que se conoce) sería suficiente para tener un drástico efecto: los neutrinos pesarían entonces más que las estrellas.

Detectar una masa así de pequeña es dificilísimo y el resultado de los experimentos ha sido desconcertante y contradictorio. Curiosamente, la detección de neutrinos de la Supernova 1987A proporcionó una pista importante. Como ya se ha señalado, si los neutrinos tienen masa cero en reposo deben viajar todos exactamente a la misma velocidad, la velocidad de la luz. Por otro lado, si el neutrino tiene una masa en reposo pequeña pero no nula, entonces es posible un cierto margen de velocidades. Los neutrinos de una supernova seguramente son muy energéticos y por lo mismo es seguro que se mueven a una velocidad muy próxima a la de la luz incluso aun no teniendo una masa cero en reposo. Sin embargo, como habrán viajado por el espacio durante mucho tiempo, unas variaciones diminutas en velocidad podrían traducirse en variaciones mensurables en su momento de llegada a la Tierra. Estudiando el margen de tiempo en el cual llegaron los neutrinos de la Supernova 1987 A, puede establecerse un límite superior para su masa en reposo de aproximadamente la treintamilava parte de la masa del electrón.

Por desgracia, la situación se complica todavía más porque se sabe que hay más de un tipo de neutrino. La mayoría de las determinaciones de la masa en reposo se refieren al neutrino originariamente postulado por Pauli, pero desde su descubrimiento se ha hallado un segundo tipo de neutrino e inferido la existencia de un tercero. Las tres especies se habrían creado en abundancia durante el big bang. Es muy difícil poner límites de manera directa a la masa de los otros dos tipos de neutrino. Experimentalmente el margen de valores posibles sigue siendo muy amplio, pero los teóricos suelen creer en la actualidad que los neutrinos no son dominantes en la masa del universo. Sensación que podría invertirse a la luz de nuevas medidas experimentales de las masas de los neutrinos.

Ni tampoco son los neutrinos las únicas reliquias posibles que podemos considerar cuando se trata de estimar el peso del universo. En el big bang podrían haberse creado otras partículas estables y de débil interacción, puede que con masas bastante mayores. (Si la masa en reposo se hace demasiado grande, su producción se suprime en relación con la de otras partículas de masa menor, ya que se requiere más energía para producirlas). Se las conoce colectivamente como WIMP, abreviatura de Weakly Interacting Massive Particles2. Los teóricos tienen una lista bastante larga de WIMP hipotéticas que llevan nombres extravagantes como gravitinos, bosones de Higgs y fotinos. Nadie sabe si realmente existen, pero si existen tendrán que tenerse en cuenta para determinar el peso del universo.

Lo llamativo es que puede ser posible comprobar directamente la existencia de las WIMP a partir de cómo se supone que actúan sobre la materia ordinaria. Aunque se predice que esta interacción habrá de ser muy débil, la gran masa de las partículas WIMP les permite tener un buen montón de energía. Se han pensado experimentos para llevar a cabo en una mina de sal del noreste de Inglaterra y bajo un pantano cerca de San Francisco y detectar el paso de WIMP. Suponiendo que el universo esté repleto de ellas, nos estaría atravesando continuamente una enorme cantidad de WIMP (a nosotros y a la Tierra). El fundamento del experimento es chocante: ¡detectar el sonido que hace una WIMP al chocar con un núcleo atómico!

El aparato consiste en un cristal de germanio o de silicona rodeado por un sistema de refrigeración. Si una WIMP golpea un núcleo en el cristal, su momento originará un retroceso del núcleo. Este golpetazo seco crea una diminuta onda sonora, o vibración, en el retículo del cristal. Conforme se vaya expandiendo la onda irá amortiguándose y convirtiéndose en energía calorífica. El experimento está pensado para detectar el diminuto pulso de calor asociado a la onda sonora en amortiguación. Como el cristal está refrigerado casi al cero absoluto, el detector es extremadamente sensible al aporte de cualquier energía calorífica.

Los teóricos conjeturan que las galaxias se hallan inmersas en enjambres en forma de gota de partículas WIMP animadas de un movimiento más bien lento, de masas que podrían oscilar entre una y mil veces la masa del protón y velocidades medias en unos pocos miles de kilómetros por segundo. Al orbitar en la galaxia nuestro sistema solar, barre este mar invisible y cada kilogramo de materia de la Tierra podría entonces dispersar unas mil WIMP al día. Dada esta tasa de sucesos, debería ser factible la detección directa de las WIMP.

Mientras continúa la caza de las WIMP, también están abordando los astrónomos el problema de pesar el universo. Incluso aunque no se pueda ver (u oír) un cuerpo, pueden ser aparentes sus efectos gravitatorios. Por ejemplo, el planeta Neptuno se descubrió porque los astrónomos se dieron cuenta de que la órbita de Urano se veía alterada por la fuerza gravitatoria de un cuerpo desconocido. La tenue estrella enana blanca Sirio B, que órbita en torno a la brillante Sirio, también se descubrió de este modo. Por ello, controlando el movimiento de objetos visibles, los astrónomos pueden hacerse también una imagen de la materia no vista. (Ya he explicado cómo esta técnica nos ha llevado a la sospecha de que pueda haber un agujero negro en Cygnus X-l.)

Durante más o menos las dos últimas dos décadas se han hecho cuidadosos estudios de cómo se mueven las estrellas de nuestra galaxia. Las estrellas orbitan en torno al centro de la Vía Láctea en una escala temporal media de algo más de doscientos millones de años. La galaxia tiene una forma parecida a un disco con un gran goterón de estrellas cerca del centro. De tal modo que tiene un cierto parecido con el sistema solar, en el que los planetas orbitan alrededor del Sol; pero los planetas interiores, Mercurio y Venus, se mueven más deprisa que los planetas exteriores, como Urano o Neptuno, debido a que los planetas interiores notan con más fuerza el tirón gravitatorio del Sol. Cabría esperar que esta regla se aplicara también a la galaxia: las estrellas cerca de la periferia del disco deberían moverse mucho más despacio que las del centro.

Sin embargo, las observaciones contradicen lo anterior. Las estrellas se mueven en todo el disco aproximadamente a la misma velocidad. La explicación debe ser que la masa de la galaxia no está concentrada cerca del centro, sino que está repartida más o menos por igual. El que la galaxia parezca estar concentrada cerca del centro hace pensar que el material luminoso es sólo una parte del asunto. Evidentemente hay presente un montón de materia oscura o invisible, buena parte en las regiones externas del disco acelerando las estrellas de esas regiones. Hasta podría haber cantidades sustanciales de materia oscura más allá del borde visible y fuera del plano del disco, envolviendo a la Vía Láctea en un halo masivo e invisible que se extendiera mucho más allá por el espacio intergaláctico. Parecida pauta de movimiento se observa en otras galaxias. Las medidas indican que las regiones visibles de las galaxias son, por término medio, mucho más de diez veces más masivas que lo que su brillo (por comparación con el del Sol) podría sugerir, llegando a elevarse hasta las cinco mil veces en las regiones más externas.

A este mismo tipo de conclusión se llega partiendo del estudio de los movimientos de galaxias en el interior de los cúmulos galácticos. Está claro que si una galaxia se mueve con rapidez suficiente escapará del tirón gravitatorio del cúmulo. Si todas las galaxias del cúmulo se mueven con igual rapidez, pronto se romperá el cúmulo. Un cúmulo típico de varios cientos de galaxias está situado en la constelación de Coma y se ha estudiado al detalle. La velocidad media de las galaxias de Coma es excesivamente alta como para que el cúmulo pueda mantenerse unido, a menos que haya por lo menos trescientas veces más materia que la materia luminosa que puede verse. Como una galaxia media tarda sólo mil millones de años más o menos en cruzar el cúmulo de Coma, ha habido tiempo más que suficiente para que el cúmulo se hubiera dispersado ya. Y no es así, y la estructura del cúmulo da toda la impresión de estar unida gravitatoriamente. Debe haber presente alguna forma de materia oscura en cantidades sustanciales que influya en el movimiento de las galaxias.

Una indicación más de materia no vista procede del examen de la estructura a gran escala del universo: cómo se agrupan los cúmulos y los supercúmulos de galaxias. Como se ha explicado en el capítulo 3, las galaxias están distribuidas de un modo que recuerda a la espuma, hilvanada en filamentos o dispersa en amplias láminas que rodean inmensos vacíos. Esa estructura agrupada y espumosa no podría haber surgido en el tiempo transcurrido desde el big bang sin el tirón gravitatorio adicional de la materia no luminosa. Sin embargo, las simulaciones por ordenador en el momento en que escribo no pueden reproducir todavía esa estructura espumosa observada con ninguna forma simple de materia oscura y es posible que se necesite un cóctel complicado.

La atención científica de última hora se centra en partículas subatómicas exóticas como candidatas a formar la materia oscura, pero también podría existir ésta bajo formas más convencionales como masas de tamaño planetario o estrellas tenues. Enjambres de estos objetos oscuros podrían vagar por el espacio y nosotros podríamos estar benditamente ajenos al fenómeno. Los astrónomos han descubierto hace poco una técnica que podría revelar la existencia de cuerpos oscuros que no están gravitatoriamente ligados a objetos visibles. La técnica hace uso de un resultado de la teoría general de la relatividad de Einstein conocido como lente gravitatoria.

La idea se basa en el hecho de que la gravedad puede torcer los rayos de luz. Einstein predijo que un rayo de luz estelar que pasara cerca del Sol se vería levemente curvado, desplazando por lo tanto la posición aparente de la estrella en el cielo. Puede comprobarse la predicción comparando la posición de la estrella con o sin la presencia del Sol en sus proximidades. Cosa que hizo en primer lugar el astrónomo británico sir Arthur Eddington en 1919, y que confirmó brillantemente la teoría de Einstein.

Lente gravitatoria. La gravedad de un cuerpo masivo (círculo) dobla los rayos de luz provenientes de una fuente lejana S. En un caso favorable, se producirá un efecto de foco. Un onbservador en el foco vería un anillo de luz en torno al cuerpo.

También las lentes doblan los rayos de luz y como resultado pueden enfocar la luz para formar una imagen. Si un cuerpo masivo es lo suficientemente simétrico, puede imitar a una lente y enfocar la luz de una fuente lejana. La figura 6.1 muestra cómo puede ser. La luz de la fuente S cae sobre un cuerpo esférico y la gravedad del cuerpo tuerce la luz a su alrededor, dirigiéndola a un punto focal en el lado opuesto. El efecto de desviación es minúsculo para la mayoría de los objetos, pero a distancias astronómicas hasta una leve curvatura en el avance de la luz terminará por originar un foco. Si el cuerpo se interpone entre la Tierra y la fuente lejana S el efecto aparecerá como una imagen muy abrillantada de S o, en casos excepcionales en los que sea exacta la línea de visión, como un círculo de luz conocido como anillo de Einstein. Para los cuerpos de formas más complicadas, seguramente el efecto lenticular produciría imágenes múltiples en lugar de una única imagen enfocada. Los astrónomos han descubierto cierto número de lentes gravitatorias a escala cosmológica: galaxias en alineación casi perfecta con la Tierra y con cuásares lejanos producen imágenes múltiples de esos cuásares y, en algunos casos, arcos y anillos completos de luz cuasárica.

En su búsqueda de planetas oscuros y de estrellas enanas y tenues, los astrónomos buscan los signos característicos de la lente que se darían en caso de que un cuerpo así se interpusiera directamente entre la Tierra y una estrella. La imagen de la estrella subiría y bajaría de brillo de manera característica conforme el cuerpo oscuro se moviera atravesando la línea de visión. Aunque el cuerpo en sí seguiría siendo invisible, su presencia se inferiría del efecto lente. Algunos astrónomos utilizan esta técnica para buscar objetos oscuros en el halo de la Vía Láctea. Aunque la probabilidad de una alineación exacta con una estrella distante es increíblemente pequeña, la lente gravitatoria puede observarse si en el espacio hay suficientes objetos oscuros. A finales de 1993, un equipo conjunto australo-norteamericano que observaba estrellas en la Gran Nube de Magallanes desde el observatorio de Mount Stromlo, en Nueva Gales del Sur, informó de lo que parece ser el primer ejemplo definido de lente gravitatoria producido por una estrella enana en el halo de nuestra galaxia.

Los agujeros negros también actúan como lentes gravitatorias y se los ha buscado intensamente utilizando fuentes de radio extragalácticas (las ondas de radio se ven desviadas del mismo modo que las ondas de luz). Se han encontrado pocos candidatos, lo que produce la impresión de que los agujeros negros estelares o de masas galácticas seguramente no supongan demasiada materia oscura.

Sin embargo, no todos los agujeros negros habrían de aparecer en una búsqueda de lentes. Es posible que las extremadas condiciones que prevalecían muy poco después del big bang estimularan la formación de agujeros negros microscópicos, puede que no mayores que un núcleo atómico. Tales objetos tendrían una masa equivalente a la de un asteroide. De este modo podría ocultarse eficazmente una buena cantidad de masa, dispersa por todo el universo. Aun siendo sorprendente, se pueden poner límites a la observación hasta de estas entidades tan extravagantes. El motivo tiene que ver con lo que se llama efecto de Hawking, que explicaré adecuadamente en el capítulo 7. En resumidas cuentas, los agujeros negros microscópicos tienen tendencia a explotar en medio del bombardeo de partículas eléctricamente cargadas. La explosión se produce al cabo de un tiempo determinado que depende del tamaño del agujero: los más pequeños explotan antes. Un agujero de la masa de un asteroide explotará al cabo de diez mil millones de años, lo que quiere decir más o menos ahora. Uno de los efectos de ese tipo de explosión sería la creación de un pulso de ondas de radio, cosa que han controlado los radioastrónomos. No se han detectado pulsos que puedan ser de este tipo y por ello se ha calculado que no puede darse una explosión así más que una vez cada tres millones de años por año luz cúbico de espacio. Lo cual no significa que sólo una minúscula fracción de la masa del universo se encuentra en forma de agujeros negros microscópicos.

En conjunto, las estimaciones de la materia oscura del universo varían según el astrónomo. Es probable que la materia oscura supere en peso a la materia luminosa por lo menos en la proporción de diez a uno, y a veces se mencionan proporciones de cien a uno. Es una idea chocante que los astrónomos no sepan de qué está hecha la mayor parte del universo. Las estrellas que durante tanto tiempo se supuso que explicaban la mayor parte del universo resultan ser una parte relativamente pequeña del total.

Para la cosmología, el asunto crucial es el de si existe suficiente materia oscura como para detener la expansión del universo. La densidad mínima de materia que ya no puede detener la expansión se denomina «densidad crítica». Su valor puede calcularse en unas cien veces la densidad de la materia visible. Sigue siendo posible esa cantidad, aunque por los pelos. Es de esperar que la búsqueda de la materia oscura nos proporcione pronto un sí o un no definitivos, porque de ello depende nada menos que el destino final del universo.

Dado el estado actual de nuestros conocimientos no podemos decir si el universo se expandirá eternamente o no. Si alguna vez empieza a contraerse, surge la pregunta de cuándo ocurrirá tal cosa. La respuesta depende justamente de en qué cantidad exceda el peso del universo al peso crítico. Si es un 1% mayor que el peso crítico, el universo empezará a contraerse dentro de un billón de años más o menos; si es el 10% más, la contracción se adelanta a dentro de cien mil millones de años.

Mientras tanto, hay teóricos que creen que puede ser posible establecer el peso del universo sólo mediante el cálculo, sin necesidad de difíciles observaciones directas. La creencia de que los seres humanos podrían alcanzar un profundo conocimiento cosmológico gracias solamente al poder de la razón continúa una tradición que se remonta a los antiguos filósofos griegos. En nuestra era científica, cierto número de cosmólogos ha intentado formular composiciones matemáticas que nos darían la masa del universo como cantidad de valor fijado por un determinado conjunto de profundos principios. Son especialmente seductores aquellos sistemas en los que el número exacto de partículas del universo queda determinado en función de determinada fórmula numerológica. Estas meditaciones de sofá no se han ganado la aprobación de la mayoría de los científicos, por fascinantes que resulten. Sin embargo, en los últimos años se ha popularizado una teoría más convincente que hace una predicción definida sobre la masa del universo. Se trata del panorama inflacionario descrito en el capítulo 3.

Una de las predicciones de la teoría inflacionaria se refiere a la cantidad de materia del universo. Supongamos que el universo empieza con una densidad de masa mucho mayor o mucho menor que el valor crítico con el que no se produce la contracción. Cuando el universo entra en la fase inflacionaria, la densidad cambia drásticamente y lo cierto es que la teoría predice que se aproxima con mucha rapidez a la densidad crítica. Cuanto más se prolongue la inflación, más se acerca la densidad a su valor crítico. En la versión estándar de la teoría, la inflación tiene sólo una duración brevísima, de modo que a menos que el universo empezara milagrosamente con la exacta densidad crítica, saldrá de la fase inflacionaria con una densidad algo menor o algo mayor que la crítica.

Sin embargo, la aproximación a la densidad crítica durante la inflación se produce a una velocidad que crece exponencialmente de modo que lo más probable es que el valor final esté muy próximo al valor crítico, incluso para periodos inflacionarios que duraran tan sólo minúsculas fracciones de segundo. Aquí el significado de «exponencialmente» significa más o menos que para cada tic que siga habiendo inflación el tiempo transcurrido entre el big bang y el inicio de la contracción se duplica. De modo que si, por ejemplo, cien tics de inflación hacen que la contracción ocurra cien mil millones de años después, entonces ciento un tics harán que la contracción ocurra doscientos mil millones de años después, mientras que ciento diez tics llevarán a una contracción cien billones de años después. Y así sucesivamente.

¿Y cuánto duró la inflación? Nadie lo sabe, pero para que la teoría explique con éxito los numerosos rompecabezas cosmológicos que acabo de describir, debió durar un mínimo de tics (más o menos cien: la cifra es bastante elástica). Sin embargo, no hay límite superior. Si por alguna extraordinaria casualidad el universo se hubiera inflado sólo el mínimo que explicara nuestras observaciones actuales, entonces la densidad posterior a la inflación seguiría estando significativamente por encima (o por debajo) del valor crítico, en cuyo caso las observaciones venideras deberían poder determinar la época en que se producirá la contracción o el hecho de que no vaya a haber contracción. Mucho más probable es que la inflación se prolongara durante muchos más tics que ese mínimo dando como resultado una densidad ciertamente muy próxima al valor crítico. Lo cual significa que si el universo va a contraerse tal cosa no se producirá todavía durante una enorme cantidad de tiempo: muchísimas veces la edad actual del universo. De ser éste el caso, los seres humanos nunca conocerán el destino del universo que habitan.

CAPÍTULO 7: LA ETERNIDAD ES MUY LARGA

Lo importante de lo infinito es que no se trata simplemente de un número muy grande. Lo infinito es cualitativamente diferente de otra cosa que sea fantástica e inimaginablemente grande. Supongamos que el universo siguiera expandiéndose toda la eternidad de manera que no tuviera fin. Que durara toda la eternidad significa que tendría una vida infinita. Si éste fuera el caso, cualquier proceso físico, por lento o improbable que fuera, tendría que darse alguna vez, del mismo modo que el mono que trasteara eternamente con una máquina de escribir terminaría por escribir las obras de William Shakespeare.

Un buen ejemplo lo proporciona el fenómeno de la emisión de ondas gravitatorias que examiné en el capítulo 5. Sólo en el caso de los procesos astronómicos más violentos la pérdida de energía en forma de radiación gravitatoria producirá cambios conspicuos. La emisión de aproximadamente un milivatio generado por el orbitar de la Tierra en torno al Sol tiene un efecto infinitesimal sobre el movimiento de la Tierra. Sin embargo, una pérdida continuada de un milivatio a lo largo de billones y billones de años terminaría por hacer que la Tierra se acercara al Sol describiendo una espiral. Por supuesto que lo más probable es que el Sol la engulla antes de que tal cosa ocurra, pero la cuestión es que los procesos que son despreciables a la escala temporal humana, pero que aun así son persistentes, pueden terminar por predominar y servir de tal manera para determinar el destino definitivo de los sistemas físicos.

Imaginemos el estado del universo dentro de muchísimo, muchísimo tiempo, por ejemplo, dentro de un cuatrillón de años. Las estrellas ya se han apagado hace mucho tiempo; el universo es oscuro. Pero no vacío. Por la negra vastedad del espacio rondan agujeros negros que rotan, estrellas de neutrones a la deriva y enanas negras, incluso algunos pocos cuerpos planetarios. En esa época, la densidad de tales objetos es extremadamente baja: el universo se ha expandido diez mil billones de veces más que su actual tamaño.

La gravedad libraría siempre una extraña batalla. El universo en expansión intenta apartar unos de otros a todos los objetos pero las atracciones gravitatorias mutuas se oponen a ello e intentan acercar los cuerpos. Como resultado, ciertos conjuntos de cuerpos (por ejemplo, los cúmulos de galaxias o lo que lleguen a ser las galaxias después de eones de degradación estructural) siguen gravitatoriamente unidos, pero estos conjuntos siguen apartándose de los demás conjuntos vecinos. El resultado definitivo de esta tirasoga depende de la rapidez con que se desacelere la tasa de expansión. Cuanto más baja sea la densidad de la materia en el universo, más «impulso» recibirán estos conjuntos de cuerpos para que se desentiendan de sus vecinos y se muevan libre e independientemente.

Dentro de un sistema gravitatorio de unión los lentos pero inexorables procesos de la gravedad ejercen su dominio. La emisión de ondas gravitatorias, por débil que sea, va drenando poco a poco la energía del sistema originando una lenta espiral de muerte. Aun de forma tan gradual, las estrellas muertas se van acercando a otras estrellas muertas o agujeros negros y se funden en una orgía de canibalismo generalizada. Hace falta un cuatrillón de años para que las ondas gravitatorias degraden por completo la órbita del Sol, una ceniza enana negra que se desliza hacia el centro galáctico en donde un gigantesco agujero negro lo espera para engullirlo.

Sin embargo, no deja de ser cierto que el Sol muerto encontrará su defunción definitiva de esta guisa, porque conforme vaya dirigiéndose lentamente hacia el centro se irá encontrando ocasionalmente con otras estrellas. A veces pasará cerca de un sistema binario, de un par de estrellas ligadas por su estrecho abrazo gravitatorio. Estará dispuesto entonces el escenario para un curioso fenómeno llamado honda gravitatoria. El movimiento de dos cuerpos en órbita uno en torno al otro exhibe una simplicidad clásica. Éste fue el problema (bajo el disfraz del planeta que gira en torno al Sol) que ocupó a Kepler y Newton y condujo al nacimiento de la ciencia moderna. En una situación ideal, y sin considerar la radiación gravitatoria, el movimiento del planeta es regular y periódico. No importa lo que se espere, el planeta sigue orbitando igual. Sin embargo, la situación es drásticamente diferente si se halla presente un tercer cuerpo, por ejemplo una estrella y dos planetas o tres estrellas. El movimiento deja de ser sencillo y periódico. La pauta de las fuerzas mutuas entre los tres cuerpos cambia continuamente de manera muy complicada. El resultado es que la energía del sistema no la comparten por igual todos los participantes, incluso siendo cuerpos idénticos. En vez de eso, se da un complejo baile en el que la parte del león de la energía se la lleva primero un cuerpo y luego otro. A lo largo de periodos largos de tiempo, el comportamiento del sistema puede ser fundamentalmente aleatorio: de hecho, el problema de dinámica gravitatoria de los tres cuerpos es un buen ejemplo de lo que se llama sistema caótico. Puede ocurrir que dos de los cuerpos «se compinchen» transmitiendo tanta energía del total disponible al tercer cuerpo que lo expulsen por completo del sistema, como sale disparado el proyectil de una honda. De ahí el término «honda gravitatoria».

El mecanismo de la honda puede expulsar estrellas de cúmulos estelares o incluso de la propia galaxia. En un futuro lejano, la gran mayoría de las estrellas muertas, de los planetas y de los agujeros negros saldrán disparados al espacio intergaláctico de esta manera, puede que para toparse con otra galaxia en desintegración o para vagar para siempre en el vasto vacío que se expande. Sin embargo, es un proceso lento: hará falta un tiempo mil millones de veces mayor que la edad actual del universo para que se complete tal disolución. El escaso porcentaje de objetos restantes emigrará, por el contrario, a los centros de las galaxias para fundirse unos con otros y formar agujeros negros gigantescos.

Como expliqué en el capítulo 5, los astrónomos tienen buenas pruebas de que existen ya monstruosos agujeros negros en el centro de algunas galaxias, aspirando glotonamente torbellinos de gases y liberando como resultado inmensas cantidades de energía. Con el tiempo, a la mayoría de las galaxias les esperará tal frenesí alimenticio, que proseguirá hasta que la materia que rodea al agujero negro haya sido absorbida o dispersada, puede que para volver a caer o para unirse a los menguantes gases intergalácticos. El hinchado agujero negro permanecerá tranquilo, con sólo alguna estrella de neutrones despistada o un pequeño agujero negro cayendo en su interior. Con todo, tampoco será éste el final de la historia del agujero negro. En 1974, Stephen Hawking descubrió que, después de todo, los agujeros negros tampoco son tan negros. Porque, a su vez, emiten un débil resplandor de radiación de calor.

El efecto Hawking puede entenderse apropiadamente sólo con la ayuda de la teoría cuántica de campos, una difícil rama de la física a la que ya he aludido en relación con la teoría de universo inflacionario. Recuérdese que un principio esencial de la teoría cuántica es el principio de incertidumbre de Heisenberg, según el cual las partículas cuánticas no poseen valores netamente definidos para todos sus atributos. Por ejemplo, un fotón o un electrón no pueden tener un valor definido para su energía en un momento determinado del tiempo. En efecto, una partícula subatómica puede «tomar prestada» energía siempre que la devuelva enseguida.

Como señalé en el capítulo 3, la incertidumbre de energía lleva a varios efectos curiosos, como la presencia fugaz de partículas de vida corta, o partículas virtuales, en el espacio aparentemente vacío. Ello nos lleva al extraño concepto de «vacío cuántico», vacío que lejos de ser vacío e inerte, bulle con la actividad de las inquietas partículas virtuales. Aunque esta actividad suele pasar desapercibida, sí puede producir efectos físicos. Uno de esos efectos se produce cuando la actividad del vacío se ve perturbada por la presencia de un campo gravitatorio.

Un caso extremo se refiere a las partículas virtuales que aparecen cerca del horizonte de sucesos de un agujero negro. Recuérdese que las partículas virtuales viven de energía prestada durante un brevísimo tiempo, tras el cual debe «devolverse» la energía con lo que las partículas se ven obligadas a desaparecer. Si por cualquier motivo las partículas virtuales reciben un impulso energético lo suficientemente grande proveniente de una fuente externa durante su breve tiempo asignado, el préstamo se puede resolver a su favor. Entonces las partículas ya no tienen ninguna obligación de desaparecer para devolverlo. El efecto de esta beneficencia es por lo tanto el de que las partículas virtuales se ven ascendidas a partículas reales, las cuales pueden disfrutar de una existencia más o menos permanente.

Según Hawking, esa beneficencia para liquidar el préstamo es exactamente la que se da cerca de un agujero negro. En ese caso, el «benefactor» que proporciona la energía requerida es el campo gravitatorio del agujero negro. Y así se desarrolla el trato. Las partículas virtuales suelen crearse en pares que se mueven en direcciones opuestas. Imaginemos uno de esos pares de partículas recién aparecidas justamente en la parte externa del horizonte de sucesos. Supongamos que el movimiento de las partículas sea de tal manera que una de ellas caiga en el agujero atravesando el horizonte. A su paso captará una enorme cantidad de energía de la intensa gravedad del agujero. Este impulso de energía, según descubrió Hawking, es suficiente para «liquidar el préstamo» por entero y ascender tanto a la partícula que cae como a su pareja (que sigue fuera del horizonte de sucesos) al estatuto de partículas reales. El destino de la partícula abandonada fuera del horizonte es azaroso. Podría también terminar por verse engullida por el agujero o podría salir disparada a gran velocidad y escapar por completo del agujero negro. Hawking predice así que debe haber un flujo constante de estas partículas huidas que salen al espacio desde las proximidades del agujero, constituyendo lo que se conoce como radiación de Hawking.

El efecto Hawking alcanzaría su mayor fuerza en los agujeros negros microscópicos. Como un electrón virtual, por ejemplo, puede recorrer como mucho 10-11 centímetros en condiciones normales antes de que se le reclame el préstamo, sólo los agujeros negros de menor tamaño que ése (lo que es decir, aproximadamente, de dimensiones nucleares) serán efectivamente capaces de crear una corriente de electrones. Si el agujero es mayor, la mayoría de los electrones virtuales no tendrá tiempo suficiente para cruzar el horizonte antes de devolver su préstamo.

La distancia que puede atravesar una partícula virtual depende de lo que viva, lo que a su vez viene dado (vía el principio de incertidumbre de Heisenberg) por el tamaño del préstamo de energía. A mayor préstamo, más corta la vida de la partícula. Un componente importante del préstamo de energía es la energía de la masa en reposo de la partícula. En el caso de un electrón, el préstamo tiene que ser por lo menos igual a la energía de masa en reposo del electrón. Para una partícula de mayor masa en reposo, por ejemplo un protón, el préstamo sería mayor y por lo mismo más breve, de modo que la distancia recorrida sería menor. Por lo tanto, la producción de protones mediante el efecto Hawking exige un agujero negro todavía más pequeño que el de dimensión nuclear. A la inversa, las partículas con masa en reposo menor que la de los electrones, por ejemplo los neutrinos, se crearían en un agujero negro de dimensión mayor que un núcleo. Los fotones, que tienen masa en reposo nula se crearán en un agujero negro de cualquier dimensión. Hasta un agujero negro de una masa solar tendrá un flujo Hawking de fotones y posiblemente también de neutrinos; sin embargo, en esos casos, la intensidad del flujo es muy débil.

Utilizar aquí la palabra «débil» no es ninguna exageración. Hawking descubrió que el espectro de energía producido por un agujero negro es el mismo que el que irradia un cuerpo caliente, de modo que una manera de expresar la fuerza del efecto Hawking es hacerlo en función de la temperatura. Para un agujero de tamaño nuclear (10-13 centímetros de diámetro), la temperatura es muy alta, unos diez mil millones de grados. Por contra, un agujero negro que pese una masa solar y tenga algo más de un kilómetro de diámetro, tiene una temperatura de menos de una diez millonésima de grado por encima del cero absoluto. Todo el objeto en su conjunto no emitiría más que la milésima parte de una cuatrillonésima de vatio en forma de radiación de Hawking.

Una de las rarezas del efecto Hawking es que la temperatura de la radiación aumenta cuando la masa del agujero negro desciende. Lo cual significa que los agujeros pequeños son más calientes que los grandes. Conforme va irradiando un agujero negro, va perdiendo energía y por lo tanto masa, así que se encoge. En consecuencia se calienta más e irradia con más fuerza, y por lo tanto se encoge con más rapidez aún. El proceso es inestable en sí mismo y termina por desbocarse, con el agujero negro emitiendo energía y encogiéndose a un ritmo cada vez más rápido.

El efecto Hawking predice que todos los agujeros negros terminarán por desaparecer sin más en una bocanada de radiación. Los momentos últimos serán espectaculares, con la apariencia de una gran bomba nuclear, un breve relámpago de intenso calor seguido de... nada. Por lo menos eso es lo que la teoría parece indicar. Pero a algunos físicos no les gusta que un objeto material pueda contraerse para formar un agujero negro que a su vez se desvanezca dejando sólo radiación calorífica. Les preocupa que dos objetos tan distintos puedan terminar produciendo idéntica radiación calorífica sin que sobreviva información del cuerpo originario. Un acto de desaparición de este tipo viola todo tipo de las tan queridas leyes de conservación. Una propuesta alternativa es la de que el agujero que desaparezca deje tras de sí un minúsculo residuo que acaso contenga enormes cantidades de información. Sea como sea, una parte abrumadora de la masa del agujero se irradia en forma de calor y de luz.

El proceso de Hawking es casi inconcebiblemente lento. Un agujero de una masa solar tardaría 1066 años en desaparecer, mientras que un agujero supermasivo tardaría más de 1093 años. Y el proceso ni siquiera empezaría a darse hasta que la temperatura de fondo del universo no hubiera descendido por debajo de la del agujero negro, porque de lo contrario el calor que fluyera hacia el agujero desde el universo circundante superaría al calor que saliera del agujero gracias al efecto Hawking. La radiación cósmica calorífica de fondo dejada por el big bang está en este momento a una temperatura en torno a los tres grados por encima del cero absoluto y harían falta 1022 años antes de que se enfriara a un nivel que diera pérdidas netas de calor en los agujeros negros de una masa solar. El proceso de Hawking no es precisamente nada atractivo para sentarse a mirar.

Pero la eternidad es larga, y supuesta la eternidad, todos los agujeros negros, hasta los supermasivos, terminarán seguramente por desaparecer, siendo sus estertores de muerte relámpagos momentáneos de luz en el cielo tenebroso de la eterna noche cósmica, epitafios fugaces de la otrora existencia de mil millones de soles deslumbrantes.

¿Qué queda?

No toda la materia cae en agujeros negros. Tenemos que pensar en las estrellas de neutrones, enanas negras y planetas solitarios que vagabundean solos por los vastos espacios intergalácticos, por no mencionar el gas y el polvo tenues que nunca se han condensado en estrellas, así como los asteroides, cometas, meteoritos y trozos de rocas que atestan los sistemas estelares. ¿Sobreviven por siempre?

Aquí nos metemos en dificultades teóricas. Necesitamos saber si la materia ordinaria, la materia que nos forma a usted y a mí y al planeta Tierra, es absolutamente estable. La clave definitiva del futuro radica en la mecánica cuántica. Aunque los procesos cuánticos se asocian normalmente a los sistemas atómicos y subatómicos, las leyes de la física cuántica deberían ser aplicables a todo, incluso a los cuerpos macroscópicos. Los efectos cuánticos sobre objetos grandes son extremadamente minúsculos, pero a lo largo de periodos muy prolongados de tiempo deberían ser capaces de producir cambios apreciables.

Los sellos de la física cuántica son la incertidumbre y la probabilidad. En el reino de lo cuántico no hay nada seguro salvo lo improbable. Lo que significa que, si un proceso es posible, dado un tiempo suficiente terminará por ocurrir por improbable que sea. Podemos observar cómo funciona esta regla en el caso de la radiactividad. Un núcleo de uranio 238 es casi completamente estable. Sin embargo, hay una probabilidad minúscula de que desprenda una partícula alfa y se transmute en torio. Para ser exactos, hay una probabilidad cierta pequeñísima por unidad de tiempo de que un núcleo de uranio dado se descomponga. Por término medio, hacen falta unos cuatro mil quinientos millones de años para que se produzca, pero como las leyes de la física exigen una probabilidad fija por unidad de tiempo cualquier núcleo de uranio dado terminará ciertamente por descomponerse.

La descomposición radiactiva alfa se da porque hay una pequeña incertidumbre en la disposición de los protones y los neutrones que componen el núcleo del átomo de uranio, de modo que siempre hay una diminuta probabilidad de que haya un cúmulo de estas partículas momentáneamente situadas fuera del núcleo, de donde se ven expulsadas de inmediato. Del mismo modo, hay una incertidumbre todavía menor, pero aun así no nula, de la posición exacta de un átomo en un sólido. Por ejemplo, un átomo de carbono en un diamante estará ubicado en una posición muy bien definida en la estructura del cristal y a las temperaturas cercanas al cero que se esperan para ese futuro lejanísimo esa posición será muy estable. Pero no del todo. Siempre hay una diminuta incertidumbre en la posición del átomo, lo que implica una diminuta probabilidad de que el átomo salte espontáneamente de su sitio en la estructura y aparezca en otra parte. Debido a estos procesos de migración, nada, ni siquiera una sustancia tan dura como el diamante, es verdaderamente sólido. Por el contrario, la materia aparentemente sólida es como un líquido muy viscoso y a lo largo de muchísimo tiempo puede fluir debido a los efectos mecánico-cuánticos. El físico teórico Freeman Dyson ha estimado que después de transcurridos unos 1065 años no sólo todos los diamantes cuidadosamente tallados se habrán reducido a cuentas esféricas, sino que cualquier pedazo de roca se habrá convertido en consecuencia en una blanda pelota.

La incertidumbre sobre la posición podría incluso llevar a transmutaciones nucleares. Consideremos, por ejemplo, dos átomos de carbono adyacentes en un cristal de diamante. Muy rara vez, la recolocación espontánea de uno de esos átomos hará que su núcleo aparezca momentáneamente pegado al núcleo del átomo adyacente. Las fuerzas nucleares de atracción pueden entonces hacer que los dos núcleos se fundan para formar un núcleo de magnesio. Esta fusión nuclear no requiere temperaturas altísimas: la fusión fría es posible pero exige una fantástica duración de tiempo. Dyson ha estimado que al cabo de 101500 años (es decir, ¡un 1 seguido de mil quinientos ceros!) toda la materia se transmutará de este modo a la forma nuclear más estable, que es la del elemento hierro.

Sin embargo, puede que la materia nuclear no sobreviva tanto tiempo debido a procesos de transmutación más rápidos, aunque aun así increíblemente lentos. La estimación de Dyson supone que los protones (y los neutrones ligados en núcleos) son absolutamente estables. En otras palabras, si un protón no cae en un agujero negro y no se le perturba de ninguna otra manera, durará toda la eternidad. Pero ¿podemos estar seguros de que es así? En mi época de estudiante nadie lo dudaba. Los protones eran eternos. Se suponía que eran partículas por completo estables. Pero siempre hay una duda que nos ronda. El problema se refiere a la existencia de la partícula llamada positrón, idéntica al electrón salvo en que, como el protón, tiene carga positiva. Los positrones son mucho más ligeros que los protones de modo que, a igualdad de las restantes condiciones, los protones prefieren transmutarse en positrones: es un profundo principio de la física que los sistemas físicos buscan su estado energético más bajo y una masa menor significa menor energía. Ahora bien, nadie sabría decir por qué los protones no se limitan a hacer tal cosa, de modo que los físicos han dado por supuesto que existe una ley de la naturaleza que lo prohibía. Hasta hace poco, este asunto no se comprendía nada bien, pero a finales de los años 70 surgió una imagen algo más clara en relación a cómo las fuerzas nucleares impulsan a las partículas a transmutarse unas en otras por medio de la mecánica cuántica. Las últimas teorías tienen un lugar natural para la ley que prohibe la descomposición de los protones, pero la mayoría de estas leyes predice también que la ley no es efectiva al ciento por ciento. Podría haber una pequeñísima probabilidad de que un protón dado se transmutara en positrón. Se predice que la masa restante aparezca parte en forma de una partícula eléctricamente neutra, como la llamada pión, y parte en forma de energía de movimiento (los productos de la descomposición se crearían a alta velocidad).

En uno de los modelos teóricos más sencillos, el tiempo medio exigido para que un protón se descomponga es de 1028 años, tiempo que es un trillón de veces más largo que la edad actual del universo. Podríamos creer entonces que este asunto de la descomposición del protón sigue siendo una curiosidad puramente académica. Sin embargo, debe recordarse que el proceso pertenece a la mecánica cuántica y de ahí su naturaleza inherentemente probabilística: 1028 es la vida media promedio que se predice, no la vida media real de cada protón. Dado un número suficiente de protones, hay una buena probabilidad de que se descomponga alguno delante de nuestros propios ojos. De hecho, dados 1028 protones podríamos esperar aproximadamente una descomposición por año, y esos 1028 protones se encuentran contenidos en nada más que 10 kilogramos de materia.

Da la casualidad de que la vida de un protón de esta duración se había descartado experimentalmente antes de que se popularizara la teoría. Sin embargo, hay diferentes versiones de la teoría que dan vidas más largas: 1030 o 1032 años o incluso más (algunas teorías predicen vidas de hasta 1080 años). Los valores inferiores se encuentran dentro del margen de la comprobación experimental. Un tiempo de descomposición de 1032 años, por ejemplo, significaría que por este sistema perderíamos uno o dos protones de nuestro cuerpo durante nuestra vida. Pero ¿cómo detectar acontecimientos tan raros?

La técnica adoptada ha sido la de reunir miles de toneladas de materia y controlarla durante muchos meses con detectores sensibles ajustados para dispararse ante los productos de la descomposición de un protón. Desgraciadamente, la búsqueda de la descomposición de un protón es como la de buscar una aguja en un pajar porque esas descomposiciones aparecen enmascaradas por un número mucho mayor de sucesos parecidos ocasionados por los productos de la radiación cósmica. La Tierra se ve continuamente bombardeada por partículas de alta energía provenientes del espacio que producen un residuo subatómico de fondo siempre presente. Para reducir esta interferencia, hay que hacer los experimentos a una buena profundidad bajo tierra.

Uno de tales experimentos se organizó a más de medio kilómetro de profundidad en una mina de sal cerca de Cleveland (Ohio). El tinglado consistió en 10.000 toneladas de agua ultrapura metida en un tanque cúbico rodeado de detectores. Se eligió el agua por su transparencia, para que permitiera a los detectores «ver» tantos protones a la vez como fuera posible. La idea era la siguiente: si un protón se descompone tal y como predicen las teorías al uso entonces produce, como se ha explicado, un pión eléctricamente neutro además de un positrón. A su vez el pión se descompone enseguida, por lo general en dos fotones muy energéticos o rayos gamma. Por último, estos rayos gamma topan con los núcleos del agua y cada uno de ellos engendra un par electrón-positrón, también muy energéticos. De hecho, estos electrones y positrones secundarios serían tan energéticos que viajarían a una velocidad cercana a la de la luz, incluso en el agua.

La luz viaja a 300.000 kilómetros por segundo en el vacío y ésa es la velocidad límite a la que puede viajar cualquier partícula. Ahora bien, el agua tiene el efecto de rebajar un tanto la velocidad de la luz, aproximadamente hasta unos 230.000 kilómetros por segundo. Por lo tanto, una partícula subatómica de alta velocidad que se moviera a casi 300.000 kilómetros por segundo en el agua viajaría a mayor velocidad que la luz en el agua. Cuando los aviones viajan a mayor velocidad que el sonido, crean una onda sonora. De manera parecida, una partícula cargada que viajara por un medio a mayor velocidad que la de la luz en ese medio crearía una onda de choque electromagnética distintiva, llamada radiación Cerenkov por su descubridor ruso. De manera que los experimentadores de Ohio montaron una serie de detectores sensibles a la luz para identificar los relámpagos de Cerenkov. Para poder distinguir los sucesos de descomposición de protones de los neutrinos cósmicos y de otra basura cósmica espuria, los experimentadores buscaban una firma característica: pares simultáneos y opuestos de pulsos de luz de Cerenkov, que habrían sido emitidos por cada par electrón-positrón moviéndose en direcciones opuestas.

Desgraciadamente, después de varios años de funcionamiento, el experimento de Ohio fracasó en descubrir pruebas convincentes de la descomposición del protón, aunque, como se indicó en el capítulo 4, sí detectó los neutrinos de la Supernova 1987 A. (Como ocurre tantas veces en la ciencia, buscar una cosa lleva al descubrimiento inesperado de otra.) Otros experimentos, con montajes diferentes, han llevado también a resultados nulos hasta el momento en que escribo. Esto puede querer decir que los protones no se descomponen. Por otro lado, puede querer decir que sí se descomponen pero que su vida supera con mucho los 1032 años. Medir una tasa de descomposición menor que ésta queda fuera de la posibilidad experimental actual, así que seguramente nuestro juicio sobre la descomposición del protón quedará en suspenso durante el futuro previsible.

La búsqueda de la descomposición del protón se vio estimulada por el trabajo teórico sobre las grandes teorías de unificación que ponen su objetivo en la unificación de la fuerza nuclear fuerte (la fuerza que une a los protones y a los neutrones en el núcleo) con la fuerza nuclear débil (responsable de la radiactividad beta) y la fuerza electromagnética. La descomposición del protón sería resultado de la íntima mezcla de estas tres fuerzas. Pero incluso si esta idea de gran unificación resulta estar equivocada, queda la posibilidad de que los protones se descompongan de algún otro modo: un modo que suponga la acción de la cuarta fuerza fundamental de la naturaleza, la gravedad.

Para ver cómo la gravedad puede originar la descomposición del protón, es necesario tener en cuenta el hecho de que el protón no es de verdad una partícula elemental con forma definida. En realidad es un cuerpo compuesto de tres partículas menores llamadas quarks. La mayor parte del tiempo el protón tiene un diámetro de aproximadamente de una diez billonésima de centímetro, que es la distancia media entre quarks. Sin embargo, los quarks no están en reposo, sino que sin parar intercambian sus posiciones en el interior del protón debido a la incertidumbre de la mecánica cuántica. De vez en cuando, dos quarks se aproximan mucho. Y todavía con menos frecuencia, los tres quarks se encuentran en una estrechísima proximidad. Y es posible que los quarks se acerquen tanto que la fuerza gravitatoria que existe entre ellos, y que normalmente es despreciable, supere a todo lo demás. De ser así, los quarks se unirán para forman un minúsculo agujero negro. En efecto, el protón se contrae bajo su propia gravedad mediante una perforación mecánica cuántica. El miniagujero resultante es muy inestable (recuérdese el proceso de Hawking) y se desvanece más o menos instantáneamente creando un positrón. Las estimaciones de la vida media del protón con este tipo de decadencia son muy inciertas y varían desde los 1045 años a unos increíbles 10220 años.

Si los protones se descomponen tras una duración inmensa, las consecuencias para el futuro lejano del universo son importantes. Toda la materia sería inestable y terminaría por desaparecer. Los objetos sólidos, como los planetas, que hayan eludido caer en un agujero negro no durarían por siempre. En lugar de eso, se irían evaporando muy gradualmente. Una vida media del protón de, digamos, 1032 años supondría que la Tierra perdería un billón de protones por segundo. A ese ritmo, nuestro planeta se habría desvanecido efectivamente al cabo de unos 1033 años, suponiendo que antes no lo hubiera destruido ninguna otra cosa.

Las estrellas de neutrones no son inmunes a este proceso. Los neutrones también están hechos de tres quarks y pueden transmutarse en partículas más ligeras mediante mecanismos parecidos a los que suponen la defunción de los protones. (En cualquier caso, los neutrones aislados son inestables y se descomponen al cabo de unos quince minutos.) Las estrellas enanas blancas, las rocas, el polvo, los cometas, las tenues nubes de gas y demás parafernalia astronómica sucumbiría del mismo modo en la eternidad del tiempo. Las 1048 toneladas de materia ordinaria que observamos en la actualidad esparcida por todo el universo está destinada a desaparecer o en los agujeros negros o por medio de una lenta descomposición nuclear.

Por supuesto que cuando los protones y los neutrones se descomponen, crean productos de descomposición, de modo que el universo no se queda necesariamente carente de materia alguna. Por ejemplo, y como ya se ha mencionado, una vía probable para la descomposición del protón es dar un positrón más un pión neutro. El pión es muy inestable y enseguida se descompone en dos fotones o puede que en un par electrón-positrón. Sea cual sea el caso, el universo irá adquiriendo poco a poco más y más positrones como resultado de la descomposición de los protones. Los físicos creen que el número total de partículas del universo cargadas positivamente (en la actualidad, sobre todo protones) es el mismo que el número de partículas cargadas negativamente (electrones sobre todo). Lo cual supone que una vez que se hayan descompuesto todos los protones habrá una mezcla a partes iguales de electrones y positrones. Ahora bien, el positrón es la llamada antipartícula del electrón y si un positrón se encuentra con un electrón se aniquilan ambos (proceso ya estudiado en el laboratorio) liberando energía en forma de fotones.

Se han hecho cálculos para intentar determinar si los positrones y los electrones que queden en un futuro lejano del universo se aniquilarían unos a otros por completo o si siempre quedaría un pequeño residuo. La aniquilación no se produce bruscamente. En su lugar, el electrón y el positrón se disponen primero en una especie de miniátomo llamado positronio, en el que ambas partículas bailan la danza de la muerte orbitando en torno al centro común de sus masas, ligadas por su mutua atracción eléctrica. Las partículas caen entonces una hacia la otra y se aniquilan. El tiempo de caída hacia la otra partícula depende de la distancia inicial entre positrón y electrón cuando se forma el «átomo» de positronio. En el laboratorio, el positronio se descompone en una minúscula fracción de segundo, pero en el espacio exterior, con pocas perturbaciones, electrones y positrones podrían quedar ligados en órbitas enormes. Las estimaciones indican que harían falta 1071 años para que la mayoría de los electrones y positrones formaran positronios, pero en la mayor parte de los casos sus órbitas tendrían ¡muchos billones de años luz de diámetro! Las partículas se moverían tan despacio que tardarían un millón de años en avanzar un centímetro. Los electrones y los positrones se habrían hecho tan perezosos que el tiempo de caída sería la fabulosa cantidad de 10116 años. Con todo, el destino final de estos átomos de positronio está sellado desde el momento mismo de su formación.

Lo que es curioso es que no todos los electrones y positrones tengan que aniquilarse necesariamente. Mientras electrones y positrones buscan a sus opuestos, la densidad de estas partículas va decreciendo siempre, tanto como resultado de la aniquilación como también por la continua expansión del universo. Conforme pase el tiempo, será más difícil que se forme un positronio. De modo que aunque el minúsculo residuo de materia residual vaya siendo cada vez menor, no desaparece nunca por completo. Siempre habrá algún electrón o positrón suelto por algún sitio, incluso aunque esa partícula habite en soledad en el interior de un volumen de espacio vacío cada vez más grande.

Podemos ahora hacernos una imagen de lo que sería el universo después de que se hayan completado todos estos procesos increíblemente lentos. Primero, quedará el resto dejado por el big bang, el fondo cósmico que siempre ha estado ahí. Consiste en fotones y neutrinos y puede que en algunas otras partículas completamente estables de las que no sabemos nada todavía. La energía de estas partículas irá decreciendo conforme se vaya expandiendo el universo hasta que formen un fondo despreciable. La materia corriente del universo habrá desaparecido. Se habrán evaporado todos los agujeros negros. La mayor parte de los agujeros negros se habrá transformado en fotones, aunque otros se habrán transformado en neutrinos y una fracción minúscula, emitida durante el último estallido de los agujeros, estará en forma de electrones, protones, neutrones y partículas más pesadas. Todas las partículas más pesadas se descomponen rápidamente y protones y neutrones se descomponen con más lentitud, dejando unos pocos electrones y positrones que se unen a los que quedan como último residuo de la materia corriente tal y como la vemos en la actualidad.

El universo del futuro lejanísimo será así una sopa inconcebiblemente aguada de fotones, neutrinos y de un número menguante de electrones y positrones, cada vez más alejados unos de otros. Por lo que sabemos, no ocurrirán más procesos físicos nunca jamás. No se dará ningún suceso significativo que altere esa árida esterilidad de un universo que ha acabado sus días y que sin embargo se enfrenta a la vida eterna: quizá muerte eterna sea una descripción más ajustada.

Esta sombría imagen de una casi-nada, fría, oscura, sin diferenciar, es lo más cercano a la «muerte térmica» de la física decimonónica que llega a la moderna cosmología. El tiempo que necesita el universo para degenerar hasta este estado es tan largo que desafía la imaginación humana. Y, sin embargo, sólo es una porción infinitesimal del infinito tiempo disponible. Como ya he señalado, la eternidad es muy larga.

Aunque la decadencia del universo ocupa una duración que excede tan enormemente la escala humana de tiempo que en la práctica carece de sentido para nosotros, todavía nos acomete la ansiedad de preguntarnos: «¿Qué le ocurrirá a nuestros descendientes? ¿Están fatalmente condenados por un universo que se irá cerrando lenta pero inexorablemente a su alrededor?» Dado el poco prometedor estado que la ciencia predice para el universo lejanísimo, da la impresión de que cualquier forma de vida debe estar condenada definitivamente. Pero la muerte no es tan sencilla.

CAPÍTULO 8: LA VIDA AL PASO

En 1972, una organización conocida como Club de Roma hizo pública una fúnebre predicción sobre el futuro de la humanidad bajo el título Los límites del crecimiento. Entre sus muchas advertencias de desastre inminente estaba la predicción de que las reservas de combustibles fósiles del mundo se acabarían dentro de muy pocas décadas. Hubo alarma general, subieron los precios del crudo y se puso de moda la investigación sobre energías alternativas. Ya estamos en la frontera del siglo XXI y todavía no hay señal de que los combustibles fósiles estén a punto de agotarse. Como resultado, la complacencia ha ocupado el lugar de la alarma. Desgraciadamente, la simple aritmética dictamina que un recurso finito no puede explotarse para siempre a una tasa finita que no disminuya. Antes o después el problema energético se echará encima. Conclusión parecida puede obtenerse en relación con la población de la Tierra: no puede seguir creciendo indefinidamente.

Algunos Jeremías creen que las crisis subsiguientes de energía y de superpoblación acabarán con la humanidad de una vez por todas. Con todo, tampoco hay necesidad de establecer un paralelismo entre la desaparición de los combustibles fósiles y la desaparición del Homo sapiens. A nuestro alrededor hay enormes fuentes de energía y nos basta tener la voluntad y el ingenio para someterlas. Lo más llamativo es que la luz solar tiene energía más que suficiente para nuestros propósitos. Problema mayor es controlar el crecimiento de la población antes de que una hambruna generalizada lo haga por nosotros. Para ello se requieren capacidades sociales, económicas y políticas más que científicas. Sin embargo, si queremos superar el cuello de botella energético originado por el agotamiento de los combustibles fósiles, si podemos estabilizar la población humana sin conflictos desastrosos y si puede limitarse el daño ecológico y de impactos de asteroides sobre el planeta, creo que la humanidad florecerá. No hay ninguna aparente ley de la naturaleza que limite la longevidad de nuestra especie.

En capítulos anteriores he descrito cómo a lo largo de duraciones temporales mareantes cambiará la estructura del universo (generalmente en el sentido de la degradación) como resultado de lentos procesos físicos. Los humanos llevamos en la Tierra como mucho unos cinco millones de años (dependiendo de qué definición de «humano» empleemos) y la civilización (según un cierto tipo) unos pocos miles de años. La Tierra podría seguir siendo habitable unos dos mil o tres mil millones de años a partir de ahora, por supuesto con una población limitada. Es un lapso de tiempo tan enorme que supera a la imaginación. Puede parecer tan largo que parezca infinito. Sin embargo, ya hemos visto cómo incluso mil millones de años son un mero abrir y cerrar de ojos comparados con la escala temporal de los cambios astronómicos y cosmológicos grandes. Al cabo de un trillón de años pueden seguir existiendo en otros lugares de nuestra galaxia hábitats parecidos a los de la Tierra.

Ciertamente podemos imaginar a nuestros descendientes, con semejante cantidad de tiempo a su disposición, desarrollando la exploración del espacio y todo tipo de maravillosas tecnologías. Tendrán tiempo de sobra para abandonar la Tierra antes de que el Sol la achicharre. Podrán buscar otro planeta adecuado y luego otro, y otro, y así sucesivamente. Expandiéndose en el espacio, la población podrá expandirse también. ¿Nos proporciona esto un alivio... saber que nuestra lucha por la supervivencia en el siglo XXI no sea definitivamente en vano?

En el capítulo 2, señalé que Bertrand Russell, en un ataque de depresión por las consecuencias de la segunda ley de la termodinámica, escribió en términos angustiosos sobre la futilidad de la existencia humana debido al hecho de que el sistema solar está condenado. Russell sintió con claridad que la defunción aparentemente inevitable de nuestro hábitat dejaba en cierto modo sin sentido la vida humana o la convertía en una farsa. Esta creencia contribuyó sin duda a su ateísmo. ¿Se habría sentido mejor Russell de haber sabido que la energía gravitatoria de un agujero negro podía superar con mucho a la del Sol y durar billones de años después de haberse desintegrado el sistema solar? Seguramente no. Lo que cuenta no es la duración real del tiempo, sino la idea de que, antes o después, el universo será inhabitable; esta idea hace que algunos sientan que nuestra existencia no tenga sentido.

De la descripción dada al final del capítulo 7 sobre el futuro lejanísimo del universo, podría inferirse que apenas puede imaginarse un entorno menos hospitalario ni más hostil. Sin embargo, no debemos ser ni chovinistas ni pesimistas. Sin duda que los seres humanos lo pasarían mal intentando vivir en un universo consistente en una sopa diluida de electrones y positrones, pero lo importante no es si nuestra especie como tal es inmortal, sino si nuestros descendientes pueden sobrevivir. Y no es probable que nuestros descendientes sean seres humanos.

La especie Homo sapiens surgió en la Tierra como producto de la evolución biológica. Pero los procesos de la evolución se modifican rápidamente con nuestras propias actividades. Ya hemos interferido el funcionamiento de la selección natural. También se va haciendo cada vez más posible controlar las mutaciones. Pronto podremos diseñar seres humanos con atributos y características físicas deseados mediante manipulación genética directa. Estas posibilidades biotecnológicas han surgido en unas pocas décadas de sociedad tecnológica. Imaginemos lo que puede conseguirse con miles o incluso millones de años de ciencia y tecnología.

En cuestión de unas pocas décadas, la humanidad ha sido capaz de abandonar el planeta y aventurarse en el espacio próximo. A lo largo de los eones, nuestros descendientes podrían dispersarse más allá de la Tierra, en el sistema solar y luego en otros sistemas estelares dentro de la galaxia. La gente suele tener la errónea idea de que tal empresa tardaría casi una eternidad. No es así. La colonización seguramente avanzaría saltando de planeta en planeta. Los colonos abandonarían la Tierra buscando un planeta adecuado a unos pocos años luz de distancia y, si pudieran viajar a casi la velocidad de la luz, el viaje sólo duraría esos pocos años. Incluso si nuestros descendientes no llegaran a pasar del 1% de la velocidad de la luz (objetivo más bien modesto), entonces el viaje duraría sólo unos pocos siglos. El establecimiento real de una colonia puede necesitar de unos siglos más para completarse, momento en que los descendientes de los colonos originarios podrían pensar en organizar su propia expedición colonizadora hacia otro planeta adecuado aún más lejos. Al cabo de otros pocos cientos de años, ese planeta estaría colonizado y así sucesivamente. Así colonizaron los polinesios las islas del Pacífico central.

La luz tarda sólo unos cien mil años en atravesar la galaxia, de modo que al 1% de esa velocidad el tiempo total de viaje es de diez millones de años. Si a lo largo de la ruta se colonizan cien mil planetas y hacen falta dos siglos para establecerse en cada uno de ellos, la escala de tiempo de colonización galáctica no hace más que triplicarse. Pero treinta millones de años es un tiempo cortísimo en términos astronómicos e incluso geológicos. El Sol tarda doscientos millones de años en orbitar una vez en torno a la galaxia; la vida en la Tierra lleva existiendo por lo menos diecisiete veces más que ese tiempo. El envejecimiento del Sol amenazará seriamente a la Tierra dentro de dos mil o tres mil millones de años, de modo que dentro de treinta millones de años los cambios acontecidos serán bien pocos. La conclusión es que nuestros descendientes podrían colonizar la galaxia en una pequeña fracción del tiempo en que la vida tardó en evolucionar sobre la Tierra hasta una sociedad tecnológica.

¿Cómo serían estos colonizadores descendientes nuestros? Si damos rienda suelta a nuestra imaginación, podemos conjeturar que los colonos podrían estar manipulados genéticamente para adaptarse con facilidad al planeta de destino. Por dar un ejemplo sencillo, si un planeta parecido a la Tierra se descubriera en torno a la estrella Epsilon Eridani y tuviera sólo un 10% de oxígeno en su atmósfera, los colonos podrían estar manipulados para generar más glóbulos rojos. Si la superficie del nuevo planeta fuera mayor, podrían estar dotados de huesos y estructura ósea más fuertes. Y así sucesivamente.

Tampoco el viaje habría de presentar problemas, incluso si se tardara varios siglos en hacerlo. La nave espacial podría estar hecha a la manera de un arca: un ecosistema completamente autosuficiente capaz de sustentar a los viajeros durante muchas generaciones. O se podría en cambio ultracongelar a los colonos para el viaje. De hecho, tendría más sentido enviar sólo una nave pequeña y una tripulación junto con millones de óvulos fertilizados y congelados además de la carga. Podrían incubarse a la llegada proporcionando al instante una población sin necesidad de los problemas logísticos y sociológicos del transporte de un gran número de adultos durante mucho tiempo.

También y por especular con lo que podría ser posible al disponer de enormes cantidades de tiempo, no hay motivo por el cual estos colonos tuvieran que ser de apariencia humana ni siquiera de mentalidad humana. Si se puede manipular a los seres para afrontar distintas necesidades, entonces cada expedición podría incluir entes diseñados a propósito con la anatomía y la psicología adecuadas a su trabajo.

Ni siquiera haría falta que los colonos fueran organismos vivos según la definición habitual. Ya es posible implantar microprocesadores con chips de silicona en los seres humanos. Un mayor desarrollo de esta tecnología podría suponer la mezcla de partes orgánicas y electrónicas artificiales que realizaran funciones fisiológicas y cerebrales. Puede ser posible, por ejemplo, diseñar una memoria «incorporada» para los cerebros humanos, parecida a la de las memorias auxiliares que existen para los ordenadores. A la inversa, puede resultar más eficiente adaptar materia orgánica para realizar los procesos que fabricar dispositivos de estado sólido para ciertas tareas. En efecto, será posible «cultivar» componentes informáticos biológicamente. Lo más probable es que en muchas tareas los ordenadores digitales se vean reemplazados por redes neuronales; ya incluso se están usando redes neuronales en lugar de ordenadores digitales para simular la inteligencia humana y predecir el comportamiento económico. Y podría ser mejor cultivar redes neuronales orgánicas a partir de trocitos de tejido cerebral que manufacturarlas ab initio. Puede que también sea factible construir una mezcla simbiótica de redes orgánicas y artificiales. Con el desarrollo de la nanotecnología, la distinción entre lo vivo y lo no vivo, lo natural y lo artificial, el cerebro y el ordenador, se irá borrando cada vez más.

De momento esas especulaciones pertenecen al reino de la ciencia ficción. ¿Pueden convertirse en hechos científicos? Después de todo, por imaginar una cosa no va a suceder necesariamente. Sin embargo, podemos aplicar a los procesos tecnológicos el mismo principio que aplicamos a los procesos naturales: con tiempo suficiente por delante, todo lo que pueda suceder, sucederá. Si los humanos y sus descendientes continúan estando suficientemente motivados (cosa que plantea un gran condicionante), entonces la tecnología sólo estará limitada por las leyes de la física. Un reto como el proyecto del genoma humano, que puede ser una tarea ingente para una única generación de científicos, sería cosa sencilla si hubiera cien, mil o un millón de generaciones que se dedicaran a llevar a cabo el trabajo.

Adoptemos la posición optimista de que sobreviviremos y de que seguiremos desarrollando nuestra tecnología hacia sus límites. ¿Qué significa eso en relación con la exploración del universo? La construcción de seres semientes diseñados a propósito abriría la posibilidad de enviar agentes a los habitáis hasta ese momento inhóspitos para realizar tareas que hoy parecen impensables. Aunque estos seres puedan ser el resultado de la tecnología basada en los humanos no tendrían por qué ser humanos en sí mismos.

¿Deberíamos sentirnos preocupados por el destino de estos extraños entes? Muchas personas pueden sentir cierta repulsión por la perspectiva de que la humanidad se vea reemplazada por tales monstruos. Si la supervivencia exige que los seres humanos dejen paso a los robots orgánicos genéticamente manipulados puede que debiéramos optar por la extinción. Con todo, si la probabilidad de la defunción de la humanidad nos deprime, tenemos que preguntarnos qué es exactamente lo que queremos conservar de los seres humanos. Seguro que no se trata de nuestra forma externa. ¿De verdad que nos preocuparía que, por ejemplo dentro de un millón de años, nuestros descendientes hubieran perdido los dedos de los pies? ¿O que tuvieran las piernas más cortas o cabeza y cerebros mayores? Después de todo nuestra forma ha cambiado mucho a lo largo de los últimos siglos y hay amplias variaciones actualmente entre los distintos grupos étnicos.

Si se nos presiona, sospecho que la mayoría de nosotros apuntaría más a lo que podríamos llamar espíritu humano... nuestra cultura, nuestro conjunto de valores, nuestra distintiva configuración mental tal y como quedan ejemplificados en nuestros logros artísticos, científicos e intelectuales. Desde luego que estas cosas merecen preservarse y perpetuarse. Si pudiéramos traspasar nuestra humanidad esencial a nuestros descendientes, fuera cual fuera su forma, entonces se obtendría la supervivencia de lo que más importa.

Que sea posible crear seres parecidos a los humanos que se dispersen por todo el cosmos es, no cabe duda, altamente especulativo. Dejando aparte cualquier otra consideración, puede ocurrir que la humanidad pierda la motivación para tan grande empeño o que los desastres económicos, ecológicos o de otro tipo traigan nuestra muerte antes de que abandonemos el planeta. Puede incluso ocurrir que los seres extraterrestres estén por delante de nosotros Y hayan ya colonizado la mayor parte de los planetas adecuados (aunque evidentemente no la Tierra... todavía). Pero caiga la tarea sobre nuestros descendientes o sobre los de alguna especie ajena a nosotros, la posibilidad de esparcirse por el universo y controlarlo por medio de la tecnología es una posibilidad fascinante, y es tentador preguntarse cómo afrontaría una superraza esa lenta degeneración del universo.

Las duraciones de tiempo para la descomposición física examinadas en el capítulo 7 son tan enormes que cualquier intento de adivinar cómo pueda ser la tecnología en un futuro lejanísimo basándose en la extrapolación de las tendencias actuales de la Tierra son inútiles. ¿Quién puede imaginar una sociedad tecnológica de un billón de años de edad? Podría parecer que fuera capaz de alcanzarlo todo. Sin embargo, cualquier tecnología, por avanzada que fuera, seguramente seguiría estando sometida a las leyes de la física. Si, por ejemplo, la teoría de la relatividad es correcta en su conclusión de que cualquier cuerpo material no puede exceder la velocidad de la luz, entonces ni siquiera el esfuerzo tecnológico de un billón de años sería capaz de romper la barrera de la luz. O lo que es más serio, si toda actividad de interés supone gastar por lo menos algo de energía, entonces el agotamiento continuo de las fuentes libres de energía del universo terminará por presentar una seria amenaza para una comunidad tecnológica por avanzada que sea.

Aplicando los principios básicos de la física a la definición más amplia de seres sentientes, podemos investigar si la degeneración del universo en un futuro lejanísimo presenta algunos obstáculos fundamentales a su supervivencia. Para que a un ser se le pueda calificar de «sentiente» debe ser capaz, por lo menos, de procesar información. Pensar y experimentar son dos ejemplos de actividad que suponen procesado de la información. Así que, ¿qué exigencias podría suponer esto sobre el estado físico del universo?

Un rasgo característico del procesado de la información es que disipa energía. Ése es el motivo por el que el procesador de texto con el que mecanografío este libro tiene que estar conectado a la red eléctrica. La cantidad de energía gastada por unidad de información depende de consideraciones termodinámicas. La disipación es mínima cuando el procesador funciona a una temperatura parecida a la de su entorno. El cerebro humano y la mayoría de los ordenadores funcionan de modo muy ineficiente y disipan copiosas cantidades de energía sobrante en forma de calor. El cerebro, por ejemplo, produce una fracción significativa del calor corporal y muchos ordenadores necesitan un sistema especial de refrigeración para evitar que se fundan. El origen de este calor residual puede remontarse a la mismísima lógica sobre la cual funciona el procesado de la información y que exige descartar información. Por ejemplo, si un ordenador lleva a cabo el cálculo 1 +2 = 3, reemplaza dos unidades de información de entrada (1 y 2) por una unidad de información de salida (3). Una vez efectuada la operación, el ordenador puede descartar la información de entrada, reemplazando dos unidades por una sola. Lo cierto es que para evitar que sus bancos de memoria se colapsen, la máquina tiene que descartar continuamente toda esa información improcedente. El proceso de borrado es, por definición, irreversible, y por lo tanto produce un incremento de la entropía. De modo que, aparentemente en sus mismísimos fundamentos, la reunión de información y su procesado terminará por agotar irreversiblemente la energía disponible e incrementará la entropía del universo.

Freeman Dyson ha contemplado las limitaciones afrontadas por una colectividad de seres sentientes (restringidos por la necesidad de disipar energía a un cierto ritmo aunque sólo fuera para pensar) conforme el universo se va enfriando y avanza hacia su muerte térmica. La primera restricción es la de que los seres han de tener una temperatura mayor que la de su entorno porque de lo contrario el calor residual no saldría de ellos. En segundo lugar, las leyes de la física limitan el ritmo al cual un sistema físico puede irradiar energía a su entorno. Evidentemente, los seres no pueden funcionar largo tiempo si producen calor residual a mayor velocidad de la que emplean en deshacerse de él. Estas exigencias ponen un mínimo a la tasa mediante la cual los seres disipan energía inevitablemente. Una exigencia esencial es que exista una fuente de energía libre para alimentar ese desprendimiento de energía calorífica vital. Dyson llega a la conclusión de que todas esas fuentes están condenadas a desvanecerse en un futuro cósmico lejanísimo, de modo que todos los seres sentientes afrontarán antes o después una crisis de energía.

Ahora bien, hay dos modos de prolongar la longevidad de la sentencia. Uno es sobrevivir lo más posible; el otro es acelerar la tasa del pensar y el experimentar. Dyson hace la razonable suposición de que la experiencia subjetiva de un ser acerca del paso del tiempo depende de la tasa a la cual procesa la información: cuanto más rápido sea el mecanismo de procesado que se use, más pensamientos y percepciones tendrá el ser por unidad de tiempo y más deprisa parecerá pasar el tiempo. Esta suposición se utiliza de manera divertida en la novela de ciencia ficción Dragon's Egg [El huevo del dragón] de Robert Forward, que cuenta la historia de una sociedad de seres conscientes que viven en la superficie de una estrella de neutrones. Estos seres utilizan la radiación nuclear en lugar de procesos químicos para mantener su existencia. Como las reacciones nucleares son miles de veces más rápidas que las reacciones químicas, los seres neutrónicos procesan la información mucho más deprisa. Un segundo de la escala de tiempo humana representa para ellos el equivalente de muchos años. Esa sociedad de la estrella de neutrones es bastante primitiva cuando los humanos entran en contacto con ella por vez primera, pero se desarrolla a ojos vistas y pronto supera a la humanidad.

Desgraciadamente, adoptar esta estrategia como medio de supervivencia en un futuro lejano tiene su lado malo: cuanto más deprisa se procese la información, mayor será la tasa de disipación de la energía y más deprisa se agotarán los recursos disponibles de energía. Podríamos creer que eso supondría la muerte inevitable para nuestros descendientes independientemente de la forma física que adoptaran. Pero no necesariamente. Dyson ha mostrado que podría alcanzarse un término medio inteligente en el que la sociedad disminuyera poco a poco su tasa de actividad con el fin de equipararse a la decadencia del universo, por ejemplo, hibernando temporadas cada vez más largas. Durante cada fase de somnolencia, se permitiría que se disipara el calor de los esfuerzos de la fase activa anterior y que se acumulara energía útil para utilizarla en la siguiente fase activa.

El tiempo subjetivo experimentado por los seres que adopten esta estrategia representará una fracción cada vez más pequeña del tiempo real transcurrido, porque el reposo de la sociedad siempre se va haciendo más largo. Pero, como no dejo de recalcar, la eternidad es muy larga y tenemos que luchar entre límites opuestos: los recursos que tienden a cero y el tiempo que tiende a infinito. Dyson ha mostrado a partir de un sencillo examen de tales límites que el tiempo subjetivo total puede ser infinito incluso con unos recursos finitos. Y cita una estadística asombrosa: una sociedad de seres con el mismo nivel demográfico que tiene actualmente la humanidad podría perdurar literalmente una eternidad gastando una energía total de 6 x 1030 julios, siendo ésta la energía desprendida por el Sol ¡en un periodo de sólo ocho horas!

Sin embargo, la auténtica inmortalidad exige algo más que la capacidad de procesar una cantidad de información infinita. Si un ser tiene un número finito de estados cerebrales, sólo puede pensar un número finito de pensamientos distintos. De perdurar para siempre, significaría que tendría los mismos pensamientos una y otra vez. Y una existencia así parece tan absurda como la de una especie condenada a desaparecer. Para escapar a este callejón sin salida, es necesario que la sociedad (o el superser único) siga creciendo sin límites. Lo cual plantea un reto serio para un futuro lejanísimo, ya que la materia se irá evaporando a mayor velocidad de la que hace falta para convertirla en materia cerebral. Puede que un individuo desesperado e ingenioso intente dominar a los escurridizos pero siempre presentes neutrinos cósmicos a fin de expandir el panorama de su actividad intelectual.

Buena parte del examen que hace Dyson (y, sin duda, la mayor Parte de las conjeturas sobre el destino de los seres conscientes en un futuro lejano) da por supuesto que los procesos mentales de estos seres siempre se reducen a una suerte de proceso computativo digital. Un ordenador digital es ciertamente una máquina de estado finito y por ello se enfrenta a un estricto límite acerca de lo que puede conseguir. Sin embargo, existen otros sistemas de otros tipos, conocidos como ordenadores analógicos. Un ejemplo sencillo es el de una regla de cálculo. Pueden hacerse operaciones continuamente ajustando la regla y en un caso ideal puede darse un número infinito de estados. De este modo los ordenadores analógicos eluden ciertas limitaciones de los ordenadores digitales, que sólo pueden almacenar y procesar una cantidad finita de información. Si la información se codifica según la idea de un ordenador analógico (digamos, por medio de las posiciones o de los ángulos de objetos materiales) la capacidad del ordenador parece ilimitada. Así que si un superser puede funcionar como un ordenador analógico, a lo mejor puede pensar no sólo un número infinito de pensamientos, sino un número infinito de pensamientos distintos.

Desgraciadamente, no sabemos si el universo en su conjunto es parecido a un ordenador analógico o digital. La física cuántica parece indicar que el universo entero debe estar «cuantizado», es decir, que en todas sus propiedades registra saltos discretos en lugar de variaciones continuas. Pero esto es una pura conjetura. Ni tampoco comprendemos realmente la relación entre la actividad mental y la cerebral; puede que sencillamente no sea posible correlacionar nuestros pensamientos y experiencias con las ideas de la física cuántica que aquí se consideran.

Sea cual sea la naturaleza de la mente, no hay duda de que los seres de un futuro lejano afrontan la crisis ecológica definitiva: la disipación cósmica de todas las fuentes de energía. Sin embargo, parece que «viviendo a medio gas» podrían alcanzar una especie de inmortalidad. En el panorama previsto por Dyson sus actividades irían haciendo cada vez menos impacto en un universo fríamente indiferente a sus exigencias y durante eones sin cuento estarían inactivos, conservando sus recuerdos pero sin aumentarlos, perturbando apenas la negrura inmóvil de un cosmos moribundo. Gracias a una organización inteligente, podrían seguir pensando un número infinito de pensamientos y experimentando un número infinito de experiencias. ¿Qué cosa mejor podríamos esperar?

La muerte térmica del cosmos ha sido uno de los mitos duraderos de nuestra época. Vimos cómo Russell y otros se basaban en la aparentemente inevitable degeneración que predice la segunda ley de la termodinámica para sostener una filosofía de ateísmo, nihilismo y desesperación. Mediante nuestra comprensión mejorada de la cosmología podemos hoy pintar un cuadro diferente. Puede que el universo se vaya parando, pero no se extingue. Desde luego que vale la segunda ley de la termodinámica, pero no necesariamente impide la inmortalidad cultural.

De hecho, puede que las cosas no sean tan crudas como las pinta el panorama de Dyson. Hasta ahora he dado por hecho que el universo permanece más o menos uniforme mientras se expande y se enfría, pero tal cosa puede no ser acertada. La gravitación es fuente de muchas inestabilidades y la uniformidad a gran escala del cosmos que vemos hoy podría dar paso a una organización más complicada en un futuro lejano. Por ejemplo, podrían amplificarse ligeras variaciones de la tasa de expansión en diferentes direcciones. Podrían acumularse inmensos agujeros negros una vez que su mutua atracción venciera el efecto dispersante de la expansión cosmológica. Y esta circunstancia daría lugar a una curiosa competencia: recuérdese que cuanto más pequeño es un agujero negro, más caliente está y más rápidamente se evapora. Si se funden dos agujeros negros, el agujero final será mayor y por ende más frío, de tal modo que el proceso de evaporación recibirá un parón. La cuestión clave en relación con el futuro lejano del universo es si la tasa de fusión de los agujeros negros será suficiente para ir a la par con la tasa de evaporación. Si es así, entonces siempre existirán algunos agujeros negros que puedan proporcionar, gracias a la radiación de Hawking, una fuente de energía útil para una sociedad adepta a la tecnología, evitando seguramente la necesidad de hibernación. Los cálculos de los físicos Don Page y Randall McKee parecen indicar que esa competencia está en el filo de la navaja y depende sustancialmente de la tasa exacta en la que vaya decreciendo la expansión del universo; en algunos modelos, sí se produce la victoria de la fusión de los agujeros negros.

Descuidada también en la exposición de Dyson se encuentra la posibilidad de que nuestros descendientes puedan intentar modificar la organización a gran escala del cosmos con el fin de preservar su propia longevidad. Los astrofísicos John Barrow y Frank Tipler han pensado distintas maneras según las cuales una sociedad tecnológicamente avanzada podría hacer ligeros ajustes en el movimiento de las estrellas para poder montar una disposición gravitatoria favorable a sus intereses. Por ejemplo, podrían utilizarse armas nucleares para alterar la órbita de un asteroide, lo suficiente por ejemplo como para que recibiera un impulso orbital desde un planeta y fuera a estrellarse en el Sol. El momento de tal impacto alteraría ligerísimamente la órbita del Sol en la galaxia. Aunque el efecto es pequeño, es acumulativo: cuanto más lejos se mueva el Sol, más grande es el desplazamiento conseguido. A una distancia de muchos años luz, la deriva podría suponer una diferencia crucial si el Sol se acercara a otra estrella, pasando de ser un mero encuentro con un ligero cabeceo a un encuentro que modificara violentamente la trayectoria del Sol por la galaxia. Manipulando muchas estrellas, se podrían crear cúmulos de cuerpos astronómicos que luego se explotarían en beneficio de la sociedad. Y como los efectos se amplifican y se acumulan, no hay límite al tamaño de los sistemas que se pueden controlar de tal modo: tirando un poquito de allí y otro poquito de allá. Con tiempo suficiente (y nuestros descendientes tendrán desde luego tiempo de sobra a su disposición) se podría llegar incluso a manejar las galaxias.

Esta grandiosa ingeniería cósmica tendría que competir con los sucesos naturales y aleatorios en los cuales las estrellas y las galaxias salen despedidas de los cúmulos ligados gravitatoriamente, tal y como se describe en el capítulo 7. Barrow y Tipler creen que se tardarían 1022 años en reorganizar una galaxia por medio de la manipulación de los asteroides. Por desgracia, la interrupción natural se da más o menos cada 1019 años, de modo que la batalla parece inclinada a favor de la naturaleza. Por otro lado, nuestros descendientes podrían aprender a controlar objetos mucho mayores que los asteroides. Asimismo, la tasa de dispersión natural depende de las velocidades orbitales de los objetos. Cuando se trata de galaxias enteras, esas velocidades decrecen conforme se expande el universo. Las velocidades menores hacen también que la manipulación artificial sea más lenta, pero los dos efectos no disminuyen al mismo ritmo. Parece que, con el tiempo, la tasa de interrupción natural podría descender por debajo de la tasa con la que una sociedad de ingenieros pudiera reordenar el universo. Y ello plantea la interesante posibilidad de que mientras pasara el tiempo los seres inteligentes pudieran controlar cada vez más un universo con recursos decrecientes, hasta que la naturaleza estuviera fundamentalmente «tecnologizada» y desapareciera la distinción entre lo que es natural y lo que es artificial.

Una suposición clave del análisis de Dyson es que los procesos de pensamiento disipan energía sin remedio. Desde luego es así en el caso de los procesos de pensamientos, humanos, y hasta hace bien poco se daba por hecho que cualquier forma de procesado de la información tenía que pagar aunque fuera un mínimo precio termodinámico. Lo sorprendente es que, esto no es estrictamente correcto. Los científicos informáticos Charles Bennett y Rolf Landauer, de IBM, han demostrado que en principio es posible la computación reversible. Lo cual significa que determinados sistemas físicos (en este momento completamente hipotéticos) podrían procesar información sin disipación de energía. Resulta posible concebir un sistema que piense un número infinito de pensamientos ¡sin necesitar ningún tipo de suministro de potencia! No está claro que tal sistema pudiera asimismo reunir la información además de procesarla, porque la adquisición de cualquier información no trivial procedente del entorno debería suponer disipación de energía de una u otra forma, aunque sólo consistiera en discriminar la señal del ruido circundante. Por lo tanto, este ser tan poco exigente no tendría percepciones del mundo que le rodeara. Sin embargo, podría recordar el universo que fue. Puede que incluso pudiera soñar.

La imagen de un universo moribundo ha obsesionado a los científicos durante más de un siglo. La suposición de que vivimos en un cosmos que va degenerándose sin parar por medio de la prodigalidad de la entropía forma parte del folclore de la cultura científica. Pero ¿hasta qué punto está bien fundamentada? ¿Podemos estar seguros de que todos los procesos físicos llevan inevitablemente hacia el caos y la degeneración?

¿Qué hay de la biología? Nos da una pista la defensa tan cerrada que de la evolución darwiniana hacen algunos biólogos. Yo creo que su reacción surge de la incómoda contradicción de un proceso que con claridad se ve constructivamente dirigido por las fuerzas físicas de las que se supone que son, en el fondo, destructivas. La vida en la Tierra comenzó con seguridad como una especie de fango primordial. La biosfera de hoy es un ecosistema rico y complejo, una red de organismos variadísimos y de enorme complicación. Aunque los biólogos, puede que temerosos de mostrar trazas de propósito divino, niegan cualquier evidencia de un progreso sistemático en la evolución, tanto para el científico como el no científico está claro que algo ha avanzado, aun yendo más o menos sin dirección, desde que la vida se originara sobre la Tierra. El problema es caracterizar con mayor precisión ese avance. ¿En qué es en lo que se ha avanzado?

Las disquisiciones anteriores en relación con la supervivencia se han centrado en la lucha entre la información (orden) y la entropía... terminando siempre con el triunfo final de la entropía. Pero ¿es que acaso debemos preocuparnos precisamente por la información per se? Después de todo, llegar a una conclusión repasando uno a uno todos los pensamientos posibles es tan emocionante como leer la guía de teléfonos. Lo que con seguridad importa es la calidad de la experiencia o, más en general, la calidad de la información que se reúne y se utiliza.

Por lo que a mí respecta, el universo comenzó en un estado más o menos informe. Con el tiempo ha ido emergiendo la riqueza y la variedad de los sistemas físicos que hoy vemos. Por lo tanto, la historia del universo es la historia del crecimiento de la complejidad organizada. Esto parece una paradoja. Comencé mi relato describiendo cómo la segunda ley de la termodinámica nos dice que el universo se muere, pasando inexorablemente de un estado inicial de baja entropía hasta un estado final de máxima entropía y de cero perspectivas. De modo que las cosas ¿van a mejor o a peor?

No hay paradoja en realidad, porque la complejidad organizada es diferente de la entropía. La entropía, o desorden, es el negativo de la información o del orden: cuanta más información procesamos (es decir, cuanto más orden generamos) mayor es el precio entrópico pagado: el orden de aquí genera desorden en algún otro sitio. Ésa es la segunda ley: siempre gana la entropía. Pero la organización y la complejidad no son simplemente orden e información. Se refieren a determinados tipos de orden e información. Reconocemos, por ejemplo, una importante distinción entre una bacteria y un cristal. Los dos están ordenados pero de distinta manera. Un retículo cristalino representa una uniformidad regimentada: de una belleza pura pero aburrida. Por contra, la organización compleja de la bacteria es sumamente interesante.

Pueden parecer argumentos subjetivos pero pueden sustentarse con las matemáticas. En los últimos años, se ha abierto todo un nuevo campo de investigación que tiene como objetivo la cuantificación de conceptos tales como la complejidad organizada, y que busca establecer principios generales de organización que vayan codo a codo con las leyes de la física existentes. El tema está aún en pañales, pero ya amenaza muchas de las suposiciones tradicionales sobre el orden y el caos.

En mi libro The Cosmic Blueprint [Proyecto cósmico], propuse la idea de que en el universo funciona una «ley de la complejidad creciente» junto con la segunda ley de la termodinámica. Entre estas dos leyes no hay incompatibilidad. En la práctica, un incremento de la complejidad organizativa de un sistema físico incrementa la entropía. Por ejemplo, en la evolución biológica sólo emerge un organismo nuevo y más complejo después de que se hayan dado muchos procesos físicos y biológicos destructivos (la muerte prematura de mutantes mal adaptados, por ejemplo). Hasta la información de un copo de nieve crea un gasto de calor que contribuye a aumentar la entropía de universo. Pero, como se ha explicado, no se trata de un intercambio directo porque la información no es el negativo de la entropía.

Me reconforta grandemente saber que otros muchos investigadores han llegado a conclusiones parecidas y que se han hecho intentos de formular una «segunda ley» de la complejidad. Aunque compatible con la segunda ley de la termodinámica, la ley de la complejidad proporciona una imagen muy distinta del cambio cósmico al describir un universo en progreso (que en cierto sentido debe sustentarse rigurosamente mediante las investigaciones a las que he aludido) partiendo de unos inicios prácticamente sin rasgos para llegar a estados cada vez más complejos.

En el contexto del fin del universo, la existencia de una ley de la complejidad creciente tiene un profundo significado. Si la complejidad organizada no es el opuesto de la entropía, entonces la limitada capacidad de entropía negativa del universo no tiene por qué poner límites al grado de complejidad. El precio entrópico pagado por el avance de la complejidad puede ser puramente casual, y no fundamental, como es el caso de la mera ordenación o procesado de la información. De ser así, entonces nuestros descendientes pueden ser capaces de alcanzar estados de complejidad organizativa cada vez mayor sin esquilmar recursos cada vez menores. Aunque puedan estar limitados en la cantidad de información que procesen, puede que no tengan límite en la riqueza y en la calidad de sus actividades físicas y mentales.

En este capítulo y en el último he intentado proporcionar un atisbo de un universo que se va deteniendo pero que quizá nunca pierda todo el vapor, de criaturas extravagantes de ciencia ficción ganándose la vida a duras penas con unos elementos que cada vez se les ponen más en contra y poniendo a prueba su ingenio contra la lógica inexorable de la segunda ley de la termodinámica. La imagen de su lucha por la supervivencia, desesperada pero no necesariamente fútil, puede animar a unos lectores y deprimir a otros. Yo tengo al respecto sentimientos encontrados.

Sin embargo, toda esta especulación se hace sobre la suposición de que el universo seguirá expandiéndose siempre. Hemos visto cómo es éste el único destino posible para el cosmos. Si la expansión se desacelera con la suficiente rapidez, el universo puede dejar de expandirse un día y empezar a contraerse hacia un big crunch. Y entonces, ¿qué esperanza hay de sobrevivir?

CAPÍTULO 9: LA VIDA AL GALOPE

Por mucho ingenio humano o no humano que se emplee, no se puede prolongar la vida para siempre a menos que haya un «siempre». Si el universo sólo puede existir durante un tiempo finito, entonces el Armagedón es inevitable. En el capítulo 6, he explicado cómo el destino último del cosmos cuelga de su peso total. Las observaciones parecen indicar que el peso del universo se encuentra muy cerca de la frontera crítica entre la expansión eterna y la contracción final. Si el universo termina por empezar a contraerse, las experiencias de cualesquiera seres sentientes serán sumamente diferentes, desde luego, de la descripción que he hecho en el último capítulo.

Los primeros estadios de la contracción cosmológica no son amenazantes en lo más mínimo. Como la pelota que llega al punto más alto de su trayectoria, el universo comenzará su caída hacia adentro muy lentamente. Supongamos por el momento que el punto más alto se alcanza dentro de cien mil millones de años: todavía habrá muchísimas estrellas activas y nuestros descendientes serán capaces de seguir los movimientos de las galaxias con telescopios ópticos, observando cómo los cúmulos galácticos van alejándose cada vez más despacio para luego acercarse unos a otros. Las galaxias que hoy vemos estarán entonces cuatro veces más lejos. Debido a la mayor edad del universo, los astrónomos serán capaces de ver unas diez veces más lejos de lo que nosotros vemos, de manera que su universo observable abarcará muchas más galaxias de las que nos son visibles en nuestra era cósmica.

El hecho de que la luz tarde miles de millones de años en atravesar el cosmos significa que los astrónomos de dentro de cien mil millones de años tardarán mucho en apreciar la contracción. Primero se darán cuenta de que la mayor parte de las galaxias relativamente cercanas se acercan en lugar de alejarse, aunque la luz de las galaxias distantes seguirá mostrando un corrimiento hacia el rojo. Sólo al cabo de decenas de miles de millones de años se hará aparente el avance sistemático hacia el interior. Será más fácil de detectar un cambio sutil en la temperatura de la radiación de calor de fondo cósmica. Recuérdese que esta radiación de fondo es un residuo del big bang y actualmente tiene una temperatura de unos tres grados sobre el cero absoluto, es decir 3 °K. Se enfría conforme se expande el universo. Dentro de cien mil millones de años habrá descendido hasta más o menos 1 °K. La temperatura tocará fondo en el momento álgido de la expansión y en cuanto la contracción empiece volverá a subir otra vez, pasando a ser de 3 °K cuando el universo alcance de nuevo la densidad que tiene hoy. En eso se tardarán otros cien mil millones de años: la subida y la caída del universo es aproximadamente simétrica con respecto al tiempo.

El universo no se contrae sin más de la noche a la mañana. De hecho, nuestros descendientes serán capaces de darse la buena vida durante decenas de miles de millones de años, incluso una vez comenzada la contracción. Sin embargo, la situación no es tan halagüeña si la inversión se produce al cabo de mucho más tiempo, digamos un cuatrillón de años. En tal caso, las estrellas se habrán apagado antes de que se llegue a ese punto y cualesquiera habitantes supervivientes afrontarán los mismos problemas que hemos abordado en un universo que siempre se expande.

Ocurra cuando ocurra la inversión medida en años desde este momento, después de un número igual de años el universo habrá vuelto a su tamaño actual. Sin embargo, su apariencia será muy distinta. Incluso con la inversión a cien mil millones de años, habrá muchos más agujeros negros y muchas menos estrellas de las que hay hoy. Los planetas habitables estarán muy solicitados.

Para cuando el universo vuelva a su actual tamaño, ya se estará contrayendo a una cierta velocidad, demediándose cada tres mil quinientos millones de años a una velocidad cada vez más acelerada. Sin embargo, lo divertido comenzará sobre los diez mil millones de años después de ese momento, cuando la subida de la radiación cósmica térmica de fondo se convierta en una seria amenaza. Para cuando la temperatura llegue hasta unos 300 °K los planetas como la Tierra no podrán hurtarse a ese calor. Se irán calentando sin cesar. Primero se derretirán los casquetes de hielo o los glaciares y luego los océanos empezarán a evaporarse.

Cuarenta millones de años después, la temperatura de la radiación de fondo alcanzará la temperatura que tiene hoy la Tierra. Los planetas de tipo terrestre serán entonces completamente inhóspitos. Por supuesto, la Tierra ya habrá afrontado ese destino porque el Sol se habrá expandido para convertirse en una gigante roja pero entonces ya no habrá ningún otro lugar para nuestros descendientes, ningún refugio seguro. La radiación térmica llena el universo. Todo el espacio está a 300 °C y sigue subiendo. Cualesquiera astrónomos que se hubieran adaptado a esas tórridas condiciones o que hubieran creado ecosistemas refrigerados para retrasar su propia cocción, se darían cuenta de que el universo se contrae en ese momento a pasos agigantados, demediándose en tamaño cada pocos millones de años. Cualesquiera galaxias que quedaran ya no serían reconocibles porque ya se habrían juntado unas con otras. Y, sin embargo, seguiría habiendo mucho espacio vacío: serían raras las colisiones entre estrellas aisladas.

Las condiciones del universo conforme se aproximara a su fase final se irían pareciendo a las que prevalecieron al poco del big bang. El astrónomo Martin Rees ha llevado a cabo un estudio escatológico del cosmos en contracción. Aplicando los principios generales de la física, ha sido capaz de pintar un cuadro de los estadios últimos de la contracción. La radiación cósmica térmica se iría haciendo tan intensa que el cielo nocturno tendría un apagado color rojo. El universo se iría transformando en un horno cósmico que lo abarcaría todo, asando cualesquiera formas de vida frágiles que pudieran esconderse y desnudando a los planetas de sus respectivas atmósferas. Poco a poco, el destello rojizo se convertiría en amarillo y luego en blanco, hasta que la ardiente radiación térmica que bañara el universo amenazara la existencia de las propias estrellas. Incapaces de irradiar su energía, las estrellas irían acumulando calor y explotarían. El espacio se llenaría de gas caliente (plasma) con un resplandor ardiente y cada vez más caliente.

Conforme se acelerara el ritmo de los cambios, las condiciones irían a la par haciéndose más extremadas si cabe. El universo empieza a cambiar apreciablemente a una escala de tiempo de sólo cien mil años, luego de mil, luego de cien, acelerando hacia la catástrofe total. La temperatura se eleva a millones, luego a miles de millones de grados. La materia que hoy ocupa amplísimas regiones del espacio se comprime en pequeñísimos volúmenes. La masa de una galaxia ocupa un espacio de unos pocos años luz de diámetro. Han llegado los últimos tres minutos.

La temperatura termina por hacerse tan alta que hasta los núcleos atómicos se desintegran. La materia queda reducida a un puré uniforme de partículas elementales. La obra del big bang y de generaciones de estrellas para poder crear los elementos químicos pesados se deshace en menos tiempo del que se tarda en leer esta página. Los núcleos atómicos (estructuras estables que podrían haber perdurado billones de años) se ven aplastados irremisiblemente. Con la excepción de los agujeros negros, todas las demás estructuras han pasado a mejor vida hace ya tiempo. El universo presenta ahora una elegante pero siniestra simplicidad. No le quedan más que segundos de vida.

Mientras el cosmos se contrae cada vez más deprisa, la temperatura sube sin límite conocido a un ritmo cada vez mayor. La materia está tan comprimida que los protones y los neutrones ya no existen como tales: sólo un puré de quarks. Y sigue acelerándose la contracción.

Está dispuesto ya el escenario para la catástrofe cósmica definitiva, dentro de unos pocos microsegundos. Los agujeros negros empiezan a fundirse unos con otros, con un interior muy poco diferente al estado de contracción generalizado del propio universo. Se trata simplemente de regiones del espacio-tiempo que han llegado al fin un poquito antes y a las que se une ahora el resto del cosmos.

En los momentos finales, la gravedad se convierte en la fuerza dominante, aplastando sin piedad la materia y el espacio. La curvatura del espacio-tiempo se incrementa a toda velocidad. Las regiones del espacio se van comprimiendo en volúmenes cada vez más pequeños. Según la teoría convencional, la implosión es infinitamente potente, liquidando la existencia de toda la materia y eliminando todo objeto físico incluyendo al tiempo y el espacio en una singularidad del espacio-tiempo.

Es el fin.

El «big crunch», tal y como lo comprendemos, no sólo es el fin de la materia: es el fin de todo. Como el propio tiempo se interrumpe en el big crunch, no tiene sentido preguntar qué ocurre a continuación, igual que no tiene sentido preguntar qué ocurría antes del big bang. No hay un «después» en el que pueda ocurrir nada en absoluto: no hay ni tiempo siquiera para la inactividad ni el espacio para el vacío. Un universo que vino de la nada mediante el big bang desaparecerá en la nada con el big crunch, sin que quede siquiera un recuerdo de sus «equisillones» años de existencia.

¿Deberíamos deprimirnos ante semejante perspectiva? ¿Qué es peor: un universo que va degenerando lentamente y expandiéndose eternamente hacia un estado de oscuro vacío u otro que implota en una ardiente aniquilación? ¿Y qué esperanza de inmortalidad queda entonces en un universo destinado a cerrarse en el tiempo?

La vida en esa aproximación al big crunch parece incluso más desesperanzada que en el futuro lejanísimo de un universo en eterna expansión. El problema no es ahora la falta de energa, sino su exceso. Sin embargo, nuestros descendientes pueden tener miles de millones o incluso billones de años para prepararse para el holocausto final. Durante este tiempo, la vida podría expandirse por todo el cosmos. En el modelo más sencillo de un universo en contracción el volumen total de espacio es finito. Cosa que ocurre porque el espacio es curvo y puede conectarse consigo mismo en el equivalente tridimensional de la superficie de una esfera. Por ello es concebible que los seres inteligentes puedan esparcirse por todo el universo y controlarlo, situándose así en disposición de afrontar el big crunch con todos los recursos posibles a su disposición.

En un primer momento, no es fácil ver por qué habrían de preocuparse. Dado que la existencia más allá del big crunch es imposible ¿a qué vendría prolongar la agonía un poquito más? En un universo con una edad de billones de años, da igual la aniquilación diez millones o un millón de años antes del final. Pero no debemos olvidar que el tiempo es relativo. El tiempo subjetivo de nuestros descendientes dependerá de su tasa metabólica y de procesado de información. Y otra vez, suponiendo que tengan muchísimo tiempo para adaptar su forma física, podrían ser capaces de convertir la llegada del Hades en una cierta forma de inmortalidad.

Una temperatura en aumento significa que las partículas se mueven más deprisa y que los procesos mentales se dan más rápidamente. Recuérdese que la exigencia esencial de un ser sentiente es la capacidad de procesar información. En un universo con una temperatura en aumento, la tasa de procesado de la información también se acelerará. Para un ser que utilizara procesos termodinámicos de mil millones de grados, la aniquilación inminente del universo parecerá estar a años vista. No hace falta temer el fin del tiempo si el tiempo remanente puede estirarse infinitamente para la mente de los observadores. Conforme la contracción se acelere hacia el big crunch final, las experiencias subjetivas de los observadores podrían en principio dilatarse cada vez con más rapidez, haciendo frente a la inmersión del Armagedón con una velocidad de pensamiento cada vez mayor. Supuestos los recursos suficientes, estos seres serían literalmente capaces de comprar tiempo.

Podríamos preguntarnos si un superser que habitara ese universo en contracción en sus últimos momentos tendría un número infinito de pensamientos y experiencias en el tiempo finito de que dispusiera. La cuestión la han estudiado John Barrow y Frank Tipler. La respuesta depende sobre todo de los detalles físicos de los estadios finales. Si el universo, por ejemplo, permanece relativamente uniforme al acercarse a su singularidad final, surge un problema fundamental. Sea cual sea la velocidad del pensamiento, la velocidad de la luz sigue inalterada y la luz puede viajar, como mucho, una distancia de un segundo luz por segundo. Como la velocidad de la luz define la velocidad limitante a la que cualquier efecto físico puede propagarse, se deduce que no puede darse ninguna comunicación entre regiones del universo que estén separadas por más de un segundo luz durante el último segundo. (Es otro ejemplo de horizonte de sucesos, parecido al que impide que la información salga de los agujeros negros.) Conforme se acerque el fin, el tamaño de las regiones comunicables y del número de partículas que contengan se encogerá hacia cero. Para que un sistema procese la información, todas las partes del sistema deben comunicarse entre sí. Está claro que la velocidad finita de la luz actúa para restringir el tamaño del «cerebro» que pueda existir al acercarse el final, lo cual a su vez podría limitar el número de estados diferentes, y por ende, pensamientos, que pudiera tener un cerebro tal.

Para eludir esta restricción es necesario que los estadios finales de la contracción cósmica se desvíen de la uniformidad, lo que, verdaderamente, es muy probable. Las abundantes investigaciones matemáticas sobre la contracción gravitatoria parecen indicar que conforme implosione el universo, la tasa de contracción variará en distintas direcciones. Curiosamente, no se trata sin más de que el universo se encoja más por una parte que por otra. Lo que ocurre es que empiezan unas oscilaciones, de manera tal que la dirección de la contracción más rápida cambia sin parar. En efecto, el universo fluctúa hacia la extinción en ciclos de violencia y complejidad crecientes. Barrow y Tipler conjeturan que estas complejas oscilaciones hacen que el horizonte de sucesos desaparezca primero por aquí y luego por allá, permitiendo que todas las regiones del espacio se mantengan en contacto. Cualquier supercerebro deberá ser muy avispado y cambiar sus comunicaciones de una a otra dirección conforme las oscilaciones contraigan más rápidamente una parte que otra. Si ese ser puede seguir el ritmo, las propias oscilaciones podrían proporcionar por sí mismas la energía necesaria para conducir los procesos de pensamiento. Lo que es más, en los modelos matemáticos sencillos parece haber un infinito número de oscilaciones en la duración finita que terminará en el big crunch. Lo cual proporciona una cantidad infinita de procesado de información y, por hipótesis, un tiempo subjetivo infinito para el superser. Así puede que no acabe nunca el mundo mental, incluso aunque el mundo físico llegue a un cese brusco en el big crunch.

¿Qué podría hacer un cerebro de capacidad ilimitada? Según Tipler, no sólo sería capaz de deliberar sobre todos los aspectos de su propia existencia y la del universo que abarca, sino que, con su poder de procesado de la información, podría simular mundos imaginarios en una orgía de realidad virtual. No habría límites al número de posibles universos que pudiera internalizar de este modo. No sólo se estirarían hasta la eternidad esos últimos tres minutos, sino que también permitirían la realidad simulada de una variedad infinita de actividad cósmica.

Por desgracia, estas especulaciones (un tanto enloquecidas) dependen de modelos físicos muy concretos que pueden resultar absolutamente carentes de realidad. También pasan por alto los efectos cuánticos que con seguridad prevalecerán en los estadios finales de la contracción gravitatoria, efectos que bien podrían situar un límite definitivo a la tasa de procesado de la información. De ser así, esperemos que ese superser o superordenador cósmico llegue por lo menos a comprender la existencia lo suficientemente bien en el tiempo de que disponga para reconciliarse con su propia mortalidad.

CAPÍTULO 10: MUERTE SÚBITA... Y RENACIMIENTO

Hasta este momento he dado por supuesto que el fin del universo, sea en un crunch o en un suspiro (o, con más exactitud, en un big crunch o en una ultracongelación), se encuentra situado en un futuro lejanísimo, puede que infinitamente lejano. Si el universo se contrae, nuestros descendientes tendrían muchos miles de millones de años de margen antes del inminente big crunch. Pero queda otra posibilidad y todavía más alarmante.

Como ya he explicado, cuando los astrónomos escrutan los cielos no ven el universo en su estado actual exhibido como una foto fija. Debido al tiempo que la luz tarda en llegarnos desde las regiones lejanas, vemos cualquier objeto dado del espacio tal y como era cuando se emitió la luz. El telescopio es a la vez un tiemposcopio. Cuanto más lejos esté situado un objeto, más antigua será la imagen que veamos. En efecto, el universo de astrónomo es como una loncha anterior de espacio y de tiempo, lo que se conoce técnicamente como «cono de luz pasada» y que se representa en la figura 10.1.

Desde un punto P concreto del espacio y del tiempo (que podría ser el aqui y el ahora, por ejemplo) un astrónomo que mira el universo ve en realidad el universo tal y como era en el pasado, no como es ahora. La información que llega de P viaja a lo largo del «cono de luz pasada» pasando por P, y que viene dibujado con las lineas oblicuas. Esas son la vias de las señales luminosas que convergen en la tierra desde regiones lejanas del universo pasado. Como ninguna información ni influencia física puede viajar más rápidamente que la luz, el observador en el momento que recoge la figura sólo puede conocer las influencias o sucesos que ocurren en la zona sombreada. Un suceso apocaliptico exterior al cono de luz podria enviar hacia la Tierra a toda velicidad influencias desastrosas (la flecha ondulada), pero el observador estaría benditamente ajeno a semejante eventualidad hasta que le llegaran esas influencias.

Según la teoría de la relatividad, ninguna información ni influencia física puede viajar a mayor velocidad que la de la luz. Por lo tanto, el cono de luz pasada marca el límite no sólo de todo conocimiento sobre el universo, sino de todos los sucesos que puedan afectarnos en este momento. Se deduce que cualquier influencia física que nos llegue a la velocidad de la luz nos llega absolutamente sin previo aviso. Si la catástrofe se dirige hacia a nosotros por encima del cono de luz pasada, no habrá precursores del apocalipsis. Lo sabremos cuando lo tengamos encima.

Por poner un ejemplo absolutamente hipotético, si el Sol estallara ahora mismo, nosotros no lo sabríamos hasta dentro de ocho minutos y medio, ya que éste es el tiempo que tarda en llegamos la luz del Sol. De forma similar, es completamente posible que una estrella cercana haya estallado como una super-nova (suceso que habría dado a la Tierra un baño de radiación letal) pero que nosotros sigamos en nuestra bendita ignorancia del hecho hasta que dentro de unos pocos años nos llegue la mala noticia atravesando la galaxia a la velocidad de la luz. De modo que aunque el universo pueda parecer tranquilo en este momento, no podemos estar seguros de que no haya ocurrido ya algo realmente terrible.

La mayor parte de la violencia súbita del universo supone daños que se limitan a su inmediata vecindad cósmica. La muerte de las estrellas o la zambullida de materia en el interior de un agujero negro perturbará a los planetas y a las estrellas cercanas, es posible que hasta una distancia de unos pocos años luz. Los estallidos más espectaculares parecen ser sucesos que acontecen en los núcleos de algunas galaxias. Como ya he descrito, a veces se expulsan inmensos surtidores de materia a una fracción considerable de la velocidad de la luz, emitiéndose asimismo prodigiosas cantidades de radiación. Es violencia a escala galáctica.

Pero ¿qué ocurre con los sucesos de proporciones universales? ¿Es posible que pueda darse una convulsión que destruya el cosmos de un solo golpe, en lo mejor de su vida, por así decirlo? ¿Podría haberse disparado ya una auténtica catástrofe cósmica y estar sus desagradables efectos llegándonos a toda velocidad incluso ahora por detrás de nuestro cono de luz pasada a nuestro frágil nicho en el espacio y el tiempo?

En 1980, los físicos Sydney Coleman y Frank de Luccia publicaron un artículo portentoso bajo el inocuo título de «Efectos gravitatorios sobre la degeneración del vacío y a partir de ésta» en la revista Physical Review D. El vacío al que se refieren no es meramente el espacio vacío, sino el estado vacío de la física cuántica. En el capítulo 3, expliqué que lo que nos parece un vacío en realidad hormiguea con una efímera actividad cuántica, conforme aparecen y desaparecen fantasmales partículas virtuales en animado azar. Recuérdese que este vacío puede no ser único; podría haber diversos estados cuánticos, todos ellos aparentemente vacíos pero que disfruten de diferentes grados de actividad cuántica y de diferentes energías asociadas.

Es un principio bien establecido de la física cuántica que los estados de alta energía tienden a degenerar a estados de energía inferior. Un átomo, por ejemplo, puede existir en una diversidad de estados excitados, todos ellos inestables, y que intentará degenerar hasta el estado de energía más baja, o estado «base», que es el estable. De modo parecido, un vacío excitado intentará degenerar a la energía más baja o vacío «auténtico». El panorama del universo inflacionario se basa en la teoría de que el universo muy primitivo tuvo un estado de vacío excitado o «falso» durante el cual se infló frenéticamente, pero que tal estado degeneró rapidísimamente hasta el vacío auténtico, cesando la inflación.

Lo que suele suponerse habitualmente es que el estado actual del universo se corresponde con el vacío auténtico; es decir, que el espacio vacío de nuestra época es el vacío de mínima energía posible. Pero ¿podemos estar seguros de esto? Coleman y De Luccia consideran la espeluznante posibilidad de que el vacío actual no sea el auténtico vacío, sino un falso vacío, metaestable, de vida larga, que nos haya inducido un falso sentido de la seguridad debido a que ha durado unos pocos miles de millones de años. Sabemos de muchos sistemas cuánticos, como el de los núcleos de uranio, que tienen vidas medias de miles de millones de años. ¿Y qué pasa si suponemos que el vacío presente cae dentro de esta categoría? La «degeneración» del mencionado vacío en el título del artículo de Coleman y De Luccia se refiere a la catastrófica posibilidad de que el vacío actual pueda degenerar súbitamente sumergiendo al cosmos en un estado de energía aún más baja, de espantosas consecuencias para nosotros (y para todo).

La clave de la hipótesis de Coleman y De Luccia es el fenómeno de túnel cuántico. La mejor manera de ilustrarlo es hacerlo con el caso sencillo de una partícula cuántica atrapada en una barrera de fuerza. Supongamos que la partícula se encuentra en una pequeña hondonada rodeada de colinas por todas partes, como se indica en la figura 10.2. Por supuesto que no tienen por qué ser colinas reales; podrían ser, por ejemplo, campos de fuerzas nucleares o eléctricas. En ausencia de la energía necesaria para remontar las colinas (o superar la barrera de fuerzas) la partícula parece atrapada para siempre. Pero recuérdese que todas las partículas cuánticas están sujetas al principio de incertidumbre de Heisenberg, que permite tomar energía prestada durante pequeños periodos de tiempo. Y ello abre una posibilidad intrigante. Si la partícula puede tomar prestada suficiente energía como para llegar a lo alto de la colina y cruzar al otro lado antes de tener que devolver el préstamo energético, podrá salir del pozo. Efectivamente, habrá practicado un «túnel» en la barrera.

Efecto tunel. Si una partícula cuántica está atrapada en un valle entre dos colinas, existe una pequeña probabilidad de que pueda escapar tomando energía prestada y saltando por encima de la colina. Efectivamente, se observa que tuneliza la barrera. Un caso familiar es el que se da cuando las partículas alfadel núcleo de determinados elementos tunelizan la barrera que es la fuerza nuclear y escapan, fenómeno conocido como radiactividad alfa. En este ejemplo, la «colina» se debe a fuerzas eléctricas y nucleares y el dibujo no es más que un esquema.

La probabilidad de que una partícula cuántica salga de la hondonada practicando un túnel depende muchísimo tanto de la altura como de la anchura de la barrera. Cuanto más alta sea la barrera, más energía debe tomar prestada la partícula para llegar a lo alto y por ello, según el principio de incertidumbre, más breve será la duración del préstamo. De ahí que las barreras altas puedan superarse mediante un túnel sólo en el caso de que sean finas, permitiendo así que la partícula las atraviese con la suficiente rapidez como para devolver a tiempo el préstamo. Razón por la cual el efecto túnel no se percibe en la vida diaria: las barreras macroscópicas son excesivamente altas y anchas como para que se den túneles significativos. En principio, un ser humano podría atravesar una pared, pero la probabilidad de que se produzca un túnel cuántico para este milagro es extremadamente pequeña. Sin embargo, a escala atómica el túnel es muy común: es, por ejemplo, el mecanismo por el cual ocurre la radiación alfa. El efecto túnel lo explotan también los semiconductores y otros dispositivos electrónicos como por ejemplo el microscopio de barrido electrónico mediante efecto túnel. En relación con el problema de la posible degeneración del vacío actual, Coleman y De Luccia conjeturan que los campos cuánticos que fabrican el vacío deben estar sometidos a un paisaje (metafórico) de fuerzas como las que se muestran en la figura 10.3

Estados de vacío falso y auténtico. Puede darse el caso de que el actual estado cuántico de espacio vacio A no sea el estado de menor energía sino que, sin embargo, esté casi estabilizado al corresponderse con una especie de valle de alta montaña. Habria entonces una pequeña probabibidad de que ese estado degenerara por el efecto túnel a un auténtico estado estable de base B. La transición entre estos estados, que se daría mediante la formación de una burbuja, liberaría una inmensa cantidad de energía.

El estado vacío actual se corresponde al fondo de valle A. Sin embargo, el auténtico vacío se corresponde al fondo del valle B, inferior a A. El vacío querría degenerar del estado de energía más alta A al estado de energía más baja B, pero se lo impide la «colina» o campo de fuerza que los separa. Aunque la colina estorba la degeneración, no la impide por completo habida cuenta del efecto túnel: el sistema puede tunelizar del valle A al valle B. Si esta teoría es correcta, entonces el universo está viviendo de tiempo prestado en el valle A pero con la siempre presente posibilidad de que tunelice al valle B en un momento aleatorio cualquiera.

Coleman y De Luccia fueron capaces de modelizar matemáticamente la degeneración del vacío... de esquematizar cómo ocurre el fenómeno. Descubrieron que la degeneración comenzaría en una localización espacial aleatoria, en forma de una burbujita de auténtico vacío rodeada de un falso vacío inestable. En cuanto se ha formado la burbuja de auténtico vacío, se expande a una velocidad que se va acercando a la de la luz, engullendo una región cada vez mayor del falso vacío y convirtiéndolo instantáneamente en auténtico vacío. La diferencia de energía entre los dos estados (que podría tener un valor enorme parecido al examinado en el capítulo 3) se concentra en la pared de la burbuja que barre el universo destruyéndolo todo a su paso.

Lo primero que sabríamos sobre la existencia de una burbuja de vacío auténtico sería la llegada de la pared y el cambio súbito de la estructura cuántica de nuestro mundo. Ni siquiera tendríamos un preaviso de tres minutos. Se alteraría drástica e instantáneamente la naturaleza de todas las partículas subatómicas y sus interacciones; por ejemplo, podrían degenerar de inmediato los protones en cuyo caso se evaporaría bruscamente toda la materia. Lo que quedara se encontraría en el interior de la burbuja de auténtico vacío... un estado de cosas muy diferente al que observamos en este momento. La diferencia más significativa se refiere a la gravitación. Coleman y De Luccia descubrieron que la energía y la presión del auténtico vacío crearían un campo gravitatorio tan intenso que la región abarcada por la burbuja se contraería, incluso conforme se expandiera la burbuja, en un tiempo menor al microsegundo. En esta ocasión nada de una suave caída hacia un big crunch: en su lugar, una brusca aniquilación de todo según implota la burbuja interior en su singularidad espaciotemporal. En resumen: aplastamiento instantáneo. «Descorazonador», señalan los autores en un eufemismo magistral, y prosiguen:

La posibilidad de que vivamos en un falso vacío nunca ha sido alentadora como tal posibilidad. La degeneración del vacío es la catástrofe ecológica definitiva; [...] tras la degeneración del vacío no sólo es imposible la vida tal y como la conocemos, sino también la química tal y como la conocemos. Sin embargo, siempre podíamos reconfortarnos estoicamente con la posibilidad de que quizá en el transcurso del tiempo el nuevo vacío sustentara, si no la vida tal y como la conocemos, sí por lo menos ciertas estructuras que fueran capaces de conocer la alegría. Esta posibilidad queda ahora eliminada.

Las horrorosas consecuencias de la degeneración del vacío fueron objeto de numerosas discusiones entre los físicos y los astrónomos después de publicarse el artículo de Coleman y De Luccia. En un estudio detallado publicado en la revista Nature, el cosmólogo Michael Turner y el físico Frank Wilczek llegaron a una conclusión apocalíptica: «Desde el punto de vista de la microfísica, por lo tanto, es bastante concebible que nuestro vacío sea metaestable... podría cuajarse una burbuja de auténtico vacío sin previo aviso en cualquier lugar del Universo y expandirse a la velocidad de la luz.»

Al poco de aparecer el artículo de Turner y Wilczek, Piet Hut y Martin Rees, también en Nature, lanzaron el espectro alarmante de que la formación de una burbuja de vacío que destruyera el universo ¡podrían dispararla los propios físicos de partículas! La preocupación consiste en que la altísima energía de la colisión de las partículas subatómicas pudiera crear las condiciones (sólo por un instante, en una región pequeñísima del espacio) que estimularan la degeneración del vacío. Una vez ocurrida la transición, incluso a escala microscópica, no habría manera de impedir que la recién formada burbuja se hinchara alcanzando proporciones astronómicas. ¿Habría que prohibir la próxima generación de aceleradores de partículas? Hut y Rees nos tranquilizaron, afortunadamente, señalando que los rayos cósmicos consiguen energías más elevadas de las que podemos alcanzar en nuestros aceleradores de partículas y que esos rayos cósmicos llevan golpeando núcleos en la atmósfera de la Tierra desde hace miles de millones de años sin disparar una degeneración del vacío. Por otra parte, con una mejora en un factor de cien, poco más o menos, en las energías de los aceleradores podríamos ser capaces de crear colisiones más energéticas que las que se han dado en la Tierra por causa de los rayos cósmicos. La cuestión, sin embargo, no es si la formación de burbujas pueda darse en la Tierra, sino si ya ha ocurrido en algún sitio del universo observable en algún momento posterior al big bang. Hut y Rees señalaban que dos rayos cósmicos pueden chocar de frente en alguna rara ocasión con energías que superan mil millones de veces a las posibles de los aceleradores existentes. De manera que tampoco hace falta una autoridad que controle los aceleradores de momento.

Paradójicamente, la formación de burbujas de vacío (el mismo fenómeno que amenaza la existencia misma del cosmos) podría, en un contexto ligeramente distinto, resultar ser la única salvación factible para sus habitantes. El único modo seguro de escapar a la muerte del universo es crear uno nuevo y huir a él. Puede sonar como lo último que podría escucharse en cuanto a especulaciones fantasiosas, pero se ha hablado mucho de los «universitos» o «crías de universo» y los argumentos que avalan su existencia tienen su lado serio.

El asunto lo planteó por vez primera en 1981 un grupo de físicos japoneses que estudiaba un modelo matemático simple del comportamiento de una burbujita de falso vacío rodeada de auténtico vacío, situación inversa a la que acabamos de ver. Lo que se predecía era que el falso vacío se inflaría tal y como se describe en el capítulo 3, expandiéndose rápidamente en un big bang hasta una gran universo. Parece que al principio la inflación de la burbuja de falso vacío originaría que la pared de la burbuja se expandiera de tal modo que la región de falso vacío crecería a expensas de la región de vacío auténtico. Pero esto contradice la expectativa de que sea el auténtico vacío de menor energía el que desplace al falso vacío de alta energía, y no al revés.

Cosa rara, si se mira desde el vacío auténtico la región del espacio ocupada por la burbuja de falso vacío no parece hincharse. De hecho, aparenta más bien ser como un agujero negro. (En esto se parece a «Tardis», la máquina del tiempo del Dr. Who, que parece mayor por dentro que por fuera3.) Un hipotético observador situado dentro de la burbuja de falso vacío vería hincharse el universo hasta proporciones enormes aunque, vista desde el exterior, la burbuja seguiría siendo compacta.

Una manera de concebir este peculiar estado de cosas es por analogía con una plancha de goma que se ampolla en un punto produciendo un globo (véase la figura 10.4). El globo forma una especie de universo cría conectado con el universo madre por un cordón umbilical o «agujero de gusano». El cuello del agujero de gusano aparece desde el universo madre como un agujero negro. Esta configuración es inestable; el agujero negro se evapora enseguida por el efecto Hawking y desaparece por completo del universo madre. Como resultado, el agujero de gusano se elimina y el universo cría, desconectado así del universo madre, se convierte en universo nuevo e independiente por derecho propio. El desarrollo del universo cría después de este desyemado del universo madre es el mismo que se supone para nuestro universo, un breve periodo de inflación seguido de la deceleración habitual. El modelo supone la evidente idea de que nuestro propio universo pueda haberse originado de este modo, como progenie de otro universo.

Una burbuja de espacio se hincha como un globo a partir del universo madre para formar un universo cria, conectado al universo madre mediante un agujero de gusano umbilical. Desde el punto de vista del universo madre, la boca de agujero de gusano parecería un agujero negro. Según se va evaporando el agujero negro, el cuello del agujero de gusano se va estrechando, desconectando el universo cria que luego lleva una vida independiente como universo de pleno derecho.

Alan Guth, primer promotor de la teoría inflacionaria, y sus colaboradores, han investigado si el panorama expuesto permite la extravagante posibilidad de crear un nuevo universo en el laboratorio. A diferencia del pavoroso caso de la degeneración del falso vacío en una burbuja de vacío auténtico, la creación de una burbuja de falso vacío rodeado por auténtico vacío no amenaza la existencia del universo. Desde luego, aun cuando el experimento pueda desencadenar un big bang, la explosión estaría absolutamente confinada en el interior de un diminuto agujero negro que se evapora enseguida. El nuevo universo crearía su propio espacio sin comerse nada del nuestro.

Aunque la idea sigue siendo muy especulativa y está basada por entero en teorizaciones matemáticas, algunos estudios parecen indicar que puede ser posible la creación de nuevos universos de esta manera, concentrando grandes cantidades de energía de modo cuidadosamente programado. En un futuro lejanísimo, cuando nuestro universo se vaya haciendo inhabitable o acercándose al big crunch, nuestros descendientes podrían tomar la decisión de escapar para siempre iniciando el proceso de gemación, atravesando luego el agujero de gusano umbilical hasta el universo vecino antes de que se cierre... el último grito en emigración. Por supuesto que nadie tiene ni remota idea de cómo podrían esos seres intrépidos conseguir tal proeza ni si podrían hacerla. Como mínimo, el viaje a través del agujero de gusano debería ser bastante incómodo a no ser que el agujero negro en el que tuvieran que zambullirse fuera muy grande.

Dejando a un lado tales cuestiones prácticas, la posibilidad misma de los universos cría abre la perspectiva de la inmortalidad genuina, no sólo para nuestros descendientes sino también para los universos. En lugar de pensar en la vida y la muerte del universo deberíamos pensar en una familia de universos que se multiplicaran ad infinitum, cada uno de ellos dando origen a nuevas generaciones de universos, puede que por legiones. Con semejante fecundidad cósmica, el montaje de universos (o de metaversos, como en realidad deberían llamarse) podría no tener ni principio ni fin. Cada universo individual tendría un nacimiento, una evolución y una muerte como se han descrito en los primeros capítulos de este libro, pero la colección existiría eternamente como conjunto.

Este panorama plantea la cuestión de si la creación de nuestro propio universo fue un asunto natural (análogo al nacimiento de un bebé) o el resultado de una manipulación deliberada (un «bebé probeta»). Podemos imaginar que una sociedad suficientemente avanzada y altruista de seres de un universo madre podría haber decidido crear universos cría no sólo para disponer de una vía de escape para su propia supervivencia, sino meramente para perpetuar la posibilidad de existencia de la vida en cualquier parte, habida cuenta que su propio universo estaba condenado. Este enfoque elimina la necesidad de abordar los formidables obstáculos que afrontaría cualquier intento de construir un agujero de gusano practicable para entrar en un universo cría.

No está claro hasta qué punto el universo cría llevaría la huella genética de su madre. Los físicos no tienen todavía idea de por qué las diversas fuerzas de la naturaleza y las partículas de materia tienen las propiedades que tienen. Por una parte, estas propiedades podrían ser parte de las leyes de la naturaleza, fijadas de una vez por todas para cualquier universo. Por otra, algunas de las propiedades podrían ser el resultado de accidentes evolutivos. Por ejemplo, bien podría haber varios estados de auténtico vacío, todos con idéntica, o casi idéntica, energía. Podría ser que cuando el falso vacío degenera al final de la era inflacionaria se limita a elegir al azar una de estos muchos posibles estados de vacío. Por lo que respecta a la física del universo, la elección del estado de vacío dictará muchas de las propiedades de las partículas y de las fuerzas que actúen entre ellas e incluso podría dictar el número de dimensiones espaciales. De manera que un universo cría podría tener propiedades completamente distintas a las de su madre. Puede que la vida sólo sea posible en un número muy escaso de las progenies, en aquellas en las que la física se parezca bastante a la de nuestro universo. O puede que haya una especie de principio hereditario que asegure que los universos cría hereden muy aproximadamente las propiedades de sus universos madre, salvo alguna mutación aquí o allá. El físico Lee Smolin ha sugerido la idea de que haya incluso una especie de evolución darwinista que funcione entre los universos y que indirectamente estimule la emergencia de la vida y la conciencia. Más interesante aún es la posibilidad de que los universos se creen mediante manipulación inteligente en un universo madre, dotándolos con las necesarias propiedades que den origen a la vida y la conciencia.

Ninguna de estas ideas supone mucho más que una loca especulación, pero el sujeto de la cosmología todavía es una ciencia joven. Las conjeturas fantasiosas que he hecho más arriba por lo menos sirven como antídotos a los deprimentes pronósticos desarrollados en capítulos anteriores. Apuntan a la posibilidad de que incluso si nuestros descendientes deben afrontar algún día los últimos tres minutos, puedan existir siempre en algún sitio seres conscientes de uno u otro tipo.

CAPÍTULO 11: ¿MUNDOS SIN FIN?

Las extravagantes ideas examinadas al final del último capítulo no son las únicas posibilidades que se han discutido en la búsqueda de un modo de evitar el apocalipsis cósmico. Siempre que doy una conferencia sobre el fin del universo, alguien suele preguntarme por el modelo cíclico. La idea es la siguiente. El universo se expande hasta un máximo de tamaño y luego se contrae hasta el big crunch, pero en lugar de aniquilarse a sí mismo por completo «rebota» no se sabe cómo y se embarca en otro ciclo de expansión y contracción (véase figura 11.1). Este proceso podría prolongarse eternamente, en cuyo caso el universo no tendría ni principio ni fin auténticos, incluso aunque cada ciclo individual estuviera marcado por un comienzo y final claros. Es una teoría que atrae concretamente a las personas que se han visto influidas por la mitología budista e hindú, en las cuales destacan los ciclos de nacimiento y muerte, de creación y destrucción.

El modelo de universo cíclico. El universo muestra un pulso den tamaño de manera periódica entre estados muy densos y estados muy distendidos. Cada ciclo empieza con un big bang y termina con un gran big crunch y es aproximadamente simétrico respecto al tiempo.

He bosquejado dos panoramas científicos muy distintos para el fin del universo. Cada uno de ellos es perturbador a su manera. La perspectiva de un cosmos aniquilándose a sí mismo en un big crunch es alarmante, por lejano que se halle en el futuro este acontecimiento. Por otro lado, un universo que durara un tiempo infinito en un estado de vacía desolación después de una duración finita de gloriosa actividad es profundamente deprimente. El hecho de que cada modelo pueda tener la posibilidad de proporcionar a los superseres la consecución de una capacidad ilimitada de procesar información puede parecer un consuelo más bien magro para nosotros, Homo sapiens de sangre caliente.

El atractivo del modelo cíclico es que elude el espectro de la aniquilación total sin reemplazarlo por la degeneración y decadencia eternas. Para evitar la futilidad de la repetición interminable, los ciclos deberían ser algo diferentes unos de otros. En una versión popular de la teoría, cada nuevo ciclo surge a modo de ave fénix de la muerte ardiente de su predecesor. A partir de esta condición prístina, desarrolla nuevos sistemas y estructuras y explora su novedosa riqueza antes de que se borre nuevamente la pizarra en el siguiente big crunch.

Por atractiva que pueda parecer la teoría, sufre desgraciadamente de graves dificultades físicas. Una de ellas es la de identificar un proceso plausible que permita al universo en contracción rebotar siendo de una alta densidad en lugar de aniquilarse a sí mismo en un big crunch. Tiene que haber una especie de fuerza antigravitatoria que se haga abrumadoramente grande en los últimos estadios de la contracción para poder invertir el sentido de la implosión y contrarrestar el formidable poder aplastante de la gravedad. Por el momento no se conoce tal fuerza y si existiera sus propiedades habrían de ser sumamente extrañas.

Quien me lea puede recordar que precisamente esa poderosa fuerza repulsiva es la que se postula en la teoría inflacionaria del big bang. Sin embargo, recuérdese que el estado de vacío excitado que produce la fuerza inflacionaria es muy inestable y degenera con mucha rapidez. Aunque es concebible que el universo diminuto, simple y naciente se originara en un estado inestable semejante, otra cosa muy diferente es postular que un universo que se encogiera procedente de una complicada situación macroscópica pudiera ingeniárselas para recuperar por todas partes el estado de vacío excitado. La situación es análoga a la de equilibrar un lápiz sobre su punta: enseguida se cae, eso es lo fácil. Mucho más difícil sería darle un golpe para que recuperara el equilibrio sobre la punta una vez más.

Incluso suponiendo que se pudieran eludir, no se sabe cómo, esas dificultades, sigue habiendo problemas serios en la idea del universo cíclico. Uno de ellos lo he examinado en el capítulo 2. Los sistemas sujetos a procesos irreversibles que avanzan a ritmo finito tienden a aproximarse a su estadio final después de cierto periodo de tiempo. Éste fue el principio que condujo a la predicción de la muerte térmica universal en el siglo XIX. Introducir ciclos cósmicos no evita esta dificultad. El universo puede compararse a un reloj que va quedándose sin cuerda. Se le irá terminando la actividad hasta que se le dé cuerda otra vez. Pero ¿qué mecanismo sería el que diera cuerda al reloj cósmico sin estar él mismo sometido a cambios irreversibles?

A primera vista, la fase de contracción del universo parece una reversión de los procesos físicos que se dan en la fase de expansión. Las galaxias que se dispersaban se vuelven a agrupar, se recalienta la radiación de fondo que se iba enfriando y los elementos complejos se trocean para conformar de nuevo un puré de partículas elementales. El estado del universo justamente antes del big crunch presenta una gran similitud con su estado justamente después del big bang. Sin embargo, la impresión de simetría es sólo superficial. Nos da una pista el hecho de que los astrónomos que vivieran en la época de la reversión, cuando la expansión se convierta en contracción, seguirán viendo durante muchos miles de millones de años que las galaxias siguen alejándose. El universo aparenta seguir expandiéndose incluso aunque se esté contrayendo. La ilusión se debe al retraso de las apariencias debido a la velocidad finita de la luz.

En los años 30, el cosmólogo Richard Tolman mostró cómo este retraso destruía la aparente simetría del universo cíclico. El motivo es sencillo. El universo comienza con una gran cantidad de radiación térmica como residuo del big bang. Con el tiempo, la luz estelar incrementa esta radiación, de modo que al cabo de unos pocos miles de millones de años hay casi tanta energía como luz solar acumulada bañando el espacio como calor de fondo. Lo cual significa que el universo se aproxima al big crunch con una cantidad considerablemente mayor de energía de radiación dispersa por todas partes que la que tuvo inmediatamente después del big bang, de tal modo que cuando el universo termine por contraerse hasta la misma densidad que tiene hoy estará algo más caliente.

Esa energía térmica extra se da a cambio del contenido de materia del universo, por medio de la fórmula de Einstein, E = mc². En el interior de las estrellas que producen la energía calorífica, los elementos ligeros como el hidrógeno pasan a conformar elementos pesados como el hierro. Un núcleo de hierro normalmente contiene veintiséis protones y treinta neutrones. Podríamos creer que ese núcleo tendría entonces la masa de veintiséis protones y treinta neutrones, pero no. El núcleo en su conjunto es aproximadamente un 1% más ligero que la suma de las masas de las partículas individuales. La masa que «falta» es la que se computa como la gran energía de unión producida por la fuerza nuclear fuerte; la masa representada por esa energía es la que se libera para dar luz de estrella.

El resultado de todo ello es una transferencia neta de energía de materia a radiación. Lo cual tiene un importante efecto en el modo de contraerse el universo, ya que el tirón gravitatorio de la radiación es bastante distinto del de la materia de la misma energía de masa. Tolman mostró que la radiación extra de la fase de contracción hace que el universo se contraiga a mayor velocidad. Si se diera no se sabe cómo un rebote, el universo emergería entonces expandiéndose a una velocidad también mayor. En otras palabras, cada big bang sería mayor que el anterior. Como resultado, el universo se expandiría hasta un mayor tamaño a cada nuevo ciclo, de tal modo que los ciclos serían cada vez mayores y más largos. (Véase figura 11.2.)

Los procesos irreversibles hacen que los ciclos cosmológicos crezcan más y más, destruyendo así el auténtico carácter cíclico.

El crecimiento irreversible de los ciclos cósmicos no es ningún misterio. Es un ejemplo de las consecuencias ineludibles de la segunda ley de la termodinámica. La radiación que se acumula representa un crecimiento de la entropía, que se manifiesta gravitatoriamente en forma de ciclos cada vez mayores. Sin embargo, sí pone fin a la idea del auténtico carácter cíclico: claramente el universo evoluciona en el tiempo. Hacia el pasado, los ciclos se acumulan en unos inicios complicados y entremezclados, mientras que los ciclos futuros se expanden sin limitación hasta que se hacen tan largos que cualquier ciclo dado sería durante su mayor parte indistinguible del panorama de la muerte térmica de los modelos de expansión eterna.

Desde los trabajos de Tolman, los cosmólogos han sido capaces de identificar otros procesos físicos que rompen la simetría de las fases de expansión y contracción de cada ciclo. Un ejemplo es la formación de agujeros negros. En el cuadro estándar, el universo empieza sin ningún agujero negro, pero con el paso del tiempo la contracción de las estrellas y otros procesos hacen que se formen agujeros negros. Conforme evolucionan las galaxias, siguen apareciendo más agujeros negros. Durante los últimos estadios de la contracción, la compresión favorecerá la formación de aún más agujeros. Algunos de los agujeros grandes pueden fundirse para formar agujeros mayores. La disposición gravitatoria del universo al acercarse al big crunch es, por lo tanto, mucho más complicada (y desde luego claramente más agujereada) de lo que fue al poco del big bang. Si el universo tuviera que rebotar, el siguiente ciclo empezaría con más agujeros negros que el presente.

Parece que la conclusión inevitable es que cualquier universo cíclico que admita que las estructuras y los sistemas físicos se propaguen de un ciclo al siguiente no podrá eludir las influencias degenerativas de la segunda ley de la termodinámica. Todavía seguirá existiendo la muerte térmica. Una manera de atajar esta conclusión sombría es suponer que las condiciones físicas en el rebote son tan extremadas que de un ciclo al siguiente no puede pasar información alguna sobre ciclos anteriores. Se destruyen todos los objetos físicos, se aniquilan todas las influencias. Efectivamente, el universo renace por completo desde el comienzo.

Sin embargo, es difícil comprender el atractivo que pueda tener este modelo. Si cada ciclo está físicamente desconectado de los demás, ¿qué significado tiene decir que los ciclos se suceden unos a otros o que representan que el mismo universo permanece no se sabe cómo? Los ciclos son efectivamente universos distintos y separados y daría lo mismo que se dijera que existen en paralelo que en sucesión. La situación recuerda a la doctrina de la reencarnación por la cual toda persona renacida no tiene recuerdos de sus vidas pasadas. ¿En qué sentido puede decirse que es la misma persona la que se reencarna?

Otra posibilidad es que se viole en algún sentido la segunda ley de la termodinámica, de modo que «se le dé cuerda al reloj» en el rebote. ¿Qué significa que se deshaga el daño causado por la segunda ley? Tomemos un sencillo ejemplo de la segunda ley en funcionamiento: pongamos la evaporación de perfume de un frasco. El cambio de suerte para el perfume supondría una gigantesca conspiración organizativa, mediante la cual cada una de las moléculas de perfume que haya en la habitación volviera al frasco. La «película» se vería al revés. De la segunda ley de la termodinámica obtenemos la distinción de pasado y futuro, la flecha del tiempo. Una violación de la segunda ley equivale por tanto a una inversión del tiempo.

Por supuesto que resulta una evasión relativamente trivial de la muerte cósmica suponer que el tiempo se invierte sin más cuando se oye el big crunch del apocalipsis. ¡Cuando las cosas se pongan mal, invirtamos el sentido de la película! Con todo, la idea ha llamado la atención de algunos cosmólogos. En los años 60 el astrofísico Thomas Gold sugirió la idea de que el tiempo pudiera correr al revés en la fase de contracción de un universo que estuviera contrayéndose. Indicó que esa inversión incluiría las funciones cerebrales de los seres que hubiera en ese momento y por ello serviría para invertir su sentido subjetivo del tiempo. Los habitantes de la fase de contracción no verían, por lo tanto, que todo a su alrededor «iría al revés», sino que experimentarían el flujo de los acontecimientos hacia adelante como lo experimentamos nosotros. Por ejemplo, percibiría el universo en expansión, no en contracción. Por medio de sus ojos, sería nuestra fase del universo la que se contraería y nuestros procesos cerebrales los que van del revés.

En los años 80 también Stephen Hawking jugó un tiempo con la idea de un universo que invirtiera el tiempo, para abandonarla admitiendo que se trataba de su «mayor error». Al principio, Hawking creyó que aplicar la mecánica cuántica a un universo cíclico exigía una simetría detallada del tiempo. Sin embargo, resulta que no es así, por lo menos en la formulación estándar de la mecánica cuántica. Recientemente, los físicos Murray GellMann y James Hartle han examinado una modificación de las reglas de la mecánica cuántica, en la que la simetría temporal sencillamente está impuesta y luego se han preguntado si este estado de cosas tendría consecuencias observables en nuestra era cósmica. Por el momento no se ve con claridad cuál pueda ser la respuesta.

Una forma muy distinta de eludir el cataclismo cósmico la ha propuesto el físico ruso Andrei Linde. Se basa en una elaboración de la teoría del universo inflacionario que se examinó en el capítulo 3. En la versión original del universo inflacionario, se suponía que el estado cuántico del universo muy primitivo se correspondía con un vacío excitado concreto que tenía el efecto de producir temporalmente la expansión desbocada. En 1983, Linde sugirió la idea de que, en vez de eso, el estado cuántico del universo primitivo podía variar de un sitio a otro de manera caótica: aquí baja energía, allí una excitación moderada, mucha excitación en algunas regiones. En donde había estado excitado, se produciría inflación. Y aún más, los cálculos de Linde sobre el comportamiento del estado cuántico mostraban claramente que los estados de alta excitación sufrían la inflación más rápida y la degeneración más lenta, de modo que cuanto más excitado fuera el estado de una región concreta del espacio más inflación habría en esa región. Está claro que al cabo de un tiempo cortísimo las regiones del espacio en las que la energía era mayor accidentalmente, y la inflación más rápida, se habrían hinchado al máximo y se harían con la parte del león del espacio total. Linde asemeja la situación a la evolución darwiniana o a la economía. Una fluctuación cuántica que tuviera éxito en llegar a un estado muy excitado, aun queriendo decir que había que tomar prestada muchísima energía, se ve inmediatamente recompensada por un inmenso crecimiento en volumen de esa región. De tal modo que enseguida pasan a predominar las regiones que toman prestada mucha energía y que sufren una superinflación.

Como resultado de la inflación caótica, el universo se dividiría en un cúmulo de miniuniversos, o burbujas, algunas inflándose a lo loco, otras sin inflarse nada. Como algunas regiones (tan sólo como resultado de las fluctuaciones aleatorias) tendrán una energía de excitación altísima habrá mucha más inflación en esas regiones de la que se suponía en la teoría original. Pero como ésas son precisamente las regiones que se inflan más, un punto escogido al azar en el universo postinflacionario estaría muy probablemente situado en esa región tan enormemente hinchada. Así, nuestra propia localización en el espacio muy probablemente está en medio de una región superinflada. Linde calcula que esas «grandes burbujas» pueden haberse inflado en un factor de 10 elevado a la potencia 108, lo que es igual a un 1 ¡seguido de cien millones de ceros!

Nuestra propia megaparcela no sería sino una entre un número infinito de burbujas muy hinchadas, de modo que a una escala enorme de tamaño el universo seguiría pareciendo extremadamente caótico. Dentro de nuestra burbuja, que se extiende más allá del universo hoy observable a una distancia fantásticamente grande, la materia y la energía están distribuidas de manera más o menos uniforme, pero más allá de nuestra burbuja hay otras burbujas, y también regiones que están todavía en proceso de inflación. Lo cierto es que en el modelo de Linde nunca cesa la inflación: siempre hay regiones del espacio en las que se está dando la inflación mientras se forman nuevas burbujas y otras burbujas pasan por sus ciclos vitales y mueren. Así que ésta es una especie de universo eterno, parecido a la teoría de los universos cría que se examinó en el capítulo anterior, en la que la vida, la esperanza y los universos surgen eternamente. No hay final a la producción de nuevos universos burbuja por medio de la inflación... y quizá tampoco principio, aunque acerca de esto último se detecta cierta prudencia en la actualidad.

La existencia de otras burbujas, ¿ofrece a nuestros descendientes algún salvavidas? ¿Pueden eludir el apocalipsis cósmico (o dicho con más precisión, el apocalipsis burbujil) marchándose a una burbuja más joven que tenga tiempo por delante? Linde abordó directamente esta cuestión en un artículo heroico sobre «La vida después de la inflación», publicado en el boletín Physics Letters en 1989. «Estos resultados implican que la vida nunca desaparecerá en el universo inflacionario», escribía. «Por desgracia, esta conclusión no significa de modo automático que se pueda ser muy optimista sobre el futuro de la humanidad.» Y apuntando a que cualquier parcela concreta, o burbuja, se iría poco a poco haciendo inhabitable, Linde termina diciendo: «La única estrategia posible de supervivencia que podemos ver por el momento es viajar de las viejas parcelas a las nuevas.»

Lo descorazonador de la versión de Linde de la teoría inflacionaria es que el tamaño medio de la burbuja es enorme. Calcula que la burbuja más cercana a la nuestra podría estar tan lejos que su distancia en años luz debería expresarse con un 1 seguido de varios millones de ceros, un número tan grande ¡que haría falta una enciclopedia para escribirlo entero! Incluso a una velocidad cercana a la de la luz, se tardaría un número parecido de años en llegar a otra burbuja, a menos que por una buena suerte extraordinaria resultara que estamos situados cerca del borde de nuestra burbuja. E incluso dándose esa feliz circunstancia, señala Linde, valdría sólo si nuestro universo continuara expandiéndose de manera predecible. El efecto físico más minúsculo (un efecto que fuera absolutamente inconspicuo en nuestra era actual) terminaría por determinar de qué manera se expande el universo una vez que la materia y la radiación que lo dominan se diluyan infinitamente. Por ejemplo, podría quedar en el universo una reliquia debilísima de la fuerza inflacionaria que ahora está ocultada por los efectos gravitatorios de la materia pero que, supuestos los océanos de tiempo necesarios para que los seres escaparan de nuestra burbuja, terminaría por hacerse sentir. En tal caso, el universo, después de una duración suficiente, volvería a experimentar la inflación, no a la manera frenética del big bang sino lentísimamente, a modo de pálida imitación del big bang. Sin embargo, este débil quejido, por débil que fuera, persistiría eternamente. Aunque el crecimiento del universo se acelerara sólo a un ritmo diminuto, el hecho de que se acelerara tiene una consecuencia física crucial. El efecto es el de crear un horizonte de sucesos dentro de la burbuja que es parecido al de un agujero al revés e igual de efectivo que él. Cualesquiera seres supervivientes se verían encerrados sin remedio en lo profundo de nuestra burbuja porque conforme se dirijan hacia el borde de la burbuja éste retrocederá a mayor velocidad aún, como resultado de la inflación renovada. Los cálculos de Linde, aun siendo fantasiosos, apuntan claramente a que el destino definitivo de la humanidad o de nuestros descendientes puede depender de efectos físicos tan pequeños que no tenemos ni la esperanza de detectarlos antes de que empiecen a manifestarse cosmológicamente.

La cosmología de Linde es, en ciertos aspectos, parecida a la antigua teoría del universo del estado estacionario, popular durante los años 50 y 60 y que sigue siendo la propuesta más sencilla y llamativa para eludir el fin del universo. En su versión original, expuesta por Hermann Bondi y Thomas Gold, la teoría del estado estacionario daba por hecho que el universo permanece inmutable a gran escala durante todo el tiempo. Por lo tanto, no tiene ni principio ni fin. Conforme se expande el universo se crea materia continuamente para llenar los huecos y mantener constante la densidad del conjunto. El destino de cualquier galaxia dada es parecido al que he descrito en capítulos anteriores: nacimiento, evolución y muerte. Pero siempre se están formando nuevas galaxias a partir de la materia recién creada, que es un suministro inagotable. Por lo tanto, el aspecto general del universo en su conjunto parece idéntico de una época a la siguiente, con el mismo número total de galaxia por volumen dado de espacio, en una mezcla de épocas distintas.

El concepto de universo de estado estacionario acaba con la necesidad de explicar cómo empezó a existir el universo a partir de la nada y combina la variedad interesante por medio del cambio evolutivo con la inmortalidad cósmica. De hecho, va más allá y proporciona una juventud cósmica eterna porque aunque las galaxias individuales van muriendo lentamente, el universo como tal nunca envejece. Nuestros descendientes nunca tendrán que ir rebuscando la basura para encontrar suministros de energía cada vez más escurridizos, ya que la materia nueva se los dará gratuitamente. Los habitantes tendrán que mudarse a una galaxia nueva cuando la vieja se quede sin combustible. Y eso puede continuar ad infinitum, con iguales vigor, diversidad y actividad mantenidos por toda la eternidad.

Sí hay, sin embargo, algunas exigencias físicas que hacen falta para que funcione la teoría. El universo dobla su tamaño cada pocos miles de millones de años debido a la expansión. Mantener una densidad contante requiere 1050 toneladas más o menos de materia nueva que se cree en ese periodo. Parece mucha, pero por término medio supone un átomo por siglo en una región del espacio del tamaño de un hangar de aviación. Es improbable que notemos ese fenómeno. Un problema más serio es el que se refiere a la naturaleza del proceso físico responsable de la creación de materia según esta teoría. Como mínimo, querríamos saber de dónde sale la energía que suministra esa masa adicional y cómo se las apaña ese recipiente milagroso de energía para ser inagotable. Problema que ya apuntó Fred Hoyle quien, con su colaborador Jayant Narlikar, desarrolló al detalle la teoría. Propusieron un nuevo tipo de campo (un campo creador) para suministrar la energía. Del propio campo creador en sí se postuló que tenía energía negativa. La apariencia de cada nueva partícula de materia de masa m tenía el efecto de contribuir con una energía -mc² al campo creador.

Aunque el campo creador proporcionaba una solución técnica al problema de la creación, deja muchas preguntas sin contestar. También parece demasiado bien traído, habida cuenta de que no son aparentes otras manifestaciones de ese misterioso campo. Más en serio, las pruebas obtenidas de la observación comenzaron a acumularse contra la teoría del estado estacionario en los años 60, la más importante de las cuales fue el descubrimiento de la radiación cósmica de calor de fondo. Este fondo uniforme recibe una explicación inmediata como reliquia del big bang, pero es difícil de explicar convincentemente según el modelo de estado estacionario. Por si fuera poco, la exploración de galaxias y radiogalaxias en el cielo profundo han mostrado incontestables evidencias de que el universo evoluciona a gran escala. Cuando esto quedó claro, Hoyle y sus colaboradores abandonaron la versión sencilla de la teoría del estado estacionario, aunque de tanto en tanto han seguido haciendo su aparición irregularmente variantes más complicadas.

Aparte de las dificultades físicas y de observación, la teoría del estado estacionario plantea algunos problemas filosóficos curiosos. Por ejemplo, si nuestros descendientes dispusieran verdaderamente de tiempo y recursos infinitos no habría limitaciones evidentes a su desarrollo tecnológico. Tendrían libertad para dispersarse por todo el universo, controlando volúmenes de espacio cada vez mayores.

Así, en un futuro lejanísimo, una gran parte del espacio estaría tecnifícado. Pero se supone por hipótesis que la naturaleza a gran escala del universo no cambia a lo largo del tiempo, de modo que la suposición del estado estacionario nos obliga a llegar a la conclusión de que el universo que hoy vemos va está tecnificado. Como las condiciones físicas del universo de estado estacionario son en conjunto las mismas en todas las épocas, también deben surgir seres inteligentes en todas las épocas. Y como este estado de cosas lleva existiendo toda la eternidad, debería haber sociedades de seres que llevan por ahí un tiempo arbitrariamente largo y que ya se habrán dispersado para ocupar un volumen arbitrariamente grande de espacio (incluyendo a nuestra región del universo) y tecnificarlo. Conclusión que no se evita suponiendo que los seres inteligentes no suelen sentir deseos de colonizar el universo. Sólo hace falta una de tales sociedades que haya surgido en un momento lejanísimo en el pasado para que sea válida la conclusión. Es otro caso del antiguo enigma de que en un universo infinito cualquier cosa que sea remotamente posible deberá ocurrir en algún momento y ocurrir además con frecuencia infinita. Siguiendo la lógica hasta su amarga conclusión, la teoría del estado estacionario predice que los procesos del universo son idénticos a las actividades tecnológicas de sus habitantes. Lo que llamamos naturaleza es, de hecho, la actividad de un superser, o de una sociedad de superseres. Parece otra versión del demiurgo de Platón (una deidad que trabajara dentro de los límites de las leyes físicas ya fabricadas), y es interesante que en sus últimas teorías cosmológicas Hoyle abogue explícitamente por tal superser.

Cualquier examen del final del universo nos enfrenta a las cuestiones sobre su finalidad. Ya he indicado que la perspectiva de un universo moribundo convenció a Bertrand Russell de la futilidad última de la existencia. Es un sentimiento del que se hace eco en años más recientes Steven Weinberg, cuyo libro Los primeros tres minutos del universo culmina con la desoladora conclusión de que «cuanto más comprensible parece el universo, más sin sentido parece también». Ya he argüido que el temor original a una lenta muerte térmica del cosmos podía estar exagerado e incluso ser erróneo, aunque la muerte súbita mediante un big crunch sigue siendo una posibilidad. He especulado con las actividades de superseres que pudieran lograr hazañas milagrosas físicas e intelectuales contra el destino. También he echado un vistazo rápido a la posibilidad de que los pensamientos puedan no conocer barreras incluso aunque las tenga el universo.

Pero ¿alivian esos panoramas alternativos nuestra sensación de incomodidad? Una vez me comentó un amigo que por lo que había oído del Paraíso no le interesaba demasiado. La perspectiva de vivir por siempre en un estado de sublime equilibrio la encontraba absolutamente carente de atractivo. Mejor morir rápidamente y acabar de una vez por todas que no tener que afrontar el aburrimiento de la vida eterna. Si la inmortalidad se limita a tener los mismos pensamientos y las mismas experiencias una y otra vez, la verdad es que parece no tener sentido. Sin embargo, si la inmortalidad se combina con el progreso, entonces podemos imaginarnos viviendo en un estado de novedad perpetua, aprendiendo o haciendo siempre cosas nuevas y emocionantes. La cuestión es ¿y para qué? Cuando los seres humanos se embarcan en un proyecto con una finalidad, tienen en mente un objetivo concreto. Si no se consigue el objetivo, el proyecto habrá fracasado (aunque no necesariamente la experiencia carezca de valor). Por otra parte, si se consigue el objetivo, el proyecto se habrá completado y entonces cesará esa actividad. ¿Puede haber auténtica finalidad en un proyecto que nunca se consiga? ¿Puede tener sentido la existencia si consiste en un viaje sin final hacia un destino al que nunca se llega?

Si el universo tiene una finalidad, y la alcanza, entonces el universo debe acabar porque su existencia continuada sería gratuita y sin sentido. A la inversa, si el universo dura eternamente, resulta difícil imaginar que el universo tenga alguna finalidad última. De modo que la muerte térmica del cosmos puede ser el precio que hay que pagar por el éxito cósmico. Puede que lo más que podamos esperar sea que la finalidad del universo se haga conocida a nuestros descendientes antes de que terminen los tres últimos minutos.

BIBLIOGRAFÍA

Barrow, John D. y Tipler. Frank J.,

The Anthropic Cosmological Principle

(Oxford: Oxford University Press, 1986).

Burrows, Adam,

«The Birth of Neutron Stars and Black Holes»,

Physics Today, 40 (1987): 28.

Chapman, Clark R. y Morrison, David,

Cosmic Catastrophes

(Nueva York y Londres: Plenum Press, 1989).

Close, Frank,

End: Cosmic Catastrophe and the Fate of the Universe

(Nueva York: Simon & Schuster, 1988).

(Edicion espanola: Fin, Catedra, 1991.)

Coleman, Sidney y De Luccia, Frank,

«Gravitational Effects on and of Vacuum Decay»,

Physical Review D, 21 (1980): 3305.

Davies, Paul,

The Cosmic Blueprint

(Nueva York: Simon & Schuster, 1989).

Proyecto cosmico,

Ediciones Piramide S.A., 1989.

Davies, Paul,

The Mind of God

(Nueva York: Simon & Schuster, 1991).

(Edicion española: La Mente de Dios, McGraw Hill, 1993.)

Dyson, Freeman J.,

«Time Without End: Physics and Biology in an Open Universe»,

Reviews of Modern Physics, 51 (1979): 447.

Gold, Thomas,

«The Arrow of Time»,

American Journal of Physics, 30 (1962): 403.

Hawking, Stephen W.,

A Brief History of Time: From the Big Bang to Black Holes

(Nueva York: Bantam, 1988).

(Edicion espanola: Historia del tiempo, Editorial Cn'tica, 1992.)

Hut, Piet y Rees, Martin J.,

«How Stable Is Our Vacuum?»

Nature, 302 (1983): 508.

Islam, Jamal N.,

The Ultimate Fate of the Universe

(Cambridge: Cambridge University Press, 1983).

Linde, Andrei D.,

Particle Physics and Inflationary Cosmologv

(Nueva York: Gordon & Breach, 1991).

Luminet, Jean-Pierre,

Black Holes

(Cambridge: Cambridge University Press, 1992).

(Edicion espanola: Agujeros negros, Alianza Editorial, S.A., 1991.)

Misner, Charles W., Thorne Kip S. y Wheeler, John A.,

Gravitation

(San Francisco: W. H. Freeman, 1970).

Page, Don y McKEE, Randall,

«Eternity Matters»,

Nature, 291 (1981): 44.

Rees, Martin J.,

«The Collapse of the Universe: An Eschatological Study»,

The Observatory. 89(1969): 193.

Smolin, Lee,

«Did the Universe Evolve?»,

Classical and Quantum Gravity, 9 (1992): 173.

Tipler, Frank J.,

The Physics Inmortality

(Nueva York: Doubleday, 1994).

(Edicion espanola: La fisica de la inmortalidad: la cosmologia moderna y su relacion con Dios y la resurreccion de los muertos, Alianza Editorial, S.A., 1997.)

Tolman, Richard C., Relativity, Thermodynamics, and Cosmology

(Oxford: Clarendon Press, 1934).

Turner, Michael S., y Wilczek, Frank,

«Is Our Vacuum Metastable?»,

Nature, 298 (1982): 633.

Waldrop, M. Mitchell,

Complexity: The Emerging Science at the Edge of Order and Chaos

(Nueva York: Simon & Schuster, 1992).

Weinberg, Steven,

The First Three Minutes: A Modern View of the Origin of the Universe, ed. actualizada

(Nueva York: Basic Books, 1988).

(Edicion espanola: Los tres primeros minutos del universo, Alianza Editorial, S.A., 2000.)

NOTAS

1 «Explorador del Fondo Cósmico». (N. del T.)

2 Partículas masivas de interacción débil. (N. del T.)

3 El autor se refiere a la serie Doctor Who, la serie de aventuras más persistente (desde el año 1963) de la televisión británica, la BBC. El protagonista viaja en el tiempo en una cápsula de su invención («Tardis») que por fuera tiene aspecto de cabina telefónica típica británica, mientras que por dentro es una gran sala llena de pantallas y mandos. (N. del T.)
